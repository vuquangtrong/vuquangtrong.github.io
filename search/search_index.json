{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":".md-typeset .cover { display: none; } .md-typeset .cover + hr { display: none; } .md-typeset h1, .md-typeset h2 { color: navy; } Code Inside Out # Interesting stuff in Embedded Systems and IoT Applications. From hardware to cloud applications. Step by step. (\uff89 \u25d5 \u30ee \u25d5)\uff89*:\u30fb\uff9f \u2727 Blog # Each post is what I\u2019ve learned, and I wrote them down to share. Hope you\u2019ll find something interesting there. Read news Projects # A list of my projects which are done for learning and practicing in free time. Wanna give me a hand ?! Let\u2019s do it together. See projects GitHub Stats # Using GitHub Stats and Top Langs by anuraghazra","title":"Home"},{"location":"#code-inside-out","text":"Interesting stuff in Embedded Systems and IoT Applications. From hardware to cloud applications. Step by step. (\uff89 \u25d5 \u30ee \u25d5)\uff89*:\u30fb\uff9f \u2727","title":"Code Inside Out"},{"location":"#blog","text":"Each post is what I\u2019ve learned, and I wrote them down to share. Hope you\u2019ll find something interesting there. Read news","title":" Blog"},{"location":"#projects","text":"A list of my projects which are done for learning and practicing in free time. Wanna give me a hand ?! Let\u2019s do it together. See projects","title":" Projects"},{"location":"#github-stats","text":"Using GitHub Stats and Top Langs by anuraghazra","title":" GitHub Stats"},{"location":"blog/","text":"","title":"Recent posts"},{"location":"blog/android/build-aosp/","tags":["android"],"text":"This guide is based on AOSP android-10.0.0_r47 and android-12.1.0_r8 Android Open Source Project # Android is an open source software stack created for a wide array of devices with different form factors. Android\u2019s primary purpose is to create an open software platform available for carriers, OEMs, and developers to make their innovative ideas a reality and to introduce a successful, real-world product that improves the mobile experience for users. Android Framework Stack Android development releases are organized into families, with alphabetical codenames. You can look up the codenames and the version numbers in Codenames, Tags, and Build Numbers . Android Code Search allows you to search AOSP without downloading anything. You can use Code Search to view the AOSP source code, switch between open source branches, and navigate cross-references. AOSPXRef is a web-based code browsers similar to Android Code Search. Android Automotive # Android Automotive is a base Android platform that runs pre-installed IVI system Android applications as well as optional second- and third-party Android Applications. Android Automotive offers openness, customization, and scale to automotive infotainment systems and head units. These things below can be confusing: Android Auto is a platform running on the user\u2019s phone, projecting the Android Auto user experience to a compatible in-vehicle infotainment system over a USB connection. Android Auto supports apps designed for in-vehicle use. Android Automotive is an operating system and platform running directly on the in-vehicle hardware. It is a full-stack, open source, highly customizable platform powering the infotainment experience. Android Automotive supports apps built for Android as well as those built for Android Auto. Google Automotive Services (GAS) is a collection of applications and services that automotive OEMs can choose to license and integrate into their in-vehicle infotainment (IVI) systems. Android Automotive Framework Stack Build AOSP System Image # The official guide at https://source.android.com/setup/build/building usually is updated to the latest version. Building an older version of AOSP may need some modifications. Preparation # Host machine It is recommended to have Ubuntu 20.04 LTS , because Windows and MacOS are not supported, and Google repo is updated to Python 3. You can optionally follow some tweaks to get better performance on your host machine such as: use noatime and remove journal feature of disk storing source code. Host packages sudo apt install \\ git curl \\ build-essential flex bison \\ libncurses5 libssl-dev libelf-dev Repo and Git tool Install repo from the package management: sudo apt install repo If it is not working, try to install manually: mkdir -p ~/.bin curl https://storage.googleapis.com/git-repo-downloads/repo > ~/.bin/repo chmod a+rx ~/.bin/repo echo 'PATH=\"${HOME}/.bin:${PATH}\"' >> ~/.bashrc source ~/.bashrc On Ubuntu 20.04, /usr/bin/env/python is not pointing to python3 , so install below package: sudo apt install python-is-python3 Set git user: git config --global user.email \"vuquangtrong@gmail.com\" git config --global user.name \"vuquangtrong\" Download and Build # Git clone modes Read details in Get up to speed with partial clone and shallow clone . Full clone This is the default mode. All blobs and trees are downloaded. Partial clone If using Git version 2.19 or greater, --partial-clone option is used to parialy download the needed objects. Blobless : Remove all file history with the option: --partial-clone --clone-filter=blob:none Treeless : Remove all directory history with the option: --partial-clone --clone-filter=tree:0 Shallow clone An older feature that does something very similar to a Treeless clone is Shallow clone with the option --depth=1 . This truncates the history to only download current commit. Android version Version API Codename Release date Major changes 12.1 32 S Mar 2022 12 31 S Oct 2021 11 30 R Sep 2020 New Permission Controls 10 29 Q Mar 2019 HIDL is deprecated, use AIDL every where 9 28 P Aug 2018 8.1 27 O Dec 2017 8.0 26 O Aug 2017 Use HIDL instead of classical HAL 7.1 25 N Aug 2016 Initialize the repo : Go to https://android.googlesource.com/platform/manifest and select a target branch. In this example, use shallow clone to reduce download time. If you need to read full log, or contribute back to the upstream repo, please fully clone the repo. android-10.0.0_r47 android-12.1.0_r8 export AOSP_BRANCH = \"android-10.0.0_r47\" mkdir $AOSP_BRANCH && cd $AOSP_BRANCH repo init \\ -u https://android.googlesource.com/platform/manifest \\ -b $AOSP_BRANCH \\ --depth = 1 export AOSP_BRANCH = \"android-12.1.0_r8\" mkdir $AOSP_BRANCH && cd $AOSP_BRANCH repo init \\ -u https://android.googlesource.com/platform/manifest \\ -b $AOSP_BRANCH \\ --depth = 1 Download source code : To speed up, use the -c (current branch) option. repo sync -c -j $( nproc ) && sync The download takes few hours to complete. Apply modifications android-10.0.0_r47 android-12.1.0_r8 There is one Python 2 script in AOSP 10.0.0_r47 which needs modified: /device/generic/goldfish/tools/mk_combined_img.py . Install Python 2: sudo apt install python2 Then edit the she-bang of the mk_combined_img.py script to use Python 2: device/generic/goldfish/tools/mk_combined_img.py - #!/usr/bin/python + #!/usr/bin/python2 All build scripts are converted to Python 3. Setup environment : source build/envsetup.sh Run lunch with no arguments to list all targets. android-10.0.0_r47 android-12.1.0_r8 lunch You ' re building on Linux Lunch menu... pick a combo: 1 . aosp_arm-eng 2 . aosp_arm64-eng 3 . aosp_blueline-userdebug 4 . aosp_bonito-userdebug 5 . aosp_car_arm-userdebug 6 . aosp_car_arm64-userdebug 7 . aosp_car_x86-userdebug 8 . aosp_car_x86_64-userdebug 9 . aosp_cf_arm64_phone-userdebug 10 . aosp_cf_x86_64_phone-userdebug 11 . aosp_cf_x86_auto-userdebug 12 . aosp_cf_x86_phone-userdebug 13 . aosp_cf_x86_tv-userdebug 14 . aosp_crosshatch-userdebug 15 . aosp_marlin-userdebug 16 . aosp_sailfish-userdebug 17 . aosp_sargo-userdebug 18 . aosp_taimen-userdebug 19 . aosp_walleye-userdebug 20 . aosp_walleye_test-userdebug 21 . aosp_x86-eng 22 . aosp_x86_64-eng 23 . beagle_x15-userdebug 24 . fuchsia_arm64-eng 25 . fuchsia_x86_64-eng 26 . hikey-userdebug 27 . hikey64_only-userdebug 28 . hikey960-userdebug 29 . hikey960_tv-userdebug 30 . hikey_tv-userdebug 31 . m_e_arm-userdebug 32 . mini_emulator_arm64-userdebug 33 . mini_emulator_x86-userdebug 34 . mini_emulator_x86_64-userdebug 35 . poplar-eng 36 . poplar-user 37 . poplar-userdebug 38 . qemu_trusty_arm64-userdebug 39 . uml-userdebug Which would you like? [ aosp_arm-eng ] : lunch You ' re building on Linux Lunch menu... pick a combo: 1 . aosp_arm-eng 2 . aosp_arm64-eng 3 . aosp_barbet-userdebug 4 . aosp_blueline-userdebug 5 . aosp_blueline_car-userdebug 6 . aosp_bonito-userdebug 7 . aosp_bonito_car-userdebug 8 . aosp_bramble-userdebug 9 . aosp_bramble_car-userdebug 10 . aosp_car_arm-userdebug 11 . aosp_car_arm64-userdebug 12 . aosp_car_x86-userdebug 13 . aosp_car_x86_64-userdebug 14 . aosp_cf_arm64_auto-userdebug 15 . aosp_cf_arm64_phone-userdebug 16 . aosp_cf_x86_64_foldable-userdebug 17 . aosp_cf_x86_64_pc-userdebug 18 . aosp_cf_x86_64_phone-userdebug 19 . aosp_cf_x86_64_tv-userdebug 20 . aosp_cf_x86_auto-userdebug 21 . aosp_cf_x86_phone-userdebug 22 . aosp_cf_x86_tv-userdebug 23 . aosp_coral-userdebug 24 . aosp_coral_car-userdebug 25 . aosp_crosshatch-userdebug 26 . aosp_crosshatch_car-userdebug 27 . aosp_crosshatch_vf-userdebug 28 . aosp_flame-userdebug 29 . aosp_flame_car-userdebug 30 . aosp_oriole-userdebug 31 . aosp_oriole_car-userdebug 32 . aosp_raven-userdebug 33 . aosp_raven_car-userdebug 34 . aosp_redfin-userdebug 35 . aosp_redfin_car-userdebug 36 . aosp_redfin_vf-userdebug 37 . aosp_sargo-userdebug 38 . aosp_sargo_car-userdebug 39 . aosp_slider-userdebug 40 . aosp_sunfish-userdebug 41 . aosp_sunfish_car-userdebug 42 . aosp_trout_arm64-userdebug 43 . aosp_trout_x86-userdebug 44 . aosp_whitefin-userdebug 45 . aosp_x86-eng 46 . aosp_x86_64-eng 47 . arm_krait-eng 48 . arm_v7_v8-eng 49 . armv8-eng 50 . armv8_cortex_a55-eng 51 . armv8_kryo385-eng 52 . beagle_x15-userdebug 53 . beagle_x15_auto-userdebug 54 . car_ui_portrait-userdebug 55 . car_x86_64-userdebug 56 . db845c-userdebug 57 . fuchsia_arm64-eng 58 . fuchsia_x86_64-eng 59 . gsi_car_arm64-userdebug 60 . gsi_car_x86_64-userdebug 61 . hikey-userdebug 62 . hikey64_only-userdebug 63 . hikey960-userdebug 64 . hikey960_tv-userdebug 65 . hikey_tv-userdebug 66 . pixel3_mainline-userdebug 67 . poplar-eng 68 . poplar-user 69 . poplar-userdebug 70 . qemu_trusty_arm64-userdebug 71 . sdk_car_arm-userdebug 72 . sdk_car_arm64-userdebug 73 . sdk_car_portrait_x86_64-userdebug 74 . sdk_car_x86-userdebug 75 . sdk_car_x86_64-userdebug 76 . silvermont-eng 77 . uml-userdebug 78 . yukawa-userdebug 79 . yukawa_sei510-userdebug Which would you like? [ aosp_arm-eng ] : Target in format <product_name>-<build_variant> where build_variant can be: user : Limited access; suited for production userdebug : Like user but with root access and debug capability; preferred for debugging eng : Development configuration with additional debugging tools Select target : android-10.0.0_r47 android-12.1.0_r8 lunch aosp_car_x86_64-eng = =========================================== PLATFORM_VERSION_CODENAME = REL PLATFORM_VERSION = 10 TARGET_PRODUCT = aosp_car_x86_64 TARGET_BUILD_VARIANT = eng TARGET_BUILD_TYPE = release TARGET_ARCH = x86_64 TARGET_ARCH_VARIANT = x86_64 TARGET_2ND_ARCH = x86 TARGET_2ND_ARCH_VARIANT = x86_64 HOST_ARCH = x86_64 HOST_2ND_ARCH = x86 HOST_OS = linux HOST_OS_EXTRA = Linux-5.13.0-30-generic-x86_64-Ubuntu-20.04.4-LTS HOST_CROSS_OS = windows HOST_CROSS_ARCH = x86 HOST_CROSS_2ND_ARCH = x86_64 HOST_BUILD_TYPE = release BUILD_ID = QP1A.190711.019 OUT_DIR = out = =========================================== lunch sdk_car_x86_64-eng = =========================================== PLATFORM_VERSION_CODENAME = REL PLATFORM_VERSION = 12 TARGET_PRODUCT = sdk_car_x86_64 TARGET_BUILD_VARIANT = eng TARGET_BUILD_TYPE = release TARGET_ARCH = x86_64 TARGET_ARCH_VARIANT = x86_64 TARGET_2ND_ARCH = x86 TARGET_2ND_ARCH_VARIANT = x86_64 HOST_ARCH = x86_64 HOST_2ND_ARCH = x86 HOST_OS = linux HOST_OS_EXTRA = Linux-5.13.0-51-generic-x86_64-Ubuntu-20.04.4-LTS HOST_CROSS_OS = windows HOST_CROSS_ARCH = x86 HOST_CROSS_2ND_ARCH = x86_64 HOST_BUILD_TYPE = release BUILD_ID = SQ3A.220605.009.B1 OUT_DIR = out PRODUCT_SOONG_NAMESPACES = device/generic/goldfish device/generic/goldfish-opengl hardware/google/camera hardware/google/camera/devices/EmulatedCamera device/generic/goldfish device/generic/goldfish-opengl = =========================================== A target can include other base targets, such as device/generic/goldfish/car/sdk_car_x86_64.mk : inherit device/generic/car/emulator/aosp_car_emulator.mk inherit $(SRC_TARGET_DIR)/product/sdk_x86_64.mk Build : m all -j $( nproc ) The compilation takes hours to complete. The minimum required amount of free memory is around 16 GB , and even with that, some configurations may not work. If you run into segfaults or other errors, try reducing your -j value. android-10.0.0_r47 android-12.1.0_r8 AOSP is built successfully AOSP SDK is built successfully Source Code structure # There are many folders in the root folder of AOSP, here are short descriptions of them: art : Android Runtime Implementation of Android Runtime layer. bionic : C-runtime library Android is not using glibc like most Linux distributions. Instead, the c-library is called bionic and is based mostly on BSD-derived sources. bootable : Boot and Startup Bootloader, and some tools for recovery, flashing such as fastboot . build : Target and build directions An important file here is the envsetup.sh script that will help you a lot when working with the platform source. Running this script in a shell will enable commands to set up environment variables, build specific modules and grep in source code files. cts : Compatibility Test The test suite to ensure that a build complies with the Android specification. dalvik : Dalvik Virtual Machine This will build the virtual machine. development : Development platform Projects which are related to development such as the source code for the SDK and NDK tools. Normally not a folder you touch when working with the platform for a target. device : Product Build configuration, hardware modules and specific code for different devices. external : External open source components Contains source code for all external open source projects such as SQLite, FreeType and WebKit. frameworks : Android framework The implementation of key services such as the System Server with the Package- and Activity managers. A lot of the mapping between the java application APIs and the native libraries is also done here. hardware : Hardware implementation The Android Hardware Abstraction Layer specification and implementation. libnativehelper : Helper functions for use with JNI. kernel : Prebuilt kernel files Just binary files, source code does not come here. packages : Applications Source code of default application such as Contacts, Calendar. prebuilt : Binary tools Files that are distributed in binary form for convenience. Examples include the cross compilations toolchain for different development machines. system : Android core That is the minimal Linux system that is started before the Dalvik VM and any java based services are enabled. This includes the source code for the init process and the default init.rc script that provide the dynamic configuration of the platform. sdk : Base additional apps Useful apps that developers can leverage on and can be enhanced further as part of the operating system. Build tricks # Make targets Here is a list of different make targets you can use to build different parts of the system: make sdk - build the tools that are part of an SDK (adb, fastboot, etc.) make snod - build the system image from the current software binaries make services make runtime make droid - make droid is the normal build. make all - make everything, whether it is included in the product definition or not make clean - remove all built files (prepare for a new build). Same as rm -rf out/<configuration>/ make modules - shows a list of submodules that can be built. List of all LOCAL_MODULE definitions. make <local_module> - make a specific module (note that this is not the same as directory name. It is the LOCAL_MODULE definition in the Android.mk file) make clean-<local_module> - clean a specific module make bootimage TARGET_PREBUILT_KERNEL=/path/to/bzImage - create a new boot image with custom bzImage. Helper macros and functions There are some helper macros and functions that are installed when you source envsetup.sh. They are documented at the top of envesetup.sh, but here is information about a few of them: hmm - List this help text lunch <product_name>-<build_variant> - Load product & build variant config (driver files, device specific configs, etc.). tapas [<App1> <App2> ...] [arm|x86|mips|armv5|arm64|x86_64|mips64] [eng|userdebug|user] - command is for building unbundled apps. If you don\u2019t supply a build variant, it defaults to eng . provision - Flash device with all required partitions. Options will be passed on to fastboot . Build Macros and functions croot - change directory to the top of the tree m - execute \u2018make\u2019 from the top of the tree (even if your current directory is somewhere else) mm - builds all the modules in the current directory mmm <dir1> ... - Builds all the modules in the supplied directories, but not their dependencies. To limit the modules being built use the syntax: mmm dir/:target1,target2 . mma - Builds all the modules in the current directory, and their dependencies. mmma <dir1> ... - Builds all the modules in the supplied directories, and their dependencies. Grep macros and functions cgrep <PATTERN> - Greps on all local C/C++ files. ggrep <PATTERN> - Greps on all local Gradle files. jgrep <PATTERN> - Greps on all local Java files. resgrep <PATTERN> - Greps on all local res/*.xml files. mangrep <PATTERN> - Greps on all local AndroidManifest.xml files. mgrep <PATTERN> - Greps on all local Makefiles files. sepgrep <PATTERN> - Greps on all local sepolicy files. sgrep <PATTERN> - Greps on all local source files. godir <filename> - Go to the directory containing a file Build logs # You can find the individual commands that AOSP build system executes to compile the image in the file <aosp_root_dir>/out/verbose.log.gz . It is the compressed package that contains the verbose log of your last build. Just extract the verbose.log.gz package, and you will get verbose.log file. Run Emulator # The Android emulator runs a virtual CPU that Google calls Goldfish. The Emulator, in fact, is a QEMU Virtual Machine which is prebuilt for a target AOSP. VM acceleration # Linux-based systems support VM acceleration through the KVM software package. Check KVM: sudo apt install -y cpu-checker kvm-ok INFO: /dev/kvm exists KVM acceleration can be used AOSP Emulator # If you run emulator in the same terminal that is set up for building AOSP, system will call to the local emulator which is shipped as a prebuilt package in the AOSP source: which emulator /mnt/work/android-10.0.0_r47/prebuilts/android-emulator/linux-x86_64/emulator With this prebuilt emulator, you may get some issue with new Kernel image, such as below error: emulator: ERROR: Can 't parse ' Linux version ' string in kernel image file: ' Linux version 4 .14.282-g21e1e64073ff-dirty ( build-user@ To fix this case, you need to find a suitable kernel version for your emulator. for example, kernel for latest Andoird 11 can not run on prebuilt QEMU for an old Android 11 version. Emulator Command Line # Emulator Command Line provides options to run an emulator. Basically, for development: emulator -verbose -show-kernel -selinux permissive -writable-system -verbose : displays which files and settings are actually selected when starting -shell : open root shell -show-kernel : option to show the kernel console, it\u2019s good for debugging -selinux {disabled|permissive} : SELinux not enforced -writable-system : writable system image -no-boot-anim : disable the boot animation -no-snapshot : do not save system state -wipe-data : remove all user data KVM Permission If you see an error with this message: ProbeKVM: This user doesn't have permissions to use KVM (/dev/kvm).\\ The KVM line in /etc/group is: [LINE_NOT_FOUND] If we see LINE_NOT_FOUND , the kvm group may need to be created along with permissions: sudo groupadd -r kvm Then ensure /lib/udev/rules.d/50-udev-default.rules contains something like: # KERNEL==\"kvm\", GROUP=\"kvm\", MODE=\"0660\" and then run: sudo gpasswd -a $USER kvm If we see kvm:... but no username at the end, running the following command may allow KVM access: sudo gpasswd -a $USER kvm You may need to log out and back in for changes to take effect. android-10.0.0_r47 android-12.1.0_r8 Run the Emulator Run the Emulator To check the kernel version, run uname -a in the emulator kernel console, e.g. it\u2019s version 5.10.66 in the above picture. ADB If you run abd in the same terminal that is set up for building AOSP, system will call to the local adb which is shipped as a prebuilt package in the AOSP source: which adb /mnt/work/android-10.0.0_r47/out/soong/host/linux-x86/bin/adb You can install adb and connect to the Emulator from any terminal, but the version of adb may different to the one running on the emulator: sudo apt install adb Then list all devices: adb devices Android Debug Bridge version 1 .0.39 Version 1 :8.1.0+r23-5~18.04 Installed as /usr/lib/android-sdk/platform-tools/adb And connect to the Emulator: adb -e shell Build Kernel # Official build guide: https://source.android.com/setup/build/building-kernels These instructions guide you through the process of selecting the right sources, building the kernel, and embedding the results into a system image built from the Android Open Source Project (AOSP). Find Kernel Makefile # The Android tree contains only prebuilt kernel binaries. When AOSP system image is build, it copies the prebuilt kernel image to the output folder. I wrote a script show_make_tree.py to list all included Makefiles in a tree view: show_make_tree.py #!/usr/bin/python3 import sys from os.path import exists __FILE = \" \\u001b [32mFile : \" # green __INHERIT = \" \\u001b [33mInherit: \" # yellow __SEARCH = \" \\u001b [31mSearch : \" # read __INCLUDE = \" \\u001b [36mInclude: \" # cyan __NONE = \" \\u001b [0m\" # reset def indent ( level , type , line ): print ( type , end = \"\" ) for _ in range ( level ): print ( \" \" , end = \"\" ) print ( line , end = \"\" ) print ( __NONE ) def find ( file , level , type ): if exists ( file ): indent ( level , type , file ) with open ( file , \"r\" ) as f : for line in f . readlines (): if line . startswith ( \"$(call inherit-product\" ): line = line . replace ( \"$(SRC_TARGET_DIR)\" , \"build/target\" ) line = line . split ( \",\" )[ 1 ] line = line . strip () line = line [: - 1 ] find ( line , level + 1 , __INHERIT ) if line . startswith ( \"include\" ): line = line . split ( \" \" )[ 1 ] line = line . strip () find ( line , level + 1 , __INCLUDE ) if search in line : indent ( level + 1 , __SEARCH , line . strip ()) if len ( sys . argv ) >= 3 : root = sys . argv [ 1 ] search = sys . argv [ 2 ] print ( \"Search for \\n\\u001b [31m\" + search + \" \\u001b [0m \\n in\" ); find ( root , 0 , __FILE ) android-10.0.0_r47 android-12.1.0_r8 Our build target is aosp_car_x86_64 , let find the makefile aosp_car_x86_64.mk : find device -name aosp_car_x86_64.mk device/generic/car/aosp_car_x86_64.mk Run search for :kernel in the target Makefile: device/generic/car/aosp_car_x86_64.mk : python show_make_tree.py \\ \"device/generic/car/aosp_car_x86_64.mk\" \\ \":kernel\" Search for :kernel in device/generic/car/aosp_car_x86_64.mk build/target/product/aosp_x86_64.mk device/generic/goldfish/x86_64-vendor.mk Found: prebuilts/qemu-kernel/x86_64/ $( PRODUCT_KERNEL_VERSION ) /kernel-qemu2:kernel-ranchu Ok, the :kernel word is in the file device/generic/goldfish/x86_64-vendor.mk device/generic/goldfish/x86_64-vendor.mk PRODUCT_KERNEL_VERSION := 4 .14 PRODUCT_PROPERTY_OVERRIDES += \\ vendor.rild.libpath = /vendor/lib64/libgoldfish-ril.so PRODUCT_COPY_FILES += \\ device/generic/goldfish/data/etc/advancedFeatures.ini:advancedFeatures.ini \\ device/generic/goldfish/data/etc/encryptionkey.img:encryptionkey.img \\ prebuilts/qemu-kernel/x86_64/ $( PRODUCT_KERNEL_VERSION ) /kernel-qemu2:kernel-ranchu PRODUCT_SDK_ADDON_COPY_FILES += \\ device/generic/goldfish/data/etc/advancedFeatures.ini:images/x86_64/advancedFeatures.ini \\ device/generic/goldfish/data/etc/encryptionkey.img:images/x86_64/encryptionkey.img \\ prebuilts/qemu-kernel/x86_64/ $( PRODUCT_KERNEL_VERSION ) /kernel-qemu2:images/x86_64/kernel-ranchu PRODUCT_SHIPPING_API_LEVEL := 28 TARGET_USES_MKE2FS := true ... So, it is clear that, the prebuilt kernel file at the version 4.14 : prebuilts/qemu-kernel/x86_64/4.14/kernel-qemu2 will be copied to: out/target/product/generic_x86_64/kernel-ranchu . Our build target is sdk_car_x86_64 , let find the makefile sdk_car_x86_64.mk : find device -name sdk_car_x86_64.mk device/generic/goldfish/car/sdk_car_x86_64.mk Run search for :kernel in the target Makefile: device/generic/goldfish/car/sdk_car_x86_64.mk : python show_make_tree.py \\ \"device/generic/goldfish/car/sdk_car_x86_64.mk\" \\ \":kernel\" Search for :kernel in device/generic/goldfish/car/sdk_car_x86_64.mk ... build/target/product/sdk_x86_64.mk build/target/product/sdk_phone_x86_64.mk ... device/generic/goldfish/x86_64-vendor.mk device/generic/goldfish/x86_64-kernel.mk Found: $( EMULATOR_KERNEL_FILE ) :kernel-ranchu Ok, the :kernel word is in the file device/generic/goldfish/x86_64-vendor.mk device/generic/goldfish/x86_64-vendor.mk include device/generic/goldfish/x86_64-kernel.mk PRODUCT_COPY_FILES += \\ $( EMULATOR_KERNEL_FILE ) :kernel-ranchu PRODUCT_SDK_ADDON_COPY_FILES += \\ $( EMULATOR_KERNEL_FILE ) :images/x86_64/kernel-ranchu ... which includes device/generic/goldfish/x86_64-kernel.mk : device/generic/goldfish/x86_64-kernel.mk TARGET_KERNEL_USE ?= 5 .10 KERNEL_MODULES_PATH := kernel/prebuilts/common-modules/virtual-device/ $( TARGET_KERNEL_USE ) /x86-64 KERNEL_MODULES_EXCLUDE := \\ $( KERNEL_MODULES_PATH ) /virt_wifi.ko \\ $( KERNEL_MODULES_PATH ) /virt_wifi_sim.ko BOARD_VENDOR_RAMDISK_KERNEL_MODULES += \\ $( filter-out $( KERNEL_MODULES_EXCLUDE ) , $( wildcard $( KERNEL_MODULES_PATH ) /*.ko )) EMULATOR_KERNEL_FILE := kernel/prebuilts/ $( TARGET_KERNEL_USE ) /x86_64/kernel- $( TARGET_KERNEL_USE ) So, it is clear that, the prebuilt kernel file at the version 5.10 : kernel/prebuilts/5.10/x86_64/kernel-5.10 will be copied to: out/target/product/emulator_car_x86_64/kernel-ranchu . Android Common Kernels # Android Common Kernels is used to run on Emulator. KMI kernel branch : Android 11 introduced GKI, which separates the kernel into a Google-maintained kernel image and vendor maintained-modules, which are built separately. Android 11: android11-5.4 Android 12: android12-5.4 android12-5.10 Legacy dessert kernel branches : Legacy dessert kernels were created to guarantee that new feature development didn\u2019t interfere with merging from the Android Common Kernel. Android 10: android-4.9-q android-4.14-q android-4.19-q Android 11 android-4.14-stable android-4.19-stable Legacy release kernel branches : Release kernels are maintained to provide backports of patches cited in the monthly Android Security Bulletin. They were created for each launch kernel when there was a new Android platform release. Android 10: android-4.9-q-release android-4.14-q-release android-4.19-q-release Build custom kernel # Download kernel and the target branch android-10.0.0_r47 android-12.1.0_r8 The above example use the AOSP android-10.0.0_r47 , which uses the kernel 4.14 . Checking on https://android.googlesource.com/kernel/manifest/+refs , there are some versions with 4.14 version: common-android-4.14 = common-android-4.14-stable has kernel/common at android-4.14-stable \u2192 this is for Android 11. q-common-android-4.14 has kernel/common at android-4.14-q \u2192 build config for goldfish is not completed. q-goldfish-android-goldfish-4.14-dev has kernel/common at android-goldfish-4.14-dev \u2192 having goldfish in name seems good for emulator. export KERNEL_BRANCH = \"q-goldfish-android-goldfish-4.14-dev\" mkdir kernel- $KERNEL_BRANCH && cd kernel- $KERNEL_BRANCH repo init \\ -u https://android.googlesource.com/kernel/manifest \\ -b $KERNEL_BRANCH \\ --depth = 1 The above example use the AOSP android-12.1.0_r8 , which uses the kernel 5.10 . So, you can select the Android Common Kernel on branch common-android12-5.10 . export KERNEL_BRANCH = \"common-android12-5.10\" mkdir kernel- $KERNEL_BRANCH && cd kernel- $KERNEL_BRANCH repo init \\ -u https://android.googlesource.com/kernel/manifest \\ -b $KERNEL_BRANCH \\ --depth = 1 Then sync the source code: repo sync -c -j $( nproc ) && sync Build the kernel : Install libs for building kernel: sudo apt install libssl-dev libelf-dev A common kernels are generic, customizable kernels and therefore don\u2019t define a default configuration. We have to set some environment settings: Environment variable Description Example BUILD_CONFIG Build config file from where you initialize the build environment. The location must be defined relative to the Repo root directory. Defaults to build.config. Mandatory for common kernels. BUILD_CONFIG=common/build.config.<target>.x86_64 CC Override compiler to be used. Falls back to the default compiler defined by build.config. CC=clang DIST_DIR Base output directory for the kernel distribution. DIST_DIR=/path/to/my/dist OUT_DIR Base output directory for the kernel build. OUT_DIR=/path/to/my/out SKIP_DEFCONFIG Skip make defconfig SKIP_DEFCONFIG=1 SKIP_MRPROPER Skip make mrproper SKIP_MRPROPER=1 bzImage vs vmlinux Big Z Image bzImage is a compressed version of the vmlinux with extra headers for booting up. vmlinux is a statically linked executable file that contains the Linux Kernel. android-10.0.0_r47 android-12.1.0_r8 Build the kernel (without Link Time Optimization (LTO) for testing): q-goldfish-android-goldfish-4.14-dev BUILD_CONFIG = goldfish/build.config.goldfish.x86_64 \\ LTO = none \\ build/build.sh If the build succeeds, there is a log to show the kernel image destination: q-goldfish-android-goldfish-4.14-dev Files copied to /mnt/work/kernel-q-goldfish-android-goldfish-4.14-dev/out/x86_64/dist Check the kernel file: q-goldfish-android-goldfish-4.14-dev file/mnt/work/kernel-q-goldfish-android-goldfish-4.14-dev/out/x86_64/dist/bzImage Linux kernel x86 boot executable bzImage, version 4 .14.175-g1aec57a9 ( build-user@build-host ) #1 SMP PREEMPT Wed May 4 05:03:19 UTC 2022, RO-rootFS, swap_dev 0x7, Normal VGA Fast re-build Not supported! From Android 11, Google introduced GKI, which separates the kernel into a Google-maintained kernel image and vendor maintained-modules, which are built separately. Build the kernel (without Link Time Optimization (LTO) for testing): common-android12-5.10 BUILD_CONFIG = common/build.config.gki.x86_64 \\ LTO = none \\ build/build.sh After build complete, check the kernel file: common-android12-5.10 file out/android12-5.10/dist/bzImage Linux kernel x86 boot executable bzImage, version 5.10.110-android12-9-00168-g131b12d50f16 (build-user@build-host) #1 SMP PREEMPT Fri May 27 16:2, RO-rootFS, swap_dev 0x15, Normal VGA Build vendor\u2019s modules , Android 12 Cuttlefish and Goldfish converge, so they share the same kernel virtual_device which can be built as below: common-android12-5.10 BUILD_CONFIG = common-modules/virtual-device/build.config.virtual_device.x86_64 \\ LTO = none \\ build/build.sh Fast re-build By default, Kernel is always built with mrproper target which removes all generated files + config + various backup files to create a clean build. When developing on one or a few modules, we can skip the some initial steps and start re-build immediately: common-android12-5.10 BUILD_CONFIG = common-modules/virtual-device/build.config.virtual_device.x86_64 \\ LTO = none \\ FAST_BUILD = 1 \\ SKIP_MRPROPER = 1 \\ SKIP_DEFCONFIG = 1 \\ build/build.sh Include custom kernel # For making a vendor module for kernel, refer to Kernel Module guide. Create a soft link to built custom kernel in AOSP root folder: android-10.0.0_r47 android-12.1.0_r8 ln -s /mnt/work/kernel-q-goldfish-android-goldfish-4.14-dev kernel-custom ln -s /mnt/work/kernel-common-android12-5.10 kernel-custom Edit the kernel make file: android-10.0.0_r47 android-12.1.0_r8 device/generic/goldfish/x86_64-kernel.mk PRODUCT_KERNEL_VERSION := 4 .14 PRODUCT_PROPERTY_OVERRIDES += \\ vendor.rild.libpath = /vendor/lib64/libgoldfish-ril.so PRODUCT_COPY_FILES += \\ device/generic/goldfish/data/etc/advancedFeatures.ini:advancedFeatures.ini \\ device/generic/goldfish/data/etc/encryptionkey.img:encryptionkey.img \\ kernel-custom/out/x86_64/dist/bzImage:kernel-ranchu PRODUCT_SDK_ADDON_COPY_FILES += \\ device/generic/goldfish/data/etc/advancedFeatures.ini:images/x86_64/advancedFeatures.ini \\ device/generic/goldfish/data/etc/encryptionkey.img:images/x86_64/encryptionkey.img \\ kernel-custom/out/x86_64/dist/bzImage:images/x86_64/kernel-ranchu PRODUCT_SHIPPING_API_LEVEL := 28 TARGET_USES_MKE2FS := true device/generic/goldfish/x86_64-kernel.mk TARGET_KERNEL_USE ?= 5 .10 KERNEL_MODULES_PATH := kernel-custom/out/android12- $( TARGET_KERNEL_USE ) /dist KERNEL_MODULES_EXCLUDE := \\ $( KERNEL_MODULES_PATH ) /virt_wifi.ko \\ $( KERNEL_MODULES_PATH ) /virt_wifi_sim.ko BOARD_VENDOR_RAMDISK_KERNEL_MODULES += \\ $( filter-out $( KERNEL_MODULES_EXCLUDE ) , $( wildcard $( KERNEL_MODULES_PATH ) /*.ko )) EMULATOR_KERNEL_FILE := $( KERNEL_MODULES_PATH ) /bzImage Finally, make system image again: m all -j $( nproc ) and run the emulator: emulator -verbose -show-kernel -selinux permissive -writable-system Use adb to access to the Emulator shell and check the Kernel version. Soong Build System # The Soong build system was introduced in Android 7.0 (Nougat) to replace Make . It leverages the Kati GNU Make clone tool and Ninja build system component to speed up builds of Android. Blueprint file format By design, Android.bp files are simple. They don\u2019t contain conditionals or control flow statements; all complexity is handled by build logic written in Go. A module in an Android.bp file starts with a module type followed by a set of properties in name: \"value\" format. Every module must have a name property, and the value must be unique across all Android.bp files, except for the name property values in namespaces and prebuilt modules, which may repeat. The srcs property specifies the source files used to build the module, as a list of strings. Soong can build many modules, refer to Soong Modules Reference and select a target module for more details. Below are examples for cc_binary , and cc_library_shared with their corresponding old Makefiles: Binary # Android.bp cc_binary { name : \"invcase\" , srcs : [ \"invcase.c\" ] , shared_libs : [ \"libinvcase\" ] , } Android.mk LOCAL_PATH := $( call my-dir ) include $(CLEAR_VARS) LOCAL_MODULE := invcase LOCAL_SRC_FILES := invcase.c LOCAL_SHARED_LIBRARIES += libinvcase include $(BUILD_EXECUTABLE) Shared Library # Android.bp cc_library_shared { name : \"libinvcase\" , srcs : [ \"libinvcase.c\" ] , } Android.mk LOCAL_PATH := $( call my-dir ) include $(CLEAR_VARS) LOCAL_MODULE := libinvcase LOCAL_SRC_FILES := libinvcase.c include $(BUILD_SHARED_LIBRARY)","title":"Build Android system and Kernel images"},{"location":"blog/android/build-aosp/#android-open-source-project","text":"Android is an open source software stack created for a wide array of devices with different form factors. Android\u2019s primary purpose is to create an open software platform available for carriers, OEMs, and developers to make their innovative ideas a reality and to introduce a successful, real-world product that improves the mobile experience for users. Android Framework Stack Android development releases are organized into families, with alphabetical codenames. You can look up the codenames and the version numbers in Codenames, Tags, and Build Numbers . Android Code Search allows you to search AOSP without downloading anything. You can use Code Search to view the AOSP source code, switch between open source branches, and navigate cross-references. AOSPXRef is a web-based code browsers similar to Android Code Search.","title":"Android Open Source Project"},{"location":"blog/android/build-aosp/#android-automotive","text":"Android Automotive is a base Android platform that runs pre-installed IVI system Android applications as well as optional second- and third-party Android Applications. Android Automotive offers openness, customization, and scale to automotive infotainment systems and head units. These things below can be confusing: Android Auto is a platform running on the user\u2019s phone, projecting the Android Auto user experience to a compatible in-vehicle infotainment system over a USB connection. Android Auto supports apps designed for in-vehicle use. Android Automotive is an operating system and platform running directly on the in-vehicle hardware. It is a full-stack, open source, highly customizable platform powering the infotainment experience. Android Automotive supports apps built for Android as well as those built for Android Auto. Google Automotive Services (GAS) is a collection of applications and services that automotive OEMs can choose to license and integrate into their in-vehicle infotainment (IVI) systems. Android Automotive Framework Stack","title":"Android Automotive"},{"location":"blog/android/build-aosp/#build-aosp-system-image","text":"The official guide at https://source.android.com/setup/build/building usually is updated to the latest version. Building an older version of AOSP may need some modifications.","title":"Build AOSP System Image"},{"location":"blog/android/build-aosp/#preparation","text":"Host machine It is recommended to have Ubuntu 20.04 LTS , because Windows and MacOS are not supported, and Google repo is updated to Python 3. You can optionally follow some tweaks to get better performance on your host machine such as: use noatime and remove journal feature of disk storing source code. Host packages sudo apt install \\ git curl \\ build-essential flex bison \\ libncurses5 libssl-dev libelf-dev Repo and Git tool Install repo from the package management: sudo apt install repo If it is not working, try to install manually: mkdir -p ~/.bin curl https://storage.googleapis.com/git-repo-downloads/repo > ~/.bin/repo chmod a+rx ~/.bin/repo echo 'PATH=\"${HOME}/.bin:${PATH}\"' >> ~/.bashrc source ~/.bashrc On Ubuntu 20.04, /usr/bin/env/python is not pointing to python3 , so install below package: sudo apt install python-is-python3 Set git user: git config --global user.email \"vuquangtrong@gmail.com\" git config --global user.name \"vuquangtrong\"","title":"Preparation"},{"location":"blog/android/build-aosp/#download-and-build","text":"Git clone modes Read details in Get up to speed with partial clone and shallow clone . Full clone This is the default mode. All blobs and trees are downloaded. Partial clone If using Git version 2.19 or greater, --partial-clone option is used to parialy download the needed objects. Blobless : Remove all file history with the option: --partial-clone --clone-filter=blob:none Treeless : Remove all directory history with the option: --partial-clone --clone-filter=tree:0 Shallow clone An older feature that does something very similar to a Treeless clone is Shallow clone with the option --depth=1 . This truncates the history to only download current commit. Android version Version API Codename Release date Major changes 12.1 32 S Mar 2022 12 31 S Oct 2021 11 30 R Sep 2020 New Permission Controls 10 29 Q Mar 2019 HIDL is deprecated, use AIDL every where 9 28 P Aug 2018 8.1 27 O Dec 2017 8.0 26 O Aug 2017 Use HIDL instead of classical HAL 7.1 25 N Aug 2016 Initialize the repo : Go to https://android.googlesource.com/platform/manifest and select a target branch. In this example, use shallow clone to reduce download time. If you need to read full log, or contribute back to the upstream repo, please fully clone the repo. android-10.0.0_r47 android-12.1.0_r8 export AOSP_BRANCH = \"android-10.0.0_r47\" mkdir $AOSP_BRANCH && cd $AOSP_BRANCH repo init \\ -u https://android.googlesource.com/platform/manifest \\ -b $AOSP_BRANCH \\ --depth = 1 export AOSP_BRANCH = \"android-12.1.0_r8\" mkdir $AOSP_BRANCH && cd $AOSP_BRANCH repo init \\ -u https://android.googlesource.com/platform/manifest \\ -b $AOSP_BRANCH \\ --depth = 1 Download source code : To speed up, use the -c (current branch) option. repo sync -c -j $( nproc ) && sync The download takes few hours to complete. Apply modifications android-10.0.0_r47 android-12.1.0_r8 There is one Python 2 script in AOSP 10.0.0_r47 which needs modified: /device/generic/goldfish/tools/mk_combined_img.py . Install Python 2: sudo apt install python2 Then edit the she-bang of the mk_combined_img.py script to use Python 2: device/generic/goldfish/tools/mk_combined_img.py - #!/usr/bin/python + #!/usr/bin/python2 All build scripts are converted to Python 3. Setup environment : source build/envsetup.sh Run lunch with no arguments to list all targets. android-10.0.0_r47 android-12.1.0_r8 lunch You ' re building on Linux Lunch menu... pick a combo: 1 . aosp_arm-eng 2 . aosp_arm64-eng 3 . aosp_blueline-userdebug 4 . aosp_bonito-userdebug 5 . aosp_car_arm-userdebug 6 . aosp_car_arm64-userdebug 7 . aosp_car_x86-userdebug 8 . aosp_car_x86_64-userdebug 9 . aosp_cf_arm64_phone-userdebug 10 . aosp_cf_x86_64_phone-userdebug 11 . aosp_cf_x86_auto-userdebug 12 . aosp_cf_x86_phone-userdebug 13 . aosp_cf_x86_tv-userdebug 14 . aosp_crosshatch-userdebug 15 . aosp_marlin-userdebug 16 . aosp_sailfish-userdebug 17 . aosp_sargo-userdebug 18 . aosp_taimen-userdebug 19 . aosp_walleye-userdebug 20 . aosp_walleye_test-userdebug 21 . aosp_x86-eng 22 . aosp_x86_64-eng 23 . beagle_x15-userdebug 24 . fuchsia_arm64-eng 25 . fuchsia_x86_64-eng 26 . hikey-userdebug 27 . hikey64_only-userdebug 28 . hikey960-userdebug 29 . hikey960_tv-userdebug 30 . hikey_tv-userdebug 31 . m_e_arm-userdebug 32 . mini_emulator_arm64-userdebug 33 . mini_emulator_x86-userdebug 34 . mini_emulator_x86_64-userdebug 35 . poplar-eng 36 . poplar-user 37 . poplar-userdebug 38 . qemu_trusty_arm64-userdebug 39 . uml-userdebug Which would you like? [ aosp_arm-eng ] : lunch You ' re building on Linux Lunch menu... pick a combo: 1 . aosp_arm-eng 2 . aosp_arm64-eng 3 . aosp_barbet-userdebug 4 . aosp_blueline-userdebug 5 . aosp_blueline_car-userdebug 6 . aosp_bonito-userdebug 7 . aosp_bonito_car-userdebug 8 . aosp_bramble-userdebug 9 . aosp_bramble_car-userdebug 10 . aosp_car_arm-userdebug 11 . aosp_car_arm64-userdebug 12 . aosp_car_x86-userdebug 13 . aosp_car_x86_64-userdebug 14 . aosp_cf_arm64_auto-userdebug 15 . aosp_cf_arm64_phone-userdebug 16 . aosp_cf_x86_64_foldable-userdebug 17 . aosp_cf_x86_64_pc-userdebug 18 . aosp_cf_x86_64_phone-userdebug 19 . aosp_cf_x86_64_tv-userdebug 20 . aosp_cf_x86_auto-userdebug 21 . aosp_cf_x86_phone-userdebug 22 . aosp_cf_x86_tv-userdebug 23 . aosp_coral-userdebug 24 . aosp_coral_car-userdebug 25 . aosp_crosshatch-userdebug 26 . aosp_crosshatch_car-userdebug 27 . aosp_crosshatch_vf-userdebug 28 . aosp_flame-userdebug 29 . aosp_flame_car-userdebug 30 . aosp_oriole-userdebug 31 . aosp_oriole_car-userdebug 32 . aosp_raven-userdebug 33 . aosp_raven_car-userdebug 34 . aosp_redfin-userdebug 35 . aosp_redfin_car-userdebug 36 . aosp_redfin_vf-userdebug 37 . aosp_sargo-userdebug 38 . aosp_sargo_car-userdebug 39 . aosp_slider-userdebug 40 . aosp_sunfish-userdebug 41 . aosp_sunfish_car-userdebug 42 . aosp_trout_arm64-userdebug 43 . aosp_trout_x86-userdebug 44 . aosp_whitefin-userdebug 45 . aosp_x86-eng 46 . aosp_x86_64-eng 47 . arm_krait-eng 48 . arm_v7_v8-eng 49 . armv8-eng 50 . armv8_cortex_a55-eng 51 . armv8_kryo385-eng 52 . beagle_x15-userdebug 53 . beagle_x15_auto-userdebug 54 . car_ui_portrait-userdebug 55 . car_x86_64-userdebug 56 . db845c-userdebug 57 . fuchsia_arm64-eng 58 . fuchsia_x86_64-eng 59 . gsi_car_arm64-userdebug 60 . gsi_car_x86_64-userdebug 61 . hikey-userdebug 62 . hikey64_only-userdebug 63 . hikey960-userdebug 64 . hikey960_tv-userdebug 65 . hikey_tv-userdebug 66 . pixel3_mainline-userdebug 67 . poplar-eng 68 . poplar-user 69 . poplar-userdebug 70 . qemu_trusty_arm64-userdebug 71 . sdk_car_arm-userdebug 72 . sdk_car_arm64-userdebug 73 . sdk_car_portrait_x86_64-userdebug 74 . sdk_car_x86-userdebug 75 . sdk_car_x86_64-userdebug 76 . silvermont-eng 77 . uml-userdebug 78 . yukawa-userdebug 79 . yukawa_sei510-userdebug Which would you like? [ aosp_arm-eng ] : Target in format <product_name>-<build_variant> where build_variant can be: user : Limited access; suited for production userdebug : Like user but with root access and debug capability; preferred for debugging eng : Development configuration with additional debugging tools Select target : android-10.0.0_r47 android-12.1.0_r8 lunch aosp_car_x86_64-eng = =========================================== PLATFORM_VERSION_CODENAME = REL PLATFORM_VERSION = 10 TARGET_PRODUCT = aosp_car_x86_64 TARGET_BUILD_VARIANT = eng TARGET_BUILD_TYPE = release TARGET_ARCH = x86_64 TARGET_ARCH_VARIANT = x86_64 TARGET_2ND_ARCH = x86 TARGET_2ND_ARCH_VARIANT = x86_64 HOST_ARCH = x86_64 HOST_2ND_ARCH = x86 HOST_OS = linux HOST_OS_EXTRA = Linux-5.13.0-30-generic-x86_64-Ubuntu-20.04.4-LTS HOST_CROSS_OS = windows HOST_CROSS_ARCH = x86 HOST_CROSS_2ND_ARCH = x86_64 HOST_BUILD_TYPE = release BUILD_ID = QP1A.190711.019 OUT_DIR = out = =========================================== lunch sdk_car_x86_64-eng = =========================================== PLATFORM_VERSION_CODENAME = REL PLATFORM_VERSION = 12 TARGET_PRODUCT = sdk_car_x86_64 TARGET_BUILD_VARIANT = eng TARGET_BUILD_TYPE = release TARGET_ARCH = x86_64 TARGET_ARCH_VARIANT = x86_64 TARGET_2ND_ARCH = x86 TARGET_2ND_ARCH_VARIANT = x86_64 HOST_ARCH = x86_64 HOST_2ND_ARCH = x86 HOST_OS = linux HOST_OS_EXTRA = Linux-5.13.0-51-generic-x86_64-Ubuntu-20.04.4-LTS HOST_CROSS_OS = windows HOST_CROSS_ARCH = x86 HOST_CROSS_2ND_ARCH = x86_64 HOST_BUILD_TYPE = release BUILD_ID = SQ3A.220605.009.B1 OUT_DIR = out PRODUCT_SOONG_NAMESPACES = device/generic/goldfish device/generic/goldfish-opengl hardware/google/camera hardware/google/camera/devices/EmulatedCamera device/generic/goldfish device/generic/goldfish-opengl = =========================================== A target can include other base targets, such as device/generic/goldfish/car/sdk_car_x86_64.mk : inherit device/generic/car/emulator/aosp_car_emulator.mk inherit $(SRC_TARGET_DIR)/product/sdk_x86_64.mk Build : m all -j $( nproc ) The compilation takes hours to complete. The minimum required amount of free memory is around 16 GB , and even with that, some configurations may not work. If you run into segfaults or other errors, try reducing your -j value. android-10.0.0_r47 android-12.1.0_r8 AOSP is built successfully AOSP SDK is built successfully","title":"Download and Build"},{"location":"blog/android/build-aosp/#source-code-structure","text":"There are many folders in the root folder of AOSP, here are short descriptions of them: art : Android Runtime Implementation of Android Runtime layer. bionic : C-runtime library Android is not using glibc like most Linux distributions. Instead, the c-library is called bionic and is based mostly on BSD-derived sources. bootable : Boot and Startup Bootloader, and some tools for recovery, flashing such as fastboot . build : Target and build directions An important file here is the envsetup.sh script that will help you a lot when working with the platform source. Running this script in a shell will enable commands to set up environment variables, build specific modules and grep in source code files. cts : Compatibility Test The test suite to ensure that a build complies with the Android specification. dalvik : Dalvik Virtual Machine This will build the virtual machine. development : Development platform Projects which are related to development such as the source code for the SDK and NDK tools. Normally not a folder you touch when working with the platform for a target. device : Product Build configuration, hardware modules and specific code for different devices. external : External open source components Contains source code for all external open source projects such as SQLite, FreeType and WebKit. frameworks : Android framework The implementation of key services such as the System Server with the Package- and Activity managers. A lot of the mapping between the java application APIs and the native libraries is also done here. hardware : Hardware implementation The Android Hardware Abstraction Layer specification and implementation. libnativehelper : Helper functions for use with JNI. kernel : Prebuilt kernel files Just binary files, source code does not come here. packages : Applications Source code of default application such as Contacts, Calendar. prebuilt : Binary tools Files that are distributed in binary form for convenience. Examples include the cross compilations toolchain for different development machines. system : Android core That is the minimal Linux system that is started before the Dalvik VM and any java based services are enabled. This includes the source code for the init process and the default init.rc script that provide the dynamic configuration of the platform. sdk : Base additional apps Useful apps that developers can leverage on and can be enhanced further as part of the operating system.","title":"Source Code structure"},{"location":"blog/android/build-aosp/#build-tricks","text":"Make targets Here is a list of different make targets you can use to build different parts of the system: make sdk - build the tools that are part of an SDK (adb, fastboot, etc.) make snod - build the system image from the current software binaries make services make runtime make droid - make droid is the normal build. make all - make everything, whether it is included in the product definition or not make clean - remove all built files (prepare for a new build). Same as rm -rf out/<configuration>/ make modules - shows a list of submodules that can be built. List of all LOCAL_MODULE definitions. make <local_module> - make a specific module (note that this is not the same as directory name. It is the LOCAL_MODULE definition in the Android.mk file) make clean-<local_module> - clean a specific module make bootimage TARGET_PREBUILT_KERNEL=/path/to/bzImage - create a new boot image with custom bzImage. Helper macros and functions There are some helper macros and functions that are installed when you source envsetup.sh. They are documented at the top of envesetup.sh, but here is information about a few of them: hmm - List this help text lunch <product_name>-<build_variant> - Load product & build variant config (driver files, device specific configs, etc.). tapas [<App1> <App2> ...] [arm|x86|mips|armv5|arm64|x86_64|mips64] [eng|userdebug|user] - command is for building unbundled apps. If you don\u2019t supply a build variant, it defaults to eng . provision - Flash device with all required partitions. Options will be passed on to fastboot . Build Macros and functions croot - change directory to the top of the tree m - execute \u2018make\u2019 from the top of the tree (even if your current directory is somewhere else) mm - builds all the modules in the current directory mmm <dir1> ... - Builds all the modules in the supplied directories, but not their dependencies. To limit the modules being built use the syntax: mmm dir/:target1,target2 . mma - Builds all the modules in the current directory, and their dependencies. mmma <dir1> ... - Builds all the modules in the supplied directories, and their dependencies. Grep macros and functions cgrep <PATTERN> - Greps on all local C/C++ files. ggrep <PATTERN> - Greps on all local Gradle files. jgrep <PATTERN> - Greps on all local Java files. resgrep <PATTERN> - Greps on all local res/*.xml files. mangrep <PATTERN> - Greps on all local AndroidManifest.xml files. mgrep <PATTERN> - Greps on all local Makefiles files. sepgrep <PATTERN> - Greps on all local sepolicy files. sgrep <PATTERN> - Greps on all local source files. godir <filename> - Go to the directory containing a file","title":"Build tricks"},{"location":"blog/android/build-aosp/#build-logs","text":"You can find the individual commands that AOSP build system executes to compile the image in the file <aosp_root_dir>/out/verbose.log.gz . It is the compressed package that contains the verbose log of your last build. Just extract the verbose.log.gz package, and you will get verbose.log file.","title":"Build logs"},{"location":"blog/android/build-aosp/#run-emulator","text":"The Android emulator runs a virtual CPU that Google calls Goldfish. The Emulator, in fact, is a QEMU Virtual Machine which is prebuilt for a target AOSP.","title":"Run Emulator"},{"location":"blog/android/build-aosp/#vm-acceleration","text":"Linux-based systems support VM acceleration through the KVM software package. Check KVM: sudo apt install -y cpu-checker kvm-ok INFO: /dev/kvm exists KVM acceleration can be used","title":"VM acceleration"},{"location":"blog/android/build-aosp/#aosp-emulator","text":"If you run emulator in the same terminal that is set up for building AOSP, system will call to the local emulator which is shipped as a prebuilt package in the AOSP source: which emulator /mnt/work/android-10.0.0_r47/prebuilts/android-emulator/linux-x86_64/emulator With this prebuilt emulator, you may get some issue with new Kernel image, such as below error: emulator: ERROR: Can 't parse ' Linux version ' string in kernel image file: ' Linux version 4 .14.282-g21e1e64073ff-dirty ( build-user@ To fix this case, you need to find a suitable kernel version for your emulator. for example, kernel for latest Andoird 11 can not run on prebuilt QEMU for an old Android 11 version.","title":"AOSP Emulator"},{"location":"blog/android/build-aosp/#emulator-command-line","text":"Emulator Command Line provides options to run an emulator. Basically, for development: emulator -verbose -show-kernel -selinux permissive -writable-system -verbose : displays which files and settings are actually selected when starting -shell : open root shell -show-kernel : option to show the kernel console, it\u2019s good for debugging -selinux {disabled|permissive} : SELinux not enforced -writable-system : writable system image -no-boot-anim : disable the boot animation -no-snapshot : do not save system state -wipe-data : remove all user data KVM Permission If you see an error with this message: ProbeKVM: This user doesn't have permissions to use KVM (/dev/kvm).\\ The KVM line in /etc/group is: [LINE_NOT_FOUND] If we see LINE_NOT_FOUND , the kvm group may need to be created along with permissions: sudo groupadd -r kvm Then ensure /lib/udev/rules.d/50-udev-default.rules contains something like: # KERNEL==\"kvm\", GROUP=\"kvm\", MODE=\"0660\" and then run: sudo gpasswd -a $USER kvm If we see kvm:... but no username at the end, running the following command may allow KVM access: sudo gpasswd -a $USER kvm You may need to log out and back in for changes to take effect. android-10.0.0_r47 android-12.1.0_r8 Run the Emulator Run the Emulator To check the kernel version, run uname -a in the emulator kernel console, e.g. it\u2019s version 5.10.66 in the above picture. ADB If you run abd in the same terminal that is set up for building AOSP, system will call to the local adb which is shipped as a prebuilt package in the AOSP source: which adb /mnt/work/android-10.0.0_r47/out/soong/host/linux-x86/bin/adb You can install adb and connect to the Emulator from any terminal, but the version of adb may different to the one running on the emulator: sudo apt install adb Then list all devices: adb devices Android Debug Bridge version 1 .0.39 Version 1 :8.1.0+r23-5~18.04 Installed as /usr/lib/android-sdk/platform-tools/adb And connect to the Emulator: adb -e shell","title":"Emulator Command Line"},{"location":"blog/android/build-aosp/#build-kernel","text":"Official build guide: https://source.android.com/setup/build/building-kernels These instructions guide you through the process of selecting the right sources, building the kernel, and embedding the results into a system image built from the Android Open Source Project (AOSP).","title":"Build Kernel"},{"location":"blog/android/build-aosp/#find-kernel-makefile","text":"The Android tree contains only prebuilt kernel binaries. When AOSP system image is build, it copies the prebuilt kernel image to the output folder. I wrote a script show_make_tree.py to list all included Makefiles in a tree view: show_make_tree.py #!/usr/bin/python3 import sys from os.path import exists __FILE = \" \\u001b [32mFile : \" # green __INHERIT = \" \\u001b [33mInherit: \" # yellow __SEARCH = \" \\u001b [31mSearch : \" # read __INCLUDE = \" \\u001b [36mInclude: \" # cyan __NONE = \" \\u001b [0m\" # reset def indent ( level , type , line ): print ( type , end = \"\" ) for _ in range ( level ): print ( \" \" , end = \"\" ) print ( line , end = \"\" ) print ( __NONE ) def find ( file , level , type ): if exists ( file ): indent ( level , type , file ) with open ( file , \"r\" ) as f : for line in f . readlines (): if line . startswith ( \"$(call inherit-product\" ): line = line . replace ( \"$(SRC_TARGET_DIR)\" , \"build/target\" ) line = line . split ( \",\" )[ 1 ] line = line . strip () line = line [: - 1 ] find ( line , level + 1 , __INHERIT ) if line . startswith ( \"include\" ): line = line . split ( \" \" )[ 1 ] line = line . strip () find ( line , level + 1 , __INCLUDE ) if search in line : indent ( level + 1 , __SEARCH , line . strip ()) if len ( sys . argv ) >= 3 : root = sys . argv [ 1 ] search = sys . argv [ 2 ] print ( \"Search for \\n\\u001b [31m\" + search + \" \\u001b [0m \\n in\" ); find ( root , 0 , __FILE ) android-10.0.0_r47 android-12.1.0_r8 Our build target is aosp_car_x86_64 , let find the makefile aosp_car_x86_64.mk : find device -name aosp_car_x86_64.mk device/generic/car/aosp_car_x86_64.mk Run search for :kernel in the target Makefile: device/generic/car/aosp_car_x86_64.mk : python show_make_tree.py \\ \"device/generic/car/aosp_car_x86_64.mk\" \\ \":kernel\" Search for :kernel in device/generic/car/aosp_car_x86_64.mk build/target/product/aosp_x86_64.mk device/generic/goldfish/x86_64-vendor.mk Found: prebuilts/qemu-kernel/x86_64/ $( PRODUCT_KERNEL_VERSION ) /kernel-qemu2:kernel-ranchu Ok, the :kernel word is in the file device/generic/goldfish/x86_64-vendor.mk device/generic/goldfish/x86_64-vendor.mk PRODUCT_KERNEL_VERSION := 4 .14 PRODUCT_PROPERTY_OVERRIDES += \\ vendor.rild.libpath = /vendor/lib64/libgoldfish-ril.so PRODUCT_COPY_FILES += \\ device/generic/goldfish/data/etc/advancedFeatures.ini:advancedFeatures.ini \\ device/generic/goldfish/data/etc/encryptionkey.img:encryptionkey.img \\ prebuilts/qemu-kernel/x86_64/ $( PRODUCT_KERNEL_VERSION ) /kernel-qemu2:kernel-ranchu PRODUCT_SDK_ADDON_COPY_FILES += \\ device/generic/goldfish/data/etc/advancedFeatures.ini:images/x86_64/advancedFeatures.ini \\ device/generic/goldfish/data/etc/encryptionkey.img:images/x86_64/encryptionkey.img \\ prebuilts/qemu-kernel/x86_64/ $( PRODUCT_KERNEL_VERSION ) /kernel-qemu2:images/x86_64/kernel-ranchu PRODUCT_SHIPPING_API_LEVEL := 28 TARGET_USES_MKE2FS := true ... So, it is clear that, the prebuilt kernel file at the version 4.14 : prebuilts/qemu-kernel/x86_64/4.14/kernel-qemu2 will be copied to: out/target/product/generic_x86_64/kernel-ranchu . Our build target is sdk_car_x86_64 , let find the makefile sdk_car_x86_64.mk : find device -name sdk_car_x86_64.mk device/generic/goldfish/car/sdk_car_x86_64.mk Run search for :kernel in the target Makefile: device/generic/goldfish/car/sdk_car_x86_64.mk : python show_make_tree.py \\ \"device/generic/goldfish/car/sdk_car_x86_64.mk\" \\ \":kernel\" Search for :kernel in device/generic/goldfish/car/sdk_car_x86_64.mk ... build/target/product/sdk_x86_64.mk build/target/product/sdk_phone_x86_64.mk ... device/generic/goldfish/x86_64-vendor.mk device/generic/goldfish/x86_64-kernel.mk Found: $( EMULATOR_KERNEL_FILE ) :kernel-ranchu Ok, the :kernel word is in the file device/generic/goldfish/x86_64-vendor.mk device/generic/goldfish/x86_64-vendor.mk include device/generic/goldfish/x86_64-kernel.mk PRODUCT_COPY_FILES += \\ $( EMULATOR_KERNEL_FILE ) :kernel-ranchu PRODUCT_SDK_ADDON_COPY_FILES += \\ $( EMULATOR_KERNEL_FILE ) :images/x86_64/kernel-ranchu ... which includes device/generic/goldfish/x86_64-kernel.mk : device/generic/goldfish/x86_64-kernel.mk TARGET_KERNEL_USE ?= 5 .10 KERNEL_MODULES_PATH := kernel/prebuilts/common-modules/virtual-device/ $( TARGET_KERNEL_USE ) /x86-64 KERNEL_MODULES_EXCLUDE := \\ $( KERNEL_MODULES_PATH ) /virt_wifi.ko \\ $( KERNEL_MODULES_PATH ) /virt_wifi_sim.ko BOARD_VENDOR_RAMDISK_KERNEL_MODULES += \\ $( filter-out $( KERNEL_MODULES_EXCLUDE ) , $( wildcard $( KERNEL_MODULES_PATH ) /*.ko )) EMULATOR_KERNEL_FILE := kernel/prebuilts/ $( TARGET_KERNEL_USE ) /x86_64/kernel- $( TARGET_KERNEL_USE ) So, it is clear that, the prebuilt kernel file at the version 5.10 : kernel/prebuilts/5.10/x86_64/kernel-5.10 will be copied to: out/target/product/emulator_car_x86_64/kernel-ranchu .","title":"Find Kernel Makefile"},{"location":"blog/android/build-aosp/#android-common-kernels","text":"Android Common Kernels is used to run on Emulator. KMI kernel branch : Android 11 introduced GKI, which separates the kernel into a Google-maintained kernel image and vendor maintained-modules, which are built separately. Android 11: android11-5.4 Android 12: android12-5.4 android12-5.10 Legacy dessert kernel branches : Legacy dessert kernels were created to guarantee that new feature development didn\u2019t interfere with merging from the Android Common Kernel. Android 10: android-4.9-q android-4.14-q android-4.19-q Android 11 android-4.14-stable android-4.19-stable Legacy release kernel branches : Release kernels are maintained to provide backports of patches cited in the monthly Android Security Bulletin. They were created for each launch kernel when there was a new Android platform release. Android 10: android-4.9-q-release android-4.14-q-release android-4.19-q-release","title":"Android Common Kernels"},{"location":"blog/android/build-aosp/#build-custom-kernel","text":"Download kernel and the target branch android-10.0.0_r47 android-12.1.0_r8 The above example use the AOSP android-10.0.0_r47 , which uses the kernel 4.14 . Checking on https://android.googlesource.com/kernel/manifest/+refs , there are some versions with 4.14 version: common-android-4.14 = common-android-4.14-stable has kernel/common at android-4.14-stable \u2192 this is for Android 11. q-common-android-4.14 has kernel/common at android-4.14-q \u2192 build config for goldfish is not completed. q-goldfish-android-goldfish-4.14-dev has kernel/common at android-goldfish-4.14-dev \u2192 having goldfish in name seems good for emulator. export KERNEL_BRANCH = \"q-goldfish-android-goldfish-4.14-dev\" mkdir kernel- $KERNEL_BRANCH && cd kernel- $KERNEL_BRANCH repo init \\ -u https://android.googlesource.com/kernel/manifest \\ -b $KERNEL_BRANCH \\ --depth = 1 The above example use the AOSP android-12.1.0_r8 , which uses the kernel 5.10 . So, you can select the Android Common Kernel on branch common-android12-5.10 . export KERNEL_BRANCH = \"common-android12-5.10\" mkdir kernel- $KERNEL_BRANCH && cd kernel- $KERNEL_BRANCH repo init \\ -u https://android.googlesource.com/kernel/manifest \\ -b $KERNEL_BRANCH \\ --depth = 1 Then sync the source code: repo sync -c -j $( nproc ) && sync Build the kernel : Install libs for building kernel: sudo apt install libssl-dev libelf-dev A common kernels are generic, customizable kernels and therefore don\u2019t define a default configuration. We have to set some environment settings: Environment variable Description Example BUILD_CONFIG Build config file from where you initialize the build environment. The location must be defined relative to the Repo root directory. Defaults to build.config. Mandatory for common kernels. BUILD_CONFIG=common/build.config.<target>.x86_64 CC Override compiler to be used. Falls back to the default compiler defined by build.config. CC=clang DIST_DIR Base output directory for the kernel distribution. DIST_DIR=/path/to/my/dist OUT_DIR Base output directory for the kernel build. OUT_DIR=/path/to/my/out SKIP_DEFCONFIG Skip make defconfig SKIP_DEFCONFIG=1 SKIP_MRPROPER Skip make mrproper SKIP_MRPROPER=1 bzImage vs vmlinux Big Z Image bzImage is a compressed version of the vmlinux with extra headers for booting up. vmlinux is a statically linked executable file that contains the Linux Kernel. android-10.0.0_r47 android-12.1.0_r8 Build the kernel (without Link Time Optimization (LTO) for testing): q-goldfish-android-goldfish-4.14-dev BUILD_CONFIG = goldfish/build.config.goldfish.x86_64 \\ LTO = none \\ build/build.sh If the build succeeds, there is a log to show the kernel image destination: q-goldfish-android-goldfish-4.14-dev Files copied to /mnt/work/kernel-q-goldfish-android-goldfish-4.14-dev/out/x86_64/dist Check the kernel file: q-goldfish-android-goldfish-4.14-dev file/mnt/work/kernel-q-goldfish-android-goldfish-4.14-dev/out/x86_64/dist/bzImage Linux kernel x86 boot executable bzImage, version 4 .14.175-g1aec57a9 ( build-user@build-host ) #1 SMP PREEMPT Wed May 4 05:03:19 UTC 2022, RO-rootFS, swap_dev 0x7, Normal VGA Fast re-build Not supported! From Android 11, Google introduced GKI, which separates the kernel into a Google-maintained kernel image and vendor maintained-modules, which are built separately. Build the kernel (without Link Time Optimization (LTO) for testing): common-android12-5.10 BUILD_CONFIG = common/build.config.gki.x86_64 \\ LTO = none \\ build/build.sh After build complete, check the kernel file: common-android12-5.10 file out/android12-5.10/dist/bzImage Linux kernel x86 boot executable bzImage, version 5.10.110-android12-9-00168-g131b12d50f16 (build-user@build-host) #1 SMP PREEMPT Fri May 27 16:2, RO-rootFS, swap_dev 0x15, Normal VGA Build vendor\u2019s modules , Android 12 Cuttlefish and Goldfish converge, so they share the same kernel virtual_device which can be built as below: common-android12-5.10 BUILD_CONFIG = common-modules/virtual-device/build.config.virtual_device.x86_64 \\ LTO = none \\ build/build.sh Fast re-build By default, Kernel is always built with mrproper target which removes all generated files + config + various backup files to create a clean build. When developing on one or a few modules, we can skip the some initial steps and start re-build immediately: common-android12-5.10 BUILD_CONFIG = common-modules/virtual-device/build.config.virtual_device.x86_64 \\ LTO = none \\ FAST_BUILD = 1 \\ SKIP_MRPROPER = 1 \\ SKIP_DEFCONFIG = 1 \\ build/build.sh","title":"Build custom kernel"},{"location":"blog/android/build-aosp/#include-custom-kernel","text":"For making a vendor module for kernel, refer to Kernel Module guide. Create a soft link to built custom kernel in AOSP root folder: android-10.0.0_r47 android-12.1.0_r8 ln -s /mnt/work/kernel-q-goldfish-android-goldfish-4.14-dev kernel-custom ln -s /mnt/work/kernel-common-android12-5.10 kernel-custom Edit the kernel make file: android-10.0.0_r47 android-12.1.0_r8 device/generic/goldfish/x86_64-kernel.mk PRODUCT_KERNEL_VERSION := 4 .14 PRODUCT_PROPERTY_OVERRIDES += \\ vendor.rild.libpath = /vendor/lib64/libgoldfish-ril.so PRODUCT_COPY_FILES += \\ device/generic/goldfish/data/etc/advancedFeatures.ini:advancedFeatures.ini \\ device/generic/goldfish/data/etc/encryptionkey.img:encryptionkey.img \\ kernel-custom/out/x86_64/dist/bzImage:kernel-ranchu PRODUCT_SDK_ADDON_COPY_FILES += \\ device/generic/goldfish/data/etc/advancedFeatures.ini:images/x86_64/advancedFeatures.ini \\ device/generic/goldfish/data/etc/encryptionkey.img:images/x86_64/encryptionkey.img \\ kernel-custom/out/x86_64/dist/bzImage:images/x86_64/kernel-ranchu PRODUCT_SHIPPING_API_LEVEL := 28 TARGET_USES_MKE2FS := true device/generic/goldfish/x86_64-kernel.mk TARGET_KERNEL_USE ?= 5 .10 KERNEL_MODULES_PATH := kernel-custom/out/android12- $( TARGET_KERNEL_USE ) /dist KERNEL_MODULES_EXCLUDE := \\ $( KERNEL_MODULES_PATH ) /virt_wifi.ko \\ $( KERNEL_MODULES_PATH ) /virt_wifi_sim.ko BOARD_VENDOR_RAMDISK_KERNEL_MODULES += \\ $( filter-out $( KERNEL_MODULES_EXCLUDE ) , $( wildcard $( KERNEL_MODULES_PATH ) /*.ko )) EMULATOR_KERNEL_FILE := $( KERNEL_MODULES_PATH ) /bzImage Finally, make system image again: m all -j $( nproc ) and run the emulator: emulator -verbose -show-kernel -selinux permissive -writable-system Use adb to access to the Emulator shell and check the Kernel version.","title":"Include custom kernel"},{"location":"blog/android/build-aosp/#soong-build-system","text":"The Soong build system was introduced in Android 7.0 (Nougat) to replace Make . It leverages the Kati GNU Make clone tool and Ninja build system component to speed up builds of Android. Blueprint file format By design, Android.bp files are simple. They don\u2019t contain conditionals or control flow statements; all complexity is handled by build logic written in Go. A module in an Android.bp file starts with a module type followed by a set of properties in name: \"value\" format. Every module must have a name property, and the value must be unique across all Android.bp files, except for the name property values in namespaces and prebuilt modules, which may repeat. The srcs property specifies the source files used to build the module, as a list of strings. Soong can build many modules, refer to Soong Modules Reference and select a target module for more details. Below are examples for cc_binary , and cc_library_shared with their corresponding old Makefiles:","title":"Soong Build System"},{"location":"blog/android/build-aosp/#binary","text":"Android.bp cc_binary { name : \"invcase\" , srcs : [ \"invcase.c\" ] , shared_libs : [ \"libinvcase\" ] , } Android.mk LOCAL_PATH := $( call my-dir ) include $(CLEAR_VARS) LOCAL_MODULE := invcase LOCAL_SRC_FILES := invcase.c LOCAL_SHARED_LIBRARIES += libinvcase include $(BUILD_EXECUTABLE)","title":"Binary"},{"location":"blog/android/build-aosp/#shared-library","text":"Android.bp cc_library_shared { name : \"libinvcase\" , srcs : [ \"libinvcase.c\" ] , } Android.mk LOCAL_PATH := $( call my-dir ) include $(CLEAR_VARS) LOCAL_MODULE := libinvcase LOCAL_SRC_FILES := libinvcase.c include $(BUILD_SHARED_LIBRARY)","title":"Shared Library"},{"location":"blog/android/build-aosp/notes/","tags":["android","notes"],"text":"Bionic # Bionic is an implementation of the standard C library, developed by Google for its Android operating system. It differs from the GNU C Library (glibc) in being designed for devices with less memory and processor power than a typical Linux system. Bionic is a C library for use with the Linux kernel, and provides libc , libdl , and libm ( libpthread functionality is part of libc , not a separate library as on some other systems). Repo: https://android.googlesource.com/platform/bionic/ Bionic only supports Linux kernels, but currently supports the arm , arm64 , x86 , and x86-64 architectures. inherit-product # In Makefiles, we usually see the command to inherit another product: $( call inherit-product, <makefile.mk> ) # or $( call inherit-product-if-exist, <makefile.mk> ) The function inherit-product is defined in build/core/product.mk : build/core/product.mk # # Functions for including product makefiles # # $(1): product to inherit # # To be called from product makefiles, and is later evaluated during the import-nodes # call below. It does three things: # 1. Inherits all of the variables from $1. # 2. Records the inheritance in the .INHERITS_FROM variable # 3. Records the calling makefile in PARENT_PRODUCT_FILES # # (2) and (3) can be used together to reconstruct the include hierarchy # See e.g. product-graph.mk for an example of this. # define inherit-product $(if $( findstring ../, $( 1 )) , \\ $( eval np : = $( call normalize-paths, $( 1 ))) , \\ $( eval np : = $( strip $( 1 )))) \\ $( foreach v, $( _product_var_list ) , \\ $( eval $( v ) : = $($( v )) $( INHERIT_TAG )$( np ))) \\ $( eval current_mk : = $( strip $( word 1 , $( _include_stack )))) \\ $( eval inherit_var : = PRODUCTS. $( current_mk ) .INHERITS_FROM ) \\ $( eval $( inherit_var ) : = $( sort $($( inherit_var )) $( np ))) \\ $( eval PARENT_PRODUCT_FILES : = $( sort $( PARENT_PRODUCT_FILES ) $( current_mk ))) endef Let\u2019s say you have: PRODUCT_VAR := a in A.mk PRODUCT_VAR := b in B.mk If you include B.mk in_ A.mk_, you will get PRODUCT_VAR := b at last. If you inherit-product B.mk in A.mk , you will get PRODUCT_VAR := a b , note the order is a then b . And inherit-product makes sure that you won\u2019t include a makefile twice because it Records that we\u2019ve visited this node, in PARENT_PRODUCT_FILES . PRODUCT_COPY_FILES # When using inherit-product , there are cases that a destination file is copied from many sources. For example: A.mk PRODUCT_COPY_FILES += \\ /path/a.txt:/path/target.txt $( call inherit-product , B.mk ) B.mk PRODUCT_COPY_FILES += \\ /path/b.txt:/path/target.txt After the inherit-product call, the variable has been changed as: PRODUCT_COPY_FILES += \\ /path/a.txt:/path/target.txt \\ /path/b.txt:/path/target.txt The rule for PRODUCT_COPY_FILES is: only eval the copy rule if this src:dest pair is the first one to match the same dest . Therefore, only the rule /path/a.txt:/path/target.txt is evaluated. The rules for PRODUCT_COPY_FILES is defined in build/core/Makefile : build/core/Makefile # ----------------------------------------------------------------- # Define rules to copy PRODUCT_COPY_FILES defined by the product. # PRODUCT_COPY_FILES contains words like <source file>:<dest file>[:<owner>]. # <dest file> is relative to $(PRODUCT_OUT), so it should look like, # e.g., \"system/etc/file.xml\". # The filter part means \"only eval the copy-one-file rule if this # src:dest pair is the first one to match the same dest\" #$(1): the src:dest pair #$(2): the dest define check-product-copy-files $( if $( filter-out $( TARGET_COPY_OUT_SYSTEM_OTHER ) /%, $( 2 )) , \\ $( if $( filter % .apk , $( 2 )) , $( error \\ Prebuilt apk found in PRODUCT_COPY_FILES : $( 1 ) , use BUILD_PREBUILT instead ! ))) endef # filter out the duplicate <source file>:<dest file> pairs. unique_product_copy_files_pairs := $( foreach cf , $( PRODUCT_COPY_FILES ) , \\ $( if $( filter $( unique_product_copy_files_pairs ) , $( cf )) ,,\\ $( eval unique_product_copy_files_pairs += $( cf )))) unique_product_copy_files_destinations := product_copy_files_ignored := $( foreach cf , $( unique_product_copy_files_pairs ) , \\ $( eval _src := $( call word-colon , 1 , $( cf ))) \\ $( eval _dest := $( call word-colon , 2 , $( cf ))) \\ $( call check-product-copy-files , $( cf ) , $( _dest )) \\ $( if $( filter $( unique_product_copy_files_destinations ) , $( _dest )) , \\ $( eval product_copy_files_ignored += $( cf )) , \\ $( eval _fulldest := $( call append-path , $( PRODUCT_OUT ) , $( _dest ))) \\ $( if $( filter % .xml , $( _dest )) ,\\ $( eval $( call copy-xml-file-checked , $( _src ) , $( _fulldest ))) ,\\ $( if $( and $( filter % .jar , $( _dest )) , $( filter $( basename $( notdir $( _dest ))) , $( PRODUCT_LOADED_BY_PRIVILEGED_MODULES ))) ,\\ $( eval $( call copy-and-uncompress-dexs , $( _src ) , $( _fulldest ))) , \\ $( if $( filter init % rc , $( notdir $( _dest )))$( filter %/ etc / init , $( dir $( _dest ))) ,\\ $( eval $( call copy-init-script-file-checked , $( _src ) , $( _fulldest ))) ,\\ $( eval $( call copy-one-file , $( _src ) , $( _fulldest )))))) \\ $( eval unique_product_copy_files_destinations += $( _dest )))) # Dump a list of overriden (and ignored PRODUCT_COPY_FILES entries) pcf_ignored_file := $( PRODUCT_OUT ) /product_copy_files_ignored.txt $(pcf_ignored_file) : PRIVATE_IGNORED := $( sort $( product_copy_files_ignored )) $(pcf_ignored_file) : echo \" $( PRIVATE_IGNORED ) \" | tr \" \" \"\\n\" > $@ $(call dist-for-goals,droidcore,$(pcf_ignored_file) : logs / $( notdir $( pcf_ignored_file )) ) pcf_ignored_file := product_copy_files_ignored := unique_product_copy_files_pairs := unique_product_copy_files_destinations :=","title":"AOSP Build Notes"},{"location":"blog/android/build-aosp/notes/#bionic","text":"Bionic is an implementation of the standard C library, developed by Google for its Android operating system. It differs from the GNU C Library (glibc) in being designed for devices with less memory and processor power than a typical Linux system. Bionic is a C library for use with the Linux kernel, and provides libc , libdl , and libm ( libpthread functionality is part of libc , not a separate library as on some other systems). Repo: https://android.googlesource.com/platform/bionic/ Bionic only supports Linux kernels, but currently supports the arm , arm64 , x86 , and x86-64 architectures.","title":"Bionic"},{"location":"blog/android/build-aosp/notes/#inherit-product","text":"In Makefiles, we usually see the command to inherit another product: $( call inherit-product, <makefile.mk> ) # or $( call inherit-product-if-exist, <makefile.mk> ) The function inherit-product is defined in build/core/product.mk : build/core/product.mk # # Functions for including product makefiles # # $(1): product to inherit # # To be called from product makefiles, and is later evaluated during the import-nodes # call below. It does three things: # 1. Inherits all of the variables from $1. # 2. Records the inheritance in the .INHERITS_FROM variable # 3. Records the calling makefile in PARENT_PRODUCT_FILES # # (2) and (3) can be used together to reconstruct the include hierarchy # See e.g. product-graph.mk for an example of this. # define inherit-product $(if $( findstring ../, $( 1 )) , \\ $( eval np : = $( call normalize-paths, $( 1 ))) , \\ $( eval np : = $( strip $( 1 )))) \\ $( foreach v, $( _product_var_list ) , \\ $( eval $( v ) : = $($( v )) $( INHERIT_TAG )$( np ))) \\ $( eval current_mk : = $( strip $( word 1 , $( _include_stack )))) \\ $( eval inherit_var : = PRODUCTS. $( current_mk ) .INHERITS_FROM ) \\ $( eval $( inherit_var ) : = $( sort $($( inherit_var )) $( np ))) \\ $( eval PARENT_PRODUCT_FILES : = $( sort $( PARENT_PRODUCT_FILES ) $( current_mk ))) endef Let\u2019s say you have: PRODUCT_VAR := a in A.mk PRODUCT_VAR := b in B.mk If you include B.mk in_ A.mk_, you will get PRODUCT_VAR := b at last. If you inherit-product B.mk in A.mk , you will get PRODUCT_VAR := a b , note the order is a then b . And inherit-product makes sure that you won\u2019t include a makefile twice because it Records that we\u2019ve visited this node, in PARENT_PRODUCT_FILES .","title":"inherit-product"},{"location":"blog/android/build-aosp/notes/#product_copy_files","text":"When using inherit-product , there are cases that a destination file is copied from many sources. For example: A.mk PRODUCT_COPY_FILES += \\ /path/a.txt:/path/target.txt $( call inherit-product , B.mk ) B.mk PRODUCT_COPY_FILES += \\ /path/b.txt:/path/target.txt After the inherit-product call, the variable has been changed as: PRODUCT_COPY_FILES += \\ /path/a.txt:/path/target.txt \\ /path/b.txt:/path/target.txt The rule for PRODUCT_COPY_FILES is: only eval the copy rule if this src:dest pair is the first one to match the same dest . Therefore, only the rule /path/a.txt:/path/target.txt is evaluated. The rules for PRODUCT_COPY_FILES is defined in build/core/Makefile : build/core/Makefile # ----------------------------------------------------------------- # Define rules to copy PRODUCT_COPY_FILES defined by the product. # PRODUCT_COPY_FILES contains words like <source file>:<dest file>[:<owner>]. # <dest file> is relative to $(PRODUCT_OUT), so it should look like, # e.g., \"system/etc/file.xml\". # The filter part means \"only eval the copy-one-file rule if this # src:dest pair is the first one to match the same dest\" #$(1): the src:dest pair #$(2): the dest define check-product-copy-files $( if $( filter-out $( TARGET_COPY_OUT_SYSTEM_OTHER ) /%, $( 2 )) , \\ $( if $( filter % .apk , $( 2 )) , $( error \\ Prebuilt apk found in PRODUCT_COPY_FILES : $( 1 ) , use BUILD_PREBUILT instead ! ))) endef # filter out the duplicate <source file>:<dest file> pairs. unique_product_copy_files_pairs := $( foreach cf , $( PRODUCT_COPY_FILES ) , \\ $( if $( filter $( unique_product_copy_files_pairs ) , $( cf )) ,,\\ $( eval unique_product_copy_files_pairs += $( cf )))) unique_product_copy_files_destinations := product_copy_files_ignored := $( foreach cf , $( unique_product_copy_files_pairs ) , \\ $( eval _src := $( call word-colon , 1 , $( cf ))) \\ $( eval _dest := $( call word-colon , 2 , $( cf ))) \\ $( call check-product-copy-files , $( cf ) , $( _dest )) \\ $( if $( filter $( unique_product_copy_files_destinations ) , $( _dest )) , \\ $( eval product_copy_files_ignored += $( cf )) , \\ $( eval _fulldest := $( call append-path , $( PRODUCT_OUT ) , $( _dest ))) \\ $( if $( filter % .xml , $( _dest )) ,\\ $( eval $( call copy-xml-file-checked , $( _src ) , $( _fulldest ))) ,\\ $( if $( and $( filter % .jar , $( _dest )) , $( filter $( basename $( notdir $( _dest ))) , $( PRODUCT_LOADED_BY_PRIVILEGED_MODULES ))) ,\\ $( eval $( call copy-and-uncompress-dexs , $( _src ) , $( _fulldest ))) , \\ $( if $( filter init % rc , $( notdir $( _dest )))$( filter %/ etc / init , $( dir $( _dest ))) ,\\ $( eval $( call copy-init-script-file-checked , $( _src ) , $( _fulldest ))) ,\\ $( eval $( call copy-one-file , $( _src ) , $( _fulldest )))))) \\ $( eval unique_product_copy_files_destinations += $( _dest )))) # Dump a list of overriden (and ignored PRODUCT_COPY_FILES entries) pcf_ignored_file := $( PRODUCT_OUT ) /product_copy_files_ignored.txt $(pcf_ignored_file) : PRIVATE_IGNORED := $( sort $( product_copy_files_ignored )) $(pcf_ignored_file) : echo \" $( PRIVATE_IGNORED ) \" | tr \" \" \"\\n\" > $@ $(call dist-for-goals,droidcore,$(pcf_ignored_file) : logs / $( notdir $( pcf_ignored_file )) ) pcf_ignored_file := product_copy_files_ignored := unique_product_copy_files_pairs := unique_product_copy_files_destinations :=","title":"PRODUCT_COPY_FILES"},{"location":"blog/android/hal/aidl/","tags":["android","hal","aidl"],"text":"This guide is written for AOSP android-12.1.0_r8 AIDL for HALs # Official overview guide is at https://source.android.com/devices/architecture/aidl/aidl-hals . AIDL has been around longer than HIDL (only from Android 8 to Android 10), and is used in many other places, such as between Android framework components or in apps. Now that AIDL has stability support, it\u2019s possible to implement an entire stack with a single IPC runtime. AIDL also has a better versioning system than HIDL. AIDL HAL interfaces # For an AIDL interface to be used between system and vendor, the interface needs two changes: Every type definition must be annotated with @VintfStability . The aidl_interface declaration needs to include stability: \"vintf\", AOSP Stable AIDL interfaces for HALs are in the same base directories as HIDL interfaces, in aidl folders. hardware/interfaces frameworks/hardware/interfaces system/hardware/interfaces Example : hardware/interfaces/light/aidl/Android.bp aidl_i nterfa ce { na me : \"android.hardware.light\" , ve n dor_available : true , srcs : [ \"android/hardware/light/*.aidl\" , ], s ta bili t y : \"vintf\" , backe n d : { java : { sdk_versio n : \"module_current\" , }, n dk : { v n dk : { e na bled : true , }, }, }, versio ns : [ \"1\" ], } AIDL runtime library # AIDL has three different backends: Java, NDK, CPP. To use Stable AIDL, you must always use the system copy of libbinder at system/lib*/libbinder.so and talk on /dev/binder . For code on the vendor image, this means that libbinder (from the VNDK) cannot be used. Instead, native vendor code must use the NDK backend of AIDL, link against libbinder_ndk (which is backed by system libbinder.so), and link against the -ndk_platform libraries created by aidl_interface entries. Convert HIDL to AIDL # Build the tool hidl2aidl if it is not compiled: m hidl2aidl Create a new folder aidl in the HAL interface: mkdir -p hardware/interfaces/invcase/aidl Generate AIDL from a specific HIDL version: hidl2aidl -o hardware/interfaces/invcase/aidl \\ -r android.hardware:hardware/interfaces \\ android.hardware.invcase@1.0 This will create aidl/android/hardware/invcase/IInvcase.aidl file. AIDL package android.hardware.invcase ; @VintfStability interface IInvcase { String getChars (); void putChars ( in String msg ); } HIDL package android.hardware.invcase @ 1.0 ; interface IInvcase { putChars ( string msg ); getChars () generates ( string msg ); }; The tool also generates a makefile for the AIDL, but it is not usable at the moment: AIDL aidl_interface { name : \"android.hardware.invcase\" , vendor : true , srcs : [ \"android/hardware/invcase/*.aidl\" ] , stability : \"vintf\" , owner : \"vqtrong\" , backend : { cpp : { enabled : false , }, java : { sdk_version : \"module_current\" , }, }, } HIDL // This file is autogenerated by hidl-gen -Landroidbp. hidl_interface { name : \"android.hardware.invcase@1.0\" , root : \"android.hardware\" , vndk : { enabled : true , }, srcs : [ \"IInvcase.hal\" , ] , interfaces : [ \"android.hidl.base@1.0\" , ] , gen_java : false , } Framework Stacks # Differences between Binderized HIDL for HAL and AIDL for HAL : Binderized HAL in the Framework stacks AIDL HAL in the Framework stacks Implementation # aidl_hal.zip Refer to Kernel Module to build and install a module to system. This guide assumes that invcase module is loaded as below: device/generic/goldfish/init.ranchu.rc + on boot + insmod /system/lib/modules/invcase.ko + chown system system /dev/invcase + chmod 0600 /dev/invcase Overview # AOSP build make target product base_vendor.mk Include new packages + PRODUCT_PACKAGES += \\ + android.hardware.invcase \\ + android.hardware.invcase-service \\ + Invcase packages apps Invcase src com invcase Invcase.java Bind to IInvcase interface import android.hardware.invcase.IInvcase ; class Invcase extends Activity { IInvcase invcaseAJ ; // AIDL Java onCreate () { IBinder binder = ServiceManager . getService ( IINVCASE_AIDL_INTERFACE ); invcaseAJ = IInvcase . Stub . asInterface ( binder ); } } res layout mipmap values AndroidManifest.xml Export main activity on Launcher <manifest package= \"com.invcase\" > <application> <activity android:name= \".Invcase\" android:exported= \"true\" > <intent-filter> <action android:name= \"android.intent.action.MAIN\" /> <category android:name= \"android.intent.category.LAUNCHER\" /> </intent-filter> </activity> </application> </manifest> android:exported=\"true\" is mandatory on Android 12 Android.bp android_app { name : \"Invcase\" , srcs : [ \"src/**/*.java\" ] , platform_apis : true static_libs : [ \"android.hardware.invcase-V1-java\" ] } platform_apis: true : use System API when do not specify any target platform android.hardware.invcase-V1-java : Java proxy for the AIDL of HAL, directly callable from User App hardware interfaces invcase aidl Android.bp android hardware invcase IInvcase.aidl @VintfStability interface IInvcase { String getChars (); void putChars ( in String msg ); } default Android.bp Invcase.h Invcase.cpp service.cpp compatible_matrices compatible_matrix.current.xml + <hal format=\"aidl\" optional=\"true\"> + <name>android.hardware.invcase</name> + <version>1</version> + <interface> + <name>IInvcase</name> + <instance>default</instance> + </interface> + </hal> Define HAL Interface # Create a new AIDL file in the folder hardware/interfaces/invcase/aidl : hardware/interfaces/invcase/aidl/android/hardware/invcase/IInvcase.aidl package android.hardware.invcase ; @VintfStability interface IInvcase { String getChars (); void putChars ( in String msg ); } Configure build # Select the backend: We will use NDK (as recommended), so declare the CPP backend as false . Set vendor: true and remove vendor_available because this is a custom vendor HAL Remove vndk section, so this HAL is located in /vendor only VNDK VNDK Build Example VNDK Extension aidl_interface { name : \"android.hardware.invcase\" , vendor : true, srcs : [ \"android/hardware/invcase/*.aidl\" ] , stability : \"vintf\" , owner : \"vqtrong\" , backend : { cpp : { enabled : false , }, java : { sdk_version : \"module_current\" , }, } , } At this time, if try to build the module with: mmm hardware/interfaces/invcase/ you will get error about the API missing: API dump for the current version of AIDL interface android.hardware.invcase does not exist. Run `m android.hardware.invcase-update-api`, or add `unstable: true` to the build rule for the interface if it does not need to be versioned. We need to freeze the API by running: m android.hardware.invcase-update-api versioning Since there is no version 1, the current version is version 1, but once we perform a change to the API, we will upgrade the aidl. The current folder needs to be renamed to 1 and a new current folder needs to be created representing version 2. Ok, build it again: mmm hardware/interfaces/invcase/ Then include the module to the system : build/make/target/product/base_vendor.mk PRODUCT_PACKAGES += \\ android.hardware.invcase \\ Implement HAL # We will use the ndk_platfrom library, therefore, let check the generated code for ndk_platform . cd out/soong/.intermediates/hardware/interfaces/invcase/aidl/android.hardware.invcase-V1-ndk_platform-source find . . ./gen ./gen/timestamp ./gen/include ./gen/include/aidl ./gen/include/aidl/android ./gen/include/aidl/android/hardware ./gen/include/aidl/android/hardware/invcase ./gen/include/aidl/android/hardware/invcase/BpInvcase.h ./gen/include/aidl/android/hardware/invcase/IInvcase.h ./gen/include/aidl/android/hardware/invcase/BnInvcase.h ./gen/android ./gen/android/hardware ./gen/android/hardware/invcase ./gen/android/hardware/invcase/IInvcase.cpp.d ./gen/android/hardware/invcase/IInvcase.cpp Our interface APIs are converted to APIs as below: IInvcase.h virtual :: ndk :: ScopedAStatus getChars ( std :: string * _aidl_return ) = 0 ; virtual :: ndk :: ScopedAStatus putChars ( const std :: string & in_msg ) = 0 ; They are virtual functions and then need to be defined. Header file hardware/interfaces/invcase/aidl/default/Invcase.h #pragma once #include <aidl/android/hardware/invcase/BnInvcase.h> namespace aidl { namespace android { namespace hardware { namespace invcase { class Invcase : public BnInvcase { public : //String getChars(); ndk :: ScopedAStatus getChars ( std :: string * _aidl_return ); //void putChars(in String msg); ndk :: ScopedAStatus putChars ( const std :: string & in_msg ); }; } // namespace invcase } // namespace hardware } // namespace android } // namespace aidl Implementation hardware/interfaces/invcase/aidl/default/Invcase.cpp #define LOG_TAG \"Invcase\" #include <utils/Log.h> #include <iostream> #include <fstream> #include \"Invcase.h\" namespace aidl { namespace android { namespace hardware { namespace invcase { //String getChars(); ndk :: ScopedAStatus Invcase::getChars ( std :: string * _aidl_return ) { std :: ifstream invcase_dev ; invcase_dev . open ( \"/dev/invcase\" ); if ( invcase_dev . good ()) { std :: string line ; invcase_dev >> line ; ALOGD ( \"Invcase service: getChars: %s\" , line . c_str ()); * _aidl_return = line ; } else { ALOGE ( \"getChars: can not open /dev/invcase\" ); return ndk :: ScopedAStatus :: fromServiceSpecificError ( -1 ); } return ndk :: ScopedAStatus :: ok (); } //void putChars(in String msg); ndk :: ScopedAStatus Invcase::putChars ( const std :: string & in_msg ) { std :: ofstream invcase_dev ; invcase_dev . open ( \"/dev/invcase\" ); if ( invcase_dev . good ()) { invcase_dev << in_msg ; ALOGD ( \"Invcase service: putChars: %s\" , in_msg . c_str ()); } else { ALOGE ( \"putChars: can not open /dev/invcase\" ); return ndk :: ScopedAStatus :: fromServiceSpecificError ( -1 ); } return ndk :: ScopedAStatus :: ok (); } } // namespace invcase } // namespace hardware } // namespace android } // namespace aidl Implement HAL Service # The HAL service will run in its own process, like in HIDL . Create a new folder for implementation in hardware/interfaces/invcase/aidl/default : Service implementation hardware/interfaces/invcase/aidl/default/service.cpp #define LOG_TAG \"Invcase\" #include <android-base/logging.h> #include <android/binder_manager.h> #include <android/binder_process.h> #include <binder/ProcessState.h> #include <binder/IServiceManager.h> #include \"Invcase.h\" using aidl :: android :: hardware :: invcase :: Invcase ; using std :: string_literals :: operator \"\" s ; void logd ( std :: string msg ) { std :: cout << msg << std :: endl ; ALOGD ( \"%s\" , msg . c_str ()); } void loge ( std :: string msg ) { std :: cout << msg << std :: endl ; ALOGE ( \"%s\" , msg . c_str ()); } int main () { // Enable vndbinder to allow vendor-to-venfor binder call android :: ProcessState :: initWithDriver ( \"/dev/vndbinder\" ); ABinderProcess_setThreadPoolMaxThreadCount ( 0 ); ABinderProcess_startThreadPool (); std :: shared_ptr < Invcase > invcase = ndk :: SharedRefBase :: make < Invcase > (); const std :: string name = Invcase :: descriptor + \"/default\" s ; if ( invcase != nullptr ) { if ( AServiceManager_addService ( invcase -> asBinder (). get (), name . c_str ()) != STATUS_OK ) { loge ( \"Failed to register IInvcase service\" ); return -1 ; } } else { loge ( \"Failed to get IInvcase instance\" ); return -1 ; } logd ( \"IInvcase service starts to join service pool\" ); ABinderProcess_joinThreadPool (); return EXIT_FAILURE ; // should not reached } vndbinder Normally, vendor processes don\u2019t open the binder driver directly and instead link against the libbinder userspace library, which opens the binder driver. Adding a method for ::android::ProcessState() selects the binder driver for libbinder . Vendor processes should call this method before calling into ProcessState , IPCThreadState , or before making any binder calls in general. To use, place the following call after the main() of a vendor process (client and server): #include <binder/ProcessState.h> int main () { android :: ProcessState :: initWithDriver ( \"/dev/vndbinder\" ); } Thread management Every instance of libbinder in a process maintains one threadpool. For most use cases, this should be exactly one threadpool, shared across all backends. The only exception to this is when vendor code might load another copy of libbinder to talk to /dev/vndbinder. Since this is on a separate binder node, the threadpool isn\u2019t shared. In the NDK backend: bool success = ABinderProcess_setThreadPoolMaxThreadCount ( 0 ); ABinderProcess_startThreadPool (); ABinderProcess_joinThreadPool (); Build Service Similar to the HIDL module, we will create a cc_binary module in the Android.bp . AIDL has three different backends: Java, NDK, CPP. To use Stable AIDL, you must always use the system copy of libbinder at system/lib*/libbinder.so and talk on /dev/binder . For code on the vendor image, this means that libbinder (from the VNDK) cannot be used: this library has an unstable C++ API and unstable internals. Instead, native vendor code must use the NDK backend of AIDL, link against libbinder_ndk (which is backed by system libbinder.so ), and link against the -ndk_platform libraries created by aidl_interface entries. hardware/interfaces/invcase/aidl/default/Android.bp cc_binary { name : \"android.hardware.invcase-service\" , vendor : true, relative_install_path : \"hw\" , init_rc : [ \"android.hardware.invcase-service.rc\" ] , vintf_fragments : [ \"android.hardware.invcase-service.xml\" ] , srcs : [ \"Invcase.cpp\" , \"service.cpp\" , ] , cflags : [ \"-Wall\" , \"-Werror\" , ] , shared_libs : [ \"libbase\" , \"liblog\" , \"libhardware\" , \"libbinder_ndk\" , \"libbinder\" , \"libutils\" , \"android.hardware.invcase-V1-ndk_platform\" , ] , } Then include the service to the system: build/make/target/product/base_vendor.mk PRODUCT_PACKAGES += \\ android.hardware.invcase \\ android.hardware.invcase-service \\ Run Service We need to define the service with the init process, so it can start whenever the hal class is started. To do this, we will create a new android.hardware.invcase-service.rc : hardware/interfaces/invcase/aidl/default/android.hardware.invcase-service.rc service android.hardware.invcase-service /vendor/bin/hw/android.hardware.invcase-service interface aidl android.hardware.invcase.IInvcase/default class hal user system group system Expose AIDL Interface A new VINTF AIDL object should be declared as below: hardware/interfaces/invcase/aidl/default/android.hardware.invcase-service.xml <manifest version= \"1.0\" type= \"device\" > <hal format= \"aidl\" > <name> android.hardware.invcase </name> <version> 1 </version> <fqname> IInvcase/default </fqname> </hal> </manifest> If this is a new package, add it to the latest framework compatibility matrix. If no interface should be added to the framework compatibility matrix (e.g. types-only package), add it to the exempt list in libvintf_fcm_exclude . hardware/interfaces/compatibility_matrices/compatibility_matrix.6.xml hardware/interfaces/compatibility_matrices/compatibility_matrix.current.xml <hal format= \"aidl\" optional= \"true\" > <name> android.hardware.invcase </name> <version> 1 </version> <interface> <name> IInvcase </name> <instance> default </instance> </interface> </hal> Define SELinux Policy for HAL service # To make the service run at boot, HAL service needs to be registered to system under a security policy. Declare new type system/sepolicy/prebuilts/api/32.0/public/hwservice.te system/sepolicy/public/hwservice.te type hal_invcase_hwservice, hwservice_manager_type; Set compatibility Ignore in API 31, which also ignore in lower API: system/sepolicy/prebuilts/api/32.0/private/compat/31.0/31.0.ignore.cil system/sepolicy/private/compat/31.0/31.0.ignore.cil (type new_objects) (typeattribute new_objects) (typeattributeset new_objects ( new_objects hal_invcase_hwservice ) ) Add service path Add a new label in the: system/sepolicy/vendor/file_contexts /(vendor|system/vendor)/bin/hw/android\\.hardware\\.invcase-service u:object_r:hal_invcase_service_exec:s0 Set service context interface : system/sepolicy/prebuilts/api/32.0/private/hwservice_contexts system/sepolicy/private/hwservice_contexts android.hardware.invcase::IInvcase u:object_r:hal_invcase_hwservice:s0 Declare attribute : system/sepolicy/prebuilts/api/32.0/public/attributes system/sepolicy/public/attributes hal_attribute(invcase); this is macro for adding below attributes: attribute hal_invcase; attribute hal_invcase_client; attribute hal_invcase_server;mon Define default domain : system/sepolicy/vendor/hal_invcase_service.te type hal_invcase_service, domain; hal_server_domain(hal_invcase_service, hal_invcase) type hal_invcase_service_exec, exec_type, vendor_file_type, vendor_file_type, file_type; init_daemon_domain(hal_invcase_service) Set binder policy : system/sepolicy/prebuilts/api/32.0/public/hal_invcase.te system/sepolicy/public/hal_invcase.te binder_call(hal_invcase_client, hal_invcase_server) binder_call(hal_invcase_server, hal_invcase_client) hal_attribute_hwservice(hal_invcase, hal_invcase_hwservice) Declare system_server as client of HAL service : system/sepolicy/prebuilts/api/29.0/private/system_server.te system/sepolicy/private/system_server.te hal_client_domain(system_server, hal_invcase) Deliver HAL module # VNDK Vendor Native Development Kit (VNDK) is a set of libraries exclusively for vendors to implement their HALs. The VNDK ships in system.img and is dynamically linked to vendor code at runtime. Refer to https://source.android.com/devices/architecture/vndk/build-system . Include HAL service and the test app to the PRODUCT_PACKAGES : build/target/product/base_vendor.mk + PRODUCT_PACKAGES += \\ + android.hardware.invcase-service \\ This will include below files to system: /vendor/lib/hw/android.hardware.invcase-service User App # The User App will be very simple to test the hardware. It contains an EditText to get user input, a Button to execute commands, and a TextView to display the result. Implement the User App Use getSystemService(Context.INVCASE_SERVICE) to obtain the instance of InvcaseManager Call to hardware through the InvcaseManager APIs packages/apps/Invcase/src/com/invcase/Invcase.java package com.invcase ; import android.content.Context ; import android.app.Activity ; import android.os.Bundle ; import android.view.View ; import android.widget.Button ; import android.widget.EditText ; import android.widget.TextView ; import android.util.Log ; import android.os.ServiceManager ; import android.os.IBinder ; import android.hardware.invcase.IInvcase ; public class Invcase extends Activity { private static final String TAG = \"Invcase\" ; private static final String IINVCASE_AIDL_INTERFACE = \"android.hardware.invcase.IInvcase/default\" ; private static IInvcase invcaseAJ ; // AIDL Java @Override protected void onCreate ( Bundle savedInstanceState ) { super . onCreate ( savedInstanceState ); setContentView ( R . layout . activity_main ); Button btn = ( Button ) findViewById ( R . id . button ); btn . setOnClickListener ( new View . OnClickListener () { @Override public void onClick ( View view ) { EditText editText = ( EditText ) findViewById ( R . id . editText ); String txt = editText . getText (). toString (); Log . d ( TAG , \"App: request= \" + txt ); if ( invcaseAJ != null ) { try { invcaseAJ . putChars ( txt ); } catch ( android . os . RemoteException e ) { Log . e ( TAG , \"IInvcase-AIDL error\" , e ); } } String ret = \"\" ; if ( invcaseAJ != null ) { try { ret = invcaseAJ . getChars (); } catch ( android . os . RemoteException e ) { Log . e ( TAG , \"IInvcase-AIDL error\" , e ); } } Log . d ( TAG , \"App: get= \" + ret ); TextView tv = ( TextView ) findViewById ( R . id . textView ); tv . setText ( ret ); } }); IBinder binder = ServiceManager . getService ( IINVCASE_AIDL_INTERFACE ); if ( binder == null ) { Log . e ( TAG , \"Getting \" + IINVCASE_AIDL_INTERFACE + \" service daemon binder failed!\" ); } else { invcaseAJ = IInvcase . Stub . asInterface ( binder ); if ( invcaseAJ == null ) { Log . e ( TAG , \"Getting IInvcase AIDL daemon interface failed!\" ); } else { Log . d ( TAG , \"IInvcase AIDL daemon interface is binded!\" ); } } } } Add User App to the Launcher packages/apps/Invcase/AndroidManifest.xml <?xml version=\"1.0\" encoding=\"utf-8\"?> <manifest xmlns:android= \"http://schemas.android.com/apk/res/android\" package= \"com.invcase\" > <application android:icon= \"@mipmap/ic_launcher\" android:label= \"@string/app_name\" > <activity android:name= \".Invcase\" android:exported= \"true\" android:label= \"@string/app_name\" > <intent-filter> <action android:name= \"android.intent.action.MAIN\" /> <category android:name= \"android.intent.category.LAUNCHER\" /> </intent-filter> </activity> </application> </manifest> on Android 12, must use android:exported=\"true\" Build User App packages/apps/Invcase/Android.bp android_app { name : \"Invcase\" , platform_apis : true, srcs : [ \"src/**/*.java\" ] , static_libs : [ \"android.hardware.invcase-V1-java\" ] } Add User App to system packages : build/target/product/base_vendor.mk + PRODUCT_PACKAGES += \\ + Invcase Permission # The device /dev/invcase is created at boot with root permission. The HAL Library is loaded when JNI Wrapper for Invcase Service is run, therefore, HAL code will run with system permission which attaches to the system_server process. The Android Init Language uses init*.rc files to automatically do some actions when a condition is met. For the target hardware, Android Init will use init.<hardware>.rc file. On Emulator, it is init.ranchu.rc . Add below lines to change the owner and permission on the /dev/invcase at boot: device/generic/goldfish/init.ranchu.rc + on boot + chown system system /dev/invcase + chmod 0600 /dev/invcase Build and Run # The Invcase Manager exports new Service APIs, therefore, need to rebuild the list of system APIs. m all -j $( nproc ) Run the Emulator and run Invcase app: The User Test application Start the Logcat to see debug lines: logcat -s Invcase Logcat shows Invcase calls There are 2 processes: The HAL process runs: Host the HAL implementation The user app process does below things: Bind to HAL process through AIDL proxy (through VNDBinder)","title":"AIDL for HALs"},{"location":"blog/android/hal/aidl/#aidl-for-hals","text":"Official overview guide is at https://source.android.com/devices/architecture/aidl/aidl-hals . AIDL has been around longer than HIDL (only from Android 8 to Android 10), and is used in many other places, such as between Android framework components or in apps. Now that AIDL has stability support, it\u2019s possible to implement an entire stack with a single IPC runtime. AIDL also has a better versioning system than HIDL.","title":"AIDL for HALs"},{"location":"blog/android/hal/aidl/#aidl-hal-interfaces","text":"For an AIDL interface to be used between system and vendor, the interface needs two changes: Every type definition must be annotated with @VintfStability . The aidl_interface declaration needs to include stability: \"vintf\", AOSP Stable AIDL interfaces for HALs are in the same base directories as HIDL interfaces, in aidl folders. hardware/interfaces frameworks/hardware/interfaces system/hardware/interfaces Example : hardware/interfaces/light/aidl/Android.bp aidl_i nterfa ce { na me : \"android.hardware.light\" , ve n dor_available : true , srcs : [ \"android/hardware/light/*.aidl\" , ], s ta bili t y : \"vintf\" , backe n d : { java : { sdk_versio n : \"module_current\" , }, n dk : { v n dk : { e na bled : true , }, }, }, versio ns : [ \"1\" ], }","title":"AIDL HAL interfaces"},{"location":"blog/android/hal/aidl/#aidl-runtime-library","text":"AIDL has three different backends: Java, NDK, CPP. To use Stable AIDL, you must always use the system copy of libbinder at system/lib*/libbinder.so and talk on /dev/binder . For code on the vendor image, this means that libbinder (from the VNDK) cannot be used. Instead, native vendor code must use the NDK backend of AIDL, link against libbinder_ndk (which is backed by system libbinder.so), and link against the -ndk_platform libraries created by aidl_interface entries.","title":"AIDL runtime library"},{"location":"blog/android/hal/aidl/#convert-hidl-to-aidl","text":"Build the tool hidl2aidl if it is not compiled: m hidl2aidl Create a new folder aidl in the HAL interface: mkdir -p hardware/interfaces/invcase/aidl Generate AIDL from a specific HIDL version: hidl2aidl -o hardware/interfaces/invcase/aidl \\ -r android.hardware:hardware/interfaces \\ android.hardware.invcase@1.0 This will create aidl/android/hardware/invcase/IInvcase.aidl file. AIDL package android.hardware.invcase ; @VintfStability interface IInvcase { String getChars (); void putChars ( in String msg ); } HIDL package android.hardware.invcase @ 1.0 ; interface IInvcase { putChars ( string msg ); getChars () generates ( string msg ); }; The tool also generates a makefile for the AIDL, but it is not usable at the moment: AIDL aidl_interface { name : \"android.hardware.invcase\" , vendor : true , srcs : [ \"android/hardware/invcase/*.aidl\" ] , stability : \"vintf\" , owner : \"vqtrong\" , backend : { cpp : { enabled : false , }, java : { sdk_version : \"module_current\" , }, }, } HIDL // This file is autogenerated by hidl-gen -Landroidbp. hidl_interface { name : \"android.hardware.invcase@1.0\" , root : \"android.hardware\" , vndk : { enabled : true , }, srcs : [ \"IInvcase.hal\" , ] , interfaces : [ \"android.hidl.base@1.0\" , ] , gen_java : false , }","title":"Convert HIDL to AIDL"},{"location":"blog/android/hal/aidl/#framework-stacks","text":"Differences between Binderized HIDL for HAL and AIDL for HAL : Binderized HAL in the Framework stacks AIDL HAL in the Framework stacks","title":"Framework Stacks"},{"location":"blog/android/hal/aidl/#implementation","text":"aidl_hal.zip Refer to Kernel Module to build and install a module to system. This guide assumes that invcase module is loaded as below: device/generic/goldfish/init.ranchu.rc + on boot + insmod /system/lib/modules/invcase.ko + chown system system /dev/invcase + chmod 0600 /dev/invcase","title":"Implementation"},{"location":"blog/android/hal/aidl/#overview","text":"AOSP build make target product base_vendor.mk Include new packages + PRODUCT_PACKAGES += \\ + android.hardware.invcase \\ + android.hardware.invcase-service \\ + Invcase packages apps Invcase src com invcase Invcase.java Bind to IInvcase interface import android.hardware.invcase.IInvcase ; class Invcase extends Activity { IInvcase invcaseAJ ; // AIDL Java onCreate () { IBinder binder = ServiceManager . getService ( IINVCASE_AIDL_INTERFACE ); invcaseAJ = IInvcase . Stub . asInterface ( binder ); } } res layout mipmap values AndroidManifest.xml Export main activity on Launcher <manifest package= \"com.invcase\" > <application> <activity android:name= \".Invcase\" android:exported= \"true\" > <intent-filter> <action android:name= \"android.intent.action.MAIN\" /> <category android:name= \"android.intent.category.LAUNCHER\" /> </intent-filter> </activity> </application> </manifest> android:exported=\"true\" is mandatory on Android 12 Android.bp android_app { name : \"Invcase\" , srcs : [ \"src/**/*.java\" ] , platform_apis : true static_libs : [ \"android.hardware.invcase-V1-java\" ] } platform_apis: true : use System API when do not specify any target platform android.hardware.invcase-V1-java : Java proxy for the AIDL of HAL, directly callable from User App hardware interfaces invcase aidl Android.bp android hardware invcase IInvcase.aidl @VintfStability interface IInvcase { String getChars (); void putChars ( in String msg ); } default Android.bp Invcase.h Invcase.cpp service.cpp compatible_matrices compatible_matrix.current.xml + <hal format=\"aidl\" optional=\"true\"> + <name>android.hardware.invcase</name> + <version>1</version> + <interface> + <name>IInvcase</name> + <instance>default</instance> + </interface> + </hal>","title":"Overview"},{"location":"blog/android/hal/aidl/#define-hal-interface","text":"Create a new AIDL file in the folder hardware/interfaces/invcase/aidl : hardware/interfaces/invcase/aidl/android/hardware/invcase/IInvcase.aidl package android.hardware.invcase ; @VintfStability interface IInvcase { String getChars (); void putChars ( in String msg ); }","title":"Define HAL Interface"},{"location":"blog/android/hal/aidl/#configure-build","text":"Select the backend: We will use NDK (as recommended), so declare the CPP backend as false . Set vendor: true and remove vendor_available because this is a custom vendor HAL Remove vndk section, so this HAL is located in /vendor only VNDK VNDK Build Example VNDK Extension aidl_interface { name : \"android.hardware.invcase\" , vendor : true, srcs : [ \"android/hardware/invcase/*.aidl\" ] , stability : \"vintf\" , owner : \"vqtrong\" , backend : { cpp : { enabled : false , }, java : { sdk_version : \"module_current\" , }, } , } At this time, if try to build the module with: mmm hardware/interfaces/invcase/ you will get error about the API missing: API dump for the current version of AIDL interface android.hardware.invcase does not exist. Run `m android.hardware.invcase-update-api`, or add `unstable: true` to the build rule for the interface if it does not need to be versioned. We need to freeze the API by running: m android.hardware.invcase-update-api versioning Since there is no version 1, the current version is version 1, but once we perform a change to the API, we will upgrade the aidl. The current folder needs to be renamed to 1 and a new current folder needs to be created representing version 2. Ok, build it again: mmm hardware/interfaces/invcase/ Then include the module to the system : build/make/target/product/base_vendor.mk PRODUCT_PACKAGES += \\ android.hardware.invcase \\","title":"Configure build"},{"location":"blog/android/hal/aidl/#implement-hal","text":"We will use the ndk_platfrom library, therefore, let check the generated code for ndk_platform . cd out/soong/.intermediates/hardware/interfaces/invcase/aidl/android.hardware.invcase-V1-ndk_platform-source find . . ./gen ./gen/timestamp ./gen/include ./gen/include/aidl ./gen/include/aidl/android ./gen/include/aidl/android/hardware ./gen/include/aidl/android/hardware/invcase ./gen/include/aidl/android/hardware/invcase/BpInvcase.h ./gen/include/aidl/android/hardware/invcase/IInvcase.h ./gen/include/aidl/android/hardware/invcase/BnInvcase.h ./gen/android ./gen/android/hardware ./gen/android/hardware/invcase ./gen/android/hardware/invcase/IInvcase.cpp.d ./gen/android/hardware/invcase/IInvcase.cpp Our interface APIs are converted to APIs as below: IInvcase.h virtual :: ndk :: ScopedAStatus getChars ( std :: string * _aidl_return ) = 0 ; virtual :: ndk :: ScopedAStatus putChars ( const std :: string & in_msg ) = 0 ; They are virtual functions and then need to be defined. Header file hardware/interfaces/invcase/aidl/default/Invcase.h #pragma once #include <aidl/android/hardware/invcase/BnInvcase.h> namespace aidl { namespace android { namespace hardware { namespace invcase { class Invcase : public BnInvcase { public : //String getChars(); ndk :: ScopedAStatus getChars ( std :: string * _aidl_return ); //void putChars(in String msg); ndk :: ScopedAStatus putChars ( const std :: string & in_msg ); }; } // namespace invcase } // namespace hardware } // namespace android } // namespace aidl Implementation hardware/interfaces/invcase/aidl/default/Invcase.cpp #define LOG_TAG \"Invcase\" #include <utils/Log.h> #include <iostream> #include <fstream> #include \"Invcase.h\" namespace aidl { namespace android { namespace hardware { namespace invcase { //String getChars(); ndk :: ScopedAStatus Invcase::getChars ( std :: string * _aidl_return ) { std :: ifstream invcase_dev ; invcase_dev . open ( \"/dev/invcase\" ); if ( invcase_dev . good ()) { std :: string line ; invcase_dev >> line ; ALOGD ( \"Invcase service: getChars: %s\" , line . c_str ()); * _aidl_return = line ; } else { ALOGE ( \"getChars: can not open /dev/invcase\" ); return ndk :: ScopedAStatus :: fromServiceSpecificError ( -1 ); } return ndk :: ScopedAStatus :: ok (); } //void putChars(in String msg); ndk :: ScopedAStatus Invcase::putChars ( const std :: string & in_msg ) { std :: ofstream invcase_dev ; invcase_dev . open ( \"/dev/invcase\" ); if ( invcase_dev . good ()) { invcase_dev << in_msg ; ALOGD ( \"Invcase service: putChars: %s\" , in_msg . c_str ()); } else { ALOGE ( \"putChars: can not open /dev/invcase\" ); return ndk :: ScopedAStatus :: fromServiceSpecificError ( -1 ); } return ndk :: ScopedAStatus :: ok (); } } // namespace invcase } // namespace hardware } // namespace android } // namespace aidl","title":"Implement HAL"},{"location":"blog/android/hal/aidl/#implement-hal-service","text":"The HAL service will run in its own process, like in HIDL . Create a new folder for implementation in hardware/interfaces/invcase/aidl/default : Service implementation hardware/interfaces/invcase/aidl/default/service.cpp #define LOG_TAG \"Invcase\" #include <android-base/logging.h> #include <android/binder_manager.h> #include <android/binder_process.h> #include <binder/ProcessState.h> #include <binder/IServiceManager.h> #include \"Invcase.h\" using aidl :: android :: hardware :: invcase :: Invcase ; using std :: string_literals :: operator \"\" s ; void logd ( std :: string msg ) { std :: cout << msg << std :: endl ; ALOGD ( \"%s\" , msg . c_str ()); } void loge ( std :: string msg ) { std :: cout << msg << std :: endl ; ALOGE ( \"%s\" , msg . c_str ()); } int main () { // Enable vndbinder to allow vendor-to-venfor binder call android :: ProcessState :: initWithDriver ( \"/dev/vndbinder\" ); ABinderProcess_setThreadPoolMaxThreadCount ( 0 ); ABinderProcess_startThreadPool (); std :: shared_ptr < Invcase > invcase = ndk :: SharedRefBase :: make < Invcase > (); const std :: string name = Invcase :: descriptor + \"/default\" s ; if ( invcase != nullptr ) { if ( AServiceManager_addService ( invcase -> asBinder (). get (), name . c_str ()) != STATUS_OK ) { loge ( \"Failed to register IInvcase service\" ); return -1 ; } } else { loge ( \"Failed to get IInvcase instance\" ); return -1 ; } logd ( \"IInvcase service starts to join service pool\" ); ABinderProcess_joinThreadPool (); return EXIT_FAILURE ; // should not reached } vndbinder Normally, vendor processes don\u2019t open the binder driver directly and instead link against the libbinder userspace library, which opens the binder driver. Adding a method for ::android::ProcessState() selects the binder driver for libbinder . Vendor processes should call this method before calling into ProcessState , IPCThreadState , or before making any binder calls in general. To use, place the following call after the main() of a vendor process (client and server): #include <binder/ProcessState.h> int main () { android :: ProcessState :: initWithDriver ( \"/dev/vndbinder\" ); } Thread management Every instance of libbinder in a process maintains one threadpool. For most use cases, this should be exactly one threadpool, shared across all backends. The only exception to this is when vendor code might load another copy of libbinder to talk to /dev/vndbinder. Since this is on a separate binder node, the threadpool isn\u2019t shared. In the NDK backend: bool success = ABinderProcess_setThreadPoolMaxThreadCount ( 0 ); ABinderProcess_startThreadPool (); ABinderProcess_joinThreadPool (); Build Service Similar to the HIDL module, we will create a cc_binary module in the Android.bp . AIDL has three different backends: Java, NDK, CPP. To use Stable AIDL, you must always use the system copy of libbinder at system/lib*/libbinder.so and talk on /dev/binder . For code on the vendor image, this means that libbinder (from the VNDK) cannot be used: this library has an unstable C++ API and unstable internals. Instead, native vendor code must use the NDK backend of AIDL, link against libbinder_ndk (which is backed by system libbinder.so ), and link against the -ndk_platform libraries created by aidl_interface entries. hardware/interfaces/invcase/aidl/default/Android.bp cc_binary { name : \"android.hardware.invcase-service\" , vendor : true, relative_install_path : \"hw\" , init_rc : [ \"android.hardware.invcase-service.rc\" ] , vintf_fragments : [ \"android.hardware.invcase-service.xml\" ] , srcs : [ \"Invcase.cpp\" , \"service.cpp\" , ] , cflags : [ \"-Wall\" , \"-Werror\" , ] , shared_libs : [ \"libbase\" , \"liblog\" , \"libhardware\" , \"libbinder_ndk\" , \"libbinder\" , \"libutils\" , \"android.hardware.invcase-V1-ndk_platform\" , ] , } Then include the service to the system: build/make/target/product/base_vendor.mk PRODUCT_PACKAGES += \\ android.hardware.invcase \\ android.hardware.invcase-service \\ Run Service We need to define the service with the init process, so it can start whenever the hal class is started. To do this, we will create a new android.hardware.invcase-service.rc : hardware/interfaces/invcase/aidl/default/android.hardware.invcase-service.rc service android.hardware.invcase-service /vendor/bin/hw/android.hardware.invcase-service interface aidl android.hardware.invcase.IInvcase/default class hal user system group system Expose AIDL Interface A new VINTF AIDL object should be declared as below: hardware/interfaces/invcase/aidl/default/android.hardware.invcase-service.xml <manifest version= \"1.0\" type= \"device\" > <hal format= \"aidl\" > <name> android.hardware.invcase </name> <version> 1 </version> <fqname> IInvcase/default </fqname> </hal> </manifest> If this is a new package, add it to the latest framework compatibility matrix. If no interface should be added to the framework compatibility matrix (e.g. types-only package), add it to the exempt list in libvintf_fcm_exclude . hardware/interfaces/compatibility_matrices/compatibility_matrix.6.xml hardware/interfaces/compatibility_matrices/compatibility_matrix.current.xml <hal format= \"aidl\" optional= \"true\" > <name> android.hardware.invcase </name> <version> 1 </version> <interface> <name> IInvcase </name> <instance> default </instance> </interface> </hal>","title":"Implement HAL Service"},{"location":"blog/android/hal/aidl/#define-selinux-policy-for-hal-service","text":"To make the service run at boot, HAL service needs to be registered to system under a security policy. Declare new type system/sepolicy/prebuilts/api/32.0/public/hwservice.te system/sepolicy/public/hwservice.te type hal_invcase_hwservice, hwservice_manager_type; Set compatibility Ignore in API 31, which also ignore in lower API: system/sepolicy/prebuilts/api/32.0/private/compat/31.0/31.0.ignore.cil system/sepolicy/private/compat/31.0/31.0.ignore.cil (type new_objects) (typeattribute new_objects) (typeattributeset new_objects ( new_objects hal_invcase_hwservice ) ) Add service path Add a new label in the: system/sepolicy/vendor/file_contexts /(vendor|system/vendor)/bin/hw/android\\.hardware\\.invcase-service u:object_r:hal_invcase_service_exec:s0 Set service context interface : system/sepolicy/prebuilts/api/32.0/private/hwservice_contexts system/sepolicy/private/hwservice_contexts android.hardware.invcase::IInvcase u:object_r:hal_invcase_hwservice:s0 Declare attribute : system/sepolicy/prebuilts/api/32.0/public/attributes system/sepolicy/public/attributes hal_attribute(invcase); this is macro for adding below attributes: attribute hal_invcase; attribute hal_invcase_client; attribute hal_invcase_server;mon Define default domain : system/sepolicy/vendor/hal_invcase_service.te type hal_invcase_service, domain; hal_server_domain(hal_invcase_service, hal_invcase) type hal_invcase_service_exec, exec_type, vendor_file_type, vendor_file_type, file_type; init_daemon_domain(hal_invcase_service) Set binder policy : system/sepolicy/prebuilts/api/32.0/public/hal_invcase.te system/sepolicy/public/hal_invcase.te binder_call(hal_invcase_client, hal_invcase_server) binder_call(hal_invcase_server, hal_invcase_client) hal_attribute_hwservice(hal_invcase, hal_invcase_hwservice) Declare system_server as client of HAL service : system/sepolicy/prebuilts/api/29.0/private/system_server.te system/sepolicy/private/system_server.te hal_client_domain(system_server, hal_invcase)","title":"Define SELinux Policy for HAL service"},{"location":"blog/android/hal/aidl/#deliver-hal-module","text":"VNDK Vendor Native Development Kit (VNDK) is a set of libraries exclusively for vendors to implement their HALs. The VNDK ships in system.img and is dynamically linked to vendor code at runtime. Refer to https://source.android.com/devices/architecture/vndk/build-system . Include HAL service and the test app to the PRODUCT_PACKAGES : build/target/product/base_vendor.mk + PRODUCT_PACKAGES += \\ + android.hardware.invcase-service \\ This will include below files to system: /vendor/lib/hw/android.hardware.invcase-service","title":"Deliver HAL module"},{"location":"blog/android/hal/aidl/#user-app","text":"The User App will be very simple to test the hardware. It contains an EditText to get user input, a Button to execute commands, and a TextView to display the result. Implement the User App Use getSystemService(Context.INVCASE_SERVICE) to obtain the instance of InvcaseManager Call to hardware through the InvcaseManager APIs packages/apps/Invcase/src/com/invcase/Invcase.java package com.invcase ; import android.content.Context ; import android.app.Activity ; import android.os.Bundle ; import android.view.View ; import android.widget.Button ; import android.widget.EditText ; import android.widget.TextView ; import android.util.Log ; import android.os.ServiceManager ; import android.os.IBinder ; import android.hardware.invcase.IInvcase ; public class Invcase extends Activity { private static final String TAG = \"Invcase\" ; private static final String IINVCASE_AIDL_INTERFACE = \"android.hardware.invcase.IInvcase/default\" ; private static IInvcase invcaseAJ ; // AIDL Java @Override protected void onCreate ( Bundle savedInstanceState ) { super . onCreate ( savedInstanceState ); setContentView ( R . layout . activity_main ); Button btn = ( Button ) findViewById ( R . id . button ); btn . setOnClickListener ( new View . OnClickListener () { @Override public void onClick ( View view ) { EditText editText = ( EditText ) findViewById ( R . id . editText ); String txt = editText . getText (). toString (); Log . d ( TAG , \"App: request= \" + txt ); if ( invcaseAJ != null ) { try { invcaseAJ . putChars ( txt ); } catch ( android . os . RemoteException e ) { Log . e ( TAG , \"IInvcase-AIDL error\" , e ); } } String ret = \"\" ; if ( invcaseAJ != null ) { try { ret = invcaseAJ . getChars (); } catch ( android . os . RemoteException e ) { Log . e ( TAG , \"IInvcase-AIDL error\" , e ); } } Log . d ( TAG , \"App: get= \" + ret ); TextView tv = ( TextView ) findViewById ( R . id . textView ); tv . setText ( ret ); } }); IBinder binder = ServiceManager . getService ( IINVCASE_AIDL_INTERFACE ); if ( binder == null ) { Log . e ( TAG , \"Getting \" + IINVCASE_AIDL_INTERFACE + \" service daemon binder failed!\" ); } else { invcaseAJ = IInvcase . Stub . asInterface ( binder ); if ( invcaseAJ == null ) { Log . e ( TAG , \"Getting IInvcase AIDL daemon interface failed!\" ); } else { Log . d ( TAG , \"IInvcase AIDL daemon interface is binded!\" ); } } } } Add User App to the Launcher packages/apps/Invcase/AndroidManifest.xml <?xml version=\"1.0\" encoding=\"utf-8\"?> <manifest xmlns:android= \"http://schemas.android.com/apk/res/android\" package= \"com.invcase\" > <application android:icon= \"@mipmap/ic_launcher\" android:label= \"@string/app_name\" > <activity android:name= \".Invcase\" android:exported= \"true\" android:label= \"@string/app_name\" > <intent-filter> <action android:name= \"android.intent.action.MAIN\" /> <category android:name= \"android.intent.category.LAUNCHER\" /> </intent-filter> </activity> </application> </manifest> on Android 12, must use android:exported=\"true\" Build User App packages/apps/Invcase/Android.bp android_app { name : \"Invcase\" , platform_apis : true, srcs : [ \"src/**/*.java\" ] , static_libs : [ \"android.hardware.invcase-V1-java\" ] } Add User App to system packages : build/target/product/base_vendor.mk + PRODUCT_PACKAGES += \\ + Invcase","title":"User App"},{"location":"blog/android/hal/aidl/#permission","text":"The device /dev/invcase is created at boot with root permission. The HAL Library is loaded when JNI Wrapper for Invcase Service is run, therefore, HAL code will run with system permission which attaches to the system_server process. The Android Init Language uses init*.rc files to automatically do some actions when a condition is met. For the target hardware, Android Init will use init.<hardware>.rc file. On Emulator, it is init.ranchu.rc . Add below lines to change the owner and permission on the /dev/invcase at boot: device/generic/goldfish/init.ranchu.rc + on boot + chown system system /dev/invcase + chmod 0600 /dev/invcase","title":"Permission"},{"location":"blog/android/hal/aidl/#build-and-run","text":"The Invcase Manager exports new Service APIs, therefore, need to rebuild the list of system APIs. m all -j $( nproc ) Run the Emulator and run Invcase app: The User Test application Start the Logcat to see debug lines: logcat -s Invcase Logcat shows Invcase calls There are 2 processes: The HAL process runs: Host the HAL implementation The user app process does below things: Bind to HAL process through AIDL proxy (through VNDBinder)","title":"Build and Run"},{"location":"blog/android/hal/classical/conventional/","tags":["android","hal"],"text":"This guide is written for AOSP android-10.0.0_r47 Conventional HAL # Conventional HALs (deprecated in Android 8.0) are interfaces that conform to a specific named and versioned application binary interface (ABI). To guarantee that HALs have a predictable structure, each hardware-specific HAL interface has properties defined in hardware.h . This interface allows the Android system to load correct versions of your HAL modules consistently. The bulk of Android system interfaces ( camera , audio , sensors , etc.) are in the form of conventional HALs, which are defined under hardware/libhardware/include/hardware . A Conventional HAL interface consists of two components: modules and devices . HAL Module # The struct hw_module_t represents a module and contains metadata such as the version, name, and author of the module. Android uses this metadata to find and load the HAL module correctly. hardware/libhardware/include/hardware/hardware/h typedef struct hw_module_t { uint32_t tag ; // must be init to HARDWARE_MODULE_TAG uint16_t module_api_version ; uint16_t hal_api_version ; const char * id ; const char * name ; const char * author ; struct hw_module_methods_t * methods ; void * dso ; } hw_module_t ; In addition, the hw_module_t struct contains a pointer to another struct, hw_module_methods_t , that contains a pointer to an open function for the module. This open function is used to initiate communication with the hardware for which the HAL is serving as an abstraction. hardware/libhardware/include/hardware/hardware/h typedef struct hw_module_methods_t { int ( * open )( const struct hw_module_t * module , const char * id , struct hw_device_t ** device ); } hw_module_methods_t ; Each hardware-specific HAL usually extends the generic hw_module_t struct with additional information for that specific piece of hardware. For example, adding to 2 functions read and write : hardware/libhardware/include/hardware/hardware/h typedef struct my_module { hw_module_t common ; int ( * read )( void ); int ( * write )( int data ); } my_module_t ; When you implement a HAL and create the module struct, you must name it HAL_MODULE_INFO_SYM and fill all the fields: struct my_module HAL_MODULE_INFO_SYM = { . common = { . tag = HARDWARE_MODULE_TAG , . module_api_version = 1 , . hal_api_version = 0 , . id = MY_MODULE_ID , . name = \"My Module\" , . author = \"Me\" , . methods = & my_hw_module_methods , }, }; HAL device # A device is represented by the hw_device_t struct. Similar to a module, each type of device defines a detailed version of the generic hw_device_t that contains function pointers for specific features of the hardware. hardware/libhardware/include/hardware/hardware/h typedef struct hw_device_t { uint32_t tag ; // must be init to HARDWARE_DEVICE_TAG uint32_t version ; struct hw_module_t * module ; /** Close this device */ int ( * close )( struct hw_device_t * device ); } hw_device_t ; typedef struct my_device { struct hw_device_t common ; uint32_t ( * get_id )(); } my_device_t ; Access to HAL # HAL implementations are built into modules (.so) files and are dynamically linked by Android when appropriate. You can build your modules by creating Android.mk files for each of your HAL implementations and pointing to your source files. In general, your shared libraries must be named in a specific format, so they can be found and loaded properly. The naming scheme varies slightly from module to module, but follows the general pattern of: <device_name>.<module_type> . Using the libhardware library, you can open a HAL library by following below steps: Call to hw_get_module(char* id, struct hw_module_t ** module) to get a pointer pointing to the target module Call module->common.methods->open() function to get a pointer pointing to the target device Use the device pointer to call to target specific functions, such as read() or write() Framework Stacks # Differences between Legacy HAL and Conventional HAL : Legacy HAL in the Framework stacks Conventional HAL in the Framework stacks Implementation # conventional_hal.zip Refer to Kernel Module to build and install a module to system. This guide assumes that invcase module is loaded as below: device/generic/goldfish/init.ranchu.rc + on boot + insmod /system/lib/modules/invcase.ko + chown system system /dev/invcase + chmod 0600 /dev/invcase Overview # AOSP build make target product base_vendor.mk Include new packages + PRODUCT_PACKAGES += \\ + invcase.default \\ + invcase_conventional_test + Invcase packages apps Invcase src com invcase Invcase.java Get InvcaseManager from SystemService class Invcase extends Activity { InvcaseManager mManager ; onCreate () { mManager = getSystemService ( Context . INVCASE_SERVICE ); } } res layout mipmap values AndroidManifest.xml Export main activity on Launcher <manifest package= \"com.invcase\" > <application> <activity android:name= \".Invcase\" android:exported= \"true\" > <intent-filter> <action android:name= \"android.intent.action.MAIN\" /> <category android:name= \"android.intent.category.LAUNCHER\" /> </intent-filter> </activity> </application> </manifest> android:exported=\"true\" is mandatory on Android 12 Android.bp android_app { name : \"Invcase\" , srcs : [ \"src/**/*.java\" ] , platform_apis : true } platform_apis: true : use System API when do not specify any target platform frameworks base Android.bp java_defaults { name: \"framework-defaults\", installable: true, srcs: [ + \"core/java/android/hardware/invcase/IInvcaseManager.aidl\", ] } api current.txt + package android.hardware.invcase { + + public final class InvcaseManager { + method @NonNull public String getData(); + method public void putData(@NonNull String); + } + + } core java android app SystemServiceRegistry.java Create an InvcaseManager instance and add it to the System Service list + import android.hardware.invcase.InvcaseManager; public final class SystemServiceRegistry { static { + registerService(Context.INVCASE_SERVICE, InvcaseManager.class, + new CachedServiceFetcher<InvcaseManager>() { + @Override + public InvcaseManager createService(ContextImpl ctx) + throws ServiceNotFoundException { + return new InvcaseManager(ctx); + }}); } } content Context.java Add Invcase Serive name public abstract class Context { + public static final String INVCASE_SERVICE = \"invcase\"; @StringDef(suffix = { \"_SERVICE\" }, value = { + INVCASE_SERVICE, }) } hardware invcase IInvcaseManager.aidl Define API for Invcase Interface interface IInvcaseManager { getData (); putData (); } InvcaseManager.java Use Invase Serive through the Invcase Interface class InvcaseManager { IInvcaseManager mService ; InvcaseManager ( Context ) throws ServiceNotFoundException { this ( context , IInvcaseManager . Stub . asInterface ( ServiceManager . getServiceOrThrow ( Context . INVCASE_SERVICE )) ); } InvcaseManager ( Context , IInvcaseManager ){} getData () { mService . getData (); } putData () { mService . putData (); } } services core java com android server invcase InvcaseService.java Implement Invcase Interface functions, public the interface class InvcaseService extends SystemService { IInvcaseManagerImpl extends IInvcaseManager . Stub { getData () { invcase_native_read (); } putData () { invcase_native_write (); } } mManagerService ; onStart () { publishBinderService ( Context . INVCASE_SERVICE , mManagerService ); } } jni com_android_server_invcase_InvcaseService.cpp Map java functions to native functions #include <hardware/hardware.h> #include <hardware/invcase.h> jni_init () { device = hw_get_module () -> open (); } jni_deinit () { free ( device ); } jni_read () { device -> read (); } jni_write () { device -> write (); } static const JNINativeMethod method_table [] = { { \"invcase_native_init\" , \"()V\" , ( void * ) jni_init }, { \"invcase_native_deinit\" , \"()V\" , ( void * ) jni_deinit }, { \"invcase_native_read\" , \"()Ljava/lang/String;\" , ( void * ) jni_read }, { \"invcase_native_write\" , \"(Ljava/lang/String;)V\" , ( void * ) jni_write }, }; register_android_server_InvcaseService ( method_table ); onload.cpp Register mapped function calls namespace android { + int register_android_server_InvcaseService(JNIEnv *env); }; extern \"C\" jint JNI_OnLoad(JavaVM* vm, void* /* reserved */) { + register_android_server_InvcaseService(env); } Android.bp cc_library_static { srcs: [ + \"com_android_server_invcase_InvcaseService.cpp\", ], } java com android server SystemServer.java Start Invcase Service + import com.android.server.invcase.InvcaseService; public final class SystemServer implements Dumpable { private void startBootstrapServices(@NonNull TimingsTraceAndSlog t) { + traceBeginAndSlog(\"StartInvcaseService\"); + mSystemServiceManager.startService(InvcaseService.class); + traceEnd(); } } hardware libhardware include hardware invcase.h Declare APIs #include <hardware/hardware.h> // hw_module_t, hw_device_t struct invcase_module_t { struct hw_module_t common ; }; struct invcase_device_t { struct hw_device_t common ; ssize_t ( * write )( char * , size_t ); ssize_t ( * read )( char * , size_t ); }; Wrap with __BEGIN_DECLS and __END_DECLS when using C language modules Android.mk Add module to build slots hardware_modules := \\ camera \\ gralloc \\ sensors \\ + invcase invcase invase.c Implement APIs using the device file dev_open () { device = new invcase_device_t { . write = dev_write ; . read = dev_read ; } } dev_close () { free ( device ) } dev_read () { read ( \"/dev/invcase\" ); } dev_write () { write ( \"/dev/invcase\" ); } hw_module_methods_t invcase_module_methods = { . open = dev_open , }; struct invcase_module_t HAL_MODULE_INFO_SYM = { . common = { . tag = HARDWARE_MODULE_TAG , . id = INVCASE_HARDWARE_MODULE_ID , . methods = & invcase_module_methods , }, }; Android.bp cc_library_shared { name : \"invcase.default\" } tests invcase invcase_conventional_test.c Android.bp HAL Library # Define headers : Declare structures: invcase_module_t invcase_device_t hardware/libhardware/include/hardware/invcase.h #ifndef INVCASE_CONVENTIONAL_H #define INVCASE_CONVENTIONAL_H #include <sys/types.h> // size_t, ssize_t #include <hardware/hardware.h> // hw_module_t, hw_device_t /* Use this for C++ */ __BEGIN_DECLS #define INVCASE_HARDWARE_MODULE_ID \"invcase\" // must be the same as the header file #define INVCASE_DEBUG \"invcase: \" #define INVCASE_BUFFER_MAX_SIZE 1024 struct invcase_module_t { struct hw_module_t common ; }; struct invcase_device_t { struct hw_device_t common ; ssize_t ( * write )( char * , size_t ); ssize_t ( * read )( char * , size_t ); }; __END_DECLS #endif /* INVCASE_CONVENTIONAL_H */ Implement the library : Include utils/Log.h to use ALOGD , ALOGE macros which will print out to Logcat Must create the structure HAL_MODULE_INFO_SYM Implement functions and assign to the module structures dev_open to initialize the device structure dev_read and dev_write access to the device file hardware/libhardware/modules/invcase/invcase.c #define LOG_TAG \"Invcase\" #include <stdlib.h> #include <stdio.h> #include <string.h> #include <fcntl.h> #include <unistd.h> #include <errno.h> #include <sys/stat.h> #include <utils/Log.h> #include \"hardware/invcase.h\" #define INVCASE_DEVICE_FILE \"/dev/invcase\" static int dev_open ( const struct hw_module_t * module , const char * name , struct hw_device_t ** device ); static int dev_close ( struct hw_device_t * device ); static ssize_t dev_write ( char * buf , size_t count ); static ssize_t dev_read ( char * buf , size_t count ); /* defined in hardware/hardware.h */ static struct hw_module_methods_t invcase_module_methods = { . open = dev_open , }; /* every module must have HAL_MODULE_INFO_SYM */ struct invcase_module_t HAL_MODULE_INFO_SYM = { . common = { . tag = HARDWARE_MODULE_TAG , . version_major = 1 , . version_minor = 0 , . id = INVCASE_HARDWARE_MODULE_ID , . name = INVCASE_HARDWARE_MODULE_ID , . author = \"vqtrong\" , . methods = & invcase_module_methods , }, }; struct invcase_device_t * invcase_dev ; static void __attribute__ (( constructor )) dev_loaded () { ALOGD ( \"Conventional HAL Module: Loaded\" ); } static void __attribute__ (( destructor )) dev_unloaded () { ALOGD ( \"Conventional HAL Module: Unloaded\" ); } static int dev_open ( const struct hw_module_t * module , const char * id , struct hw_device_t ** device ) { // use calloc to initialize memory with 0 invcase_dev = ( struct invcase_device_t * ) calloc ( 1 , sizeof ( struct invcase_device_t )); if ( invcase_dev == NULL ) { ALOGE ( \"Conventional HAL Module: Unable to calloc, %s, ID: %s \\n \" , strerror ( errno ), id ); return - ENOMEM ; } invcase_dev -> common . tag = HARDWARE_MODULE_TAG ; invcase_dev -> common . version = 1 ; invcase_dev -> common . module = ( struct hw_module_t * ) module ; invcase_dev -> common . close = dev_close ; invcase_dev -> write = dev_write ; invcase_dev -> read = dev_read ; * device = ( struct hw_device_t * ) invcase_dev ; ALOGD ( \"Conventional HAL Module: Device %s is initialized \\n \" , id ); return 0 ; } static int dev_close ( struct hw_device_t * device ) { if ( device ) { free ( device ); ALOGD ( \"Conventional HAL Module: free device \\n \" ); } return 0 ; } static ssize_t dev_write ( char * buf , size_t count ) { int fd ; int ret ; fd = open ( INVCASE_DEVICE_FILE , O_WRONLY ); if ( fd < 0 ) { ALOGE ( \"Conventional HAL Module: Unable to open %s to write \\n \" , INVCASE_DEVICE_FILE ); return fd ; } ret = write ( fd , buf , count ); if ( ret < 0 ) { ALOGE ( \"Conventional HAL Module: Unable to write to %s \\n \" , INVCASE_DEVICE_FILE ); return ret ; } ALOGD ( \"Conventional HAL Module: invcase_write: buf= %s \\n \" , buf ); close ( fd ); return 0 ; } static ssize_t dev_read ( char * buf , size_t count ) { int fd ; int ret ; fd = open ( INVCASE_DEVICE_FILE , O_RDONLY ); if ( fd < 0 ) { ALOGE ( \"Conventional HAL Module: Unable to open %s to read \\n \" , INVCASE_DEVICE_FILE ); return fd ; } ret = read ( fd , buf , count ); if ( ret < 0 ) { ALOGE ( \"Conventional HAL Module: Unable to read from %s \\n \" , INVCASE_DEVICE_FILE ); return ret ; } ALOGD ( \"Conventional HAL Module: invcase_read: buf= %s \\n \" , buf ); close ( fd ); return 0 ; } Build the module library invcase.default.so : hardware/libhardware/modules/invcase/Android.bp // This default implementation is loaded if no other device specific modules are // present. The exact load order can be seen in libhardware/hardware.c // The format of the name is invcase.<hardware>.so cc_library_shared { name : \"invcase.default\" , relative_install_path : \"hw\" , srcs : [ \"invcase.c\" ] , cflags : [ \"-Wall\" , \"-Werror\" ] , header_libs : [ \"libhardware_headers\" ] , shared_libs : [ \"liblog\" , \"libcutils\" , ] , } A test application that uses the HAL module library: hardware/libhardware/tests/invcase/invcase_conventional_test.c #include <stdlib.h> #include <stdio.h> #include <string.h> #include <hardware/invcase.h> int main () { int err ; struct invcase_module_t * module = NULL ; struct invcase_device_t * device = NULL ; char buffer [ INVCASE_BUFFER_MAX_SIZE ]; printf ( \"InvCase Conventional HAL Test App \\n \" ); err = hw_get_module ( INVCASE_HARDWARE_MODULE_ID , ( struct hw_module_t const ** ) & module ); if ( err != 0 ) { printf ( \"hw_get_module() failed: (%s) \\n \" , strerror ( - err )); return -1 ; } else { printf ( \"hw_get_module() OK \\n \" ); if ( module -> common . methods -> open ( ( struct hw_module_t * ) module , INVCASE_HARDWARE_MODULE_ID , ( struct hw_device_t ** ) & device ) != 0 ) { printf ( \"HAL failed to open! (%s) \\n \" , strerror ( - err )); return -1 ; } else { printf ( \"hw_get_module() Open: OK \\n \" ); } } printf ( \"Input a string: \" ); scanf ( \"%s\" , buffer ); err = device -> write ( buffer , strlen ( buffer )); if ( err != 0 ) { printf ( \"HAL failed to write! (%s) \\n \" , strerror ( - err )); } err = device -> read ( buffer , INVCASE_BUFFER_MAX_SIZE ); if ( err != 0 ) { printf ( \"HAL failed to read! (%s) \\n \" , strerror ( - err )); } printf ( \"Converted string: \" ); printf ( \"%s \\n \" , buffer ); return 0 ; } Build the test app: hardware/libhardware/tests/invcase/Android.bp cc_binary { name : \"invcase_conventional_test\" , srcs : [ \"invcase_conventional_test.c\" ] , shared_libs : [ \"liblog\" , \"libhardware\" , ] , cflags : [ \"-Wall\" , \"-Werror\" , \"-Wextra\" , ] , } Include HAL Library and the Test app to the system packages : build/target/product/base_vendor.mk + PRODUCT_PACKAGES += \\ + invcase.default \\ + invcase_conventional_test This will include below files to system: /system/lib/hw/invcase.default.so /system/lib64/hw/invcase.default.so /system/bin/invcase_conventional_test Rebuild the system image , run the emulator and run the test app: Conventional HAL Test App JNI Wrapper # The Java Native Interface (JNI) is a foreign function interface programming framework that enables Java code running in a Java virtual machine (JVM) to call and be called by native applications (programs specific to a hardware and operating system platform) and libraries written in other languages such as C, C++ and assembly. Create java functions that call to native function in HAL library jni_read calls to invcase_read jni_write calls to invcase_write Register mapped functions with their signatures (encoded parameters) Note that Java functions always have 2 default arguments: JNIEnv* env : a structure containing methods that we can use our native code to access Java elements jobject selfClass : the class of calling object Implement JNI Mapping Note that the function jniRegisterNativeMethods will register JNI functions for the class frameworks/services/core/java/com/android/server/invcase/InvcaseService.java : frameworks/base/services/core/jni/com_android_server_invcase_InvcaseService.cpp #define LOG_TAG \"Invcase\" // #define INVCASE_USE_CONVENTIONAL_HAL #include \"jni.h\" #include <nativehelper/JNIHelp.h> #include \"android_runtime/AndroidRuntime.h\" #include <utils/misc.h> #include <utils/Log.h> #include <stdio.h> #include <hardware/hardware.h> #include <hardware/invcase.h> namespace android { static struct invcase_module_t * module = NULL ; static struct invcase_device_t * device = NULL ; static void jni_init ( JNIEnv * /* env */ , jobject /* clazz */ ) { int err ; err = hw_get_module ( INVCASE_HARDWARE_MODULE_ID , ( struct hw_module_t const ** ) & module ); if ( err != 0 ) { ALOGE ( \"JNI: hw_get_module() failed: (%s) \\n \" , strerror ( - err )); return ; } else { ALOGD ( \"JNI: hw_get_module() OK \\n \" ); if ( module -> common . methods -> open ( ( struct hw_module_t * ) module , INVCASE_HARDWARE_MODULE_ID , ( struct hw_device_t ** ) & device ) != 0 ) { ALOGE ( \"JNI: HAL failed to open! (%s) \\n \" , strerror ( - err )); return ; } else { ALOGD ( \"JNI: hw_get_module() Open: OK \\n \" ); } } } static void jni_deinit ( JNIEnv * /* env */ , jobject /* clazz */ ) { if ( device ) { free ( device ); ALOGD ( \"JNI: Free device \\n \" ); } } static jstring jni_read ( JNIEnv * env , jobject /* clazz */ ) { char buff [ INVCASE_BUFFER_MAX_SIZE ]; int err = -1 ; if ( device ) { ALOGD ( \"JNI: device->read: %p \\n \" , device -> read ); err = device -> read ( buff , INVCASE_BUFFER_MAX_SIZE ); } else { ALOGE ( \"JNI: Device is NULL \\n \" ); } if ( err != 0 ) { ALOGE ( \"JNI: Can not read from device \\n \" ); } ALOGD ( \"JNI: jni_read: %s \\n \" , buff ); return env -> NewStringUTF ( buff ); } static void jni_write ( JNIEnv * env , jobject /* clazz */ , jstring string ) { const char * buff = env -> GetStringUTFChars ( string , NULL ); int length = env -> GetStringLength ( string ); int err = -1 ; ALOGD ( \"JNI: jni_write: %s length= %d \\n \" , buff , length ); if ( device ) { ALOGD ( \"JNI: device->write: %p \\n \" , device -> write ); err = device -> write (( char * ) buff , length ); } else { ALOGE ( \"JNI: Device is NULL \\n \" ); } if ( err != 0 ) { ALOGE ( \"JNI: Can not write to device \\n \" ); } } static const JNINativeMethod method_table [] = { { \"invcase_native_init\" , \"()V\" , ( void * ) jni_init }, { \"invcase_native_deinit\" , \"()V\" , ( void * ) jni_deinit }, { \"invcase_native_read\" , \"()Ljava/lang/String;\" , ( void * ) jni_read }, { \"invcase_native_write\" , \"(Ljava/lang/String;)V\" , ( void * ) jni_write }, }; int register_android_server_InvcaseService ( JNIEnv * env ) { ALOGD ( \"JNI: register_android_server_InvcaseService \\n \" ); return jniRegisterNativeMethods ( env , \"com/android/server/invcase/InvcaseService\" , method_table , NELEM ( method_table ) ); } } Call the register function : frameworks/base/services/core/jni/onload.cpp namespace android { + int register_android_server_InvcaseService(JNIEnv *env); }; extern \"C\" jint JNI_OnLoad(JavaVM* vm, void* /* reserved */) { + register_android_server_InvcaseService(env); } Build new JNI wrapper : frameworks/base/services/core/jni/Android.bp cc_library_static { name: \"libservices.core\", srcs: [ + \"com_android_server_invcase_InvcaseService.cpp\", ], } cc_defaults { name: \"libservices.core-libs\", shared_libs: [ + \"libinvcase\", ], Declare API : frameworks/base/api/current.txt + package android.hardware.invcase { + + public final class InvcaseManager { + method @NonNull public String getData(); + method public void putData(@NonNull String); + } + + } Service and Manager # Define a name for new Service frameworks/base/core/java/android/content/Context.java public abstract class Context { @StringDef(suffix = { \"_SERVICE\" }, value = { + INVCASE_SERVICE, }) + /** + * Use with {@link #getSystemService(String)} to retrieve a + * {@link android.hardware.invcase.InvcaseManager}. + * + * @see #getSystemService(String) + * @hide + */ + public static final String INVCASE_SERVICE = \"invcase\"; Define the Service Interface Use AIDL to describe public functions exported by the Service: frameworks/base/core/java/android/hardware/invcase/IInvcaseManager.aidl package android.hardware.invcase ; /** * Invcase Manager interface * * {@hide} */ interface IInvcaseManager { String getData (); void putData ( String data ); } Build AIDL : frameworks/base/Android.bp java_defaults { name: \"framework-defaults\", installable: true, srcs: [ + \"core/java/android/hardware/invcase/IInvcaseManager.aidl\", ] } Implement the Service Manager A Service Manager is the wrapper for the interface of the target Service which is obtained by calling to <Interface>.Stub.asInterface . User application will call to the functions of the Service Manager, not directly calling to the actual service interface. frameworks/base/core/java/android/hardware/invcase/InvcaseManager.java package android.hardware.invcase ; import android.annotation.NonNull ; import android.content.Context ; import android.util.Log ; import android.os.RemoteException ; import android.os.ServiceManager ; import android.os.ServiceManager.ServiceNotFoundException ; public final class InvcaseManager { static final String TAG = \"Invcase\" ; private final Context mContext ; private final IInvcaseManager mService ; /** * Creates a InvcaseManager. * * @hide */ public InvcaseManager ( @NonNull Context context ) throws ServiceNotFoundException { this ( context , IInvcaseManager . Stub . asInterface ( ServiceManager . getServiceOrThrow ( Context . INVCASE_SERVICE ))); } /** * Creates a InvcaseManager with a provided service implementation. * * @hide */ public InvcaseManager ( @NonNull Context context , @NonNull IInvcaseManager service ) { mContext = context ; mService = service ; Log . d ( TAG , \"InvcaseManager: mContext= \" + mContext + \" mService= \" + mService ); } public @NonNull String getData () { try { String str = mService . getData (); Log . d ( TAG , \"InvcaseManager: mService.getData= \" + str ); return str ; } catch ( RemoteException e ) { e . printStackTrace (); } return null ; } public void putData ( @NonNull String data ) { try { Log . d ( TAG , \"InvcaseManager: mService.putData= \" + data ); mService . putData ( data ); } catch ( RemoteException e ) { e . printStackTrace (); } } } Implement the Service The Service will implement the actual code for Service Interface functions by extending the <Interface>.Stub class. Note that JNI Native functions are exported to this object, therefore, it can call to HAL library\u2019s functions. frameworks/base/services/core/java/com/android/server/invcase/InvcaseService.java package com.android.server.invcase ; import android.hardware.invcase.IInvcaseManager ; import android.content.Context ; import android.util.Log ; import com.android.server.SystemService ; public class InvcaseService extends SystemService { static final String TAG = \"Invcase\" ; static final boolean DEBUG = false ; final IInvcaseManagerImpl mManagerService ; private final class IInvcaseManagerImpl extends IInvcaseManager . Stub { @Override public String getData () { String str = invcase_native_read (); Log . d ( TAG , \"InvcaseService: IInvcaseManager.getData= \" + str ); return str ; } @Override public void putData ( String data ) { Log . d ( TAG , \"InvcaseService: IInvcaseManager.putData= \" + data ); invcase_native_write ( data ); } } public InvcaseService ( Context context ) { super ( context ); invcase_native_init (); mManagerService = new IInvcaseManagerImpl (); Log . d ( TAG , \"InvcaseService: mManagerService= \" + mManagerService ); } @Override public void onStart () { publishBinderService ( Context . INVCASE_SERVICE , mManagerService ); Log . d ( TAG , \"InvcaseService: onStart\" ); } @Override protected void finalize () throws Throwable { invcase_native_deinit (); super . finalize (); } private static native void invcase_native_init (); private static native void invcase_native_deinit (); private static native String invcase_native_read (); private static native void invcase_native_write ( String string ); } Run our service : All system services are run in the same process called system_server which is implemented in the SystemServer.java . This process runs under system user. frameworks/base/services/java/com/android/server/SystemServer.java import com.android.server.invcase.InvcaseService; import android.util.Log; public final class SystemServer implements Dumpable { private void startBootstrapServices(@NonNull TimingsTraceAndSlog t) { + // Manages Invcase device. + traceBeginAndSlog(\"StartInvcaseService\"); + Log.d(\"Invcase\", \"SystemServer: start InvcaseService\"); + mSystemServiceManager.startService(InvcaseService.class); + traceEnd(); User App # The User App will be very simple to test the hardware. It contains an EditText to get user input, a Button to execute commands, and a TextView to display the result. Implement the User App Use getSystemService(Context.INVCASE_SERVICE) to obtain the instance of InvcaseManager Call to hardware through the InvcaseManager APIs packages/apps/Invcase/src/com/invcase/Invcase.java package com.invcase ; import android.hardware.invcase.InvcaseManager ; import android.content.Context ; import android.app.Activity ; import android.os.Bundle ; import android.view.View ; import android.widget.Button ; import android.widget.EditText ; import android.widget.TextView ; import android.util.Log ; public class Invcase extends Activity { private static final String TAG = \"Invcase\" ; private InvcaseManager mManager ; @Override protected void onCreate ( Bundle savedInstanceState ) { super . onCreate ( savedInstanceState ); setContentView ( R . layout . activity_main ); mManager = ( InvcaseManager ) getSystemService ( Context . INVCASE_SERVICE ); Log . d ( TAG , \"App: mManager= \" + mManager ); Button btn = ( Button ) findViewById ( R . id . button ); btn . setOnClickListener ( new View . OnClickListener () { @Override public void onClick ( View view ) { EditText editText = ( EditText ) findViewById ( R . id . editText ); String txt = editText . getText (). toString (); Log . d ( TAG , \"App: request= \" + txt ); mManager . putData ( txt ); String ret = mManager . getData (); Log . d ( TAG , \"App: received= \" + ret ); TextView tv = ( TextView ) findViewById ( R . id . textView ); tv . setText ( ret ); } }); } } Add User App to the Launcher packages/apps/Invcase/AndroidManifest.xml <?xml version=\"1.0\" encoding=\"utf-8\"?> <manifest xmlns:android= \"http://schemas.android.com/apk/res/android\" package= \"com.invcase\" > <application android:icon= \"@mipmap/ic_launcher\" android:label= \"@string/app_name\" > <activity android:name= \".Invcase\" android:exported= \"true\" android:label= \"@string/app_name\" > <intent-filter> <action android:name= \"android.intent.action.MAIN\" /> <category android:name= \"android.intent.category.LAUNCHER\" /> </intent-filter> </activity> </application> </manifest> on Android 12, must use android:exported=\"true\" Build User App packages/apps/Invcase/Android.bp android_app { name : \"Invcase\" , platform_apis : true, srcs : [ \"src/**/*.java\" ] } Add User App to system packages : build/target/product/base_vendor.mk + PRODUCT_PACKAGES += \\ + Invcase Permission # The device /dev/invcase is created at boot with root permission. The HAL Library is loaded when JNI Wrapper for Invcase Service is run, therefore, HAL code will run with system permission which attaches to the system_server process. The Android Init Language uses init*.rc files to automatically do some actions when a condition is met. For the target hardware, Android Init will use init.<hardware>.rc file. On Emulator, it is init.ranchu.rc . Add below lines to change the owner and permission on the /dev/invcase at boot: device/generic/goldfish/init.ranchu.rc + on boot + chown system system /dev/invcase + chmod 0600 /dev/invcase Build and Run # The Invcase Manager exports new Service APIs, therefore, need to rebuild the list of system APIs. m all -j $( nproc ) Run the Emulator and run Invcase app: The User Test application Start the Logcat to see debug lines: logcat -s Invcase Logcat shows Invcase calls There are 2 processes: The system_server process (yellow) does below things: Load HAL module Load JNI functions Start Invcase Service whichs creates an object of Invcase Manager Implementation The user app process (white) does below things: Load System Service Registry to have an object of Invcase Manager Interface Use received service interface to communicate with Invcase Manager Implementation in the Invcase Service","title":"Conventional HAL"},{"location":"blog/android/hal/classical/conventional/#conventional-hal","text":"Conventional HALs (deprecated in Android 8.0) are interfaces that conform to a specific named and versioned application binary interface (ABI). To guarantee that HALs have a predictable structure, each hardware-specific HAL interface has properties defined in hardware.h . This interface allows the Android system to load correct versions of your HAL modules consistently. The bulk of Android system interfaces ( camera , audio , sensors , etc.) are in the form of conventional HALs, which are defined under hardware/libhardware/include/hardware . A Conventional HAL interface consists of two components: modules and devices .","title":"Conventional HAL"},{"location":"blog/android/hal/classical/conventional/#hal-module","text":"The struct hw_module_t represents a module and contains metadata such as the version, name, and author of the module. Android uses this metadata to find and load the HAL module correctly. hardware/libhardware/include/hardware/hardware/h typedef struct hw_module_t { uint32_t tag ; // must be init to HARDWARE_MODULE_TAG uint16_t module_api_version ; uint16_t hal_api_version ; const char * id ; const char * name ; const char * author ; struct hw_module_methods_t * methods ; void * dso ; } hw_module_t ; In addition, the hw_module_t struct contains a pointer to another struct, hw_module_methods_t , that contains a pointer to an open function for the module. This open function is used to initiate communication with the hardware for which the HAL is serving as an abstraction. hardware/libhardware/include/hardware/hardware/h typedef struct hw_module_methods_t { int ( * open )( const struct hw_module_t * module , const char * id , struct hw_device_t ** device ); } hw_module_methods_t ; Each hardware-specific HAL usually extends the generic hw_module_t struct with additional information for that specific piece of hardware. For example, adding to 2 functions read and write : hardware/libhardware/include/hardware/hardware/h typedef struct my_module { hw_module_t common ; int ( * read )( void ); int ( * write )( int data ); } my_module_t ; When you implement a HAL and create the module struct, you must name it HAL_MODULE_INFO_SYM and fill all the fields: struct my_module HAL_MODULE_INFO_SYM = { . common = { . tag = HARDWARE_MODULE_TAG , . module_api_version = 1 , . hal_api_version = 0 , . id = MY_MODULE_ID , . name = \"My Module\" , . author = \"Me\" , . methods = & my_hw_module_methods , }, };","title":"HAL Module"},{"location":"blog/android/hal/classical/conventional/#hal-device","text":"A device is represented by the hw_device_t struct. Similar to a module, each type of device defines a detailed version of the generic hw_device_t that contains function pointers for specific features of the hardware. hardware/libhardware/include/hardware/hardware/h typedef struct hw_device_t { uint32_t tag ; // must be init to HARDWARE_DEVICE_TAG uint32_t version ; struct hw_module_t * module ; /** Close this device */ int ( * close )( struct hw_device_t * device ); } hw_device_t ; typedef struct my_device { struct hw_device_t common ; uint32_t ( * get_id )(); } my_device_t ;","title":"HAL device"},{"location":"blog/android/hal/classical/conventional/#access-to-hal","text":"HAL implementations are built into modules (.so) files and are dynamically linked by Android when appropriate. You can build your modules by creating Android.mk files for each of your HAL implementations and pointing to your source files. In general, your shared libraries must be named in a specific format, so they can be found and loaded properly. The naming scheme varies slightly from module to module, but follows the general pattern of: <device_name>.<module_type> . Using the libhardware library, you can open a HAL library by following below steps: Call to hw_get_module(char* id, struct hw_module_t ** module) to get a pointer pointing to the target module Call module->common.methods->open() function to get a pointer pointing to the target device Use the device pointer to call to target specific functions, such as read() or write()","title":"Access to HAL"},{"location":"blog/android/hal/classical/conventional/#framework-stacks","text":"Differences between Legacy HAL and Conventional HAL : Legacy HAL in the Framework stacks Conventional HAL in the Framework stacks","title":"Framework Stacks"},{"location":"blog/android/hal/classical/conventional/#implementation","text":"conventional_hal.zip Refer to Kernel Module to build and install a module to system. This guide assumes that invcase module is loaded as below: device/generic/goldfish/init.ranchu.rc + on boot + insmod /system/lib/modules/invcase.ko + chown system system /dev/invcase + chmod 0600 /dev/invcase","title":"Implementation"},{"location":"blog/android/hal/classical/conventional/#overview","text":"AOSP build make target product base_vendor.mk Include new packages + PRODUCT_PACKAGES += \\ + invcase.default \\ + invcase_conventional_test + Invcase packages apps Invcase src com invcase Invcase.java Get InvcaseManager from SystemService class Invcase extends Activity { InvcaseManager mManager ; onCreate () { mManager = getSystemService ( Context . INVCASE_SERVICE ); } } res layout mipmap values AndroidManifest.xml Export main activity on Launcher <manifest package= \"com.invcase\" > <application> <activity android:name= \".Invcase\" android:exported= \"true\" > <intent-filter> <action android:name= \"android.intent.action.MAIN\" /> <category android:name= \"android.intent.category.LAUNCHER\" /> </intent-filter> </activity> </application> </manifest> android:exported=\"true\" is mandatory on Android 12 Android.bp android_app { name : \"Invcase\" , srcs : [ \"src/**/*.java\" ] , platform_apis : true } platform_apis: true : use System API when do not specify any target platform frameworks base Android.bp java_defaults { name: \"framework-defaults\", installable: true, srcs: [ + \"core/java/android/hardware/invcase/IInvcaseManager.aidl\", ] } api current.txt + package android.hardware.invcase { + + public final class InvcaseManager { + method @NonNull public String getData(); + method public void putData(@NonNull String); + } + + } core java android app SystemServiceRegistry.java Create an InvcaseManager instance and add it to the System Service list + import android.hardware.invcase.InvcaseManager; public final class SystemServiceRegistry { static { + registerService(Context.INVCASE_SERVICE, InvcaseManager.class, + new CachedServiceFetcher<InvcaseManager>() { + @Override + public InvcaseManager createService(ContextImpl ctx) + throws ServiceNotFoundException { + return new InvcaseManager(ctx); + }}); } } content Context.java Add Invcase Serive name public abstract class Context { + public static final String INVCASE_SERVICE = \"invcase\"; @StringDef(suffix = { \"_SERVICE\" }, value = { + INVCASE_SERVICE, }) } hardware invcase IInvcaseManager.aidl Define API for Invcase Interface interface IInvcaseManager { getData (); putData (); } InvcaseManager.java Use Invase Serive through the Invcase Interface class InvcaseManager { IInvcaseManager mService ; InvcaseManager ( Context ) throws ServiceNotFoundException { this ( context , IInvcaseManager . Stub . asInterface ( ServiceManager . getServiceOrThrow ( Context . INVCASE_SERVICE )) ); } InvcaseManager ( Context , IInvcaseManager ){} getData () { mService . getData (); } putData () { mService . putData (); } } services core java com android server invcase InvcaseService.java Implement Invcase Interface functions, public the interface class InvcaseService extends SystemService { IInvcaseManagerImpl extends IInvcaseManager . Stub { getData () { invcase_native_read (); } putData () { invcase_native_write (); } } mManagerService ; onStart () { publishBinderService ( Context . INVCASE_SERVICE , mManagerService ); } } jni com_android_server_invcase_InvcaseService.cpp Map java functions to native functions #include <hardware/hardware.h> #include <hardware/invcase.h> jni_init () { device = hw_get_module () -> open (); } jni_deinit () { free ( device ); } jni_read () { device -> read (); } jni_write () { device -> write (); } static const JNINativeMethod method_table [] = { { \"invcase_native_init\" , \"()V\" , ( void * ) jni_init }, { \"invcase_native_deinit\" , \"()V\" , ( void * ) jni_deinit }, { \"invcase_native_read\" , \"()Ljava/lang/String;\" , ( void * ) jni_read }, { \"invcase_native_write\" , \"(Ljava/lang/String;)V\" , ( void * ) jni_write }, }; register_android_server_InvcaseService ( method_table ); onload.cpp Register mapped function calls namespace android { + int register_android_server_InvcaseService(JNIEnv *env); }; extern \"C\" jint JNI_OnLoad(JavaVM* vm, void* /* reserved */) { + register_android_server_InvcaseService(env); } Android.bp cc_library_static { srcs: [ + \"com_android_server_invcase_InvcaseService.cpp\", ], } java com android server SystemServer.java Start Invcase Service + import com.android.server.invcase.InvcaseService; public final class SystemServer implements Dumpable { private void startBootstrapServices(@NonNull TimingsTraceAndSlog t) { + traceBeginAndSlog(\"StartInvcaseService\"); + mSystemServiceManager.startService(InvcaseService.class); + traceEnd(); } } hardware libhardware include hardware invcase.h Declare APIs #include <hardware/hardware.h> // hw_module_t, hw_device_t struct invcase_module_t { struct hw_module_t common ; }; struct invcase_device_t { struct hw_device_t common ; ssize_t ( * write )( char * , size_t ); ssize_t ( * read )( char * , size_t ); }; Wrap with __BEGIN_DECLS and __END_DECLS when using C language modules Android.mk Add module to build slots hardware_modules := \\ camera \\ gralloc \\ sensors \\ + invcase invcase invase.c Implement APIs using the device file dev_open () { device = new invcase_device_t { . write = dev_write ; . read = dev_read ; } } dev_close () { free ( device ) } dev_read () { read ( \"/dev/invcase\" ); } dev_write () { write ( \"/dev/invcase\" ); } hw_module_methods_t invcase_module_methods = { . open = dev_open , }; struct invcase_module_t HAL_MODULE_INFO_SYM = { . common = { . tag = HARDWARE_MODULE_TAG , . id = INVCASE_HARDWARE_MODULE_ID , . methods = & invcase_module_methods , }, }; Android.bp cc_library_shared { name : \"invcase.default\" } tests invcase invcase_conventional_test.c Android.bp","title":"Overview"},{"location":"blog/android/hal/classical/conventional/#hal-library","text":"Define headers : Declare structures: invcase_module_t invcase_device_t hardware/libhardware/include/hardware/invcase.h #ifndef INVCASE_CONVENTIONAL_H #define INVCASE_CONVENTIONAL_H #include <sys/types.h> // size_t, ssize_t #include <hardware/hardware.h> // hw_module_t, hw_device_t /* Use this for C++ */ __BEGIN_DECLS #define INVCASE_HARDWARE_MODULE_ID \"invcase\" // must be the same as the header file #define INVCASE_DEBUG \"invcase: \" #define INVCASE_BUFFER_MAX_SIZE 1024 struct invcase_module_t { struct hw_module_t common ; }; struct invcase_device_t { struct hw_device_t common ; ssize_t ( * write )( char * , size_t ); ssize_t ( * read )( char * , size_t ); }; __END_DECLS #endif /* INVCASE_CONVENTIONAL_H */ Implement the library : Include utils/Log.h to use ALOGD , ALOGE macros which will print out to Logcat Must create the structure HAL_MODULE_INFO_SYM Implement functions and assign to the module structures dev_open to initialize the device structure dev_read and dev_write access to the device file hardware/libhardware/modules/invcase/invcase.c #define LOG_TAG \"Invcase\" #include <stdlib.h> #include <stdio.h> #include <string.h> #include <fcntl.h> #include <unistd.h> #include <errno.h> #include <sys/stat.h> #include <utils/Log.h> #include \"hardware/invcase.h\" #define INVCASE_DEVICE_FILE \"/dev/invcase\" static int dev_open ( const struct hw_module_t * module , const char * name , struct hw_device_t ** device ); static int dev_close ( struct hw_device_t * device ); static ssize_t dev_write ( char * buf , size_t count ); static ssize_t dev_read ( char * buf , size_t count ); /* defined in hardware/hardware.h */ static struct hw_module_methods_t invcase_module_methods = { . open = dev_open , }; /* every module must have HAL_MODULE_INFO_SYM */ struct invcase_module_t HAL_MODULE_INFO_SYM = { . common = { . tag = HARDWARE_MODULE_TAG , . version_major = 1 , . version_minor = 0 , . id = INVCASE_HARDWARE_MODULE_ID , . name = INVCASE_HARDWARE_MODULE_ID , . author = \"vqtrong\" , . methods = & invcase_module_methods , }, }; struct invcase_device_t * invcase_dev ; static void __attribute__ (( constructor )) dev_loaded () { ALOGD ( \"Conventional HAL Module: Loaded\" ); } static void __attribute__ (( destructor )) dev_unloaded () { ALOGD ( \"Conventional HAL Module: Unloaded\" ); } static int dev_open ( const struct hw_module_t * module , const char * id , struct hw_device_t ** device ) { // use calloc to initialize memory with 0 invcase_dev = ( struct invcase_device_t * ) calloc ( 1 , sizeof ( struct invcase_device_t )); if ( invcase_dev == NULL ) { ALOGE ( \"Conventional HAL Module: Unable to calloc, %s, ID: %s \\n \" , strerror ( errno ), id ); return - ENOMEM ; } invcase_dev -> common . tag = HARDWARE_MODULE_TAG ; invcase_dev -> common . version = 1 ; invcase_dev -> common . module = ( struct hw_module_t * ) module ; invcase_dev -> common . close = dev_close ; invcase_dev -> write = dev_write ; invcase_dev -> read = dev_read ; * device = ( struct hw_device_t * ) invcase_dev ; ALOGD ( \"Conventional HAL Module: Device %s is initialized \\n \" , id ); return 0 ; } static int dev_close ( struct hw_device_t * device ) { if ( device ) { free ( device ); ALOGD ( \"Conventional HAL Module: free device \\n \" ); } return 0 ; } static ssize_t dev_write ( char * buf , size_t count ) { int fd ; int ret ; fd = open ( INVCASE_DEVICE_FILE , O_WRONLY ); if ( fd < 0 ) { ALOGE ( \"Conventional HAL Module: Unable to open %s to write \\n \" , INVCASE_DEVICE_FILE ); return fd ; } ret = write ( fd , buf , count ); if ( ret < 0 ) { ALOGE ( \"Conventional HAL Module: Unable to write to %s \\n \" , INVCASE_DEVICE_FILE ); return ret ; } ALOGD ( \"Conventional HAL Module: invcase_write: buf= %s \\n \" , buf ); close ( fd ); return 0 ; } static ssize_t dev_read ( char * buf , size_t count ) { int fd ; int ret ; fd = open ( INVCASE_DEVICE_FILE , O_RDONLY ); if ( fd < 0 ) { ALOGE ( \"Conventional HAL Module: Unable to open %s to read \\n \" , INVCASE_DEVICE_FILE ); return fd ; } ret = read ( fd , buf , count ); if ( ret < 0 ) { ALOGE ( \"Conventional HAL Module: Unable to read from %s \\n \" , INVCASE_DEVICE_FILE ); return ret ; } ALOGD ( \"Conventional HAL Module: invcase_read: buf= %s \\n \" , buf ); close ( fd ); return 0 ; } Build the module library invcase.default.so : hardware/libhardware/modules/invcase/Android.bp // This default implementation is loaded if no other device specific modules are // present. The exact load order can be seen in libhardware/hardware.c // The format of the name is invcase.<hardware>.so cc_library_shared { name : \"invcase.default\" , relative_install_path : \"hw\" , srcs : [ \"invcase.c\" ] , cflags : [ \"-Wall\" , \"-Werror\" ] , header_libs : [ \"libhardware_headers\" ] , shared_libs : [ \"liblog\" , \"libcutils\" , ] , } A test application that uses the HAL module library: hardware/libhardware/tests/invcase/invcase_conventional_test.c #include <stdlib.h> #include <stdio.h> #include <string.h> #include <hardware/invcase.h> int main () { int err ; struct invcase_module_t * module = NULL ; struct invcase_device_t * device = NULL ; char buffer [ INVCASE_BUFFER_MAX_SIZE ]; printf ( \"InvCase Conventional HAL Test App \\n \" ); err = hw_get_module ( INVCASE_HARDWARE_MODULE_ID , ( struct hw_module_t const ** ) & module ); if ( err != 0 ) { printf ( \"hw_get_module() failed: (%s) \\n \" , strerror ( - err )); return -1 ; } else { printf ( \"hw_get_module() OK \\n \" ); if ( module -> common . methods -> open ( ( struct hw_module_t * ) module , INVCASE_HARDWARE_MODULE_ID , ( struct hw_device_t ** ) & device ) != 0 ) { printf ( \"HAL failed to open! (%s) \\n \" , strerror ( - err )); return -1 ; } else { printf ( \"hw_get_module() Open: OK \\n \" ); } } printf ( \"Input a string: \" ); scanf ( \"%s\" , buffer ); err = device -> write ( buffer , strlen ( buffer )); if ( err != 0 ) { printf ( \"HAL failed to write! (%s) \\n \" , strerror ( - err )); } err = device -> read ( buffer , INVCASE_BUFFER_MAX_SIZE ); if ( err != 0 ) { printf ( \"HAL failed to read! (%s) \\n \" , strerror ( - err )); } printf ( \"Converted string: \" ); printf ( \"%s \\n \" , buffer ); return 0 ; } Build the test app: hardware/libhardware/tests/invcase/Android.bp cc_binary { name : \"invcase_conventional_test\" , srcs : [ \"invcase_conventional_test.c\" ] , shared_libs : [ \"liblog\" , \"libhardware\" , ] , cflags : [ \"-Wall\" , \"-Werror\" , \"-Wextra\" , ] , } Include HAL Library and the Test app to the system packages : build/target/product/base_vendor.mk + PRODUCT_PACKAGES += \\ + invcase.default \\ + invcase_conventional_test This will include below files to system: /system/lib/hw/invcase.default.so /system/lib64/hw/invcase.default.so /system/bin/invcase_conventional_test Rebuild the system image , run the emulator and run the test app: Conventional HAL Test App","title":"HAL Library"},{"location":"blog/android/hal/classical/conventional/#jni-wrapper","text":"The Java Native Interface (JNI) is a foreign function interface programming framework that enables Java code running in a Java virtual machine (JVM) to call and be called by native applications (programs specific to a hardware and operating system platform) and libraries written in other languages such as C, C++ and assembly. Create java functions that call to native function in HAL library jni_read calls to invcase_read jni_write calls to invcase_write Register mapped functions with their signatures (encoded parameters) Note that Java functions always have 2 default arguments: JNIEnv* env : a structure containing methods that we can use our native code to access Java elements jobject selfClass : the class of calling object Implement JNI Mapping Note that the function jniRegisterNativeMethods will register JNI functions for the class frameworks/services/core/java/com/android/server/invcase/InvcaseService.java : frameworks/base/services/core/jni/com_android_server_invcase_InvcaseService.cpp #define LOG_TAG \"Invcase\" // #define INVCASE_USE_CONVENTIONAL_HAL #include \"jni.h\" #include <nativehelper/JNIHelp.h> #include \"android_runtime/AndroidRuntime.h\" #include <utils/misc.h> #include <utils/Log.h> #include <stdio.h> #include <hardware/hardware.h> #include <hardware/invcase.h> namespace android { static struct invcase_module_t * module = NULL ; static struct invcase_device_t * device = NULL ; static void jni_init ( JNIEnv * /* env */ , jobject /* clazz */ ) { int err ; err = hw_get_module ( INVCASE_HARDWARE_MODULE_ID , ( struct hw_module_t const ** ) & module ); if ( err != 0 ) { ALOGE ( \"JNI: hw_get_module() failed: (%s) \\n \" , strerror ( - err )); return ; } else { ALOGD ( \"JNI: hw_get_module() OK \\n \" ); if ( module -> common . methods -> open ( ( struct hw_module_t * ) module , INVCASE_HARDWARE_MODULE_ID , ( struct hw_device_t ** ) & device ) != 0 ) { ALOGE ( \"JNI: HAL failed to open! (%s) \\n \" , strerror ( - err )); return ; } else { ALOGD ( \"JNI: hw_get_module() Open: OK \\n \" ); } } } static void jni_deinit ( JNIEnv * /* env */ , jobject /* clazz */ ) { if ( device ) { free ( device ); ALOGD ( \"JNI: Free device \\n \" ); } } static jstring jni_read ( JNIEnv * env , jobject /* clazz */ ) { char buff [ INVCASE_BUFFER_MAX_SIZE ]; int err = -1 ; if ( device ) { ALOGD ( \"JNI: device->read: %p \\n \" , device -> read ); err = device -> read ( buff , INVCASE_BUFFER_MAX_SIZE ); } else { ALOGE ( \"JNI: Device is NULL \\n \" ); } if ( err != 0 ) { ALOGE ( \"JNI: Can not read from device \\n \" ); } ALOGD ( \"JNI: jni_read: %s \\n \" , buff ); return env -> NewStringUTF ( buff ); } static void jni_write ( JNIEnv * env , jobject /* clazz */ , jstring string ) { const char * buff = env -> GetStringUTFChars ( string , NULL ); int length = env -> GetStringLength ( string ); int err = -1 ; ALOGD ( \"JNI: jni_write: %s length= %d \\n \" , buff , length ); if ( device ) { ALOGD ( \"JNI: device->write: %p \\n \" , device -> write ); err = device -> write (( char * ) buff , length ); } else { ALOGE ( \"JNI: Device is NULL \\n \" ); } if ( err != 0 ) { ALOGE ( \"JNI: Can not write to device \\n \" ); } } static const JNINativeMethod method_table [] = { { \"invcase_native_init\" , \"()V\" , ( void * ) jni_init }, { \"invcase_native_deinit\" , \"()V\" , ( void * ) jni_deinit }, { \"invcase_native_read\" , \"()Ljava/lang/String;\" , ( void * ) jni_read }, { \"invcase_native_write\" , \"(Ljava/lang/String;)V\" , ( void * ) jni_write }, }; int register_android_server_InvcaseService ( JNIEnv * env ) { ALOGD ( \"JNI: register_android_server_InvcaseService \\n \" ); return jniRegisterNativeMethods ( env , \"com/android/server/invcase/InvcaseService\" , method_table , NELEM ( method_table ) ); } } Call the register function : frameworks/base/services/core/jni/onload.cpp namespace android { + int register_android_server_InvcaseService(JNIEnv *env); }; extern \"C\" jint JNI_OnLoad(JavaVM* vm, void* /* reserved */) { + register_android_server_InvcaseService(env); } Build new JNI wrapper : frameworks/base/services/core/jni/Android.bp cc_library_static { name: \"libservices.core\", srcs: [ + \"com_android_server_invcase_InvcaseService.cpp\", ], } cc_defaults { name: \"libservices.core-libs\", shared_libs: [ + \"libinvcase\", ], Declare API : frameworks/base/api/current.txt + package android.hardware.invcase { + + public final class InvcaseManager { + method @NonNull public String getData(); + method public void putData(@NonNull String); + } + + }","title":"JNI Wrapper"},{"location":"blog/android/hal/classical/conventional/#service-and-manager","text":"Define a name for new Service frameworks/base/core/java/android/content/Context.java public abstract class Context { @StringDef(suffix = { \"_SERVICE\" }, value = { + INVCASE_SERVICE, }) + /** + * Use with {@link #getSystemService(String)} to retrieve a + * {@link android.hardware.invcase.InvcaseManager}. + * + * @see #getSystemService(String) + * @hide + */ + public static final String INVCASE_SERVICE = \"invcase\"; Define the Service Interface Use AIDL to describe public functions exported by the Service: frameworks/base/core/java/android/hardware/invcase/IInvcaseManager.aidl package android.hardware.invcase ; /** * Invcase Manager interface * * {@hide} */ interface IInvcaseManager { String getData (); void putData ( String data ); } Build AIDL : frameworks/base/Android.bp java_defaults { name: \"framework-defaults\", installable: true, srcs: [ + \"core/java/android/hardware/invcase/IInvcaseManager.aidl\", ] } Implement the Service Manager A Service Manager is the wrapper for the interface of the target Service which is obtained by calling to <Interface>.Stub.asInterface . User application will call to the functions of the Service Manager, not directly calling to the actual service interface. frameworks/base/core/java/android/hardware/invcase/InvcaseManager.java package android.hardware.invcase ; import android.annotation.NonNull ; import android.content.Context ; import android.util.Log ; import android.os.RemoteException ; import android.os.ServiceManager ; import android.os.ServiceManager.ServiceNotFoundException ; public final class InvcaseManager { static final String TAG = \"Invcase\" ; private final Context mContext ; private final IInvcaseManager mService ; /** * Creates a InvcaseManager. * * @hide */ public InvcaseManager ( @NonNull Context context ) throws ServiceNotFoundException { this ( context , IInvcaseManager . Stub . asInterface ( ServiceManager . getServiceOrThrow ( Context . INVCASE_SERVICE ))); } /** * Creates a InvcaseManager with a provided service implementation. * * @hide */ public InvcaseManager ( @NonNull Context context , @NonNull IInvcaseManager service ) { mContext = context ; mService = service ; Log . d ( TAG , \"InvcaseManager: mContext= \" + mContext + \" mService= \" + mService ); } public @NonNull String getData () { try { String str = mService . getData (); Log . d ( TAG , \"InvcaseManager: mService.getData= \" + str ); return str ; } catch ( RemoteException e ) { e . printStackTrace (); } return null ; } public void putData ( @NonNull String data ) { try { Log . d ( TAG , \"InvcaseManager: mService.putData= \" + data ); mService . putData ( data ); } catch ( RemoteException e ) { e . printStackTrace (); } } } Implement the Service The Service will implement the actual code for Service Interface functions by extending the <Interface>.Stub class. Note that JNI Native functions are exported to this object, therefore, it can call to HAL library\u2019s functions. frameworks/base/services/core/java/com/android/server/invcase/InvcaseService.java package com.android.server.invcase ; import android.hardware.invcase.IInvcaseManager ; import android.content.Context ; import android.util.Log ; import com.android.server.SystemService ; public class InvcaseService extends SystemService { static final String TAG = \"Invcase\" ; static final boolean DEBUG = false ; final IInvcaseManagerImpl mManagerService ; private final class IInvcaseManagerImpl extends IInvcaseManager . Stub { @Override public String getData () { String str = invcase_native_read (); Log . d ( TAG , \"InvcaseService: IInvcaseManager.getData= \" + str ); return str ; } @Override public void putData ( String data ) { Log . d ( TAG , \"InvcaseService: IInvcaseManager.putData= \" + data ); invcase_native_write ( data ); } } public InvcaseService ( Context context ) { super ( context ); invcase_native_init (); mManagerService = new IInvcaseManagerImpl (); Log . d ( TAG , \"InvcaseService: mManagerService= \" + mManagerService ); } @Override public void onStart () { publishBinderService ( Context . INVCASE_SERVICE , mManagerService ); Log . d ( TAG , \"InvcaseService: onStart\" ); } @Override protected void finalize () throws Throwable { invcase_native_deinit (); super . finalize (); } private static native void invcase_native_init (); private static native void invcase_native_deinit (); private static native String invcase_native_read (); private static native void invcase_native_write ( String string ); } Run our service : All system services are run in the same process called system_server which is implemented in the SystemServer.java . This process runs under system user. frameworks/base/services/java/com/android/server/SystemServer.java import com.android.server.invcase.InvcaseService; import android.util.Log; public final class SystemServer implements Dumpable { private void startBootstrapServices(@NonNull TimingsTraceAndSlog t) { + // Manages Invcase device. + traceBeginAndSlog(\"StartInvcaseService\"); + Log.d(\"Invcase\", \"SystemServer: start InvcaseService\"); + mSystemServiceManager.startService(InvcaseService.class); + traceEnd();","title":"Service and Manager"},{"location":"blog/android/hal/classical/conventional/#user-app","text":"The User App will be very simple to test the hardware. It contains an EditText to get user input, a Button to execute commands, and a TextView to display the result. Implement the User App Use getSystemService(Context.INVCASE_SERVICE) to obtain the instance of InvcaseManager Call to hardware through the InvcaseManager APIs packages/apps/Invcase/src/com/invcase/Invcase.java package com.invcase ; import android.hardware.invcase.InvcaseManager ; import android.content.Context ; import android.app.Activity ; import android.os.Bundle ; import android.view.View ; import android.widget.Button ; import android.widget.EditText ; import android.widget.TextView ; import android.util.Log ; public class Invcase extends Activity { private static final String TAG = \"Invcase\" ; private InvcaseManager mManager ; @Override protected void onCreate ( Bundle savedInstanceState ) { super . onCreate ( savedInstanceState ); setContentView ( R . layout . activity_main ); mManager = ( InvcaseManager ) getSystemService ( Context . INVCASE_SERVICE ); Log . d ( TAG , \"App: mManager= \" + mManager ); Button btn = ( Button ) findViewById ( R . id . button ); btn . setOnClickListener ( new View . OnClickListener () { @Override public void onClick ( View view ) { EditText editText = ( EditText ) findViewById ( R . id . editText ); String txt = editText . getText (). toString (); Log . d ( TAG , \"App: request= \" + txt ); mManager . putData ( txt ); String ret = mManager . getData (); Log . d ( TAG , \"App: received= \" + ret ); TextView tv = ( TextView ) findViewById ( R . id . textView ); tv . setText ( ret ); } }); } } Add User App to the Launcher packages/apps/Invcase/AndroidManifest.xml <?xml version=\"1.0\" encoding=\"utf-8\"?> <manifest xmlns:android= \"http://schemas.android.com/apk/res/android\" package= \"com.invcase\" > <application android:icon= \"@mipmap/ic_launcher\" android:label= \"@string/app_name\" > <activity android:name= \".Invcase\" android:exported= \"true\" android:label= \"@string/app_name\" > <intent-filter> <action android:name= \"android.intent.action.MAIN\" /> <category android:name= \"android.intent.category.LAUNCHER\" /> </intent-filter> </activity> </application> </manifest> on Android 12, must use android:exported=\"true\" Build User App packages/apps/Invcase/Android.bp android_app { name : \"Invcase\" , platform_apis : true, srcs : [ \"src/**/*.java\" ] } Add User App to system packages : build/target/product/base_vendor.mk + PRODUCT_PACKAGES += \\ + Invcase","title":"User App"},{"location":"blog/android/hal/classical/conventional/#permission","text":"The device /dev/invcase is created at boot with root permission. The HAL Library is loaded when JNI Wrapper for Invcase Service is run, therefore, HAL code will run with system permission which attaches to the system_server process. The Android Init Language uses init*.rc files to automatically do some actions when a condition is met. For the target hardware, Android Init will use init.<hardware>.rc file. On Emulator, it is init.ranchu.rc . Add below lines to change the owner and permission on the /dev/invcase at boot: device/generic/goldfish/init.ranchu.rc + on boot + chown system system /dev/invcase + chmod 0600 /dev/invcase","title":"Permission"},{"location":"blog/android/hal/classical/conventional/#build-and-run","text":"The Invcase Manager exports new Service APIs, therefore, need to rebuild the list of system APIs. m all -j $( nproc ) Run the Emulator and run Invcase app: The User Test application Start the Logcat to see debug lines: logcat -s Invcase Logcat shows Invcase calls There are 2 processes: The system_server process (yellow) does below things: Load HAL module Load JNI functions Start Invcase Service whichs creates an object of Invcase Manager Implementation The user app process (white) does below things: Load System Service Registry to have an object of Invcase Manager Interface Use received service interface to communicate with Invcase Manager Implementation in the Invcase Service","title":"Build and Run"},{"location":"blog/android/hal/classical/legacy/","tags":["android","hal"],"text":"This guide is written for AOSP android-10.0.0_r47 Legacy HAL # Legacy HALs (deprecated in Android 8.0) are interfaces that predate conventional HALs. While there\u2019s no uniform or standardized way to describe a legacy HAL, anything predating Android 8.0 that is not a conventional HAL is a legacy HAL. A few important subsystems (Wi-Fi, Radio Interface Layer, and Bluetooth) are legacy HALs. Parts of some legacy HALs are contained in libhardware_legacy , while other parts are interspersed throughout the codebase. This method is the simplest way to implement a HAL library because it is the way to create a shared library without any standardized interface. Access to HAL # The HAL implementations are built to lib*.so . You can link to the library and call to its functions. For example: Android.bp shared_libs : [ \"lib<hardware>\" , ] Framework Stacks # Legacy HAL in the Framework stacks Implementation # legacy_hal.zip Refer to Kernel Module to build and install a module to system. This guide assumes that invcase module is loaded as below: device/generic/goldfish/init.ranchu.rc + on boot + insmod /system/lib/modules/invcase.ko + chown system system /dev/invcase + chmod 0600 /dev/invcase Overview # AOSP build make target product base_vendor.mk Include new packages + PRODUCT_PACKAGES += \\ + libinvcase \\ + invcase_legacy_test \\ + Invcase packages apps Invcase src com invcase Invcase.java Get InvcaseManager from SystemService class Invcase extends Activity { InvcaseManager mManager ; onCreate () { mManager = getSystemService ( Context . INVCASE_SERVICE ); } } res layout mipmap values AndroidManifest.xml Export main activity on Launcher <manifest package= \"com.invcase\" > <application> <activity android:name= \".Invcase\" android:exported= \"true\" > <intent-filter> <action android:name= \"android.intent.action.MAIN\" /> <category android:name= \"android.intent.category.LAUNCHER\" /> </intent-filter> </activity> </application> </manifest> android:exported=\"true\" is mandatory on Android 12 Android.bp android_app { name : \"Invcase\" , srcs : [ \"src/**/*.java\" ] , platform_apis : true } platform_apis: true : use System API when do not specify any target platform frameworks base Android.bp java_defaults { name: \"framework-defaults\", installable: true, srcs: [ + \"core/java/android/hardware/invcase/IInvcaseManager.aidl\", ] } api current.txt + package android.hardware.invcase { + + public final class InvcaseManager { + method @NonNull public String getData(); + method public void putData(@NonNull String); + } + + } core java android app SystemServiceRegistry.java Create an InvcaseManager instance and add it to the System Service list + import android.hardware.invcase.InvcaseManager; public final class SystemServiceRegistry { static { + registerService(Context.INVCASE_SERVICE, InvcaseManager.class, + new CachedServiceFetcher<InvcaseManager>() { + @Override + public InvcaseManager createService(ContextImpl ctx) + throws ServiceNotFoundException { + return new InvcaseManager(ctx); + }}); } } content Context.java Add Invcase Serive name public abstract class Context { + public static final String INVCASE_SERVICE = \"invcase\"; @StringDef(suffix = { \"_SERVICE\" }, value = { + INVCASE_SERVICE, }) } hardware invcase IInvcaseManager.aidl Define API for Invcase Interface interface IInvcaseManager { getData (); putData (); } InvcaseManager.java Use Invase Serive through the Invcase Interface class InvcaseManager { IInvcaseManager mService ; InvcaseManager ( Context ) throws ServiceNotFoundException { this ( context , IInvcaseManager . Stub . asInterface ( ServiceManager . getServiceOrThrow ( Context . INVCASE_SERVICE )) ); } InvcaseManager ( Context , IInvcaseManager ){} getData () { mService . getData (); } putData () { mService . putData (); } } services core java com android server invcase InvcaseService.java Implement Invcase Interface functions, public the interface class InvcaseService extends SystemService { IInvcaseManagerImpl extends IInvcaseManager . Stub { getData () { invcase_native_read (); } putData () { invcase_native_write (); } } mManagerService ; onStart () { publishBinderService ( Context . INVCASE_SERVICE , mManagerService ); } } jni com_android_server_invcase_InvcaseService.cpp Map java functions to native functions #include <hardware_legacy/invcase.h> jni_read () { invcase_read (); } jni_write () { invcase_write (); } static const JNINativeMethod method_table [] = { { \"invcase_native_read\" , \"()Ljava/lang/String;\" , ( void * ) jni_read }, { \"invcase_native_write\" , \"(Ljava/lang/String;)V\" , ( void * ) jni_write }, }; register_android_server_InvcaseService ( method_table ); onload.cpp Register mapped function calls namespace android { + int register_android_server_InvcaseService(JNIEnv *env); }; extern \"C\" jint JNI_OnLoad(JavaVM* vm, void* /* reserved */) { + register_android_server_InvcaseService(env); } Android.bp cc_library_static { srcs: [ + \"com_android_server_invcase_InvcaseService.cpp\", ], } cc_defaults { shared_libs: [ + \"libinvcase\", ], } java com android server SystemServer.java Start Invcase Service + import com.android.server.invcase.InvcaseService; public final class SystemServer implements Dumpable { private void startBootstrapServices(@NonNull TimingsTraceAndSlog t) { + traceBeginAndSlog(\"StartInvcaseService\"); + mSystemServiceManager.startService(InvcaseService.class); + traceEnd(); } } hardware libhardware_legacy include hardware_legacy invcase.h Declare APIs invcase_read (); invcase_write (); Wrap with extern \"C\" {} when using C language invcase invase.c Implement APIs using the device file invcase_read () { read ( \"/dev/invcase\" ); } invcase_write () { write ( \"/dev/invcase\" ); } Android.bp cc_library_shared { name : \"libinvcase\" } test invcase_legacy_test.c Android.bp HAL Library # Define headers : Declare APIs: invcase_read invcase_write hardware/libhardware_legacy/include/hardware_legacy/invcase.h #ifndef INVCASE_LEGACY_H #define INVCASE_LEGACY_H #include <sys/types.h> #ifdef __cplusplus extern \"C\" { #endif #define INVCASE_BUFFER_MAX_SIZE 1024 int invcase_read ( char * buf , size_t count ); int invcase_write ( char * buf , size_t count ); #ifdef __cplusplus } #endif #endif /* INVCASE_LEGACY_H */ Implement the library : Include utils/Log.h to use ALOGD , ALOGE macros which will print out to Logcat Implement the APIs which return 0 when succeeded hardware/libhardware_legacy/invcase/invcase.c #define LOG_TAG \"Invcase\" #include <stdlib.h> #include <stdio.h> #include <string.h> #include <fcntl.h> #include <unistd.h> #include <sys/stat.h> #include <utils/Log.h> #include \"hardware_legacy/invcase.h\" #define INVCASE_DEVICE_FILE \"/dev/invcase\" void __attribute__ (( constructor )) invcase_loaded () { ALOGD ( \"Legacy HAL Module: Loaded\" ); } void __attribute__ (( destructor )) invcase_unloaded () { ALOGD ( \"Legacy HAL Module: Unloaded\" ); } int invcase_write ( char * buf , size_t count ) { int fd ; int ret ; fd = open ( INVCASE_DEVICE_FILE , O_WRONLY ); if ( fd < 0 ) { ALOGE ( \"Unable to open %s to write \\n \" , INVCASE_DEVICE_FILE ); return fd ; } ret = write ( fd , buf , count ); if ( ret < 0 ) { ALOGE ( \"Unable to write to %s \\n \" , INVCASE_DEVICE_FILE ); return ret ; } ALOGD ( \"invcase_write: buf= %s \\n \" , buf ); close ( fd ); return 0 ; } int invcase_read ( char * buf , size_t count ) { int fd ; int ret ; fd = open ( INVCASE_DEVICE_FILE , O_RDONLY ); if ( fd < 0 ) { ALOGE ( \"Unable to open %s to read \\n \" , INVCASE_DEVICE_FILE ); return fd ; } ret = read ( fd , buf , count ); if ( ret < 0 ) { ALOGE ( \"Unable to read from %s \\n \" , INVCASE_DEVICE_FILE ); return ret ; } ALOGD ( \"invcase_read: buf= %s \\n \" , buf ); close ( fd ); return 0 ; } Build the shared library libinvcase.so : hardware/libhardware_legacy/invcase/Android.bp cc_library_shared { name : \"libinvcase\" , srcs : [ \"invcase.c\" ] , cflags : [ \"-Wall\" , \"-Werror\" ] , header_libs : [ \"libhardware_legacy_headers\" ] , shared_libs : [ \"liblog\" , \"libcutils\" , ] , } A test application that uses the HAL shared library: hardware/libhardware_legacy/invcase/test/invcase_legacy_test.c #include <stdio.h> #include <string.h> #include \"hardware_legacy/invcase.h\" int main () { char buffer [ INVCASE_BUFFER_MAX_SIZE ]; printf ( \"InvCase Legacy HAL Test App \\n \" ); printf ( \"Input a string: \" ); scanf ( \"%s\" , buffer ); invcase_write ( buffer , strlen ( buffer )); invcase_read ( buffer , INVCASE_BUFFER_MAX_SIZE ); printf ( \"Converted string: \" ); printf ( \"%s \\n \" , buffer ); return 0 ; } Build the test app: hardware/libhardware_legacy/invcase/test/Android.bp cc_binary { name : \"invcase_legacy_test\" , srcs : [ \"invcase_legacy_test.c\" ] , shared_libs : [ \"libinvcase\" ] , } Include HAL Library and the Test app to the system packages : build/target/product/base_vendor.mk + PRODUCT_PACKAGES += \\ + libinvcase \\ + invcase_legacy_test This will include below files to system: /system/lib/libinvcase.so /system/lib64/libinvcase.so /system/bin/invcase_legacy_test Rebuild the system image , run the emulator and run the test app: Legacy HAL Test App JNI Wrapper # The Java Native Interface (JNI) is a foreign function interface programming framework that enables Java code running in a Java virtual machine (JVM) to call and be called by native applications (programs specific to a hardware and operating system platform) and libraries written in other languages such as C, C++ and assembly. Create java functions that call to native function in HAL library jni_read calls to invcase_read jni_write calls to invcase_write Register mapped functions with their signatures (encoded parameters) Note that Java functions always have 2 default arguments: JNIEnv* env : a structure containing methods that we can use our native code to access Java elements jobject selfClass : the class of calling object Implement JNI Mapping Note that the function jniRegisterNativeMethods will register JNI functions for the class frameworks/services/core/java/com/android/server/invcase/InvcaseService.java : frameworks/base/services/core/jni/com_android_server_invcase_InvcaseService.cpp #define LOG_TAG \"Invcase\" #include \"jni.h\" #include <nativehelper/JNIHelp.h> #include \"android_runtime/AndroidRuntime.h\" #include <utils/misc.h> #include <utils/Log.h> #include <stdio.h> #include <hardware_legacy/invcase.h> namespace android { static void jni_init ( JNIEnv * /* env */ , jobject /* clazz */ ) { } static void jni_deinit ( JNIEnv * /* env */ , jobject /* clazz */ ) { } static jstring jni_read ( JNIEnv * env , jobject /* clazz */ ) { char buff [ INVCASE_BUFFER_MAX_SIZE ]; int err = -1 ; ALOGD ( \"JNI: invcase_read: %p \\n \" , invcase_read ); err = invcase_read ( buff , INVCASE_BUFFER_MAX_SIZE ); if ( err != 0 ) { ALOGE ( \"JNI: Can not read from device \\n \" ); } ALOGD ( \"JNI: jni_read: %s \\n \" , buff ); return env -> NewStringUTF ( buff ); } static void jni_write ( JNIEnv * env , jobject /* clazz */ , jstring string ) { const char * buff = env -> GetStringUTFChars ( string , NULL ); int length = env -> GetStringLength ( string ); int err = -1 ; ALOGD ( \"JNI: jni_write: %s length= %d \\n \" , buff , length ); ALOGD ( \"JNI: invcase_write: %p \\n \" , invcase_write ); err = invcase_write (( char * ) buff , length ); if ( err != 0 ) { ALOGE ( \"JNI: Can not write to device \\n \" ); } } static const JNINativeMethod method_table [] = { { \"invcase_native_init\" , \"()V\" , ( void * ) jni_init }, { \"invcase_native_deinit\" , \"()V\" , ( void * ) jni_deinit }, { \"invcase_native_read\" , \"()Ljava/lang/String;\" , ( void * ) jni_read }, { \"invcase_native_write\" , \"(Ljava/lang/String;)V\" , ( void * ) jni_write }, }; int register_android_server_InvcaseService ( JNIEnv * env ) { ALOGD ( \"JNI: register_android_server_InvcaseService \\n \" ); return jniRegisterNativeMethods ( env , \"com/android/server/invcase/InvcaseService\" , method_table , NELEM ( method_table ) ); } } Call the register function : frameworks/base/services/core/jni/onload.cpp namespace android { + int register_android_server_InvcaseService(JNIEnv *env); }; extern \"C\" jint JNI_OnLoad(JavaVM* vm, void* /* reserved */) { + register_android_server_InvcaseService(env); } Build new JNI wrapper : frameworks/base/services/core/jni/Android.bp cc_library_static { name: \"libservices.core\", srcs: [ + \"com_android_server_invcase_InvcaseService.cpp\", ], } cc_defaults { name: \"libservices.core-libs\", shared_libs: [ + \"libinvcase\", ], Declare API : frameworks/base/api/current.txt + package android.hardware.invcase { + + public final class InvcaseManager { + method @NonNull public String getData(); + method public void putData(@NonNull String); + } + + } Service and Manager # Define a name for new Service frameworks/base/core/java/android/content/Context.java public abstract class Context { @StringDef(suffix = { \"_SERVICE\" }, value = { + INVCASE_SERVICE, }) + /** + * Use with {@link #getSystemService(String)} to retrieve a + * {@link android.hardware.invcase.InvcaseManager}. + * + * @see #getSystemService(String) + * @hide + */ + public static final String INVCASE_SERVICE = \"invcase\"; Define the Service Interface Use AIDL to describe public functions exported by the Service: frameworks/base/core/java/android/hardware/invcase/IInvcaseManager.aidl package android.hardware.invcase ; /** * Invcase Manager interface * * {@hide} */ interface IInvcaseManager { String getData (); void putData ( String data ); } Build AIDL : frameworks/base/Android.bp java_defaults { name: \"framework-defaults\", installable: true, srcs: [ + \"core/java/android/hardware/invcase/IInvcaseManager.aidl\", ] } Implement the Service Manager A Service Manager is the wrapper for the interface of the target Service which is obtained by calling to <Interface>.Stub.asInterface . User application will call to the functions of the Service Manager, not directly calling to the actual service interface. frameworks/base/core/java/android/hardware/invcase/InvcaseManager.java package android.hardware.invcase ; import android.annotation.NonNull ; import android.content.Context ; import android.util.Log ; import android.os.RemoteException ; import android.os.ServiceManager ; import android.os.ServiceManager.ServiceNotFoundException ; public final class InvcaseManager { static final String TAG = \"Invcase\" ; private final Context mContext ; private final IInvcaseManager mService ; /** * Creates a InvcaseManager. * * @hide */ public InvcaseManager ( @NonNull Context context ) throws ServiceNotFoundException { this ( context , IInvcaseManager . Stub . asInterface ( ServiceManager . getServiceOrThrow ( Context . INVCASE_SERVICE ))); } /** * Creates a InvcaseManager with a provided service implementation. * * @hide */ public InvcaseManager ( @NonNull Context context , @NonNull IInvcaseManager service ) { mContext = context ; mService = service ; Log . d ( TAG , \"InvcaseManager: mContext= \" + mContext + \" mService= \" + mService ); } public @NonNull String getData () { try { String str = mService . getData (); Log . d ( TAG , \"InvcaseManager: mService.getData= \" + str ); return str ; } catch ( RemoteException e ) { e . printStackTrace (); } return null ; } public void putData ( @NonNull String data ) { try { Log . d ( TAG , \"InvcaseManager: mService.putData= \" + data ); mService . putData ( data ); } catch ( RemoteException e ) { e . printStackTrace (); } } } Implement the Service The Service will implement the actual code for Service Interface functions by extending the <Interface>.Stub class. Note that JNI Native functions are exported to this object, therefore, it can call to HAL library\u2019s functions. frameworks/base/services/core/java/com/android/server/invcase/InvcaseService.java package com.android.server.invcase ; import android.hardware.invcase.IInvcaseManager ; import android.content.Context ; import android.util.Log ; import com.android.server.SystemService ; public class InvcaseService extends SystemService { static final String TAG = \"Invcase\" ; static final boolean DEBUG = false ; final IInvcaseManagerImpl mManagerService ; private final class IInvcaseManagerImpl extends IInvcaseManager . Stub { @Override public String getData () { String str = invcase_native_read (); Log . d ( TAG , \"InvcaseService: IInvcaseManager.getData= \" + str ); return str ; } @Override public void putData ( String data ) { Log . d ( TAG , \"InvcaseService: IInvcaseManager.putData= \" + data ); invcase_native_write ( data ); } } public InvcaseService ( Context context ) { super ( context ); invcase_native_init (); mManagerService = new IInvcaseManagerImpl (); Log . d ( TAG , \"InvcaseService: mManagerService= \" + mManagerService ); } @Override public void onStart () { publishBinderService ( Context . INVCASE_SERVICE , mManagerService ); Log . d ( TAG , \"InvcaseService: onStart\" ); } @Override protected void finalize () throws Throwable { invcase_native_deinit (); super . finalize (); } private static native void invcase_native_init (); private static native void invcase_native_deinit (); private static native String invcase_native_read (); private static native void invcase_native_write ( String string ); } Run our service : All system services are run in the same process called system_server which is implemented in the SystemServer.java . This process runs under system user. frameworks/base/services/java/com/android/server/SystemServer.java import com.android.server.invcase.InvcaseService; import android.util.Log; public final class SystemServer implements Dumpable { private void startBootstrapServices(@NonNull TimingsTraceAndSlog t) { + // Manages Invcase device. + traceBeginAndSlog(\"StartInvcaseService\"); + Log.d(\"Invcase\", \"SystemServer: start InvcaseService\"); + mSystemServiceManager.startService(InvcaseService.class); + traceEnd(); User App # The User App will be very simple to test the hardware. It contains an EditText to get user input, a Button to execute commands, and a TextView to display the result. Implement the User App Use getSystemService(Context.INVCASE_SERVICE) to obtain the instance of InvcaseManager Call to hardware through the InvcaseManager APIs packages/apps/Invcase/src/com/invcase/Invcase.java package com.invcase ; import android.hardware.invcase.InvcaseManager ; import android.content.Context ; import android.app.Activity ; import android.os.Bundle ; import android.view.View ; import android.widget.Button ; import android.widget.EditText ; import android.widget.TextView ; import android.util.Log ; public class Invcase extends Activity { private static final String TAG = \"Invcase\" ; private InvcaseManager mManager ; @Override protected void onCreate ( Bundle savedInstanceState ) { super . onCreate ( savedInstanceState ); setContentView ( R . layout . activity_main ); mManager = ( InvcaseManager ) getSystemService ( Context . INVCASE_SERVICE ); Log . d ( TAG , \"App: mManager= \" + mManager ); Button btn = ( Button ) findViewById ( R . id . button ); btn . setOnClickListener ( new View . OnClickListener () { @Override public void onClick ( View view ) { EditText editText = ( EditText ) findViewById ( R . id . editText ); String txt = editText . getText (). toString (); Log . d ( TAG , \"App: request= \" + txt ); mManager . putData ( txt ); String ret = mManager . getData (); Log . d ( TAG , \"App: received= \" + ret ); TextView tv = ( TextView ) findViewById ( R . id . textView ); tv . setText ( ret ); } }); } } Add User App to the Launcher packages/apps/Invcase/AndroidManifest.xml <?xml version=\"1.0\" encoding=\"utf-8\"?> <manifest xmlns:android= \"http://schemas.android.com/apk/res/android\" package= \"com.invcase\" > <application android:icon= \"@mipmap/ic_launcher\" android:label= \"@string/app_name\" > <activity android:name= \".Invcase\" android:exported= \"true\" android:label= \"@string/app_name\" > <intent-filter> <action android:name= \"android.intent.action.MAIN\" /> <category android:name= \"android.intent.category.LAUNCHER\" /> </intent-filter> </activity> </application> </manifest> on Android 12, must use android:exported=\"true\" Build User App packages/apps/Invcase/Android.bp android_app { name : \"Invcase\" , platform_apis : true, srcs : [ \"src/**/*.java\" ] } Add User App to system packages : build/target/product/base_vendor.mk + PRODUCT_PACKAGES += \\ + Invcase Permission # The device /dev/invcase is created at boot with root permission. The HAL Library is loaded when JNI Wrapper for Invcase Service is run, therefore, HAL code will run with system permission which attaches to the system_server process. The Android Init Language uses init*.rc files to automatically do some actions when a condition is met. For the target hardware, Android Init will use init.<hardware>.rc file. On Emulator, it is init.ranchu.rc . Add below lines to change the owner and permission on the /dev/invcase at boot: device/generic/goldfish/init.ranchu.rc + on boot + chown system system /dev/invcase + chmod 0600 /dev/invcase Build and Run # The Invcase Manager exports new Service APIs, therefore, need to rebuild the list of system APIs. m all -j $( nproc ) Run the Emulator and run Invcase app: The User Test application Start the Logcat to see debug lines: logcat -s Invcase Logcat shows Invcase calls There are 2 processes: The system_server process (yellow) does below things: Load HAL module Load JNI functions Start Invcase Service whichs creates an object of Invcase Manager Implementation The user app process (white) does below things: Load System Service Registry to have an object of Invcase Manager Interface Use received service interface to communicate with Invcase Manager Implementation in the Invcase Service","title":"Legacy HAL"},{"location":"blog/android/hal/classical/legacy/#legacy-hal","text":"Legacy HALs (deprecated in Android 8.0) are interfaces that predate conventional HALs. While there\u2019s no uniform or standardized way to describe a legacy HAL, anything predating Android 8.0 that is not a conventional HAL is a legacy HAL. A few important subsystems (Wi-Fi, Radio Interface Layer, and Bluetooth) are legacy HALs. Parts of some legacy HALs are contained in libhardware_legacy , while other parts are interspersed throughout the codebase. This method is the simplest way to implement a HAL library because it is the way to create a shared library without any standardized interface.","title":"Legacy HAL"},{"location":"blog/android/hal/classical/legacy/#access-to-hal","text":"The HAL implementations are built to lib*.so . You can link to the library and call to its functions. For example: Android.bp shared_libs : [ \"lib<hardware>\" , ]","title":"Access to HAL"},{"location":"blog/android/hal/classical/legacy/#framework-stacks","text":"Legacy HAL in the Framework stacks","title":"Framework Stacks"},{"location":"blog/android/hal/classical/legacy/#implementation","text":"legacy_hal.zip Refer to Kernel Module to build and install a module to system. This guide assumes that invcase module is loaded as below: device/generic/goldfish/init.ranchu.rc + on boot + insmod /system/lib/modules/invcase.ko + chown system system /dev/invcase + chmod 0600 /dev/invcase","title":"Implementation"},{"location":"blog/android/hal/classical/legacy/#overview","text":"AOSP build make target product base_vendor.mk Include new packages + PRODUCT_PACKAGES += \\ + libinvcase \\ + invcase_legacy_test \\ + Invcase packages apps Invcase src com invcase Invcase.java Get InvcaseManager from SystemService class Invcase extends Activity { InvcaseManager mManager ; onCreate () { mManager = getSystemService ( Context . INVCASE_SERVICE ); } } res layout mipmap values AndroidManifest.xml Export main activity on Launcher <manifest package= \"com.invcase\" > <application> <activity android:name= \".Invcase\" android:exported= \"true\" > <intent-filter> <action android:name= \"android.intent.action.MAIN\" /> <category android:name= \"android.intent.category.LAUNCHER\" /> </intent-filter> </activity> </application> </manifest> android:exported=\"true\" is mandatory on Android 12 Android.bp android_app { name : \"Invcase\" , srcs : [ \"src/**/*.java\" ] , platform_apis : true } platform_apis: true : use System API when do not specify any target platform frameworks base Android.bp java_defaults { name: \"framework-defaults\", installable: true, srcs: [ + \"core/java/android/hardware/invcase/IInvcaseManager.aidl\", ] } api current.txt + package android.hardware.invcase { + + public final class InvcaseManager { + method @NonNull public String getData(); + method public void putData(@NonNull String); + } + + } core java android app SystemServiceRegistry.java Create an InvcaseManager instance and add it to the System Service list + import android.hardware.invcase.InvcaseManager; public final class SystemServiceRegistry { static { + registerService(Context.INVCASE_SERVICE, InvcaseManager.class, + new CachedServiceFetcher<InvcaseManager>() { + @Override + public InvcaseManager createService(ContextImpl ctx) + throws ServiceNotFoundException { + return new InvcaseManager(ctx); + }}); } } content Context.java Add Invcase Serive name public abstract class Context { + public static final String INVCASE_SERVICE = \"invcase\"; @StringDef(suffix = { \"_SERVICE\" }, value = { + INVCASE_SERVICE, }) } hardware invcase IInvcaseManager.aidl Define API for Invcase Interface interface IInvcaseManager { getData (); putData (); } InvcaseManager.java Use Invase Serive through the Invcase Interface class InvcaseManager { IInvcaseManager mService ; InvcaseManager ( Context ) throws ServiceNotFoundException { this ( context , IInvcaseManager . Stub . asInterface ( ServiceManager . getServiceOrThrow ( Context . INVCASE_SERVICE )) ); } InvcaseManager ( Context , IInvcaseManager ){} getData () { mService . getData (); } putData () { mService . putData (); } } services core java com android server invcase InvcaseService.java Implement Invcase Interface functions, public the interface class InvcaseService extends SystemService { IInvcaseManagerImpl extends IInvcaseManager . Stub { getData () { invcase_native_read (); } putData () { invcase_native_write (); } } mManagerService ; onStart () { publishBinderService ( Context . INVCASE_SERVICE , mManagerService ); } } jni com_android_server_invcase_InvcaseService.cpp Map java functions to native functions #include <hardware_legacy/invcase.h> jni_read () { invcase_read (); } jni_write () { invcase_write (); } static const JNINativeMethod method_table [] = { { \"invcase_native_read\" , \"()Ljava/lang/String;\" , ( void * ) jni_read }, { \"invcase_native_write\" , \"(Ljava/lang/String;)V\" , ( void * ) jni_write }, }; register_android_server_InvcaseService ( method_table ); onload.cpp Register mapped function calls namespace android { + int register_android_server_InvcaseService(JNIEnv *env); }; extern \"C\" jint JNI_OnLoad(JavaVM* vm, void* /* reserved */) { + register_android_server_InvcaseService(env); } Android.bp cc_library_static { srcs: [ + \"com_android_server_invcase_InvcaseService.cpp\", ], } cc_defaults { shared_libs: [ + \"libinvcase\", ], } java com android server SystemServer.java Start Invcase Service + import com.android.server.invcase.InvcaseService; public final class SystemServer implements Dumpable { private void startBootstrapServices(@NonNull TimingsTraceAndSlog t) { + traceBeginAndSlog(\"StartInvcaseService\"); + mSystemServiceManager.startService(InvcaseService.class); + traceEnd(); } } hardware libhardware_legacy include hardware_legacy invcase.h Declare APIs invcase_read (); invcase_write (); Wrap with extern \"C\" {} when using C language invcase invase.c Implement APIs using the device file invcase_read () { read ( \"/dev/invcase\" ); } invcase_write () { write ( \"/dev/invcase\" ); } Android.bp cc_library_shared { name : \"libinvcase\" } test invcase_legacy_test.c Android.bp","title":"Overview"},{"location":"blog/android/hal/classical/legacy/#hal-library","text":"Define headers : Declare APIs: invcase_read invcase_write hardware/libhardware_legacy/include/hardware_legacy/invcase.h #ifndef INVCASE_LEGACY_H #define INVCASE_LEGACY_H #include <sys/types.h> #ifdef __cplusplus extern \"C\" { #endif #define INVCASE_BUFFER_MAX_SIZE 1024 int invcase_read ( char * buf , size_t count ); int invcase_write ( char * buf , size_t count ); #ifdef __cplusplus } #endif #endif /* INVCASE_LEGACY_H */ Implement the library : Include utils/Log.h to use ALOGD , ALOGE macros which will print out to Logcat Implement the APIs which return 0 when succeeded hardware/libhardware_legacy/invcase/invcase.c #define LOG_TAG \"Invcase\" #include <stdlib.h> #include <stdio.h> #include <string.h> #include <fcntl.h> #include <unistd.h> #include <sys/stat.h> #include <utils/Log.h> #include \"hardware_legacy/invcase.h\" #define INVCASE_DEVICE_FILE \"/dev/invcase\" void __attribute__ (( constructor )) invcase_loaded () { ALOGD ( \"Legacy HAL Module: Loaded\" ); } void __attribute__ (( destructor )) invcase_unloaded () { ALOGD ( \"Legacy HAL Module: Unloaded\" ); } int invcase_write ( char * buf , size_t count ) { int fd ; int ret ; fd = open ( INVCASE_DEVICE_FILE , O_WRONLY ); if ( fd < 0 ) { ALOGE ( \"Unable to open %s to write \\n \" , INVCASE_DEVICE_FILE ); return fd ; } ret = write ( fd , buf , count ); if ( ret < 0 ) { ALOGE ( \"Unable to write to %s \\n \" , INVCASE_DEVICE_FILE ); return ret ; } ALOGD ( \"invcase_write: buf= %s \\n \" , buf ); close ( fd ); return 0 ; } int invcase_read ( char * buf , size_t count ) { int fd ; int ret ; fd = open ( INVCASE_DEVICE_FILE , O_RDONLY ); if ( fd < 0 ) { ALOGE ( \"Unable to open %s to read \\n \" , INVCASE_DEVICE_FILE ); return fd ; } ret = read ( fd , buf , count ); if ( ret < 0 ) { ALOGE ( \"Unable to read from %s \\n \" , INVCASE_DEVICE_FILE ); return ret ; } ALOGD ( \"invcase_read: buf= %s \\n \" , buf ); close ( fd ); return 0 ; } Build the shared library libinvcase.so : hardware/libhardware_legacy/invcase/Android.bp cc_library_shared { name : \"libinvcase\" , srcs : [ \"invcase.c\" ] , cflags : [ \"-Wall\" , \"-Werror\" ] , header_libs : [ \"libhardware_legacy_headers\" ] , shared_libs : [ \"liblog\" , \"libcutils\" , ] , } A test application that uses the HAL shared library: hardware/libhardware_legacy/invcase/test/invcase_legacy_test.c #include <stdio.h> #include <string.h> #include \"hardware_legacy/invcase.h\" int main () { char buffer [ INVCASE_BUFFER_MAX_SIZE ]; printf ( \"InvCase Legacy HAL Test App \\n \" ); printf ( \"Input a string: \" ); scanf ( \"%s\" , buffer ); invcase_write ( buffer , strlen ( buffer )); invcase_read ( buffer , INVCASE_BUFFER_MAX_SIZE ); printf ( \"Converted string: \" ); printf ( \"%s \\n \" , buffer ); return 0 ; } Build the test app: hardware/libhardware_legacy/invcase/test/Android.bp cc_binary { name : \"invcase_legacy_test\" , srcs : [ \"invcase_legacy_test.c\" ] , shared_libs : [ \"libinvcase\" ] , } Include HAL Library and the Test app to the system packages : build/target/product/base_vendor.mk + PRODUCT_PACKAGES += \\ + libinvcase \\ + invcase_legacy_test This will include below files to system: /system/lib/libinvcase.so /system/lib64/libinvcase.so /system/bin/invcase_legacy_test Rebuild the system image , run the emulator and run the test app: Legacy HAL Test App","title":"HAL Library"},{"location":"blog/android/hal/classical/legacy/#jni-wrapper","text":"The Java Native Interface (JNI) is a foreign function interface programming framework that enables Java code running in a Java virtual machine (JVM) to call and be called by native applications (programs specific to a hardware and operating system platform) and libraries written in other languages such as C, C++ and assembly. Create java functions that call to native function in HAL library jni_read calls to invcase_read jni_write calls to invcase_write Register mapped functions with their signatures (encoded parameters) Note that Java functions always have 2 default arguments: JNIEnv* env : a structure containing methods that we can use our native code to access Java elements jobject selfClass : the class of calling object Implement JNI Mapping Note that the function jniRegisterNativeMethods will register JNI functions for the class frameworks/services/core/java/com/android/server/invcase/InvcaseService.java : frameworks/base/services/core/jni/com_android_server_invcase_InvcaseService.cpp #define LOG_TAG \"Invcase\" #include \"jni.h\" #include <nativehelper/JNIHelp.h> #include \"android_runtime/AndroidRuntime.h\" #include <utils/misc.h> #include <utils/Log.h> #include <stdio.h> #include <hardware_legacy/invcase.h> namespace android { static void jni_init ( JNIEnv * /* env */ , jobject /* clazz */ ) { } static void jni_deinit ( JNIEnv * /* env */ , jobject /* clazz */ ) { } static jstring jni_read ( JNIEnv * env , jobject /* clazz */ ) { char buff [ INVCASE_BUFFER_MAX_SIZE ]; int err = -1 ; ALOGD ( \"JNI: invcase_read: %p \\n \" , invcase_read ); err = invcase_read ( buff , INVCASE_BUFFER_MAX_SIZE ); if ( err != 0 ) { ALOGE ( \"JNI: Can not read from device \\n \" ); } ALOGD ( \"JNI: jni_read: %s \\n \" , buff ); return env -> NewStringUTF ( buff ); } static void jni_write ( JNIEnv * env , jobject /* clazz */ , jstring string ) { const char * buff = env -> GetStringUTFChars ( string , NULL ); int length = env -> GetStringLength ( string ); int err = -1 ; ALOGD ( \"JNI: jni_write: %s length= %d \\n \" , buff , length ); ALOGD ( \"JNI: invcase_write: %p \\n \" , invcase_write ); err = invcase_write (( char * ) buff , length ); if ( err != 0 ) { ALOGE ( \"JNI: Can not write to device \\n \" ); } } static const JNINativeMethod method_table [] = { { \"invcase_native_init\" , \"()V\" , ( void * ) jni_init }, { \"invcase_native_deinit\" , \"()V\" , ( void * ) jni_deinit }, { \"invcase_native_read\" , \"()Ljava/lang/String;\" , ( void * ) jni_read }, { \"invcase_native_write\" , \"(Ljava/lang/String;)V\" , ( void * ) jni_write }, }; int register_android_server_InvcaseService ( JNIEnv * env ) { ALOGD ( \"JNI: register_android_server_InvcaseService \\n \" ); return jniRegisterNativeMethods ( env , \"com/android/server/invcase/InvcaseService\" , method_table , NELEM ( method_table ) ); } } Call the register function : frameworks/base/services/core/jni/onload.cpp namespace android { + int register_android_server_InvcaseService(JNIEnv *env); }; extern \"C\" jint JNI_OnLoad(JavaVM* vm, void* /* reserved */) { + register_android_server_InvcaseService(env); } Build new JNI wrapper : frameworks/base/services/core/jni/Android.bp cc_library_static { name: \"libservices.core\", srcs: [ + \"com_android_server_invcase_InvcaseService.cpp\", ], } cc_defaults { name: \"libservices.core-libs\", shared_libs: [ + \"libinvcase\", ], Declare API : frameworks/base/api/current.txt + package android.hardware.invcase { + + public final class InvcaseManager { + method @NonNull public String getData(); + method public void putData(@NonNull String); + } + + }","title":"JNI Wrapper"},{"location":"blog/android/hal/classical/legacy/#service-and-manager","text":"Define a name for new Service frameworks/base/core/java/android/content/Context.java public abstract class Context { @StringDef(suffix = { \"_SERVICE\" }, value = { + INVCASE_SERVICE, }) + /** + * Use with {@link #getSystemService(String)} to retrieve a + * {@link android.hardware.invcase.InvcaseManager}. + * + * @see #getSystemService(String) + * @hide + */ + public static final String INVCASE_SERVICE = \"invcase\"; Define the Service Interface Use AIDL to describe public functions exported by the Service: frameworks/base/core/java/android/hardware/invcase/IInvcaseManager.aidl package android.hardware.invcase ; /** * Invcase Manager interface * * {@hide} */ interface IInvcaseManager { String getData (); void putData ( String data ); } Build AIDL : frameworks/base/Android.bp java_defaults { name: \"framework-defaults\", installable: true, srcs: [ + \"core/java/android/hardware/invcase/IInvcaseManager.aidl\", ] } Implement the Service Manager A Service Manager is the wrapper for the interface of the target Service which is obtained by calling to <Interface>.Stub.asInterface . User application will call to the functions of the Service Manager, not directly calling to the actual service interface. frameworks/base/core/java/android/hardware/invcase/InvcaseManager.java package android.hardware.invcase ; import android.annotation.NonNull ; import android.content.Context ; import android.util.Log ; import android.os.RemoteException ; import android.os.ServiceManager ; import android.os.ServiceManager.ServiceNotFoundException ; public final class InvcaseManager { static final String TAG = \"Invcase\" ; private final Context mContext ; private final IInvcaseManager mService ; /** * Creates a InvcaseManager. * * @hide */ public InvcaseManager ( @NonNull Context context ) throws ServiceNotFoundException { this ( context , IInvcaseManager . Stub . asInterface ( ServiceManager . getServiceOrThrow ( Context . INVCASE_SERVICE ))); } /** * Creates a InvcaseManager with a provided service implementation. * * @hide */ public InvcaseManager ( @NonNull Context context , @NonNull IInvcaseManager service ) { mContext = context ; mService = service ; Log . d ( TAG , \"InvcaseManager: mContext= \" + mContext + \" mService= \" + mService ); } public @NonNull String getData () { try { String str = mService . getData (); Log . d ( TAG , \"InvcaseManager: mService.getData= \" + str ); return str ; } catch ( RemoteException e ) { e . printStackTrace (); } return null ; } public void putData ( @NonNull String data ) { try { Log . d ( TAG , \"InvcaseManager: mService.putData= \" + data ); mService . putData ( data ); } catch ( RemoteException e ) { e . printStackTrace (); } } } Implement the Service The Service will implement the actual code for Service Interface functions by extending the <Interface>.Stub class. Note that JNI Native functions are exported to this object, therefore, it can call to HAL library\u2019s functions. frameworks/base/services/core/java/com/android/server/invcase/InvcaseService.java package com.android.server.invcase ; import android.hardware.invcase.IInvcaseManager ; import android.content.Context ; import android.util.Log ; import com.android.server.SystemService ; public class InvcaseService extends SystemService { static final String TAG = \"Invcase\" ; static final boolean DEBUG = false ; final IInvcaseManagerImpl mManagerService ; private final class IInvcaseManagerImpl extends IInvcaseManager . Stub { @Override public String getData () { String str = invcase_native_read (); Log . d ( TAG , \"InvcaseService: IInvcaseManager.getData= \" + str ); return str ; } @Override public void putData ( String data ) { Log . d ( TAG , \"InvcaseService: IInvcaseManager.putData= \" + data ); invcase_native_write ( data ); } } public InvcaseService ( Context context ) { super ( context ); invcase_native_init (); mManagerService = new IInvcaseManagerImpl (); Log . d ( TAG , \"InvcaseService: mManagerService= \" + mManagerService ); } @Override public void onStart () { publishBinderService ( Context . INVCASE_SERVICE , mManagerService ); Log . d ( TAG , \"InvcaseService: onStart\" ); } @Override protected void finalize () throws Throwable { invcase_native_deinit (); super . finalize (); } private static native void invcase_native_init (); private static native void invcase_native_deinit (); private static native String invcase_native_read (); private static native void invcase_native_write ( String string ); } Run our service : All system services are run in the same process called system_server which is implemented in the SystemServer.java . This process runs under system user. frameworks/base/services/java/com/android/server/SystemServer.java import com.android.server.invcase.InvcaseService; import android.util.Log; public final class SystemServer implements Dumpable { private void startBootstrapServices(@NonNull TimingsTraceAndSlog t) { + // Manages Invcase device. + traceBeginAndSlog(\"StartInvcaseService\"); + Log.d(\"Invcase\", \"SystemServer: start InvcaseService\"); + mSystemServiceManager.startService(InvcaseService.class); + traceEnd();","title":"Service and Manager"},{"location":"blog/android/hal/classical/legacy/#user-app","text":"The User App will be very simple to test the hardware. It contains an EditText to get user input, a Button to execute commands, and a TextView to display the result. Implement the User App Use getSystemService(Context.INVCASE_SERVICE) to obtain the instance of InvcaseManager Call to hardware through the InvcaseManager APIs packages/apps/Invcase/src/com/invcase/Invcase.java package com.invcase ; import android.hardware.invcase.InvcaseManager ; import android.content.Context ; import android.app.Activity ; import android.os.Bundle ; import android.view.View ; import android.widget.Button ; import android.widget.EditText ; import android.widget.TextView ; import android.util.Log ; public class Invcase extends Activity { private static final String TAG = \"Invcase\" ; private InvcaseManager mManager ; @Override protected void onCreate ( Bundle savedInstanceState ) { super . onCreate ( savedInstanceState ); setContentView ( R . layout . activity_main ); mManager = ( InvcaseManager ) getSystemService ( Context . INVCASE_SERVICE ); Log . d ( TAG , \"App: mManager= \" + mManager ); Button btn = ( Button ) findViewById ( R . id . button ); btn . setOnClickListener ( new View . OnClickListener () { @Override public void onClick ( View view ) { EditText editText = ( EditText ) findViewById ( R . id . editText ); String txt = editText . getText (). toString (); Log . d ( TAG , \"App: request= \" + txt ); mManager . putData ( txt ); String ret = mManager . getData (); Log . d ( TAG , \"App: received= \" + ret ); TextView tv = ( TextView ) findViewById ( R . id . textView ); tv . setText ( ret ); } }); } } Add User App to the Launcher packages/apps/Invcase/AndroidManifest.xml <?xml version=\"1.0\" encoding=\"utf-8\"?> <manifest xmlns:android= \"http://schemas.android.com/apk/res/android\" package= \"com.invcase\" > <application android:icon= \"@mipmap/ic_launcher\" android:label= \"@string/app_name\" > <activity android:name= \".Invcase\" android:exported= \"true\" android:label= \"@string/app_name\" > <intent-filter> <action android:name= \"android.intent.action.MAIN\" /> <category android:name= \"android.intent.category.LAUNCHER\" /> </intent-filter> </activity> </application> </manifest> on Android 12, must use android:exported=\"true\" Build User App packages/apps/Invcase/Android.bp android_app { name : \"Invcase\" , platform_apis : true, srcs : [ \"src/**/*.java\" ] } Add User App to system packages : build/target/product/base_vendor.mk + PRODUCT_PACKAGES += \\ + Invcase","title":"User App"},{"location":"blog/android/hal/classical/legacy/#permission","text":"The device /dev/invcase is created at boot with root permission. The HAL Library is loaded when JNI Wrapper for Invcase Service is run, therefore, HAL code will run with system permission which attaches to the system_server process. The Android Init Language uses init*.rc files to automatically do some actions when a condition is met. For the target hardware, Android Init will use init.<hardware>.rc file. On Emulator, it is init.ranchu.rc . Add below lines to change the owner and permission on the /dev/invcase at boot: device/generic/goldfish/init.ranchu.rc + on boot + chown system system /dev/invcase + chmod 0600 /dev/invcase","title":"Permission"},{"location":"blog/android/hal/classical/legacy/#build-and-run","text":"The Invcase Manager exports new Service APIs, therefore, need to rebuild the list of system APIs. m all -j $( nproc ) Run the Emulator and run Invcase app: The User Test application Start the Logcat to see debug lines: logcat -s Invcase Logcat shows Invcase calls There are 2 processes: The system_server process (yellow) does below things: Load HAL module Load JNI functions Start Invcase Service whichs creates an object of Invcase Manager Implementation The user app process (white) does below things: Load System Service Registry to have an object of Invcase Manager Interface Use received service interface to communicate with Invcase Manager Implementation in the Invcase Service","title":"Build and Run"},{"location":"blog/android/hal/hidl/","tags":["android","hidl"],"text":"HIDL # HIDL specifies data structures and method signatures, organized in interfaces (similar to a class) that are collected into packages. HIDL is intended to be used for inter-process communication (IPC), between the HAL and its users. As of Android 10, HIDL is deprecated and Android is migrating to use AIDL everywhere. HIDL supports two ways to transfer data without using an RPC call: shared memory and a Fast Message Queue (FMQ). To update devices running earlier versions of Android to Android O, you can wrap both Conventional and Legacy HALs in a new HIDL interface that serves the HAL in Passthrough and Binderized modes. This wrapping is transparent to both the HAL and the Android framework. Moving to HIDL in Project Treble You can refer to Conventional HAL or Binderized HAL to see the changes in actual framework stack, such as: Interfaces & Packages # HIDL is built around interfaces, an abstract type used in object-oriented languages to define behaviors. Each interface is part of a package. Packages # Package names can have sublevels such as package.subpackage . The root directory for published HIDL packages is hardware/interfaces or vendor/<vendorName> . The package name forms one or more subdirectories under the root directory; all files defining a package are in the same directory. For example, package android.hardware.invcase.passthrough@1.0 could be found under hardware/interfaces/invase/passthrough/1.0 . The following table lists package prefixes and locations: Package Prefix Location Interface Types android.hardware.* hardware/interfaces/* HAL android.frameworks.* frameworks/hardware/interfaces/* frameworks related android.system.* system/hardware/interfaces/* system related android.hidl.* system/libhidl/transport/* core The package directory contains files with extension .hal . Every file must contain a package statement naming the package and version the file is part of. The file types.hal , if present, does not define an interface but instead defines data types accessible to every interface in the package. Versioning # Packages are versioned, and interfaces have the version of their package. Versions are expressed in two integers, major.minor . Major versions are not backwards compatible. Incrementing the major version number resets the minor version number to 0. Minor versions are backwards compatible. Incrementing the minor number indicates the newer version is fully backward compatible with the previous version. New data structures and methods can be added, but no existing data structures or method signatures may be changed. Multiple major or minor versions of a HAL can be present on a device simultaneously. However, a minor version should be preferred over a major version because client code that works with a previous minor version interface will also work with later minor versions of that same interface. Interface # Aside from types.hal , every other .hal file defines an interface. An interface is typically defined as follows: interface IBar extends IFoo { // IFoo is another interface // embedded types struct MyStruct { /*...*/ }; // interface methods create ( int32_t id ) generates ( MyStruct s ); close (); }; An interface without an explicit extends declaration will implicitly extend from the class android.hidl.base@1.0::IBase (similar to the java.lang.Object in Java). The IBase interface, implicitly imported, declares several reserved methods that should not and cannot be re-declared in user-defined interfaces or used otherwise. These methods include: ping interfaceChain interfaceDescriptor notifySyspropsChanged linkToDeath unlinkToDeath setHALInstrumentation getDebugInfo debug getHashChain Import # The import statement is HIDL mechanism to access package interfaces and types in another package. For fully-qualified values, the following import cases are supported: Whole-package imports . If the value is a package name and a version (syntax described below), then the entire package is imported into the importing entity. Partial imports . If the value is: An interface, the package\u2019s types.hal and that interface are imported into the importing entity. A UDT defined in types.hal, then only that UDT is imported into the importing entity (other types in types.hal are not imported). Types-only imports . If the value uses the syntax of a partial import described above, but with the keyword types instead of an Interface name, only the UDTs in types.hal of the designated package are imported. import android.hardware.nfc @ 1.0 ; // import a whole package import android.hardware.example @ 1.0 :: IQuux ; // import an interface and types.hal import android.hardware.example @ 1.0 :: types ; // import just types.hal Inheritance # An interface can be an extension of a previously-defined interface. An interface can extend only one other interface (no multiple inheritance). Extensions can be one of the following three types: Interface can add functionality to another one, incorporating its API unchanged. Package can add functionality to another one, incorporating its API unchanged. Interface can import types from a package or from a specific interface. Each interface in a package with a non-zero minor version number must extend an interface in the previous version of the package. derivative.IBar@4.0 extends original.IFoo@1.2 . derivative.IBar@4.1 CANNOT extend original.IFoo@1.3 . derivative.IBar@4.1 MUST extend derivative.IBar@4.0 . derivative.IBar@5.0 CAN extend original.IFoo@1.3 .","title":"HAL Interface Definition Language"},{"location":"blog/android/hal/hidl/#hidl","text":"HIDL specifies data structures and method signatures, organized in interfaces (similar to a class) that are collected into packages. HIDL is intended to be used for inter-process communication (IPC), between the HAL and its users. As of Android 10, HIDL is deprecated and Android is migrating to use AIDL everywhere. HIDL supports two ways to transfer data without using an RPC call: shared memory and a Fast Message Queue (FMQ). To update devices running earlier versions of Android to Android O, you can wrap both Conventional and Legacy HALs in a new HIDL interface that serves the HAL in Passthrough and Binderized modes. This wrapping is transparent to both the HAL and the Android framework. Moving to HIDL in Project Treble You can refer to Conventional HAL or Binderized HAL to see the changes in actual framework stack, such as:","title":"HIDL"},{"location":"blog/android/hal/hidl/#interfaces--packages","text":"HIDL is built around interfaces, an abstract type used in object-oriented languages to define behaviors. Each interface is part of a package.","title":"Interfaces &amp; Packages"},{"location":"blog/android/hal/hidl/#packages","text":"Package names can have sublevels such as package.subpackage . The root directory for published HIDL packages is hardware/interfaces or vendor/<vendorName> . The package name forms one or more subdirectories under the root directory; all files defining a package are in the same directory. For example, package android.hardware.invcase.passthrough@1.0 could be found under hardware/interfaces/invase/passthrough/1.0 . The following table lists package prefixes and locations: Package Prefix Location Interface Types android.hardware.* hardware/interfaces/* HAL android.frameworks.* frameworks/hardware/interfaces/* frameworks related android.system.* system/hardware/interfaces/* system related android.hidl.* system/libhidl/transport/* core The package directory contains files with extension .hal . Every file must contain a package statement naming the package and version the file is part of. The file types.hal , if present, does not define an interface but instead defines data types accessible to every interface in the package.","title":"Packages"},{"location":"blog/android/hal/hidl/#versioning","text":"Packages are versioned, and interfaces have the version of their package. Versions are expressed in two integers, major.minor . Major versions are not backwards compatible. Incrementing the major version number resets the minor version number to 0. Minor versions are backwards compatible. Incrementing the minor number indicates the newer version is fully backward compatible with the previous version. New data structures and methods can be added, but no existing data structures or method signatures may be changed. Multiple major or minor versions of a HAL can be present on a device simultaneously. However, a minor version should be preferred over a major version because client code that works with a previous minor version interface will also work with later minor versions of that same interface.","title":"Versioning"},{"location":"blog/android/hal/hidl/#interface","text":"Aside from types.hal , every other .hal file defines an interface. An interface is typically defined as follows: interface IBar extends IFoo { // IFoo is another interface // embedded types struct MyStruct { /*...*/ }; // interface methods create ( int32_t id ) generates ( MyStruct s ); close (); }; An interface without an explicit extends declaration will implicitly extend from the class android.hidl.base@1.0::IBase (similar to the java.lang.Object in Java). The IBase interface, implicitly imported, declares several reserved methods that should not and cannot be re-declared in user-defined interfaces or used otherwise. These methods include: ping interfaceChain interfaceDescriptor notifySyspropsChanged linkToDeath unlinkToDeath setHALInstrumentation getDebugInfo debug getHashChain","title":"Interface"},{"location":"blog/android/hal/hidl/#import","text":"The import statement is HIDL mechanism to access package interfaces and types in another package. For fully-qualified values, the following import cases are supported: Whole-package imports . If the value is a package name and a version (syntax described below), then the entire package is imported into the importing entity. Partial imports . If the value is: An interface, the package\u2019s types.hal and that interface are imported into the importing entity. A UDT defined in types.hal, then only that UDT is imported into the importing entity (other types in types.hal are not imported). Types-only imports . If the value uses the syntax of a partial import described above, but with the keyword types instead of an Interface name, only the UDTs in types.hal of the designated package are imported. import android.hardware.nfc @ 1.0 ; // import a whole package import android.hardware.example @ 1.0 :: IQuux ; // import an interface and types.hal import android.hardware.example @ 1.0 :: types ; // import just types.hal","title":"Import"},{"location":"blog/android/hal/hidl/#inheritance","text":"An interface can be an extension of a previously-defined interface. An interface can extend only one other interface (no multiple inheritance). Extensions can be one of the following three types: Interface can add functionality to another one, incorporating its API unchanged. Package can add functionality to another one, incorporating its API unchanged. Interface can import types from a package or from a specific interface. Each interface in a package with a non-zero minor version number must extend an interface in the previous version of the package. derivative.IBar@4.0 extends original.IFoo@1.2 . derivative.IBar@4.1 CANNOT extend original.IFoo@1.3 . derivative.IBar@4.1 MUST extend derivative.IBar@4.0 . derivative.IBar@5.0 CAN extend original.IFoo@1.3 .","title":"Inheritance"},{"location":"blog/android/hal/hidl/binderized/","tags":["android","hal","hidl"],"text":"This guide is written for AOSP android-10.0.0_r47 From Android 12, you can not create any new HAL using HIDL! Refer to AIDL for HALs . Binderized HAL # In a Binderized HAL, the Android framework and HALs communicate with each other using binder inter-process communication (IPC) calls. All devices launching with Android O 8.0 or later must support binderized HALs only. Framework Stacks # Differences between Conventional HAL and Binderized HIDL for HAL : Conventional HAL in the Framework stacks Binderized HAL in the Framework stacks Implementation # binderized_hal.zip Refer to Kernel Module to build and install a module to system. This guide assumes that invcase module is loaded as below: device/generic/goldfish/init.ranchu.rc + on boot + insmod /system/lib/modules/invcase.ko + chown system system /dev/invcase + chmod 0600 /dev/invcase Overview # AOSP build make target product base_vendor.mk Include new packages + PRODUCT_PACKAGES += \\ + android.hardware.invcase@1.0-service \\ + invcase_hidl_test \\ + Invcase gsi 29.txt Add new vendor native library VNDK-core: android.hardware.input.common@1.0.so + VNDK-core: android.hardware.invcase@1.0.so VNDK-core: android.hardware.ir@1.0.so packages apps Invcase src com invcase Invcase.java Get InvcaseManager from SystemService class Invcase extends Activity { InvcaseManager mManager ; onCreate () { mManager = getSystemService ( Context . INVCASE_SERVICE ); } } res layout mipmap values AndroidManifest.xml Export main activity on Launcher <manifest package= \"com.invcase\" > <application> <activity android:name= \".Invcase\" android:exported= \"true\" > <intent-filter> <action android:name= \"android.intent.action.MAIN\" /> <category android:name= \"android.intent.category.LAUNCHER\" /> </intent-filter> </activity> </application> </manifest> android:exported=\"true\" is mandatory on Android 12 Android.bp android_app { name : \"Invcase\" , srcs : [ \"src/**/*.java\" ] , platform_apis : true } platform_apis: true : use System API when do not specify any target platform device generic car common manifest.xml Declare new interface + <hal format=\"hidl\"> + <name>android.hardware.invcase</name> + <transport>hwbinder</transport> + <version>1.0</version> + <interface> + <name>IInvcase</name> + <instance>default</instance> + </interface> + </hal> frameworks base Android.bp java_defaults { name: \"framework-defaults\", installable: true, srcs: [ + \"core/java/android/hardware/invcase/IInvcaseManager.aidl\", ] } api current.txt + package android.hardware.invcase { + + public final class InvcaseManager { + method @NonNull public String getData(); + method public void putData(@NonNull String); + } + + } core java android app SystemServiceRegistry.java Create an InvcaseManager instance and add it to the System Service list + import android.hardware.invcase.InvcaseManager; public final class SystemServiceRegistry { static { + registerService(Context.INVCASE_SERVICE, InvcaseManager.class, + new CachedServiceFetcher<InvcaseManager>() { + @Override + public InvcaseManager createService(ContextImpl ctx) + throws ServiceNotFoundException { + return new InvcaseManager(ctx); + }}); } } content Context.java Add Invcase Serive name public abstract class Context { + public static final String INVCASE_SERVICE = \"invcase\"; @StringDef(suffix = { \"_SERVICE\" }, value = { + INVCASE_SERVICE, }) } hardware invcase IInvcaseManager.aidl Define API for Invcase Interface interface IInvcaseManager { getData (); putData (); } InvcaseManager.java Use Invase Serive through the Invcase Interface class InvcaseManager { IInvcaseManager mService ; InvcaseManager ( Context ) throws ServiceNotFoundException { this ( context , IInvcaseManager . Stub . asInterface ( ServiceManager . getServiceOrThrow ( Context . INVCASE_SERVICE )) ); } InvcaseManager ( Context , IInvcaseManager ){} getData () { mService . getData (); } putData () { mService . putData (); } } services core java com android server invcase InvcaseService.java Implement Invcase Interface functions, public the interface class InvcaseService extends SystemService { IInvcaseManagerImpl extends IInvcaseManager . Stub { getData () { invcase_native_read (); } putData () { invcase_native_write (); } } mManagerService ; onStart () { publishBinderService ( Context . INVCASE_SERVICE , mManagerService ); } } jni com_android_server_invcase_InvcaseService.cpp Map java functions to native functions #include <hardware_legacy/invcase.h> jni_read () { invcase_read (); } jni_write () { invcase_write (); } static const JNINativeMethod method_table [] = { { \"invcase_native_read\" , \"()Ljava/lang/String;\" , ( void * ) jni_read }, { \"invcase_native_write\" , \"(Ljava/lang/String;)V\" , ( void * ) jni_write }, }; register_android_server_InvcaseService ( method_table ); onload.cpp Register mapped function calls namespace android { + int register_android_server_InvcaseService(JNIEnv *env); }; extern \"C\" jint JNI_OnLoad(JavaVM* vm, void* /* reserved */) { + register_android_server_InvcaseService(env); } Android.bp cc_library_static { srcs: [ + \"com_android_server_invcase_InvcaseService.cpp\", ], } cc_defaults { shared_libs: [ + \"android.hardware.invcase@1.0\", ], } java com android server SystemServer.java Start Invcase Service + import com.android.server.invcase.InvcaseService; public final class SystemServer implements Dumpable { private void startBootstrapServices(@NonNull TimingsTraceAndSlog t) { + traceBeginAndSlog(\"StartInvcaseService\"); + mSystemServiceManager.startService(InvcaseService.class); + traceEnd(); } } hardware interfaces invcase 1.0 default Android.bp Invcase.h Invcase.cpp IInvcase.hal interface IInvcase { putChars ( string msg ); getChars () generates ( string msg ); }; Android.bp Define HAL Interface # Create a new HAL file in the folder hardware/interfaces : hardware/interfaces/invcase/1.0/IInvcase.hal package android.hardware.invcase @ 1.0 ; interface IInvcase { putChars ( string msg ); getChars () generates ( string msg ); }; Prepare HAL files # Source hidl-gen is a compiler for the HIDL (HAL Interface Design Language) which generates C++ and Java endpoints for RPC mechanisms. The main userspace libraries which this compiler uses can be found at system/libhidl . Build hidl-gen if it is not built: m hidl-gen Then run it to generate C++ source file and Makefile: export INVCASE_PACKAGE = android.hardware.invcase@1.0 export INVCASE_LOC = hardware/interfaces/invcase/1.0/default/ export HIDL_INF = android.hardware:hardware/interfaces export HIDL_LIB = android.hidl:system/libhidl/transport hidl-gen -o $INVCASE_LOC -Lc++-impl \\ -r $HIDL_INF -r $HIDL_LIB $INVCASE_PACKAGE hidl-gen -o $INVCASE_LOC -Landroidbp-impl \\ -r $HIDL_INF -r $HIDL_LIB $INVCASE_PACKAGE After these command, 3 files are generated in the default folder: Android.bp , Invcase.h , and Invcase.cpp . The generated files are for implement the HAL. Service Add three empty files for HAL service process in the 1.0/default folder: android.hardware.invcase@1.0-service.rc android.hardware.invcase@1.0-service.xml service.cpp Makefile Run the tool: ./hardware/interfaces/update-makefiles.sh to generate hardware/interfaces/invcase/1.0/Android.bp // This file is autogenerated by hidl-gen -Landroidbp. hidl_i nterfa ce { na me : \"android.hardware.invcase@1.0\" , roo t : \"android.hardware\" , v n dk : { e na bled : true , }, srcs : [ \"IInvcase.hal\" , ], i nterfa ces : [ \"android.hidl.base@1.0\" , ], ge n _java : false , } Implement HAL # Header : hardware/interfaces/invcase/1.0/default/Invcase.h #pragma once #include <android/hardware/invcase/1.0/IInvcase.h> #include <hidl/MQDescriptor.h> #include <hidl/Status.h> namespace android { namespace hardware { namespace invcase { namespace V1_0 { namespace implementation { using :: android :: hardware :: hidl_array ; using :: android :: hardware :: hidl_memory ; using :: android :: hardware :: hidl_string ; using :: android :: hardware :: hidl_vec ; using :: android :: hardware :: Return ; using :: android :: hardware :: Void ; using :: android :: sp ; struct Invcase : public IInvcase { // Methods from ::android::hardware::invcase::V1_0::IInvcase follow. Return < void > putChars ( const hidl_string & msg ) override ; Return < void > getChars ( getChars_cb _hidl_cb ) override ; // Methods from ::android::hidl::base::V1_0::IBase follow. }; // FIXME: most likely delete, this is only for passthrough implementations // extern \"C\" IInvcase* HIDL_FETCH_IInvcase(const char* name); } // namespace implementation } // namespace V1_0 } // namespace invcase } // namespace hardware } // namespace android Source : hardware/interfaces/invcase/1.0/default/Invcase.cpp #define LOG_TAG \"Invcase\" #include <utils/Log.h> #include <iostream> #include <fstream> #include \"Invcase.h\" namespace android { namespace hardware { namespace invcase { namespace V1_0 { namespace implementation { // Methods from ::android::hardware::invcase::V1_0::IInvcase follow. Return < void > Invcase :: putChars ( const hidl_string & msg ) { std :: ofstream invcase_dev ; invcase_dev . open ( \"/dev/invcase\" ); if ( invcase_dev . good ()) { invcase_dev << msg ; ALOGE ( \"putChars: %s\" , msg . c_str ()); } else { ALOGE ( \"putChars: can not open /dev/invcase\" ); } return Void (); } Return < void > Invcase :: getChars ( getChars_cb _hidl_cb ) { std :: ifstream invcase_dev ; invcase_dev . open ( \"/dev/invcase\" ); if ( invcase_dev . good ()) { std :: string line ; invcase_dev >> line ; ALOGE ( \"getChars: %s\" , line . c_str ()); hidl_string result ( line ); _hidl_cb ( result ); } else { ALOGE ( \"getChars: can not open /dev/invcase\" ); } return Void (); } // Methods from ::android::hidl::base::V1_0::IBase follow. //IInvcase* HIDL_FETCH_IInvcase(const char* /* name */) { //return new Invcase(); //} // } // namespace implementation } // namespace V1_0 } // namespace invcase } // namespace hardware } // namespace android Implement HAL Service # To host the library we need to create a simple executable: hardware/interfaces/invcase/1.0/default/service.cpp #define LOG_TAG \"Invcase\" #include <iostream> #include <android/hardware/invcase/1.0/IInvcase.h> #include <hidl/HidlTransportSupport.h> #include <hidl/LegacySupport.h> #include <utils/Log.h> #include \"Invcase.h\" using android :: hardware :: invcase :: V1_0 :: IInvcase ; using android :: hardware :: invcase :: V1_0 :: implementation :: Invcase ; using android :: hardware :: configureRpcThreadpool ; using android :: hardware :: joinRpcThreadpool ; using android :: sp ; void logd ( std :: string msg ) { std :: cout << msg << std :: endl ; ALOGD ( \"%s\" , msg . c_str ()); } void loge ( std :: string msg ) { std :: cout << msg << std :: endl ; ALOGE ( \"%s\" , msg . c_str ()); } int main ( int /* argc */ , char ** /* argv */ ) { configureRpcThreadpool ( 1 , true /*callerWillJoin*/ ); android :: sp < IInvcase > invcase = new Invcase (); if ( invcase != nullptr ) { if ( invcase -> registerAsService () != :: android :: OK ) { loge ( \"Failed to register IInvcase service\" ); return -1 ; } } else { loge ( \"Failed to get IInvcase instance\" ); return -1 ; } logd ( \"IInvcase service starts to join service pool\" ); joinRpcThreadpool (); return 1 ; // joinRpcThreadpool shouldn't exit } And request to start service at startup: hardware/interfaces/invcase/1.0/default/android.hardware.invcase@1.0-service.rc service vendor.invcase-1-0 /vendor/bin/hw/android.hardware.invcase@1.0-service class hal user system group system Makefile : By default, hidl-gen creates a Makefile to build a shared library using the name android.hardware.invcase@1.0-service (note the suffix -service ). hardware/interfaces/invcase/1.0/default/Android.bp cc_binary { name : \"android.hardware.invcase@1.0-service\" , defaults : [ \"hidl_defaults\" ], vendor : true , relative_install_path : \"hw\" , srcs : [ \"service.cpp\" , \"Invcase.cpp\" ], init_rc : [ \"android.hardware.invcase@1.0-service.rc\" ], shared_libs : [ \"android.hardware.invcase@1.0\" , \"libhidlbase\" , \"libhidltransport\" , \"liblog\" , \"libutils\" , ], vintf_fragments : [ \"android.hardware.invcase@1.0.xml\" ], } A test application that request the HAL service: hardware/interfaces/invcase/1.0/test/invcase_hidl_test.cpp #define LOG_TAG \"Invcase\" #include <iostream> #include <android/hardware/invcase/1.0/IInvcase.h> #include <hidl/HidlTransportSupport.h> #include <hidl/LegacySupport.h> #include <utils/Log.h> #include <android/hardware/invcase/1.0/default/Invcase.h> using android :: hardware :: invcase :: V1_0 :: IInvcase ; using android :: hardware :: hidl_string ; using android :: sp ; void logd ( std :: string msg ) { std :: cout << msg << std :: endl ; ALOGD ( \"%s\" , msg . c_str ()); } void loge ( std :: string msg ) { std :: cout << msg << std :: endl ; ALOGE ( \"%s\" , msg . c_str ()); } int main ( int /* argc */ , char ** /* argv */ ) { android :: sp < IInvcase > invcase = IInvcase :: getService (); if ( invcase == nullptr ) { loge ( \"Failed to get Invcase service\" ); return -1 ; } logd ( \"Got Invcase service\" ); std :: string msg = \"Hello World!\" ; logd ( \"Send: \" + msg ); invcase -> putChars ( msg ); invcase -> getChars ([ & ]( hidl_string result ) { logd ( \"Receive: \" + std :: string ( result )); }); return 0 ; } Build the test app: hardware/interfaces/invcase/1.0/test/Android.bpp cc_binary { name : \"invcase_hidl_test\" , defaults : [ \"hidl_defaults\" ] , proprietary : true, relative_install_path : \"hw\" , srcs : [ \"invcase_hidl_test.cpp\" ] , shared_libs : [ \"android.hardware.invcase@1.0\" , \"libhidlbase\" , \"libhidltransport\" , \"libutils\" , \"liblog\" , ] , } Define SELinux Policy for HAL service # To make the service run at boot, HAL service needs to be registered to system under a security policy. Declare the new type : system/sepolicy/prebuilts/api/29.0/public/hwservice.te system/sepolicy/public/hwservice.te type hal_invcase_hwservice, hwservice_manager_type; Set compatibility Ignore in API 28, which also ignore in API 27 and API 26: system/sepolicy/prebuilts/api/29.0/private/compat/28.0/28.0.ignore.cil system/sepolicy/private/compat/28.0/28.0.ignore.cil (type new_objects) (typeattribute new_objects) (typeattributeset new_objects ( new_objects hal_invcase_hwservice ) ) Do not allow other apps to access : system/sepolicy/prebuilts/api/29.0/private/app_neverallows.te system/sepolicy/private/app_neverallows.te neverallow all_untrusted_apps { hal_invcase_hwservice } Set service context interface : system/sepolicy/prebuilts/api/29.0/private/hwservice_contexts system/sepolicy/private/hwservice_contexts android.hardware.invcase :: IInvcase u : object_r : hal_invcase_hwservice : s 0 Declare attribute : system/sepolicy/prebuilts/api/29.0/public/attributes system/sepolicy/public/attributes hal_attribute(invcase); this is macro for adding below attributes: attribute hal_invcase; attribute hal_invcase_client; attribute hal_invcase_server; Define default domain : system/sepolicy/vendor/hal_invcase_default.te type hal_invcase_default, domain; hal_server_domain(hal_invcase_default, hal_invcase) type hal_invcase_default_exec, exec_type, vendor_file_type, vendor_file_type, file_type; init_daemon_domain(hal_invcase_default) Set binder policy : system/sepolicy/prebuilts/api/29.0/public/hal_invcase.te system/sepolicy/public/hal_invcase.te binder_call(hal_invcase_client, hal_invcase_server) binder_call(hal_invcase_server, hal_invcase_client) hal_attribute_hwservice(hal_invcase, hal_invcase_hwservice) Set system context : Note the HAL process path! system/sepolicy/vendor/file_contexts /(vendor|system/vendor)/bin/hw/android\\.hardware\\.invcase@1\\.0-service u : object_r : hal_invcase_default_exec : s 0 Declare system_server as client of HAL service : system/sepolicy/prebuilts/api/29.0/private/system_server.te system/sepolicy/private/system_server.te hal_client_domain(system_server, hal_invcase) Deliver HAL module # VNDK Vendor Native Development Kit (VNDK) is a set of libraries exclusively for vendors to implement their HALs. The VNDK ships in system.img and is dynamically linked to vendor code at runtime. Refer to https://source.android.com/devices/architecture/vndk/build-system . Include HAL service and the test app to the PRODUCT_PACKAGES : build/target/product/base_vendor.mk + PRODUCT_PACKAGES += \\ + android.hardware.invcase@1.0-service \\ + invcase_hidl_test \\ This will include below files to system: /vendor/lib/hw/android.hardware.invcase@1.0-service /vendor/bin/hw/invcase_hidl_test Export HAL Interface Using show_make_tree.py to find the included manifest: python show_make_tree.py \\ \"device/generic/car/aosp_car_x86_64.mk\" \\ \"manifest.xml:\" File : device/generic/car/aosp_car_x86_64.mk Inherit: device/generic/car/common/car.mk Found : device/generic/car/common/manifest.xml: $( TARGET_COPY_OUT_VENDOR ) /manifest.xml Inherit: device/generic/goldfish/vendor.mk Found : device/generic/goldfish/manifest.xml: $( TARGET_COPY_OUT_VENDOR ) /manifest.xml \\ Because car.mk inherits goldfish/vendor.mk , so file manifest.xml is copied from device/generic/car/common/manifest.xml as it is registered first. Read more about PRODUCT_COPY_FILES rules . We add the HAL interface as below: device/generic/car/common/manifest.xml + <hal format=\"hidl\"> + <name>android.hardware.invcase</name> + <transport>hwbinder</transport> + <version>1.0</version> + <interface> + <name>IInvcase</name> + <instance>default</instance> + </interface> + </hal> API locked If you encounter below error, it is because only Google can add interface into hardware/interfaces . error: VNDK library list has been changed. Changing the VNDK library list is not allowed in API locked branches. You have to explicitly add the VNDK core to the API list: build/make/target/product/gsi/29.txt VNDK-core: android.hardware.input.common@1.0.so + VNDK-core: android.hardware.invcase@1.0.so VNDK-core: android.hardware.ir@1.0.so JNI Wrapper # The Java Native Interface (JNI) is a foreign function interface programming framework that enables Java code running in a Java virtual machine (JVM) to call and be called by native applications (programs specific to a hardware and operating system platform) and libraries written in other languages such as C, C++ and assembly. Create java functions that call to native function in HAL library jni_read calls to invcase_read jni_write calls to invcase_write Register mapped functions with their signatures (encoded parameters) Note that Java functions always have 2 default arguments: JNIEnv* env : a structure containing methods that we can use our native code to access Java elements jobject selfClass : the class of calling object Implement JNI Mapping Note that the function jniRegisterNativeMethods will register JNI functions for the class frameworks/services/core/java/com/android/server/invcase/InvcaseService.java : frameworks/base/services/core/jni/com_android_server_invcase_InvcaseService.cpp #define LOG_TAG \"Invcase\" #include \"jni.h\" #include <nativehelper/JNIHelp.h> #include \"android_runtime/AndroidRuntime.h\" #include <utils/misc.h> #include <utils/Log.h> #include <stdio.h> #include <android/hardware/invcase/1.0/IInvcase.h> using android :: hardware :: invcase :: V1_0 :: IInvcase ; using android :: hardware :: hidl_string ; namespace android { static void jni_init ( JNIEnv * /* env */ , jobject /* clazz */ ) { } static void jni_deinit ( JNIEnv * /* env */ , jobject /* clazz */ ) { } static jstring jni_read ( JNIEnv * env , jobject /* clazz */ ) { sp < IInvcase > invcase = IInvcase :: getService (); if ( invcase == nullptr ) { ALOGE ( \"JNI: Failed to get Invcase service \\n \" ); return env -> NewStringUTF ( \"\" ); } std :: string msg ; invcase -> getChars ([ & ]( hidl_string result ) { msg = std :: string ( result ); }); const char * buff = msg . c_str (); ALOGD ( \"JNI: Receive: %s \\n \" , buff ); return env -> NewStringUTF ( buff ); } static void jni_write ( JNIEnv * env , jobject /* clazz */ , jstring string ) { sp < IInvcase > invcase = IInvcase :: getService (); if ( invcase == nullptr ) { ALOGE ( \"JNI: Failed to get Invcase service \\n \" ); return ; } const char * buff = env -> GetStringUTFChars ( string , NULL ); ALOGD ( \"JNI: Send: %s \\n \" , buff ); invcase -> putChars ( std :: string ( buff )); } static const JNINativeMethod method_table [] = { { \"invcase_native_init\" , \"()V\" , ( void * ) jni_init }, { \"invcase_native_deinit\" , \"()V\" , ( void * ) jni_deinit }, { \"invcase_native_read\" , \"()Ljava/lang/String;\" , ( void * ) jni_read }, { \"invcase_native_write\" , \"(Ljava/lang/String;)V\" , ( void * ) jni_write }, }; int register_android_server_InvcaseService ( JNIEnv * env ) { ALOGD ( \"JNI: register_android_server_InvcaseService \\n \" ); return jniRegisterNativeMethods ( env , \"com/android/server/invcase/InvcaseService\" , method_table , NELEM ( method_table ) ); } } Call the register function : frameworks/base/services/core/jni/onload.cpp namespace android { + int register_android_server_InvcaseService(JNIEnv *env); }; extern \"C\" jint JNI_OnLoad(JavaVM* vm, void* /* reserved */) { + register_android_server_InvcaseService(env); } Build new JNI wrapper : frameworks/base/services/core/jni/Android.bp cc_library_static { name: \"libservices.core\", srcs: [ + \"com_android_server_invcase_InvcaseService.cpp\", ], } cc_defaults { name: \"libservices.core-libs\", shared_libs: [ + \"android.hardware.invcase@1.0\", ], Declare API : frameworks/base/api/current.txt + package android.hardware.invcase { + public final class InvcaseManager { + method @NonNull public String getData(); + method public void putData(@NonNull String); + } + } Service and Manager # Define a name for new Service frameworks/base/core/java/android/content/Context.java public abstract class Context { @StringDef(suffix = { \"_SERVICE\" }, value = { + INVCASE_SERVICE, }) + /** + * Use with {@link #getSystemService(String)} to retrieve a + * {@link android.hardware.invcase.InvcaseManager}. + * + * @see #getSystemService(String) + * @hide + */ + public static final String INVCASE_SERVICE = \"invcase\"; Define the Service Interface Use AIDL to describe public functions exported by the Service: frameworks/base/core/java/android/hardware/invcase/IInvcaseManager.aidl package android.hardware.invcase ; /** * Invcase Manager interface * * {@hide} */ interface IInvcaseManager { String getData (); void putData ( String data ); } Build AIDL : frameworks/base/Android.bp java_defaults { name: \"framework-defaults\", installable: true, srcs: [ + \"core/java/android/hardware/invcase/IInvcaseManager.aidl\", ] } Implement the Service Manager A Service Manager is the wrapper for the interface of the target Service which is obtained by calling to <Interface>.Stub.asInterface . User application will call to the functions of the Service Manager, not directly calling to the actual service interface. frameworks/base/core/java/android/hardware/invcase/InvcaseManager.java package android.hardware.invcase ; import android.annotation.NonNull ; import android.content.Context ; import android.util.Log ; import android.os.RemoteException ; import android.os.ServiceManager ; import android.os.ServiceManager.ServiceNotFoundException ; public final class InvcaseManager { static final String TAG = \"Invcase\" ; private final Context mContext ; private final IInvcaseManager mService ; /** * Creates a InvcaseManager. * * @hide */ public InvcaseManager ( @NonNull Context context ) throws ServiceNotFoundException { this ( context , IInvcaseManager . Stub . asInterface ( ServiceManager . getServiceOrThrow ( Context . INVCASE_SERVICE ))); } /** * Creates a InvcaseManager with a provided service implementation. * * @hide */ public InvcaseManager ( @NonNull Context context , @NonNull IInvcaseManager service ) { mContext = context ; mService = service ; Log . d ( TAG , \"InvcaseManager: mContext= \" + mContext + \" mService= \" + mService ); } public @NonNull String getData () { try { String str = mService . getData (); Log . d ( TAG , \"InvcaseManager: mService.getData= \" + str ); return str ; } catch ( RemoteException e ) { e . printStackTrace (); } return null ; } public void putData ( @NonNull String data ) { try { Log . d ( TAG , \"InvcaseManager: mService.putData= \" + data ); mService . putData ( data ); } catch ( RemoteException e ) { e . printStackTrace (); } } } Implement the Service The Service will implement the actual code for Service Interface functions by extending the <Interface>.Stub class. Note that JNI Native functions are exported to this object, therefore, it can call to HAL library\u2019s functions. frameworks/base/services/core/java/com/android/server/invcase/InvcaseService.java package com.android.server.invcase ; import android.hardware.invcase.IInvcaseManager ; import android.content.Context ; import android.util.Log ; import com.android.server.SystemService ; public class InvcaseService extends SystemService { static final String TAG = \"Invcase\" ; static final boolean DEBUG = false ; final IInvcaseManagerImpl mManagerService ; private final class IInvcaseManagerImpl extends IInvcaseManager . Stub { @Override public String getData () { String str = invcase_native_read (); Log . d ( TAG , \"InvcaseService: IInvcaseManager.getData= \" + str ); return str ; } @Override public void putData ( String data ) { Log . d ( TAG , \"InvcaseService: IInvcaseManager.putData= \" + data ); invcase_native_write ( data ); } } public InvcaseService ( Context context ) { super ( context ); invcase_native_init (); mManagerService = new IInvcaseManagerImpl (); Log . d ( TAG , \"InvcaseService: mManagerService= \" + mManagerService ); } @Override public void onStart () { publishBinderService ( Context . INVCASE_SERVICE , mManagerService ); Log . d ( TAG , \"InvcaseService: onStart\" ); } @Override protected void finalize () throws Throwable { invcase_native_deinit (); super . finalize (); } private static native void invcase_native_init (); private static native void invcase_native_deinit (); private static native String invcase_native_read (); private static native void invcase_native_write ( String string ); } Run our service : All system services are run in the same process called system_server which is implemented in the SystemServer.java . This process runs under system user. frameworks/base/services/java/com/android/server/SystemServer.java import com.android.server.invcase.InvcaseService; import android.util.Log; public final class SystemServer implements Dumpable { private void startBootstrapServices(@NonNull TimingsTraceAndSlog t) { + // Manages Invcase device. + traceBeginAndSlog(\"StartInvcaseService\"); + Log.d(\"Invcase\", \"SystemServer: start InvcaseService\"); + mSystemServiceManager.startService(InvcaseService.class); + traceEnd(); User App # The User App will be very simple to test the hardware. It contains an EditText to get user input, a Button to execute commands, and a TextView to display the result. Implement the User App Use getSystemService(Context.INVCASE_SERVICE) to obtain the instance of InvcaseManager Call to hardware through the InvcaseManager APIs packages/apps/Invcase/src/com/invcase/Invcase.java package com.invcase ; import android.hardware.invcase.InvcaseManager ; import android.content.Context ; import android.app.Activity ; import android.os.Bundle ; import android.view.View ; import android.widget.Button ; import android.widget.EditText ; import android.widget.TextView ; import android.util.Log ; public class Invcase extends Activity { private static final String TAG = \"Invcase\" ; private InvcaseManager mManager ; @Override protected void onCreate ( Bundle savedInstanceState ) { super . onCreate ( savedInstanceState ); setContentView ( R . layout . activity_main ); mManager = ( InvcaseManager ) getSystemService ( Context . INVCASE_SERVICE ); Log . d ( TAG , \"App: mManager= \" + mManager ); Button btn = ( Button ) findViewById ( R . id . button ); btn . setOnClickListener ( new View . OnClickListener () { @Override public void onClick ( View view ) { EditText editText = ( EditText ) findViewById ( R . id . editText ); String txt = editText . getText (). toString (); Log . d ( TAG , \"App: request= \" + txt ); mManager . putData ( txt ); String ret = mManager . getData (); Log . d ( TAG , \"App: received= \" + ret ); TextView tv = ( TextView ) findViewById ( R . id . textView ); tv . setText ( ret ); } }); } } Add User App to the Launcher packages/apps/Invcase/AndroidManifest.xml <?xml version=\"1.0\" encoding=\"utf-8\"?> <manifest xmlns:android= \"http://schemas.android.com/apk/res/android\" package= \"com.invcase\" > <application android:icon= \"@mipmap/ic_launcher\" android:label= \"@string/app_name\" > <activity android:name= \".Invcase\" android:exported= \"true\" android:label= \"@string/app_name\" > <intent-filter> <action android:name= \"android.intent.action.MAIN\" /> <category android:name= \"android.intent.category.LAUNCHER\" /> </intent-filter> </activity> </application> </manifest> on Android 12, must use android:exported=\"true\" Build User App packages/apps/Invcase/Android.bp android_app { name : \"Invcase\" , platform_apis : true, srcs : [ \"src/**/*.java\" ] } Add User App to system packages : build/target/product/base_vendor.mk + PRODUCT_PACKAGES += \\ + Invcase Permission # The device /dev/invcase is created at boot with root permission. The HAL Library is loaded when JNI Wrapper for Invcase Service is run, therefore, HAL code will run with system permission which attaches to the system_server process. The Android Init Language uses init*.rc files to automatically do some actions when a condition is met. For the target hardware, Android Init will use init.<hardware>.rc file. On Emulator, it is init.ranchu.rc . Add below lines to change the owner and permission on the /dev/invcase at boot: device/generic/goldfish/init.ranchu.rc + on boot + chown system system /dev/invcase + chmod 0600 /dev/invcase Build and Run # The Invcase Manager exports new Service APIs, therefore, need to rebuild the list of system APIs. m all -j $( nproc ) Run the Emulator and run Invcase app: The User Test application Start the Logcat to see debug lines: logcat -s Invcase Logcat shows Invcase calls There are 3 processes: The system_server process (yellow) does below things: Load JNI functions Start Invcase Service whichs creates an object of Invcase Manager Implementation The HAL process (purple) runs: Host the HAL implementation The user app (white) process does below things: Load System Service Registry to have an object of Invcase Manager Interface Use received service interface to communicate with Invcase Manager Implementation in the Invcase Service","title":"Binderized HAL (HIDL)"},{"location":"blog/android/hal/hidl/binderized/#binderized-hal","text":"In a Binderized HAL, the Android framework and HALs communicate with each other using binder inter-process communication (IPC) calls. All devices launching with Android O 8.0 or later must support binderized HALs only.","title":"Binderized HAL"},{"location":"blog/android/hal/hidl/binderized/#framework-stacks","text":"Differences between Conventional HAL and Binderized HIDL for HAL : Conventional HAL in the Framework stacks Binderized HAL in the Framework stacks","title":"Framework Stacks"},{"location":"blog/android/hal/hidl/binderized/#implementation","text":"binderized_hal.zip Refer to Kernel Module to build and install a module to system. This guide assumes that invcase module is loaded as below: device/generic/goldfish/init.ranchu.rc + on boot + insmod /system/lib/modules/invcase.ko + chown system system /dev/invcase + chmod 0600 /dev/invcase","title":"Implementation"},{"location":"blog/android/hal/hidl/binderized/#overview","text":"AOSP build make target product base_vendor.mk Include new packages + PRODUCT_PACKAGES += \\ + android.hardware.invcase@1.0-service \\ + invcase_hidl_test \\ + Invcase gsi 29.txt Add new vendor native library VNDK-core: android.hardware.input.common@1.0.so + VNDK-core: android.hardware.invcase@1.0.so VNDK-core: android.hardware.ir@1.0.so packages apps Invcase src com invcase Invcase.java Get InvcaseManager from SystemService class Invcase extends Activity { InvcaseManager mManager ; onCreate () { mManager = getSystemService ( Context . INVCASE_SERVICE ); } } res layout mipmap values AndroidManifest.xml Export main activity on Launcher <manifest package= \"com.invcase\" > <application> <activity android:name= \".Invcase\" android:exported= \"true\" > <intent-filter> <action android:name= \"android.intent.action.MAIN\" /> <category android:name= \"android.intent.category.LAUNCHER\" /> </intent-filter> </activity> </application> </manifest> android:exported=\"true\" is mandatory on Android 12 Android.bp android_app { name : \"Invcase\" , srcs : [ \"src/**/*.java\" ] , platform_apis : true } platform_apis: true : use System API when do not specify any target platform device generic car common manifest.xml Declare new interface + <hal format=\"hidl\"> + <name>android.hardware.invcase</name> + <transport>hwbinder</transport> + <version>1.0</version> + <interface> + <name>IInvcase</name> + <instance>default</instance> + </interface> + </hal> frameworks base Android.bp java_defaults { name: \"framework-defaults\", installable: true, srcs: [ + \"core/java/android/hardware/invcase/IInvcaseManager.aidl\", ] } api current.txt + package android.hardware.invcase { + + public final class InvcaseManager { + method @NonNull public String getData(); + method public void putData(@NonNull String); + } + + } core java android app SystemServiceRegistry.java Create an InvcaseManager instance and add it to the System Service list + import android.hardware.invcase.InvcaseManager; public final class SystemServiceRegistry { static { + registerService(Context.INVCASE_SERVICE, InvcaseManager.class, + new CachedServiceFetcher<InvcaseManager>() { + @Override + public InvcaseManager createService(ContextImpl ctx) + throws ServiceNotFoundException { + return new InvcaseManager(ctx); + }}); } } content Context.java Add Invcase Serive name public abstract class Context { + public static final String INVCASE_SERVICE = \"invcase\"; @StringDef(suffix = { \"_SERVICE\" }, value = { + INVCASE_SERVICE, }) } hardware invcase IInvcaseManager.aidl Define API for Invcase Interface interface IInvcaseManager { getData (); putData (); } InvcaseManager.java Use Invase Serive through the Invcase Interface class InvcaseManager { IInvcaseManager mService ; InvcaseManager ( Context ) throws ServiceNotFoundException { this ( context , IInvcaseManager . Stub . asInterface ( ServiceManager . getServiceOrThrow ( Context . INVCASE_SERVICE )) ); } InvcaseManager ( Context , IInvcaseManager ){} getData () { mService . getData (); } putData () { mService . putData (); } } services core java com android server invcase InvcaseService.java Implement Invcase Interface functions, public the interface class InvcaseService extends SystemService { IInvcaseManagerImpl extends IInvcaseManager . Stub { getData () { invcase_native_read (); } putData () { invcase_native_write (); } } mManagerService ; onStart () { publishBinderService ( Context . INVCASE_SERVICE , mManagerService ); } } jni com_android_server_invcase_InvcaseService.cpp Map java functions to native functions #include <hardware_legacy/invcase.h> jni_read () { invcase_read (); } jni_write () { invcase_write (); } static const JNINativeMethod method_table [] = { { \"invcase_native_read\" , \"()Ljava/lang/String;\" , ( void * ) jni_read }, { \"invcase_native_write\" , \"(Ljava/lang/String;)V\" , ( void * ) jni_write }, }; register_android_server_InvcaseService ( method_table ); onload.cpp Register mapped function calls namespace android { + int register_android_server_InvcaseService(JNIEnv *env); }; extern \"C\" jint JNI_OnLoad(JavaVM* vm, void* /* reserved */) { + register_android_server_InvcaseService(env); } Android.bp cc_library_static { srcs: [ + \"com_android_server_invcase_InvcaseService.cpp\", ], } cc_defaults { shared_libs: [ + \"android.hardware.invcase@1.0\", ], } java com android server SystemServer.java Start Invcase Service + import com.android.server.invcase.InvcaseService; public final class SystemServer implements Dumpable { private void startBootstrapServices(@NonNull TimingsTraceAndSlog t) { + traceBeginAndSlog(\"StartInvcaseService\"); + mSystemServiceManager.startService(InvcaseService.class); + traceEnd(); } } hardware interfaces invcase 1.0 default Android.bp Invcase.h Invcase.cpp IInvcase.hal interface IInvcase { putChars ( string msg ); getChars () generates ( string msg ); }; Android.bp","title":"Overview"},{"location":"blog/android/hal/hidl/binderized/#define-hal-interface","text":"Create a new HAL file in the folder hardware/interfaces : hardware/interfaces/invcase/1.0/IInvcase.hal package android.hardware.invcase @ 1.0 ; interface IInvcase { putChars ( string msg ); getChars () generates ( string msg ); };","title":"Define HAL Interface"},{"location":"blog/android/hal/hidl/binderized/#prepare-hal-files","text":"Source hidl-gen is a compiler for the HIDL (HAL Interface Design Language) which generates C++ and Java endpoints for RPC mechanisms. The main userspace libraries which this compiler uses can be found at system/libhidl . Build hidl-gen if it is not built: m hidl-gen Then run it to generate C++ source file and Makefile: export INVCASE_PACKAGE = android.hardware.invcase@1.0 export INVCASE_LOC = hardware/interfaces/invcase/1.0/default/ export HIDL_INF = android.hardware:hardware/interfaces export HIDL_LIB = android.hidl:system/libhidl/transport hidl-gen -o $INVCASE_LOC -Lc++-impl \\ -r $HIDL_INF -r $HIDL_LIB $INVCASE_PACKAGE hidl-gen -o $INVCASE_LOC -Landroidbp-impl \\ -r $HIDL_INF -r $HIDL_LIB $INVCASE_PACKAGE After these command, 3 files are generated in the default folder: Android.bp , Invcase.h , and Invcase.cpp . The generated files are for implement the HAL. Service Add three empty files for HAL service process in the 1.0/default folder: android.hardware.invcase@1.0-service.rc android.hardware.invcase@1.0-service.xml service.cpp Makefile Run the tool: ./hardware/interfaces/update-makefiles.sh to generate hardware/interfaces/invcase/1.0/Android.bp // This file is autogenerated by hidl-gen -Landroidbp. hidl_i nterfa ce { na me : \"android.hardware.invcase@1.0\" , roo t : \"android.hardware\" , v n dk : { e na bled : true , }, srcs : [ \"IInvcase.hal\" , ], i nterfa ces : [ \"android.hidl.base@1.0\" , ], ge n _java : false , }","title":"Prepare HAL files"},{"location":"blog/android/hal/hidl/binderized/#implement-hal","text":"Header : hardware/interfaces/invcase/1.0/default/Invcase.h #pragma once #include <android/hardware/invcase/1.0/IInvcase.h> #include <hidl/MQDescriptor.h> #include <hidl/Status.h> namespace android { namespace hardware { namespace invcase { namespace V1_0 { namespace implementation { using :: android :: hardware :: hidl_array ; using :: android :: hardware :: hidl_memory ; using :: android :: hardware :: hidl_string ; using :: android :: hardware :: hidl_vec ; using :: android :: hardware :: Return ; using :: android :: hardware :: Void ; using :: android :: sp ; struct Invcase : public IInvcase { // Methods from ::android::hardware::invcase::V1_0::IInvcase follow. Return < void > putChars ( const hidl_string & msg ) override ; Return < void > getChars ( getChars_cb _hidl_cb ) override ; // Methods from ::android::hidl::base::V1_0::IBase follow. }; // FIXME: most likely delete, this is only for passthrough implementations // extern \"C\" IInvcase* HIDL_FETCH_IInvcase(const char* name); } // namespace implementation } // namespace V1_0 } // namespace invcase } // namespace hardware } // namespace android Source : hardware/interfaces/invcase/1.0/default/Invcase.cpp #define LOG_TAG \"Invcase\" #include <utils/Log.h> #include <iostream> #include <fstream> #include \"Invcase.h\" namespace android { namespace hardware { namespace invcase { namespace V1_0 { namespace implementation { // Methods from ::android::hardware::invcase::V1_0::IInvcase follow. Return < void > Invcase :: putChars ( const hidl_string & msg ) { std :: ofstream invcase_dev ; invcase_dev . open ( \"/dev/invcase\" ); if ( invcase_dev . good ()) { invcase_dev << msg ; ALOGE ( \"putChars: %s\" , msg . c_str ()); } else { ALOGE ( \"putChars: can not open /dev/invcase\" ); } return Void (); } Return < void > Invcase :: getChars ( getChars_cb _hidl_cb ) { std :: ifstream invcase_dev ; invcase_dev . open ( \"/dev/invcase\" ); if ( invcase_dev . good ()) { std :: string line ; invcase_dev >> line ; ALOGE ( \"getChars: %s\" , line . c_str ()); hidl_string result ( line ); _hidl_cb ( result ); } else { ALOGE ( \"getChars: can not open /dev/invcase\" ); } return Void (); } // Methods from ::android::hidl::base::V1_0::IBase follow. //IInvcase* HIDL_FETCH_IInvcase(const char* /* name */) { //return new Invcase(); //} // } // namespace implementation } // namespace V1_0 } // namespace invcase } // namespace hardware } // namespace android","title":"Implement HAL"},{"location":"blog/android/hal/hidl/binderized/#implement-hal-service","text":"To host the library we need to create a simple executable: hardware/interfaces/invcase/1.0/default/service.cpp #define LOG_TAG \"Invcase\" #include <iostream> #include <android/hardware/invcase/1.0/IInvcase.h> #include <hidl/HidlTransportSupport.h> #include <hidl/LegacySupport.h> #include <utils/Log.h> #include \"Invcase.h\" using android :: hardware :: invcase :: V1_0 :: IInvcase ; using android :: hardware :: invcase :: V1_0 :: implementation :: Invcase ; using android :: hardware :: configureRpcThreadpool ; using android :: hardware :: joinRpcThreadpool ; using android :: sp ; void logd ( std :: string msg ) { std :: cout << msg << std :: endl ; ALOGD ( \"%s\" , msg . c_str ()); } void loge ( std :: string msg ) { std :: cout << msg << std :: endl ; ALOGE ( \"%s\" , msg . c_str ()); } int main ( int /* argc */ , char ** /* argv */ ) { configureRpcThreadpool ( 1 , true /*callerWillJoin*/ ); android :: sp < IInvcase > invcase = new Invcase (); if ( invcase != nullptr ) { if ( invcase -> registerAsService () != :: android :: OK ) { loge ( \"Failed to register IInvcase service\" ); return -1 ; } } else { loge ( \"Failed to get IInvcase instance\" ); return -1 ; } logd ( \"IInvcase service starts to join service pool\" ); joinRpcThreadpool (); return 1 ; // joinRpcThreadpool shouldn't exit } And request to start service at startup: hardware/interfaces/invcase/1.0/default/android.hardware.invcase@1.0-service.rc service vendor.invcase-1-0 /vendor/bin/hw/android.hardware.invcase@1.0-service class hal user system group system Makefile : By default, hidl-gen creates a Makefile to build a shared library using the name android.hardware.invcase@1.0-service (note the suffix -service ). hardware/interfaces/invcase/1.0/default/Android.bp cc_binary { name : \"android.hardware.invcase@1.0-service\" , defaults : [ \"hidl_defaults\" ], vendor : true , relative_install_path : \"hw\" , srcs : [ \"service.cpp\" , \"Invcase.cpp\" ], init_rc : [ \"android.hardware.invcase@1.0-service.rc\" ], shared_libs : [ \"android.hardware.invcase@1.0\" , \"libhidlbase\" , \"libhidltransport\" , \"liblog\" , \"libutils\" , ], vintf_fragments : [ \"android.hardware.invcase@1.0.xml\" ], } A test application that request the HAL service: hardware/interfaces/invcase/1.0/test/invcase_hidl_test.cpp #define LOG_TAG \"Invcase\" #include <iostream> #include <android/hardware/invcase/1.0/IInvcase.h> #include <hidl/HidlTransportSupport.h> #include <hidl/LegacySupport.h> #include <utils/Log.h> #include <android/hardware/invcase/1.0/default/Invcase.h> using android :: hardware :: invcase :: V1_0 :: IInvcase ; using android :: hardware :: hidl_string ; using android :: sp ; void logd ( std :: string msg ) { std :: cout << msg << std :: endl ; ALOGD ( \"%s\" , msg . c_str ()); } void loge ( std :: string msg ) { std :: cout << msg << std :: endl ; ALOGE ( \"%s\" , msg . c_str ()); } int main ( int /* argc */ , char ** /* argv */ ) { android :: sp < IInvcase > invcase = IInvcase :: getService (); if ( invcase == nullptr ) { loge ( \"Failed to get Invcase service\" ); return -1 ; } logd ( \"Got Invcase service\" ); std :: string msg = \"Hello World!\" ; logd ( \"Send: \" + msg ); invcase -> putChars ( msg ); invcase -> getChars ([ & ]( hidl_string result ) { logd ( \"Receive: \" + std :: string ( result )); }); return 0 ; } Build the test app: hardware/interfaces/invcase/1.0/test/Android.bpp cc_binary { name : \"invcase_hidl_test\" , defaults : [ \"hidl_defaults\" ] , proprietary : true, relative_install_path : \"hw\" , srcs : [ \"invcase_hidl_test.cpp\" ] , shared_libs : [ \"android.hardware.invcase@1.0\" , \"libhidlbase\" , \"libhidltransport\" , \"libutils\" , \"liblog\" , ] , }","title":"Implement HAL Service"},{"location":"blog/android/hal/hidl/binderized/#define-selinux-policy-for-hal-service","text":"To make the service run at boot, HAL service needs to be registered to system under a security policy. Declare the new type : system/sepolicy/prebuilts/api/29.0/public/hwservice.te system/sepolicy/public/hwservice.te type hal_invcase_hwservice, hwservice_manager_type; Set compatibility Ignore in API 28, which also ignore in API 27 and API 26: system/sepolicy/prebuilts/api/29.0/private/compat/28.0/28.0.ignore.cil system/sepolicy/private/compat/28.0/28.0.ignore.cil (type new_objects) (typeattribute new_objects) (typeattributeset new_objects ( new_objects hal_invcase_hwservice ) ) Do not allow other apps to access : system/sepolicy/prebuilts/api/29.0/private/app_neverallows.te system/sepolicy/private/app_neverallows.te neverallow all_untrusted_apps { hal_invcase_hwservice } Set service context interface : system/sepolicy/prebuilts/api/29.0/private/hwservice_contexts system/sepolicy/private/hwservice_contexts android.hardware.invcase :: IInvcase u : object_r : hal_invcase_hwservice : s 0 Declare attribute : system/sepolicy/prebuilts/api/29.0/public/attributes system/sepolicy/public/attributes hal_attribute(invcase); this is macro for adding below attributes: attribute hal_invcase; attribute hal_invcase_client; attribute hal_invcase_server; Define default domain : system/sepolicy/vendor/hal_invcase_default.te type hal_invcase_default, domain; hal_server_domain(hal_invcase_default, hal_invcase) type hal_invcase_default_exec, exec_type, vendor_file_type, vendor_file_type, file_type; init_daemon_domain(hal_invcase_default) Set binder policy : system/sepolicy/prebuilts/api/29.0/public/hal_invcase.te system/sepolicy/public/hal_invcase.te binder_call(hal_invcase_client, hal_invcase_server) binder_call(hal_invcase_server, hal_invcase_client) hal_attribute_hwservice(hal_invcase, hal_invcase_hwservice) Set system context : Note the HAL process path! system/sepolicy/vendor/file_contexts /(vendor|system/vendor)/bin/hw/android\\.hardware\\.invcase@1\\.0-service u : object_r : hal_invcase_default_exec : s 0 Declare system_server as client of HAL service : system/sepolicy/prebuilts/api/29.0/private/system_server.te system/sepolicy/private/system_server.te hal_client_domain(system_server, hal_invcase)","title":"Define SELinux Policy for HAL service"},{"location":"blog/android/hal/hidl/binderized/#deliver-hal-module","text":"VNDK Vendor Native Development Kit (VNDK) is a set of libraries exclusively for vendors to implement their HALs. The VNDK ships in system.img and is dynamically linked to vendor code at runtime. Refer to https://source.android.com/devices/architecture/vndk/build-system . Include HAL service and the test app to the PRODUCT_PACKAGES : build/target/product/base_vendor.mk + PRODUCT_PACKAGES += \\ + android.hardware.invcase@1.0-service \\ + invcase_hidl_test \\ This will include below files to system: /vendor/lib/hw/android.hardware.invcase@1.0-service /vendor/bin/hw/invcase_hidl_test Export HAL Interface Using show_make_tree.py to find the included manifest: python show_make_tree.py \\ \"device/generic/car/aosp_car_x86_64.mk\" \\ \"manifest.xml:\" File : device/generic/car/aosp_car_x86_64.mk Inherit: device/generic/car/common/car.mk Found : device/generic/car/common/manifest.xml: $( TARGET_COPY_OUT_VENDOR ) /manifest.xml Inherit: device/generic/goldfish/vendor.mk Found : device/generic/goldfish/manifest.xml: $( TARGET_COPY_OUT_VENDOR ) /manifest.xml \\ Because car.mk inherits goldfish/vendor.mk , so file manifest.xml is copied from device/generic/car/common/manifest.xml as it is registered first. Read more about PRODUCT_COPY_FILES rules . We add the HAL interface as below: device/generic/car/common/manifest.xml + <hal format=\"hidl\"> + <name>android.hardware.invcase</name> + <transport>hwbinder</transport> + <version>1.0</version> + <interface> + <name>IInvcase</name> + <instance>default</instance> + </interface> + </hal> API locked If you encounter below error, it is because only Google can add interface into hardware/interfaces . error: VNDK library list has been changed. Changing the VNDK library list is not allowed in API locked branches. You have to explicitly add the VNDK core to the API list: build/make/target/product/gsi/29.txt VNDK-core: android.hardware.input.common@1.0.so + VNDK-core: android.hardware.invcase@1.0.so VNDK-core: android.hardware.ir@1.0.so","title":"Deliver HAL module"},{"location":"blog/android/hal/hidl/binderized/#jni-wrapper","text":"The Java Native Interface (JNI) is a foreign function interface programming framework that enables Java code running in a Java virtual machine (JVM) to call and be called by native applications (programs specific to a hardware and operating system platform) and libraries written in other languages such as C, C++ and assembly. Create java functions that call to native function in HAL library jni_read calls to invcase_read jni_write calls to invcase_write Register mapped functions with their signatures (encoded parameters) Note that Java functions always have 2 default arguments: JNIEnv* env : a structure containing methods that we can use our native code to access Java elements jobject selfClass : the class of calling object Implement JNI Mapping Note that the function jniRegisterNativeMethods will register JNI functions for the class frameworks/services/core/java/com/android/server/invcase/InvcaseService.java : frameworks/base/services/core/jni/com_android_server_invcase_InvcaseService.cpp #define LOG_TAG \"Invcase\" #include \"jni.h\" #include <nativehelper/JNIHelp.h> #include \"android_runtime/AndroidRuntime.h\" #include <utils/misc.h> #include <utils/Log.h> #include <stdio.h> #include <android/hardware/invcase/1.0/IInvcase.h> using android :: hardware :: invcase :: V1_0 :: IInvcase ; using android :: hardware :: hidl_string ; namespace android { static void jni_init ( JNIEnv * /* env */ , jobject /* clazz */ ) { } static void jni_deinit ( JNIEnv * /* env */ , jobject /* clazz */ ) { } static jstring jni_read ( JNIEnv * env , jobject /* clazz */ ) { sp < IInvcase > invcase = IInvcase :: getService (); if ( invcase == nullptr ) { ALOGE ( \"JNI: Failed to get Invcase service \\n \" ); return env -> NewStringUTF ( \"\" ); } std :: string msg ; invcase -> getChars ([ & ]( hidl_string result ) { msg = std :: string ( result ); }); const char * buff = msg . c_str (); ALOGD ( \"JNI: Receive: %s \\n \" , buff ); return env -> NewStringUTF ( buff ); } static void jni_write ( JNIEnv * env , jobject /* clazz */ , jstring string ) { sp < IInvcase > invcase = IInvcase :: getService (); if ( invcase == nullptr ) { ALOGE ( \"JNI: Failed to get Invcase service \\n \" ); return ; } const char * buff = env -> GetStringUTFChars ( string , NULL ); ALOGD ( \"JNI: Send: %s \\n \" , buff ); invcase -> putChars ( std :: string ( buff )); } static const JNINativeMethod method_table [] = { { \"invcase_native_init\" , \"()V\" , ( void * ) jni_init }, { \"invcase_native_deinit\" , \"()V\" , ( void * ) jni_deinit }, { \"invcase_native_read\" , \"()Ljava/lang/String;\" , ( void * ) jni_read }, { \"invcase_native_write\" , \"(Ljava/lang/String;)V\" , ( void * ) jni_write }, }; int register_android_server_InvcaseService ( JNIEnv * env ) { ALOGD ( \"JNI: register_android_server_InvcaseService \\n \" ); return jniRegisterNativeMethods ( env , \"com/android/server/invcase/InvcaseService\" , method_table , NELEM ( method_table ) ); } } Call the register function : frameworks/base/services/core/jni/onload.cpp namespace android { + int register_android_server_InvcaseService(JNIEnv *env); }; extern \"C\" jint JNI_OnLoad(JavaVM* vm, void* /* reserved */) { + register_android_server_InvcaseService(env); } Build new JNI wrapper : frameworks/base/services/core/jni/Android.bp cc_library_static { name: \"libservices.core\", srcs: [ + \"com_android_server_invcase_InvcaseService.cpp\", ], } cc_defaults { name: \"libservices.core-libs\", shared_libs: [ + \"android.hardware.invcase@1.0\", ], Declare API : frameworks/base/api/current.txt + package android.hardware.invcase { + public final class InvcaseManager { + method @NonNull public String getData(); + method public void putData(@NonNull String); + } + }","title":"JNI Wrapper"},{"location":"blog/android/hal/hidl/binderized/#service-and-manager","text":"Define a name for new Service frameworks/base/core/java/android/content/Context.java public abstract class Context { @StringDef(suffix = { \"_SERVICE\" }, value = { + INVCASE_SERVICE, }) + /** + * Use with {@link #getSystemService(String)} to retrieve a + * {@link android.hardware.invcase.InvcaseManager}. + * + * @see #getSystemService(String) + * @hide + */ + public static final String INVCASE_SERVICE = \"invcase\"; Define the Service Interface Use AIDL to describe public functions exported by the Service: frameworks/base/core/java/android/hardware/invcase/IInvcaseManager.aidl package android.hardware.invcase ; /** * Invcase Manager interface * * {@hide} */ interface IInvcaseManager { String getData (); void putData ( String data ); } Build AIDL : frameworks/base/Android.bp java_defaults { name: \"framework-defaults\", installable: true, srcs: [ + \"core/java/android/hardware/invcase/IInvcaseManager.aidl\", ] } Implement the Service Manager A Service Manager is the wrapper for the interface of the target Service which is obtained by calling to <Interface>.Stub.asInterface . User application will call to the functions of the Service Manager, not directly calling to the actual service interface. frameworks/base/core/java/android/hardware/invcase/InvcaseManager.java package android.hardware.invcase ; import android.annotation.NonNull ; import android.content.Context ; import android.util.Log ; import android.os.RemoteException ; import android.os.ServiceManager ; import android.os.ServiceManager.ServiceNotFoundException ; public final class InvcaseManager { static final String TAG = \"Invcase\" ; private final Context mContext ; private final IInvcaseManager mService ; /** * Creates a InvcaseManager. * * @hide */ public InvcaseManager ( @NonNull Context context ) throws ServiceNotFoundException { this ( context , IInvcaseManager . Stub . asInterface ( ServiceManager . getServiceOrThrow ( Context . INVCASE_SERVICE ))); } /** * Creates a InvcaseManager with a provided service implementation. * * @hide */ public InvcaseManager ( @NonNull Context context , @NonNull IInvcaseManager service ) { mContext = context ; mService = service ; Log . d ( TAG , \"InvcaseManager: mContext= \" + mContext + \" mService= \" + mService ); } public @NonNull String getData () { try { String str = mService . getData (); Log . d ( TAG , \"InvcaseManager: mService.getData= \" + str ); return str ; } catch ( RemoteException e ) { e . printStackTrace (); } return null ; } public void putData ( @NonNull String data ) { try { Log . d ( TAG , \"InvcaseManager: mService.putData= \" + data ); mService . putData ( data ); } catch ( RemoteException e ) { e . printStackTrace (); } } } Implement the Service The Service will implement the actual code for Service Interface functions by extending the <Interface>.Stub class. Note that JNI Native functions are exported to this object, therefore, it can call to HAL library\u2019s functions. frameworks/base/services/core/java/com/android/server/invcase/InvcaseService.java package com.android.server.invcase ; import android.hardware.invcase.IInvcaseManager ; import android.content.Context ; import android.util.Log ; import com.android.server.SystemService ; public class InvcaseService extends SystemService { static final String TAG = \"Invcase\" ; static final boolean DEBUG = false ; final IInvcaseManagerImpl mManagerService ; private final class IInvcaseManagerImpl extends IInvcaseManager . Stub { @Override public String getData () { String str = invcase_native_read (); Log . d ( TAG , \"InvcaseService: IInvcaseManager.getData= \" + str ); return str ; } @Override public void putData ( String data ) { Log . d ( TAG , \"InvcaseService: IInvcaseManager.putData= \" + data ); invcase_native_write ( data ); } } public InvcaseService ( Context context ) { super ( context ); invcase_native_init (); mManagerService = new IInvcaseManagerImpl (); Log . d ( TAG , \"InvcaseService: mManagerService= \" + mManagerService ); } @Override public void onStart () { publishBinderService ( Context . INVCASE_SERVICE , mManagerService ); Log . d ( TAG , \"InvcaseService: onStart\" ); } @Override protected void finalize () throws Throwable { invcase_native_deinit (); super . finalize (); } private static native void invcase_native_init (); private static native void invcase_native_deinit (); private static native String invcase_native_read (); private static native void invcase_native_write ( String string ); } Run our service : All system services are run in the same process called system_server which is implemented in the SystemServer.java . This process runs under system user. frameworks/base/services/java/com/android/server/SystemServer.java import com.android.server.invcase.InvcaseService; import android.util.Log; public final class SystemServer implements Dumpable { private void startBootstrapServices(@NonNull TimingsTraceAndSlog t) { + // Manages Invcase device. + traceBeginAndSlog(\"StartInvcaseService\"); + Log.d(\"Invcase\", \"SystemServer: start InvcaseService\"); + mSystemServiceManager.startService(InvcaseService.class); + traceEnd();","title":"Service and Manager"},{"location":"blog/android/hal/hidl/binderized/#user-app","text":"The User App will be very simple to test the hardware. It contains an EditText to get user input, a Button to execute commands, and a TextView to display the result. Implement the User App Use getSystemService(Context.INVCASE_SERVICE) to obtain the instance of InvcaseManager Call to hardware through the InvcaseManager APIs packages/apps/Invcase/src/com/invcase/Invcase.java package com.invcase ; import android.hardware.invcase.InvcaseManager ; import android.content.Context ; import android.app.Activity ; import android.os.Bundle ; import android.view.View ; import android.widget.Button ; import android.widget.EditText ; import android.widget.TextView ; import android.util.Log ; public class Invcase extends Activity { private static final String TAG = \"Invcase\" ; private InvcaseManager mManager ; @Override protected void onCreate ( Bundle savedInstanceState ) { super . onCreate ( savedInstanceState ); setContentView ( R . layout . activity_main ); mManager = ( InvcaseManager ) getSystemService ( Context . INVCASE_SERVICE ); Log . d ( TAG , \"App: mManager= \" + mManager ); Button btn = ( Button ) findViewById ( R . id . button ); btn . setOnClickListener ( new View . OnClickListener () { @Override public void onClick ( View view ) { EditText editText = ( EditText ) findViewById ( R . id . editText ); String txt = editText . getText (). toString (); Log . d ( TAG , \"App: request= \" + txt ); mManager . putData ( txt ); String ret = mManager . getData (); Log . d ( TAG , \"App: received= \" + ret ); TextView tv = ( TextView ) findViewById ( R . id . textView ); tv . setText ( ret ); } }); } } Add User App to the Launcher packages/apps/Invcase/AndroidManifest.xml <?xml version=\"1.0\" encoding=\"utf-8\"?> <manifest xmlns:android= \"http://schemas.android.com/apk/res/android\" package= \"com.invcase\" > <application android:icon= \"@mipmap/ic_launcher\" android:label= \"@string/app_name\" > <activity android:name= \".Invcase\" android:exported= \"true\" android:label= \"@string/app_name\" > <intent-filter> <action android:name= \"android.intent.action.MAIN\" /> <category android:name= \"android.intent.category.LAUNCHER\" /> </intent-filter> </activity> </application> </manifest> on Android 12, must use android:exported=\"true\" Build User App packages/apps/Invcase/Android.bp android_app { name : \"Invcase\" , platform_apis : true, srcs : [ \"src/**/*.java\" ] } Add User App to system packages : build/target/product/base_vendor.mk + PRODUCT_PACKAGES += \\ + Invcase","title":"User App"},{"location":"blog/android/hal/hidl/binderized/#permission","text":"The device /dev/invcase is created at boot with root permission. The HAL Library is loaded when JNI Wrapper for Invcase Service is run, therefore, HAL code will run with system permission which attaches to the system_server process. The Android Init Language uses init*.rc files to automatically do some actions when a condition is met. For the target hardware, Android Init will use init.<hardware>.rc file. On Emulator, it is init.ranchu.rc . Add below lines to change the owner and permission on the /dev/invcase at boot: device/generic/goldfish/init.ranchu.rc + on boot + chown system system /dev/invcase + chmod 0600 /dev/invcase","title":"Permission"},{"location":"blog/android/hal/hidl/binderized/#build-and-run","text":"The Invcase Manager exports new Service APIs, therefore, need to rebuild the list of system APIs. m all -j $( nproc ) Run the Emulator and run Invcase app: The User Test application Start the Logcat to see debug lines: logcat -s Invcase Logcat shows Invcase calls There are 3 processes: The system_server process (yellow) does below things: Load JNI functions Start Invcase Service whichs creates an object of Invcase Manager Implementation The HAL process (purple) runs: Host the HAL implementation The user app (white) process does below things: Load System Service Registry to have an object of Invcase Manager Interface Use received service interface to communicate with Invcase Manager Implementation in the Invcase Service","title":"Build and Run"},{"location":"blog/android/kernel-module/","tags":["android","kernel"],"text":"This guide is based on AOSP android-10.0.0_r47 and android-12.1.0_r8 Loadable Kernel Module # As part of the module kernel requirements introduced in Android 8.0, all system-on-chip (SoC) kernels must support loadable kernel modules. To support loadable kernel modules, android-base.cfg in all common kernels includes the following kernel-config options (or their kernel-version equivalent): CONFIG_MODULES=y CONFIG_MODULE_UNLOAD=y CONFIG_MODVERSIONS=y All device kernels must enable these options. Kernel modules should also support unloading and reloading whenever possible. Kernel Menu Config # Parsing the Kernel Menu Config needs a library, so install it: sudo apt install libncurses5-dev Next, set the BUILD_CONFIG to define the DEFCONFIG file then run the config script: android-10.0.0_r47 android-12.1.0_r8 BUILD_CONFIG = goldfish/build.config.goldfish.x86_64 \\ build/config.sh BUILD_CONFIG = common/build.config.gki.x86_64 \\ build/config.sh The Kenel Menuconfig UI Kernel Module # Implement a Kernel module invcase that inverses the characters\u2019 case, e.g. AbC \u2192 aBc : Change Overview : kernel common/drivers or goldfish/drivers invcase invcase.c invcase_init () { register a character device at / dev / invcase } invcase_exit () { remove / dev / invcase } invcase_receive () { read from harware to buffer copy from buffer to user } invcase_send () { copy from user to buffer write from buffer to hardware } file_operations { . read = invcase_receive , . write = invcase_send , }; module_init ( invcase_init ); module_exit ( invcase_exit ); Kconfig menuconfig INVCASE tristate \"Inverse Characters Case\" default y Makefile or Kbuild obj - $ ( CONFIG_INVCASE ) += invcase . o invcase - y := invcase . o Kconfig += source \"drivers/invcase/Kconfig\" Makefile or Kbuild + obj-$(CONFIG_INVCASE) += invcase/ Module implementation : invcase_init : register a character device at /dev/invcase invcase_exit : remove the registered device invcase_receive : aka read , copy from an internal buffer to the user buffer Use f_pos to know how many bytes have been read Return the number of bytes for current read command Return 0 to indicate end of data invcase_send : aka write , copy from the user buffer to the internal buffer Use f_pos to know how many bytes have been written Return the number of bytes for current write command System write expects that total returned bytes must be equal to the total requested bytes, therefore invcase/invcase.c #include <linux/module.h> // all kernel modules #include <linux/kernel.h> // KERN_INFO #include <linux/errno.h> // EFAULT #include <linux/device.h> // device register #include <linux/fs.h> // file_operations #include <linux/types.h> // size_t #include <linux/uaccess.h> // copy_from/to_user MODULE_LICENSE ( \"GPL\" ); MODULE_AUTHOR ( \"VQTRONG\" ); MODULE_DESCRIPTION ( \"Inverse Case\" ); /* DEVICE NAME */ #define DEVICE_NAME \"invcase\" // The device will appear at /dev/invcase #define CLASS_NAME \"invcase\" #define DEVICE_DEBUG \"invcase: \" /* Global variable */ static int majorNumber = 0 ; static struct class * invcaseClass = NULL ; static struct device * invcaseDevice = NULL ; #define MAX_SIZE 1024 static char __buffer [ MAX_SIZE ] = { 0 }; /* Function declaration */ static int invcase_init ( void ); static void invcase_exit ( void ); static ssize_t invcase_receive ( struct file * filp , char * buf , size_t count , loff_t * f_pos ); static ssize_t invcase_send ( struct file * filp , const char * buf , size_t count , loff_t * f_pos ); /* Device operations */ static struct file_operations __fops = { . owner = THIS_MODULE , . read = invcase_receive , . write = invcase_send , }; static int invcase_init ( void ){ // Try to dynamically allocate a major number for the device -- more difficult but worth it majorNumber = register_chrdev ( 0 , DEVICE_NAME , & __fops ); if ( majorNumber < 0 ){ printk ( KERN_ERR DEVICE_DEBUG \"Failed to register a major number \\n \" ); return majorNumber ; } printk ( KERN_INFO DEVICE_DEBUG \"Registered with major number %d \\n \" , majorNumber ); // Register the device class invcaseClass = class_create ( THIS_MODULE , CLASS_NAME ); if ( IS_ERR ( invcaseClass )) // Check for error and clean up if there is { unregister_chrdev ( majorNumber , DEVICE_NAME ); printk ( KERN_ERR DEVICE_DEBUG \"Failed to register device class \\n \" ); return PTR_ERR ( invcaseClass ); // Correct way to return an error on a pointer } printk ( KERN_INFO DEVICE_DEBUG \"Device class registered correctly \\n \" ); // Register the device driver invcaseDevice = device_create ( invcaseClass , NULL , MKDEV ( majorNumber , 0 ), NULL , DEVICE_NAME ); if ( IS_ERR ( invcaseDevice )) // Clean up if there is an error { class_destroy ( invcaseClass ); unregister_chrdev ( majorNumber , DEVICE_NAME ); printk ( KERN_ERR DEVICE_DEBUG \"Failed to create the device \\n \" ); return PTR_ERR ( invcaseDevice ); } // clear buffer memset ( __buffer , 0 , MAX_SIZE ); printk ( KERN_INFO DEVICE_DEBUG \"Init! \\n \" ); return 0 ; // Zero means OK } static void invcase_exit ( void ){ device_destroy ( invcaseClass , MKDEV ( majorNumber , 0 )); // remove the device class_unregister ( invcaseClass ); // unregister the device class class_destroy ( invcaseClass ); // remove the device class unregister_chrdev ( majorNumber , DEVICE_NAME ); // unregister the major number printk ( KERN_INFO DEVICE_DEBUG \"Exit \\n \" ); } static ssize_t invcase_receive ( struct file * filp , char * buf , size_t count , loff_t * f_pos ) { ssize_t remain = MAX_SIZE - * f_pos ; ssize_t len = count > remain ? remain : count ; printk ( KERN_INFO DEVICE_DEBUG \"Read from device, remain=%ld, *f_pos= %lld, count= %ld \\n \" , remain , * f_pos , count ); if ( remain <= 0 ) return 0 ; if ( copy_to_user ( buf , __buffer +* f_pos , len )) { printk ( KERN_ERR DEVICE_DEBUG \"Can not copy to user \\n \" ); return - EFAULT ; } printk ( KERN_INFO DEVICE_DEBUG \"Read from device: %s \\n \" , __buffer ); * f_pos += len ; return len ; } static ssize_t invcase_send ( struct file * filp , const char * buf , size_t count , loff_t * f_pos ) { int i ; ssize_t remain = MAX_SIZE - * f_pos ; ssize_t len = count > remain ? remain : count ; printk ( KERN_INFO DEVICE_DEBUG \"Write to device, remain=%ld, *f_pos= %lld, count= %ld \\n \" , remain , * f_pos , count ); if ( * f_pos == 0 ) memset ( __buffer , 0 , MAX_SIZE ); if ( remain <= 0 ) return count ; // ignore all requested bytes if ( copy_from_user ( __buffer +* f_pos , buf , len )) { printk ( KERN_ERR DEVICE_DEBUG \"Can not copy from user \\n \" ); return - EFAULT ; } printk ( KERN_INFO DEVICE_DEBUG \"Write to device: %s \\n \" , __buffer ); for ( i =* f_pos ; i <* f_pos + len ; i ++ ) { if ( __buffer [ i ] >= 'A' && __buffer [ i ] <= 'Z' ) { __buffer [ i ] += 32 ; } else if ( __buffer [ i ] >= 'a' && __buffer [ i ] <= 'z' ) { __buffer [ i ] -= 32 ; } } printk ( KERN_INFO DEVICE_DEBUG \"Convert to: %s \\n \" , __buffer ); * f_pos += len ; return len ; } module_init ( invcase_init ); module_exit ( invcase_exit ); Kinux Kernel Makefiles Refer https://docs.kernel.org/kbuild/makefiles.html to understand about the different targets: built-in , modules , library , etc. Add module to Menuconfig : invcase/Kconfig # Invcase Device configuration menuconfig INVCASE tristate \"Inverse Characters Case\" default y help Say Y to include this module Say N will not build this module Say M to build this module but not include to kernel yet Append invcase to list of menu: Kbuild + source \"drivers/invcase/Kconfig\" New module in Kernel Menu Config Add module to Makefile : invcase/Makefile or invcase/Kbuild obj-$(CONFIG_INVCASE) += invcase.o Append invcase to list of modules: Kbuild or Makefile + obj-$(CONFIG_INVCASE) += invcase/ Rebuild kernel with a fast build option when kernel has been built completely before: android-10.0.0_r47 android-12.1.0_r8 BUILD_CONFIG = goldfish/build.config.goldfish.x86_64 \\ LTO = none \\ build/build.sh BUILD_CONFIG = common/build.config.gki.x86_64 \\ LTO = none \\ FAST_BUILD = 1 \\ SKIP_MRPROPER = 1 \\ SKIP_DEFCONFIG = 1 \\ build/config.sh Add module to system image The above example build the target module as a built-in module. In case you build a loadable module .ko , you have to copy the module into system image, and insert the module at boot: device/generic/goldfish/vendor.mk PRODUCT_COPY_FILES += \\ + path/to/invcase.ko:system/lib/modules/invcase.ko device/generic/goldfish/init.ranchu.rc + on boot + insmod /system/lib/modules/invcase.ko Change permission The module is initialized or loaded by root user. Change the permission if needed: device/generic/goldfish/init.ranchu.rc + on boot + chown system system /dev/invcase + chmod 0600 /dev/invcase Rebuild system image to include new module: Note to change the kernel images and modules which is used for making AOSP system image. Follow the guide Include custom kernel for more details. m all -j $( nproc ) Run emulator : emulator -verbose -show-kernel -selinux permissive -writable-system Now, you can test the invcase device using echo and cat . Check the log in dmesg also. Test the invcase device with terminal Vendor Module # From AOSP 11, Vendor modules are recommended to built separately in common-modules and are built with option EXT_MODULES . For example: build.config.virtual_device.x86_64 \u2192 build.config.virtual_device which declares: EXT_MODULES = \"common-modules/virtual-device\" External modules do not listed in Kernel Config Menu. You have to change them manually in build command or in common-modules/virtual-device/Kbuild file. Appendix # A simple device can be implemented and tested in Linux. Install Kernel Headers sudo apt install linux-headers- $( uname -r ) Makefile BINARY : = invcase BUILD : = / lib / modules / $ ( shell uname - r ) / build obj - m := $ ( BINARY ). o all : make - C $ ( BUILD ) M = $ ( PWD ) modules install : echo ' KERNEL == \"invcase\" , SUBSYSTEM == \"invcase\" , MODE = \"0777\" ' | sudo tee / etc / udev / rules . d / 99 - invcase . rules sudo insmod $ ( BINARY ). ko remove : sudo rmmod $ ( BINARY ) clean : make - C $ ( BUILD ) M = $ ( PWD ) clean","title":"Kernel Module"},{"location":"blog/android/kernel-module/#loadable-kernel-module","text":"As part of the module kernel requirements introduced in Android 8.0, all system-on-chip (SoC) kernels must support loadable kernel modules. To support loadable kernel modules, android-base.cfg in all common kernels includes the following kernel-config options (or their kernel-version equivalent): CONFIG_MODULES=y CONFIG_MODULE_UNLOAD=y CONFIG_MODVERSIONS=y All device kernels must enable these options. Kernel modules should also support unloading and reloading whenever possible.","title":"Loadable Kernel Module"},{"location":"blog/android/kernel-module/#kernel-menu-config","text":"Parsing the Kernel Menu Config needs a library, so install it: sudo apt install libncurses5-dev Next, set the BUILD_CONFIG to define the DEFCONFIG file then run the config script: android-10.0.0_r47 android-12.1.0_r8 BUILD_CONFIG = goldfish/build.config.goldfish.x86_64 \\ build/config.sh BUILD_CONFIG = common/build.config.gki.x86_64 \\ build/config.sh The Kenel Menuconfig UI","title":"Kernel Menu Config"},{"location":"blog/android/kernel-module/#kernel-module","text":"Implement a Kernel module invcase that inverses the characters\u2019 case, e.g. AbC \u2192 aBc : Change Overview : kernel common/drivers or goldfish/drivers invcase invcase.c invcase_init () { register a character device at / dev / invcase } invcase_exit () { remove / dev / invcase } invcase_receive () { read from harware to buffer copy from buffer to user } invcase_send () { copy from user to buffer write from buffer to hardware } file_operations { . read = invcase_receive , . write = invcase_send , }; module_init ( invcase_init ); module_exit ( invcase_exit ); Kconfig menuconfig INVCASE tristate \"Inverse Characters Case\" default y Makefile or Kbuild obj - $ ( CONFIG_INVCASE ) += invcase . o invcase - y := invcase . o Kconfig += source \"drivers/invcase/Kconfig\" Makefile or Kbuild + obj-$(CONFIG_INVCASE) += invcase/ Module implementation : invcase_init : register a character device at /dev/invcase invcase_exit : remove the registered device invcase_receive : aka read , copy from an internal buffer to the user buffer Use f_pos to know how many bytes have been read Return the number of bytes for current read command Return 0 to indicate end of data invcase_send : aka write , copy from the user buffer to the internal buffer Use f_pos to know how many bytes have been written Return the number of bytes for current write command System write expects that total returned bytes must be equal to the total requested bytes, therefore invcase/invcase.c #include <linux/module.h> // all kernel modules #include <linux/kernel.h> // KERN_INFO #include <linux/errno.h> // EFAULT #include <linux/device.h> // device register #include <linux/fs.h> // file_operations #include <linux/types.h> // size_t #include <linux/uaccess.h> // copy_from/to_user MODULE_LICENSE ( \"GPL\" ); MODULE_AUTHOR ( \"VQTRONG\" ); MODULE_DESCRIPTION ( \"Inverse Case\" ); /* DEVICE NAME */ #define DEVICE_NAME \"invcase\" // The device will appear at /dev/invcase #define CLASS_NAME \"invcase\" #define DEVICE_DEBUG \"invcase: \" /* Global variable */ static int majorNumber = 0 ; static struct class * invcaseClass = NULL ; static struct device * invcaseDevice = NULL ; #define MAX_SIZE 1024 static char __buffer [ MAX_SIZE ] = { 0 }; /* Function declaration */ static int invcase_init ( void ); static void invcase_exit ( void ); static ssize_t invcase_receive ( struct file * filp , char * buf , size_t count , loff_t * f_pos ); static ssize_t invcase_send ( struct file * filp , const char * buf , size_t count , loff_t * f_pos ); /* Device operations */ static struct file_operations __fops = { . owner = THIS_MODULE , . read = invcase_receive , . write = invcase_send , }; static int invcase_init ( void ){ // Try to dynamically allocate a major number for the device -- more difficult but worth it majorNumber = register_chrdev ( 0 , DEVICE_NAME , & __fops ); if ( majorNumber < 0 ){ printk ( KERN_ERR DEVICE_DEBUG \"Failed to register a major number \\n \" ); return majorNumber ; } printk ( KERN_INFO DEVICE_DEBUG \"Registered with major number %d \\n \" , majorNumber ); // Register the device class invcaseClass = class_create ( THIS_MODULE , CLASS_NAME ); if ( IS_ERR ( invcaseClass )) // Check for error and clean up if there is { unregister_chrdev ( majorNumber , DEVICE_NAME ); printk ( KERN_ERR DEVICE_DEBUG \"Failed to register device class \\n \" ); return PTR_ERR ( invcaseClass ); // Correct way to return an error on a pointer } printk ( KERN_INFO DEVICE_DEBUG \"Device class registered correctly \\n \" ); // Register the device driver invcaseDevice = device_create ( invcaseClass , NULL , MKDEV ( majorNumber , 0 ), NULL , DEVICE_NAME ); if ( IS_ERR ( invcaseDevice )) // Clean up if there is an error { class_destroy ( invcaseClass ); unregister_chrdev ( majorNumber , DEVICE_NAME ); printk ( KERN_ERR DEVICE_DEBUG \"Failed to create the device \\n \" ); return PTR_ERR ( invcaseDevice ); } // clear buffer memset ( __buffer , 0 , MAX_SIZE ); printk ( KERN_INFO DEVICE_DEBUG \"Init! \\n \" ); return 0 ; // Zero means OK } static void invcase_exit ( void ){ device_destroy ( invcaseClass , MKDEV ( majorNumber , 0 )); // remove the device class_unregister ( invcaseClass ); // unregister the device class class_destroy ( invcaseClass ); // remove the device class unregister_chrdev ( majorNumber , DEVICE_NAME ); // unregister the major number printk ( KERN_INFO DEVICE_DEBUG \"Exit \\n \" ); } static ssize_t invcase_receive ( struct file * filp , char * buf , size_t count , loff_t * f_pos ) { ssize_t remain = MAX_SIZE - * f_pos ; ssize_t len = count > remain ? remain : count ; printk ( KERN_INFO DEVICE_DEBUG \"Read from device, remain=%ld, *f_pos= %lld, count= %ld \\n \" , remain , * f_pos , count ); if ( remain <= 0 ) return 0 ; if ( copy_to_user ( buf , __buffer +* f_pos , len )) { printk ( KERN_ERR DEVICE_DEBUG \"Can not copy to user \\n \" ); return - EFAULT ; } printk ( KERN_INFO DEVICE_DEBUG \"Read from device: %s \\n \" , __buffer ); * f_pos += len ; return len ; } static ssize_t invcase_send ( struct file * filp , const char * buf , size_t count , loff_t * f_pos ) { int i ; ssize_t remain = MAX_SIZE - * f_pos ; ssize_t len = count > remain ? remain : count ; printk ( KERN_INFO DEVICE_DEBUG \"Write to device, remain=%ld, *f_pos= %lld, count= %ld \\n \" , remain , * f_pos , count ); if ( * f_pos == 0 ) memset ( __buffer , 0 , MAX_SIZE ); if ( remain <= 0 ) return count ; // ignore all requested bytes if ( copy_from_user ( __buffer +* f_pos , buf , len )) { printk ( KERN_ERR DEVICE_DEBUG \"Can not copy from user \\n \" ); return - EFAULT ; } printk ( KERN_INFO DEVICE_DEBUG \"Write to device: %s \\n \" , __buffer ); for ( i =* f_pos ; i <* f_pos + len ; i ++ ) { if ( __buffer [ i ] >= 'A' && __buffer [ i ] <= 'Z' ) { __buffer [ i ] += 32 ; } else if ( __buffer [ i ] >= 'a' && __buffer [ i ] <= 'z' ) { __buffer [ i ] -= 32 ; } } printk ( KERN_INFO DEVICE_DEBUG \"Convert to: %s \\n \" , __buffer ); * f_pos += len ; return len ; } module_init ( invcase_init ); module_exit ( invcase_exit ); Kinux Kernel Makefiles Refer https://docs.kernel.org/kbuild/makefiles.html to understand about the different targets: built-in , modules , library , etc. Add module to Menuconfig : invcase/Kconfig # Invcase Device configuration menuconfig INVCASE tristate \"Inverse Characters Case\" default y help Say Y to include this module Say N will not build this module Say M to build this module but not include to kernel yet Append invcase to list of menu: Kbuild + source \"drivers/invcase/Kconfig\" New module in Kernel Menu Config Add module to Makefile : invcase/Makefile or invcase/Kbuild obj-$(CONFIG_INVCASE) += invcase.o Append invcase to list of modules: Kbuild or Makefile + obj-$(CONFIG_INVCASE) += invcase/ Rebuild kernel with a fast build option when kernel has been built completely before: android-10.0.0_r47 android-12.1.0_r8 BUILD_CONFIG = goldfish/build.config.goldfish.x86_64 \\ LTO = none \\ build/build.sh BUILD_CONFIG = common/build.config.gki.x86_64 \\ LTO = none \\ FAST_BUILD = 1 \\ SKIP_MRPROPER = 1 \\ SKIP_DEFCONFIG = 1 \\ build/config.sh Add module to system image The above example build the target module as a built-in module. In case you build a loadable module .ko , you have to copy the module into system image, and insert the module at boot: device/generic/goldfish/vendor.mk PRODUCT_COPY_FILES += \\ + path/to/invcase.ko:system/lib/modules/invcase.ko device/generic/goldfish/init.ranchu.rc + on boot + insmod /system/lib/modules/invcase.ko Change permission The module is initialized or loaded by root user. Change the permission if needed: device/generic/goldfish/init.ranchu.rc + on boot + chown system system /dev/invcase + chmod 0600 /dev/invcase Rebuild system image to include new module: Note to change the kernel images and modules which is used for making AOSP system image. Follow the guide Include custom kernel for more details. m all -j $( nproc ) Run emulator : emulator -verbose -show-kernel -selinux permissive -writable-system Now, you can test the invcase device using echo and cat . Check the log in dmesg also. Test the invcase device with terminal","title":"Kernel Module"},{"location":"blog/android/kernel-module/#vendor-module","text":"From AOSP 11, Vendor modules are recommended to built separately in common-modules and are built with option EXT_MODULES . For example: build.config.virtual_device.x86_64 \u2192 build.config.virtual_device which declares: EXT_MODULES = \"common-modules/virtual-device\" External modules do not listed in Kernel Config Menu. You have to change them manually in build command or in common-modules/virtual-device/Kbuild file.","title":"Vendor Module"},{"location":"blog/android/kernel-module/#appendix","text":"A simple device can be implemented and tested in Linux. Install Kernel Headers sudo apt install linux-headers- $( uname -r ) Makefile BINARY : = invcase BUILD : = / lib / modules / $ ( shell uname - r ) / build obj - m := $ ( BINARY ). o all : make - C $ ( BUILD ) M = $ ( PWD ) modules install : echo ' KERNEL == \"invcase\" , SUBSYSTEM == \"invcase\" , MODE = \"0777\" ' | sudo tee / etc / udev / rules . d / 99 - invcase . rules sudo insmod $ ( BINARY ). ko remove : sudo rmmod $ ( BINARY ) clean : make - C $ ( BUILD ) M = $ ( PWD ) clean","title":"Appendix"},{"location":"blog/arduino/esp32/introduction/","tags":["arduino","esp32"],"text":"Hardware # ESP32 Development Boards The ESP32 chip comes with 48 pins with multiple functions. Not all pins are exposed in all ESP32 development boards, and some pins cannot be used. The ESP32 is divided by family: ESP32: WiFi and BLE ESP32-S: WiFi only ESP32-C: WiFi and BLE 5 It\u2019s better to start with a dev board having embedded USB-to-Serial port. Please buy a good quality board, and it should be well known, and breadboard-friendly. ESP32 Pinout NodeMCU-32S Devkit V4 GPIOs All GPIOs can be configured as interrupts. GPIO 6 to GPIO 11 are exposed in some ESP32 development boards. However, these pins are connected to the integrated SPI flash on the ESP-WROOM-32 chip and are not recommended for other uses. Some GPIOs change their state to HIGH or output PWM signals at boot or reset: GPIO 1,3,5, 6-11,14,15. Enable (EN) is the 3.3 V regulator\u2019s enable pin. It\u2019s pulled up, so connect to ground to disable the 3.3 V regulator. This means that you can use this pin connected to a pushbutton to restart your ESP32, for example. The absolute maximum current drawn per GPIO is 40 mA according to the \u201cRecommended Operating Conditions\u201d section in the ESP32 datasheet. Capacitive touch GPIOs The ESP32 has 10 internal capacitive touch sensors on GPIO 0,2,4,12-15,27,32,33. These can sense variations in anything that holds an electrical charge, like the human skin. So they can detect variations induced when touching the GPIOs with a finger. These pins can be easily integrated into capacitive pads and replace mechanical buttons. Analog to Digital Converter The ESP32 has 18 x 12 bits ADC input channels. ADC2 pins cannot be used when Wi-Fi is used . The ESP32 ADC pins don\u2019t have a linear behavior. You probably won\u2019t be able to distinguish between 0 and 0.1 V, or between 3.2 and 3.3 V. Digital to Analog Converter There are 2 x 8 bits DAC channels on the ESP32 to convert digital signals into analog voltage signal outputs. PWM The ESP32 LED PWM controller has 16 independent channels that can be configured to generate PWM signals with different properties. All pins that can act as outputs can be used as PWM pins (GPIOs 34 to 39 can\u2019t generate PWM). I2C The ESP32 has two I2C channels and any pin can be set as SDA or SCL. SPI0 can be used to access to the external storage unit as a fast cache. SPI1 can be used as the Master host. SPI2, SPI3 can be used as both Master and Slave. SPI ESP32 has 4 SPI controllers. They are SPI0, SPI1, SPI2, SPI3. SPI0 and SPI1 share one BUS prefixed with \u201cSPI\u201d, they consist of signals \u201cD, Q, CS0 ~ CS2, CLK, WP, HD\u201d, and they are not exposed to user. SPI flash integrated (SPI0, SPI1): GPIOs 34 to 39 are GPIs \u2013 input only pins. These pins don\u2019t have internal pull-up or pull-down resistors. They can\u2019t be used as outputs, so use these pins only as inputs SPI2 and SPI3 use BUS prefixed with \u201cHSPI\u201d and \u201cVSPI\u201d respectively, and they are accessible from user. Hall Effect Sensor The ESP32 also features a built-in hall effect sensor that detects changes in the magnetic field in its surroundings. Arduino IDE # Install Arduino IDE and start it. ESP32 Arduino Core\u2019s documentation from the Espressif manufacturer contains guides and tutorials. Add ESP32 to board managers : Go to Preferences , then add the below URL: https://raw.githubusercontent.com/espressif/arduino-esp32/gh-pages/package_esp32_index.json Add a new board to board manager Download ESP32 board packages : Go to Tools \u2192 Board \u2192 Board Manager and search for esp32 , then install it. Download Board Support Packages (BSP) Example: Blink Go to Files \u2192 Examples \u2192 01. Basics \u2192 Blink to create a new sketch: Blink the built-in LED every second // the setup function runs once when you press reset or power the board void setup () { // initialize digital pin LED_BUILTIN as an output. pinMode ( LED_BUILTIN , OUTPUT ); } // the loop function runs over and over again forever void loop () { // turn the LED on (HIGH is the voltage level) digitalWrite ( LED_BUILTIN , HIGH ); delay ( 500 ); // turn the LED off by making the voltage LOW digitalWrite ( LED_BUILTIN , LOW ); delay ( 500 ); } Select target board Go to Tools , then under Board \u2192 ESP32 Arduino , select your target board, for example, NodeMCU-32S. You also have to select the COM port, baudrate, and Flash frequency. Select ModeMCU-32S as the target board Flash and Run Press Upload to compile and download program to the target board. Press EN button to reset the board and check the user LED. Fix: Failed to connect to ESP32: Timed out waiting for packet header Some ESP32 development boards don\u2019t go into flashing/uploading mode automatically when uploading a new code, therefore, you have to Hold the BOOT/FLASH button while uploading programm. Another way to make your board go into uploading mode automatically is to connect a 10 uF electrolytic capacitor between the EN pin and GND . Add 10uF electrolytic capacitor Espressif ESP32 Libraries # td:first-of-type { font-weight: bold; } td:not(:first-of-type):not(:last-of-type) { color: gray; } .yes { color: green; font-style: normal; font-weight: bold } .no { color: red; font-style: normal; } Peripheral ESP32 ESP32-S2 ESP32-C3 Comments ADC Yes Yes Yes Bluetooth Yes Not Supported Not Supported Bluetooth Classic BLE Yes Not Supported Yes DAC Yes Yes Not Supported Ethernet Yes Not Supported Not Supported RMII only GPIO Yes Yes Yes Hall Sensor Yes Not Supported Not Supported I2C Yes Yes Yes I2S Yes No No Work in-progress LEDC Yes Yes Yes Motor PWM No Not Supported Not Supported Pulse Counter No No No RMT Yes Yes Yes SDIO No No No SPI Yes Yes Yes Timer Yes Yes Yes Temp. Sensor Not Supported Yes Yes Touch Yes Yes Not Supported TWAI No No No UART Yes Yes Yes USB Not Supported Yes Yes ESP32-C3 only CDC/JTAG Wi-Fi Yes Yes Yes Serial # Arduino has built-in Serial object that can be used to communicate with the board through the default UART0 port on the target board. Most of ESP32 Boards has mapped the primary UART0 port to the USB-to-COM chip, therefore, you can easily use the Serial function without any additional board. The below example show how to initialize the Serial port and interact with user input: Display a message and read a number void setup () { // start Serial port Serial . begin ( 115200 ); while ( ! Serial ) { ; // wait for serial port to connect. Needed for native USB } } void loop () { // print a message Serial . print ( \"Enter a number: \" ); // wait for user input while ( ! Serial . available ()) delay ( 10 ); // read user input, convert it to a number int num = Serial . parseInt (); // look for the newline (enter) character // if found, feedback a message if ( Serial . read () == '\\n' ) { Serial . print ( \"You entered \" ); Serial . print ( num ); Serial . println (); } } Flash the program, and open Serial Monitor from Arduino Tools , then you can enter a number to test the application: Serial communication LED Control # The LED control (LEDC) peripheral is primarly designed to control the intensity of LEDs, although it can also be used to generate PWM signals for other purposes. APIs included: /* set up */ double ledcSetup ( uint8_t channel , double freq , uint8_t resolution_bits ); double ledcChangeFrequency ( uint8_t chan , double freq , uint8_t bit_num ); /* pin */ void ledcAttachPin ( uint8_t pin , uint8_t chan ); void ledcDetachPin ( uint8_t pin ); /* write/read */ void ledcWrite ( uint8_t chan , uint32_t duty ); uint32_t ledcRead ( uint8_t chan ); // return duty double ledcReadFreq ( uint8_t chan ); double ledcWriteTone ( uint8_t chan , double freq ); // at 50% PWM double ledcWriteNote ( uint8_t chan , note_t note , uint8_t octave ); Example of Fading LED : #define MIN_BRIGHTNESS 0 #define MAX_BRIGHTNESS 255 #define TIMER_CHANNEL 0 #define TIMER_FREQUENCY 5000 #define TIMER_RESOLUTION 12 int brightness = 0 ; int fadeAmount = 5 ; int dutyMax = pow ( 2 , TIMER_RESOLUTION ) - 1 ; void setLedBrightness ( uint8_t channel , uint32_t value , uint32_t valueMax = MAX_BRIGHTNESS ) { uint32_t duty = ( dutyMax / valueMax ) * min ( value , valueMax ); ledcWrite ( channel , duty ); } void setup () { ledcSetup ( TIMER_CHANNEL , TIMER_FREQUENCY , TIMER_RESOLUTION ); ledcAttachPin ( LED_BUILTIN , TIMER_CHANNEL ); } void loop () { setLedBrightness ( TIMER_CHANNEL , brightness ); brightness = brightness + fadeAmount ; if ( brightness <= MIN_BRIGHTNESS || brightness >= MAX_BRIGHTNESS ) { fadeAmount = - fadeAmount ; } delay ( 10 ); } WiFi Functions # ESP32 has the main feature of WiFi connection. The official EPS Libraries show all additional drivers for ESP32\u2019s peripherals, including WiFi APIs . The Wi-Fi API provides support for the 802.11b/g/n protocol driver. This API includes: Station mode (STA mode or Wi-Fi client mode). ESP32 connects to an access point AP mode (aka Soft-AP mode or Access Point mode). Devices connect to the ESP32 Security modes (WPA, WPA2, WEP, etc.) Scanning for access points Client Station # Include headers #include <WiFi.h> Connect to a WiFi Network const char * ssid = \"SSID\" ; const char * password = \"password\" ; void setup () { WiFi . begin ( ssid , password ); while ( WiFi . status () != WL_CONNECTED ) { delay ( 500 ); } Serial . println ( WiFi . localIP ()); } Create a WiFi Client const char * host = \"192.168.5.94\" ; const int port = 80 ; WiFiClient client ; if ( ! client . connect ( host , port )) { return ; } Request to the Web Server void loop () { client . print ( \"GET \" + String ( request ) + \" HTTP/1.1 \\r\\n \" + \"Host: \" + String ( host ) + \" \\r\\n \" + \"Connection: close \\r\\n \" + \" \\r\\n \" ); while ( client . available ()) { String line = client . readStringUntil ( '\\r' ); } } Example of Web Server using Python: Run on localhost:80 Return current time in format \"%H:%M:%S\" for each request /time #!/usr/bin/env python3 import socket import datetime import http.server class ExampleHTTPHandler ( http . server . SimpleHTTPRequestHandler ): def do_GET ( self ): if self . path == '/time' : self . send_response ( 200 ) self . send_header ( 'Content-Type' , 'text/plain' ) self . end_headers () # get current time now = datetime . datetime . now () . strftime ( \"%H:%M:%S\" ) self . wfile . write ( now . encode ()) self . wfile . write ( b ' \\r\\n ' ) else : # fallback to default handler super () . do_GET () def main (): print ( \"IP Addresses:\" ) for i in socket . getaddrinfo ( socket . gethostname (), None ): print ( i [ 4 ][ 0 ]) # Run webserver on localhost:80 server_address = ( '' , 80 ) # using multithread and ExampleHTTPHandler httpd = http . server . ThreadingHTTPServer ( server_address , ExampleHTTPHandler ) print ( \"Server starts\" ) httpd . serve_forever () if __name__ == \"__main__\" : main () Example of WiFi Web Client : Request to URI /time on the Web Server at host:port Print out lines of Web Server\u2019s response Note: This example is not optimized (re-create clients in the loop) #include <WiFi.h> // Set these to your desired credentials. const char * ssid = \"HomeSweetHome\" ; const char * password = \"password\" ; // URI const char * host = \"192.168.5.94\" ; const int port = 80 ; const char * request_time = \"/time\" ; void setup () { Serial . begin ( 115200 ); Serial . println (); Serial . print ( \"Connecting to \" ); Serial . println ( ssid ); // connect to the WiFi WiFi . begin ( ssid , password ); while ( WiFi . status () != WL_CONNECTED ) { delay ( 500 ); Serial . print ( \".\" ); } Serial . println ( \"\" ); Serial . println ( \"WiFi connected\" ); Serial . print ( \"IP address: \" ); Serial . println ( WiFi . localIP ()); } void loop () { // Create a client WiFiClient client ; // connect to the host using TCP if ( ! client . connect ( host , port )) { Serial . println ( \"HTTP connection failed\" ); return ; } // send GET request to HTTP Webserver client . print ( \"GET \" + String ( request_time ) + \" HTTP/1.1 \\r\\n \" + \"Host: \" + String ( host ) + \" \\r\\n \" + \"Connection: close \\r\\n \" + \" \\r\\n \" ); // wait for response in 5s unsigned long timeout = millis (); while ( client . available () == 0 ) { if ( millis () - timeout > 5000 ) { Serial . println ( \">>> Client Timeout !\" ); client . stop (); return ; } } // // Read all the lines of the reply from server and print them to Serial while ( client . available ()) { String line = client . readStringUntil ( '\\r' ); Serial . print ( line ); } Serial . println (); } Output console of a client when requesting /time Soft Access Point # Include headers #include <WiFi.h> #include <WiFiClient.h> #include <WiFiAP.h> Create a WiFi Access Point const char * ssid = \"ESP32-AP\" ; const char * password = \"password\" ; void setup () { // start the Access Point WiFi . softAP ( ssid , password ); // get local IP IPAddress myIP = WiFi . softAPIP (); } Run a Web Server WiFiServer server ( 80 ); void setup () { // after run the Access Point server . begin (); } void loop () { // listen for incoming clients WiFiClient client = server . available (); if ( client ) { while ( client . connected ()) { if ( client . available ()) { // read data from client char c = client . read (); } } client . stop (); } } Response to client // send header client . println ( \"HTTP/1.1 200 OK \\n \" \"Content-type:text/html \\n \" ); // send content client . println ( \"Hello \\n \" ); Example of processing user request to change webpage\u2019s background color: Web Server listens to user requests in format GET /<action> , corresponding to URLs in format <WebServerIP>/<action> The action could be red or green as the selected color, other actions will clear the color Show buttons for user to select #include <WiFi.h> #include <WiFiClient.h> #include <WiFiAP.h> // Set these to your desired credentials. const char * ssid = \"ESP32-AP\" ; const char * password = \"password\" ; // Run a webser at port 80 WiFiServer server ( 80 ); // A sample webpage show a solid background color enum BG_COLOR { NONE , RED , GREEN }; BG_COLOR bg_color = NONE ; const char * red = \"red\" ; const char * green = \"green\" ; const char * none = \"initial\" ; const char * get_bg_color () { switch ( bg_color ) { case RED : return red ; case GREEN : return green ; default : return none ; } } void send_response ( WiFiClient * client ) { // send Header with OK response client -> println ( \"HTTP/1.1 200 OK \\n \" \"Content-type:text/html \\n \" ); // send Content client -> println ( \"<html>\" \"<body \" \"style= \\\" \" \"background-color:\" + String ( get_bg_color ()) + \";\" \"text-align:center;\" \" \\\" >\" \"<a href= \\\" / \\\" ><button>NONE</a></button>\" \"<a href= \\\" /red \\\" ><button>RED</a></button>\" \"<a href= \\\" /green \\\" ><button>GREEN</a></button>\" \"</body>\" \"</html>\" ); } void setup () { Serial . begin ( 115200 ); Serial . println (); Serial . println ( \"Configuring access point...\" ); // You can remove the password parameter if you want the AP to be open. WiFi . softAP ( ssid , password ); // Show AP address IPAddress myIP = WiFi . softAPIP (); Serial . print ( \"AP IP address: \" ); Serial . println ( myIP ); // Start Web Server server . begin (); Serial . println ( \"Server started\" ); } void loop () { // listen for incoming clients WiFiClient client = server . available (); if ( client ) { Serial . println ( \"New Client.\" ); // string to hold client HTTP request String clientString = \"\" ; while ( client . connected ()) { if ( client . available ()) { char c = client . read (); //Serial.write(c); // newline char means end of string if ( c == '\\n' ) { // if the current line is blank, you got two newline characters in a row. // that's the end of the client HTTP request, so send a response: if ( clientString . length () == 0 ) { send_response ( & client ); // break out of the while loop: break ; } else { // if you got a newline, then process the completed string Serial . println ( clientString ); // Check to see if the client request was \"GET /red\" or \"GET /green\": if ( clientString . startsWith ( \"GET /red \" )) { Serial . println ( \"RED\" ); bg_color = RED ; } else if ( clientString . startsWith ( \"GET /green \" )) { Serial . println ( \"GREEN\" ); bg_color = GREEN ; } else if ( clientString . startsWith ( \"GET / \" )) { Serial . println ( \"NONE\" ); bg_color = NONE ; } clientString = \"\" ; } } else if ( c != '\\r' ) { // if you got anything else but a carriage return character, clientString += c ; // add it to the end of the currentLine } } } // close the connection: client . stop (); Serial . println ( \"Client Disconnected.\" ); } } The webpage from ESP32 Web Server Output console for a request /red Preferences (Saved Data) # The Preferences library is unique to arduino-esp32. It should be considered as the replacement for the Arduino EEPROM library. It uses a portion of the on-board non-volatile memory (NVS) of the ESP32 to store data. This data is retained across restarts and loss of power events to the system. Preferences works best for storing many small values, rather than a few large values. If large amounts of data are to be stored, consider using a file system library such as LitteFS. Data is saved in below format: namespace { key1 : value1 key2 : value2 } Include header and initiate an instance : #include <Preferences.h> Preferences preferences ; Begin a namespace bool begin ( const char * name , bool readOnly = false , const char * partition_label = NULL ) Read/Write data Note: Key name is limited to 15 chars. size_t put < Type > ( const char * key , < Type > value ); size_t get < Type > ( const char * key , < Type > defaultValue = 0 ); bool remove ( const char * key ); PreferenceType getType ( const char * key ); Clear data bool clear () Close session bool clear () Namespace In the Arduino implementation of Preferences, there is no method of completely removing a namespace. As a result, over the course of several projects, the ESP32 non-volatile storage (nvs) Preferences partition may become full. To completely erase and reformat the NVS memory used by Preferences, create a sketch that contains: #include <nvs_flash.h> void setup () { nvs_flash_erase (); // erase the NVS partition and... nvs_flash_init (); // initialize the NVS partition. } void loop () {} Example to save username/password : If no user found, add a new user If an user exists, prompt for the password If the password is correct, allow changing user If password is incorrect 3 times, lock the machine #include <Preferences.h> Preferences preferences ; #define NS_ACCOUNT \"account\" #define KEY_USER \"user\" #define KEY_PASSWD \"passwd\" /* account { user: XXX passwd: YYY } */ String user ; String passwd ; String passwd2 ; void input ( String & prompt , String & str ) { str = \"\" ; Serial . print ( prompt ); while ( str == \"\" ){ str = Serial . readString (); } Serial . println ( str ); } void addUser () { while ( true ) { String prompt = \"Enter Username: \" ; input ( prompt , user ); prompt = \"Enter Password: \" ; input ( prompt , passwd ); prompt = \"Retry Password: \" ; input ( prompt , passwd2 ); if ( passwd == passwd2 ) { int r = -1 ; Serial . println ( \"Save new account: \" + user + \" / \" + passwd ); r = preferences . putString ( KEY_USER , user ); if ( r == 0 ) Serial . println ( \"Can NOT user!\" ); r = preferences . putString ( KEY_PASSWD , passwd ); if ( r == 0 ) Serial . println ( \"Can NOT passwd!\" ); preferences . end (); delay ( 1000 ); ESP . restart (); } } } void askPassword () { Serial . println ( \"Welcome \" + user + \"!\" ); passwd = preferences . getString ( KEY_PASSWD ); int trial = 3 ; String prompt = \"Enter Password: \" ; while ( trial > 0 ) { input ( prompt , passwd2 ); trial -- ; if ( passwd == passwd2 ) { break ; } } if ( trial > 0 ) { Serial . println ( \"Logged in! You can change user!\" ); addUser (); } else { Serial . println ( \"LOCKED!\" ); while ( true ){} } } void setup () { Serial . begin ( 115200 ); while ( ! Serial ) {} // open namespace NS_ACCOUNT with readOnly = false preferences . begin ( NS_ACCOUNT , false ); user = preferences . getString ( KEY_USER ); if ( user == \"\" ) { Serial . println ( \"No user found!\" ); addUser (); } else { askPassword (); } } void loop () { delay ( 1000 ); } Output console of a login example References # Arduino Language Reference ESP32 Arduino Core\u2019s documentation Random Nerd Tutorials - ESP32","title":"Getting started with ESP32 Development Boards"},{"location":"blog/arduino/esp32/introduction/#hardware","text":"ESP32 Development Boards The ESP32 chip comes with 48 pins with multiple functions. Not all pins are exposed in all ESP32 development boards, and some pins cannot be used. The ESP32 is divided by family: ESP32: WiFi and BLE ESP32-S: WiFi only ESP32-C: WiFi and BLE 5 It\u2019s better to start with a dev board having embedded USB-to-Serial port. Please buy a good quality board, and it should be well known, and breadboard-friendly. ESP32 Pinout NodeMCU-32S Devkit V4 GPIOs All GPIOs can be configured as interrupts. GPIO 6 to GPIO 11 are exposed in some ESP32 development boards. However, these pins are connected to the integrated SPI flash on the ESP-WROOM-32 chip and are not recommended for other uses. Some GPIOs change their state to HIGH or output PWM signals at boot or reset: GPIO 1,3,5, 6-11,14,15. Enable (EN) is the 3.3 V regulator\u2019s enable pin. It\u2019s pulled up, so connect to ground to disable the 3.3 V regulator. This means that you can use this pin connected to a pushbutton to restart your ESP32, for example. The absolute maximum current drawn per GPIO is 40 mA according to the \u201cRecommended Operating Conditions\u201d section in the ESP32 datasheet. Capacitive touch GPIOs The ESP32 has 10 internal capacitive touch sensors on GPIO 0,2,4,12-15,27,32,33. These can sense variations in anything that holds an electrical charge, like the human skin. So they can detect variations induced when touching the GPIOs with a finger. These pins can be easily integrated into capacitive pads and replace mechanical buttons. Analog to Digital Converter The ESP32 has 18 x 12 bits ADC input channels. ADC2 pins cannot be used when Wi-Fi is used . The ESP32 ADC pins don\u2019t have a linear behavior. You probably won\u2019t be able to distinguish between 0 and 0.1 V, or between 3.2 and 3.3 V. Digital to Analog Converter There are 2 x 8 bits DAC channels on the ESP32 to convert digital signals into analog voltage signal outputs. PWM The ESP32 LED PWM controller has 16 independent channels that can be configured to generate PWM signals with different properties. All pins that can act as outputs can be used as PWM pins (GPIOs 34 to 39 can\u2019t generate PWM). I2C The ESP32 has two I2C channels and any pin can be set as SDA or SCL. SPI0 can be used to access to the external storage unit as a fast cache. SPI1 can be used as the Master host. SPI2, SPI3 can be used as both Master and Slave. SPI ESP32 has 4 SPI controllers. They are SPI0, SPI1, SPI2, SPI3. SPI0 and SPI1 share one BUS prefixed with \u201cSPI\u201d, they consist of signals \u201cD, Q, CS0 ~ CS2, CLK, WP, HD\u201d, and they are not exposed to user. SPI flash integrated (SPI0, SPI1): GPIOs 34 to 39 are GPIs \u2013 input only pins. These pins don\u2019t have internal pull-up or pull-down resistors. They can\u2019t be used as outputs, so use these pins only as inputs SPI2 and SPI3 use BUS prefixed with \u201cHSPI\u201d and \u201cVSPI\u201d respectively, and they are accessible from user. Hall Effect Sensor The ESP32 also features a built-in hall effect sensor that detects changes in the magnetic field in its surroundings.","title":"Hardware"},{"location":"blog/arduino/esp32/introduction/#arduino-ide","text":"Install Arduino IDE and start it. ESP32 Arduino Core\u2019s documentation from the Espressif manufacturer contains guides and tutorials. Add ESP32 to board managers : Go to Preferences , then add the below URL: https://raw.githubusercontent.com/espressif/arduino-esp32/gh-pages/package_esp32_index.json Add a new board to board manager Download ESP32 board packages : Go to Tools \u2192 Board \u2192 Board Manager and search for esp32 , then install it. Download Board Support Packages (BSP) Example: Blink Go to Files \u2192 Examples \u2192 01. Basics \u2192 Blink to create a new sketch: Blink the built-in LED every second // the setup function runs once when you press reset or power the board void setup () { // initialize digital pin LED_BUILTIN as an output. pinMode ( LED_BUILTIN , OUTPUT ); } // the loop function runs over and over again forever void loop () { // turn the LED on (HIGH is the voltage level) digitalWrite ( LED_BUILTIN , HIGH ); delay ( 500 ); // turn the LED off by making the voltage LOW digitalWrite ( LED_BUILTIN , LOW ); delay ( 500 ); } Select target board Go to Tools , then under Board \u2192 ESP32 Arduino , select your target board, for example, NodeMCU-32S. You also have to select the COM port, baudrate, and Flash frequency. Select ModeMCU-32S as the target board Flash and Run Press Upload to compile and download program to the target board. Press EN button to reset the board and check the user LED. Fix: Failed to connect to ESP32: Timed out waiting for packet header Some ESP32 development boards don\u2019t go into flashing/uploading mode automatically when uploading a new code, therefore, you have to Hold the BOOT/FLASH button while uploading programm. Another way to make your board go into uploading mode automatically is to connect a 10 uF electrolytic capacitor between the EN pin and GND . Add 10uF electrolytic capacitor","title":"Arduino IDE"},{"location":"blog/arduino/esp32/introduction/#espressif-esp32-libraries","text":"td:first-of-type { font-weight: bold; } td:not(:first-of-type):not(:last-of-type) { color: gray; } .yes { color: green; font-style: normal; font-weight: bold } .no { color: red; font-style: normal; } Peripheral ESP32 ESP32-S2 ESP32-C3 Comments ADC Yes Yes Yes Bluetooth Yes Not Supported Not Supported Bluetooth Classic BLE Yes Not Supported Yes DAC Yes Yes Not Supported Ethernet Yes Not Supported Not Supported RMII only GPIO Yes Yes Yes Hall Sensor Yes Not Supported Not Supported I2C Yes Yes Yes I2S Yes No No Work in-progress LEDC Yes Yes Yes Motor PWM No Not Supported Not Supported Pulse Counter No No No RMT Yes Yes Yes SDIO No No No SPI Yes Yes Yes Timer Yes Yes Yes Temp. Sensor Not Supported Yes Yes Touch Yes Yes Not Supported TWAI No No No UART Yes Yes Yes USB Not Supported Yes Yes ESP32-C3 only CDC/JTAG Wi-Fi Yes Yes Yes","title":"Espressif ESP32 Libraries"},{"location":"blog/arduino/esp32/introduction/#serial","text":"Arduino has built-in Serial object that can be used to communicate with the board through the default UART0 port on the target board. Most of ESP32 Boards has mapped the primary UART0 port to the USB-to-COM chip, therefore, you can easily use the Serial function without any additional board. The below example show how to initialize the Serial port and interact with user input: Display a message and read a number void setup () { // start Serial port Serial . begin ( 115200 ); while ( ! Serial ) { ; // wait for serial port to connect. Needed for native USB } } void loop () { // print a message Serial . print ( \"Enter a number: \" ); // wait for user input while ( ! Serial . available ()) delay ( 10 ); // read user input, convert it to a number int num = Serial . parseInt (); // look for the newline (enter) character // if found, feedback a message if ( Serial . read () == '\\n' ) { Serial . print ( \"You entered \" ); Serial . print ( num ); Serial . println (); } } Flash the program, and open Serial Monitor from Arduino Tools , then you can enter a number to test the application: Serial communication","title":"Serial"},{"location":"blog/arduino/esp32/introduction/#led-control","text":"The LED control (LEDC) peripheral is primarly designed to control the intensity of LEDs, although it can also be used to generate PWM signals for other purposes. APIs included: /* set up */ double ledcSetup ( uint8_t channel , double freq , uint8_t resolution_bits ); double ledcChangeFrequency ( uint8_t chan , double freq , uint8_t bit_num ); /* pin */ void ledcAttachPin ( uint8_t pin , uint8_t chan ); void ledcDetachPin ( uint8_t pin ); /* write/read */ void ledcWrite ( uint8_t chan , uint32_t duty ); uint32_t ledcRead ( uint8_t chan ); // return duty double ledcReadFreq ( uint8_t chan ); double ledcWriteTone ( uint8_t chan , double freq ); // at 50% PWM double ledcWriteNote ( uint8_t chan , note_t note , uint8_t octave ); Example of Fading LED : #define MIN_BRIGHTNESS 0 #define MAX_BRIGHTNESS 255 #define TIMER_CHANNEL 0 #define TIMER_FREQUENCY 5000 #define TIMER_RESOLUTION 12 int brightness = 0 ; int fadeAmount = 5 ; int dutyMax = pow ( 2 , TIMER_RESOLUTION ) - 1 ; void setLedBrightness ( uint8_t channel , uint32_t value , uint32_t valueMax = MAX_BRIGHTNESS ) { uint32_t duty = ( dutyMax / valueMax ) * min ( value , valueMax ); ledcWrite ( channel , duty ); } void setup () { ledcSetup ( TIMER_CHANNEL , TIMER_FREQUENCY , TIMER_RESOLUTION ); ledcAttachPin ( LED_BUILTIN , TIMER_CHANNEL ); } void loop () { setLedBrightness ( TIMER_CHANNEL , brightness ); brightness = brightness + fadeAmount ; if ( brightness <= MIN_BRIGHTNESS || brightness >= MAX_BRIGHTNESS ) { fadeAmount = - fadeAmount ; } delay ( 10 ); }","title":"LED Control"},{"location":"blog/arduino/esp32/introduction/#wifi-functions","text":"ESP32 has the main feature of WiFi connection. The official EPS Libraries show all additional drivers for ESP32\u2019s peripherals, including WiFi APIs . The Wi-Fi API provides support for the 802.11b/g/n protocol driver. This API includes: Station mode (STA mode or Wi-Fi client mode). ESP32 connects to an access point AP mode (aka Soft-AP mode or Access Point mode). Devices connect to the ESP32 Security modes (WPA, WPA2, WEP, etc.) Scanning for access points","title":"WiFi Functions"},{"location":"blog/arduino/esp32/introduction/#client-station","text":"Include headers #include <WiFi.h> Connect to a WiFi Network const char * ssid = \"SSID\" ; const char * password = \"password\" ; void setup () { WiFi . begin ( ssid , password ); while ( WiFi . status () != WL_CONNECTED ) { delay ( 500 ); } Serial . println ( WiFi . localIP ()); } Create a WiFi Client const char * host = \"192.168.5.94\" ; const int port = 80 ; WiFiClient client ; if ( ! client . connect ( host , port )) { return ; } Request to the Web Server void loop () { client . print ( \"GET \" + String ( request ) + \" HTTP/1.1 \\r\\n \" + \"Host: \" + String ( host ) + \" \\r\\n \" + \"Connection: close \\r\\n \" + \" \\r\\n \" ); while ( client . available ()) { String line = client . readStringUntil ( '\\r' ); } } Example of Web Server using Python: Run on localhost:80 Return current time in format \"%H:%M:%S\" for each request /time #!/usr/bin/env python3 import socket import datetime import http.server class ExampleHTTPHandler ( http . server . SimpleHTTPRequestHandler ): def do_GET ( self ): if self . path == '/time' : self . send_response ( 200 ) self . send_header ( 'Content-Type' , 'text/plain' ) self . end_headers () # get current time now = datetime . datetime . now () . strftime ( \"%H:%M:%S\" ) self . wfile . write ( now . encode ()) self . wfile . write ( b ' \\r\\n ' ) else : # fallback to default handler super () . do_GET () def main (): print ( \"IP Addresses:\" ) for i in socket . getaddrinfo ( socket . gethostname (), None ): print ( i [ 4 ][ 0 ]) # Run webserver on localhost:80 server_address = ( '' , 80 ) # using multithread and ExampleHTTPHandler httpd = http . server . ThreadingHTTPServer ( server_address , ExampleHTTPHandler ) print ( \"Server starts\" ) httpd . serve_forever () if __name__ == \"__main__\" : main () Example of WiFi Web Client : Request to URI /time on the Web Server at host:port Print out lines of Web Server\u2019s response Note: This example is not optimized (re-create clients in the loop) #include <WiFi.h> // Set these to your desired credentials. const char * ssid = \"HomeSweetHome\" ; const char * password = \"password\" ; // URI const char * host = \"192.168.5.94\" ; const int port = 80 ; const char * request_time = \"/time\" ; void setup () { Serial . begin ( 115200 ); Serial . println (); Serial . print ( \"Connecting to \" ); Serial . println ( ssid ); // connect to the WiFi WiFi . begin ( ssid , password ); while ( WiFi . status () != WL_CONNECTED ) { delay ( 500 ); Serial . print ( \".\" ); } Serial . println ( \"\" ); Serial . println ( \"WiFi connected\" ); Serial . print ( \"IP address: \" ); Serial . println ( WiFi . localIP ()); } void loop () { // Create a client WiFiClient client ; // connect to the host using TCP if ( ! client . connect ( host , port )) { Serial . println ( \"HTTP connection failed\" ); return ; } // send GET request to HTTP Webserver client . print ( \"GET \" + String ( request_time ) + \" HTTP/1.1 \\r\\n \" + \"Host: \" + String ( host ) + \" \\r\\n \" + \"Connection: close \\r\\n \" + \" \\r\\n \" ); // wait for response in 5s unsigned long timeout = millis (); while ( client . available () == 0 ) { if ( millis () - timeout > 5000 ) { Serial . println ( \">>> Client Timeout !\" ); client . stop (); return ; } } // // Read all the lines of the reply from server and print them to Serial while ( client . available ()) { String line = client . readStringUntil ( '\\r' ); Serial . print ( line ); } Serial . println (); } Output console of a client when requesting /time","title":"Client Station"},{"location":"blog/arduino/esp32/introduction/#soft-access-point","text":"Include headers #include <WiFi.h> #include <WiFiClient.h> #include <WiFiAP.h> Create a WiFi Access Point const char * ssid = \"ESP32-AP\" ; const char * password = \"password\" ; void setup () { // start the Access Point WiFi . softAP ( ssid , password ); // get local IP IPAddress myIP = WiFi . softAPIP (); } Run a Web Server WiFiServer server ( 80 ); void setup () { // after run the Access Point server . begin (); } void loop () { // listen for incoming clients WiFiClient client = server . available (); if ( client ) { while ( client . connected ()) { if ( client . available ()) { // read data from client char c = client . read (); } } client . stop (); } } Response to client // send header client . println ( \"HTTP/1.1 200 OK \\n \" \"Content-type:text/html \\n \" ); // send content client . println ( \"Hello \\n \" ); Example of processing user request to change webpage\u2019s background color: Web Server listens to user requests in format GET /<action> , corresponding to URLs in format <WebServerIP>/<action> The action could be red or green as the selected color, other actions will clear the color Show buttons for user to select #include <WiFi.h> #include <WiFiClient.h> #include <WiFiAP.h> // Set these to your desired credentials. const char * ssid = \"ESP32-AP\" ; const char * password = \"password\" ; // Run a webser at port 80 WiFiServer server ( 80 ); // A sample webpage show a solid background color enum BG_COLOR { NONE , RED , GREEN }; BG_COLOR bg_color = NONE ; const char * red = \"red\" ; const char * green = \"green\" ; const char * none = \"initial\" ; const char * get_bg_color () { switch ( bg_color ) { case RED : return red ; case GREEN : return green ; default : return none ; } } void send_response ( WiFiClient * client ) { // send Header with OK response client -> println ( \"HTTP/1.1 200 OK \\n \" \"Content-type:text/html \\n \" ); // send Content client -> println ( \"<html>\" \"<body \" \"style= \\\" \" \"background-color:\" + String ( get_bg_color ()) + \";\" \"text-align:center;\" \" \\\" >\" \"<a href= \\\" / \\\" ><button>NONE</a></button>\" \"<a href= \\\" /red \\\" ><button>RED</a></button>\" \"<a href= \\\" /green \\\" ><button>GREEN</a></button>\" \"</body>\" \"</html>\" ); } void setup () { Serial . begin ( 115200 ); Serial . println (); Serial . println ( \"Configuring access point...\" ); // You can remove the password parameter if you want the AP to be open. WiFi . softAP ( ssid , password ); // Show AP address IPAddress myIP = WiFi . softAPIP (); Serial . print ( \"AP IP address: \" ); Serial . println ( myIP ); // Start Web Server server . begin (); Serial . println ( \"Server started\" ); } void loop () { // listen for incoming clients WiFiClient client = server . available (); if ( client ) { Serial . println ( \"New Client.\" ); // string to hold client HTTP request String clientString = \"\" ; while ( client . connected ()) { if ( client . available ()) { char c = client . read (); //Serial.write(c); // newline char means end of string if ( c == '\\n' ) { // if the current line is blank, you got two newline characters in a row. // that's the end of the client HTTP request, so send a response: if ( clientString . length () == 0 ) { send_response ( & client ); // break out of the while loop: break ; } else { // if you got a newline, then process the completed string Serial . println ( clientString ); // Check to see if the client request was \"GET /red\" or \"GET /green\": if ( clientString . startsWith ( \"GET /red \" )) { Serial . println ( \"RED\" ); bg_color = RED ; } else if ( clientString . startsWith ( \"GET /green \" )) { Serial . println ( \"GREEN\" ); bg_color = GREEN ; } else if ( clientString . startsWith ( \"GET / \" )) { Serial . println ( \"NONE\" ); bg_color = NONE ; } clientString = \"\" ; } } else if ( c != '\\r' ) { // if you got anything else but a carriage return character, clientString += c ; // add it to the end of the currentLine } } } // close the connection: client . stop (); Serial . println ( \"Client Disconnected.\" ); } } The webpage from ESP32 Web Server Output console for a request /red","title":"Soft Access Point"},{"location":"blog/arduino/esp32/introduction/#preferences-saved-data","text":"The Preferences library is unique to arduino-esp32. It should be considered as the replacement for the Arduino EEPROM library. It uses a portion of the on-board non-volatile memory (NVS) of the ESP32 to store data. This data is retained across restarts and loss of power events to the system. Preferences works best for storing many small values, rather than a few large values. If large amounts of data are to be stored, consider using a file system library such as LitteFS. Data is saved in below format: namespace { key1 : value1 key2 : value2 } Include header and initiate an instance : #include <Preferences.h> Preferences preferences ; Begin a namespace bool begin ( const char * name , bool readOnly = false , const char * partition_label = NULL ) Read/Write data Note: Key name is limited to 15 chars. size_t put < Type > ( const char * key , < Type > value ); size_t get < Type > ( const char * key , < Type > defaultValue = 0 ); bool remove ( const char * key ); PreferenceType getType ( const char * key ); Clear data bool clear () Close session bool clear () Namespace In the Arduino implementation of Preferences, there is no method of completely removing a namespace. As a result, over the course of several projects, the ESP32 non-volatile storage (nvs) Preferences partition may become full. To completely erase and reformat the NVS memory used by Preferences, create a sketch that contains: #include <nvs_flash.h> void setup () { nvs_flash_erase (); // erase the NVS partition and... nvs_flash_init (); // initialize the NVS partition. } void loop () {} Example to save username/password : If no user found, add a new user If an user exists, prompt for the password If the password is correct, allow changing user If password is incorrect 3 times, lock the machine #include <Preferences.h> Preferences preferences ; #define NS_ACCOUNT \"account\" #define KEY_USER \"user\" #define KEY_PASSWD \"passwd\" /* account { user: XXX passwd: YYY } */ String user ; String passwd ; String passwd2 ; void input ( String & prompt , String & str ) { str = \"\" ; Serial . print ( prompt ); while ( str == \"\" ){ str = Serial . readString (); } Serial . println ( str ); } void addUser () { while ( true ) { String prompt = \"Enter Username: \" ; input ( prompt , user ); prompt = \"Enter Password: \" ; input ( prompt , passwd ); prompt = \"Retry Password: \" ; input ( prompt , passwd2 ); if ( passwd == passwd2 ) { int r = -1 ; Serial . println ( \"Save new account: \" + user + \" / \" + passwd ); r = preferences . putString ( KEY_USER , user ); if ( r == 0 ) Serial . println ( \"Can NOT user!\" ); r = preferences . putString ( KEY_PASSWD , passwd ); if ( r == 0 ) Serial . println ( \"Can NOT passwd!\" ); preferences . end (); delay ( 1000 ); ESP . restart (); } } } void askPassword () { Serial . println ( \"Welcome \" + user + \"!\" ); passwd = preferences . getString ( KEY_PASSWD ); int trial = 3 ; String prompt = \"Enter Password: \" ; while ( trial > 0 ) { input ( prompt , passwd2 ); trial -- ; if ( passwd == passwd2 ) { break ; } } if ( trial > 0 ) { Serial . println ( \"Logged in! You can change user!\" ); addUser (); } else { Serial . println ( \"LOCKED!\" ); while ( true ){} } } void setup () { Serial . begin ( 115200 ); while ( ! Serial ) {} // open namespace NS_ACCOUNT with readOnly = false preferences . begin ( NS_ACCOUNT , false ); user = preferences . getString ( KEY_USER ); if ( user == \"\" ) { Serial . println ( \"No user found!\" ); addUser (); } else { askPassword (); } } void loop () { delay ( 1000 ); } Output console of a login example","title":"Preferences (Saved Data)"},{"location":"blog/arduino/esp32/introduction/#references","text":"Arduino Language Reference ESP32 Arduino Core\u2019s documentation Random Nerd Tutorials - ESP32","title":"References"},{"location":"blog/book/v-model/","tags":["book","management"],"text":"The V-Model # The V-model is a type of Software Development Life Cycle (SDLC) model where process executes sequentially in V-shape. It is also known as Verification and Validation model , based on the association of a testing phase for each corresponding development stage. The V-Model Verification It involves static analysis technique (review) done without executing code . This is the process of evaluation of the product development phase to find whether specified requirements meet. Validation It involves dynamic analysis technique (functional, non-functional), testing done by executing code . Validation is the process to evaluate the software after the completion of the development phase to determine whether software meets the customer expectations and requirements. Stages # Each Development stage will have a Verification stage and a Validation stage. Requirements Analysis Requirements of the System are collected by analyzing the needs of the users, through interviews, questionares, document analysis. This step\u2019s output is User Requirements Document . User Requirements document will typically describe the system\u2019s functional , interface , performance , data , security as expected by users; used by Business Analysts to communicate their understanding of the system to the users. Verification is done by the users who will review UR documents carefully and confirm the Requirements. User Acceptance Testing Validation User Acceptance Test (UAT) Plans are composed by business users, performed in a user environment that resembles the production environment, using realistic data. UAT verifies that delivered system meets user\u2019s requirement and system is ready for use in real time. System design Software Requirement Specification document System engineers analyze and understand the business of the proposed system by studying the User Requirements document. They figure out possibilities and techniques by which the user requirements can be implemented. It plans out how the system components will be and how they will interact with each other to run the entire system. This document contains the general system organization, windows, menu, entity diagrams, and some example business scenarios to help understanding about the system. Verification System engineers and Business Analysts work togerther on UR and SRS. If any of the requirements are not feasible, the user is informed of the issue. A resolution is found and the User Requirement document is edited accordingly. System testing Validation System Test Plans are composed by client\u2019s business team, to ensure that expectations from application developed are met, including functional and non-functional requirements. Load and performance testing, stress testing, regression testing are some type of system testing. Architecture design High-level Design document System design is broken down further into modules taking up different functionalities. The data transfer and communication between the internal modules and with the outside world (other systems) is clearly understood. Verification System Architec and senior developer in team will review the documents to find out any problem, such as error in estimation, missing corner-cases, exception handler, mis-matched interface. Integration Testing Validation Integration Test Plans verify that units created and tested independently can coexist and communicate among themselves. Test results are shared with customer\u2019s team. Module Design Low-level Design document The designed system is broken up into smaller units or modules and each of them is explained so that the programmer can start coding directly. It contains detailed functional logic, interface, or pseudocode, such as database table; API input, output and step of algorithms. Verification Document is reviewed by developer before implementation to make sure the argorithms is kept simple and easy to debug. This step can help to optimize the design. Component testing Validation Module Test Plans is excecuted by developers or by an automated system that checks the functional requirements of the module, including the input, outputs. Coding An actual implementation of a code. Verification Code Review is held in team to check the implementation. That activity helps to correcty mis-leading function, or any potential problem. Developers must folow rules of conding convention, and design pattents. Unit testing Validation Unit Test Plans is excecuted by developers or by an automated system that only checks the function of the smallest and independent blocks, such as a function. Application # V- Model application is almost the same as the waterfall model, as both the models are of sequential type. Requirements have to be very clear before the project starts , because it is usually expensive to go back and make changes. The most suitable scenarios: Requirements are well-defined, clearly documented and fixed Product definition is stable Technology is not dynamic and is well understood by the project team The project is short Advantages # Simple and easy to use : The model has defined stages with expected input, output, and action. Time save : Design and testing plan can be done together in early stage Proactive defect tracking : Verification can help to find potential issues in early stages Disadvantages # Very rigid and least flexible : A next step starts when the previous step is verified. Any change in a top stage may lead to changes in lower stages and whole process can be affected No prototype guidance : No initial prototypes of the software are produced. If a prototype","title":"The V-Model in Software Development"},{"location":"blog/book/v-model/#the-v-model","text":"The V-model is a type of Software Development Life Cycle (SDLC) model where process executes sequentially in V-shape. It is also known as Verification and Validation model , based on the association of a testing phase for each corresponding development stage. The V-Model Verification It involves static analysis technique (review) done without executing code . This is the process of evaluation of the product development phase to find whether specified requirements meet. Validation It involves dynamic analysis technique (functional, non-functional), testing done by executing code . Validation is the process to evaluate the software after the completion of the development phase to determine whether software meets the customer expectations and requirements.","title":"The V-Model"},{"location":"blog/book/v-model/#stages","text":"Each Development stage will have a Verification stage and a Validation stage. Requirements Analysis Requirements of the System are collected by analyzing the needs of the users, through interviews, questionares, document analysis. This step\u2019s output is User Requirements Document . User Requirements document will typically describe the system\u2019s functional , interface , performance , data , security as expected by users; used by Business Analysts to communicate their understanding of the system to the users. Verification is done by the users who will review UR documents carefully and confirm the Requirements. User Acceptance Testing Validation User Acceptance Test (UAT) Plans are composed by business users, performed in a user environment that resembles the production environment, using realistic data. UAT verifies that delivered system meets user\u2019s requirement and system is ready for use in real time. System design Software Requirement Specification document System engineers analyze and understand the business of the proposed system by studying the User Requirements document. They figure out possibilities and techniques by which the user requirements can be implemented. It plans out how the system components will be and how they will interact with each other to run the entire system. This document contains the general system organization, windows, menu, entity diagrams, and some example business scenarios to help understanding about the system. Verification System engineers and Business Analysts work togerther on UR and SRS. If any of the requirements are not feasible, the user is informed of the issue. A resolution is found and the User Requirement document is edited accordingly. System testing Validation System Test Plans are composed by client\u2019s business team, to ensure that expectations from application developed are met, including functional and non-functional requirements. Load and performance testing, stress testing, regression testing are some type of system testing. Architecture design High-level Design document System design is broken down further into modules taking up different functionalities. The data transfer and communication between the internal modules and with the outside world (other systems) is clearly understood. Verification System Architec and senior developer in team will review the documents to find out any problem, such as error in estimation, missing corner-cases, exception handler, mis-matched interface. Integration Testing Validation Integration Test Plans verify that units created and tested independently can coexist and communicate among themselves. Test results are shared with customer\u2019s team. Module Design Low-level Design document The designed system is broken up into smaller units or modules and each of them is explained so that the programmer can start coding directly. It contains detailed functional logic, interface, or pseudocode, such as database table; API input, output and step of algorithms. Verification Document is reviewed by developer before implementation to make sure the argorithms is kept simple and easy to debug. This step can help to optimize the design. Component testing Validation Module Test Plans is excecuted by developers or by an automated system that checks the functional requirements of the module, including the input, outputs. Coding An actual implementation of a code. Verification Code Review is held in team to check the implementation. That activity helps to correcty mis-leading function, or any potential problem. Developers must folow rules of conding convention, and design pattents. Unit testing Validation Unit Test Plans is excecuted by developers or by an automated system that only checks the function of the smallest and independent blocks, such as a function.","title":"Stages"},{"location":"blog/book/v-model/#application","text":"V- Model application is almost the same as the waterfall model, as both the models are of sequential type. Requirements have to be very clear before the project starts , because it is usually expensive to go back and make changes. The most suitable scenarios: Requirements are well-defined, clearly documented and fixed Product definition is stable Technology is not dynamic and is well understood by the project team The project is short","title":"Application"},{"location":"blog/book/v-model/#advantages","text":"Simple and easy to use : The model has defined stages with expected input, output, and action. Time save : Design and testing plan can be done together in early stage Proactive defect tracking : Verification can help to find potential issues in early stages","title":"Advantages"},{"location":"blog/book/v-model/#disadvantages","text":"Very rigid and least flexible : A next step starts when the previous step is verified. Any change in a top stage may lead to changes in lower stages and whole process can be affected No prototype guidance : No initial prototypes of the software are produced. If a prototype","title":"Disadvantages"},{"location":"blog/c-cpp/","text":"","title":"C/C++ Programming"},{"location":"blog/c-cpp/compilation/","tags":["c/c++"],"text":"Following are the steps that a program goes through until it is translated into an executable form: Preprocessing Compilation Assembly Linking Source code used in this guide : compilation.zip mylib.h // declaration int min ( int a , int b ); mylib.c // implementation int min ( int a , int b ) { return ( a < b ) ? a : b ; } header.h // to look for min() function #include \"mylib.h\" // macros #define SPEED_MAX 10 /* comment */ #define SPEED_INC 1 /* will be removed */ #define SPEED_UP(x) min((x) + SPEED_INC, SPEED_MAX) source.c #include <stdbool.h> #include \"header.h\" #ifndef SPEED_INIT #define SPEED_INIT 0 #endif int spd = SPEED_INIT ; void main () { while ( true ) { spd = SPEED_UP ( spd ); } } Overview of compilation in this example Preprocessing # The following works will be done by the preprocessor: Expand included files Substitute macros Remove disabled code and comments It works on one C++ source file at a time. It also adds some special markers that tell the compiler where each line came from so that it can use those to produce sensible error messages. Some errors can be produced at this stage with clever use of the #if and #error directives. Find include files : gcc -M source.c /usr/include/stdc-predef.h /usr/lib/gcc/x86_64-linux-gnu/7/include/stdbool.h header.h mylib.h stdc-predef.h contains definitions of global environment and primitives types Output of Preprocessor : Content of mylib.h is copied to header.h , after that, the new content of header.h is copied into source.c . The content of stdbool.h is also copied into source.c Macros are expanded to the final definition. Definition defined in the command line will be generated and added to the source code in this step. If you don\u2019t declare SPEED_INIT , the #ifndef directive will be activated, and SPEED_INIT is declared. All comments are removed gcc -E source.c -DSPEED_INIT = 5 # 1 \"source.c\" # 1 \"<built-in>\" # 1 \"<command-line>\" # 1 \"/usr/include/stdc-predef.h\" 1 3 4 # 1 \"<command-line>\" 2 # 1 \"source.c\" # 1 \"/usr/lib/gcc/x86_64-linux-gnu/7/include/stdbool.h\" 1 3 4 # 2 \"source.c\" 2 # 1 \"header.h\" 1 # 1 \"mylib.h\" 1 int min ( int a , int b ); # 3 \"header.h\" 2 # 3 \"source.c\" 2 int spd = 5 ; void main () { while ( # 7 \"source.c\" 3 4 1 # 7 \"source.c\" ) { spd = min (( spd ) + 1 , 10 ); } } To see macros used in the source.c , run with -E -dU option: Defined -DSPEED_INIT=5 gcc -E -dU source.c -DSPEED_INIT = 5 # 3 \"source.c\" 2 int spd = 5 ; #define SPEED_INIT 5 Undefined SPEED_INIT gcc -E -dU source.c # 3 \"source.c\" 2 #undef SPEED_INIT int spd = 0 ; #define SPEED_INIT 0 Compilation # The compilation step is performed on each output of the preprocessor. The compiler parses the pure source code (now without any preprocessor directives) and converts it into assembly code. You will see instructions to declare the object spd , the function main() , and a call to the function min() . Note that there is no implementation of the function min: . gcc -S source.c -DSPEED_INIT = 5 .file \"source.c\" .text .globl spd # symbol spd .data .align 4 .type spd , @ object # is an object .size spd , 4 # size of int = 4 spd: # definiation of spd .long 5 # with init value is 5 .text .globl main # symbol main .type main , @ function # is a function main: # definition of main .LFB0: .cfi_startproc pushq % rbp .cfi_def_cfa_offset 16 .cfi_offset 6 , - 16 movq % rsp , % rbp .cfi_def_cfa_register 6 .L2: movl spd ( % rip ), % eax # load spd to register addl $ 1 , % eax # add 1 to spd in the register movl $ 10 , % esi # load 10 to register movl % eax , % edi # load calculated value of (spd+1) call min@PLT # call to min() movl % eax , spd ( % rip ) # save value back to spd jmp .L2 # loop back to L2 (while(true)) .cfi_endproc .LFE0: .size main , . - main .ident \"GCC: (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\" .section .note.GNU - stack , \"\" , @ progbits Assembly # The assembler creates an object written in machine code using a formatted structure (ELF, COFF, etc.). This object file contains the compiled code (in binary form) of the symbols defined in the input. Symbols in object files are referred to by name. Object files can refer to symbols that are not defined. This is the case when you use a declaration, and don\u2019t provide a definition for it. All symbols and their definitions are listed, but not assigned to any address in the term of memory space. It means object file don\u2019t provide information of where to find a symbol. The produced object files can be put in special archives called static libraries, for easier reusing later on. It\u2019s at this stage that \u201cregular\u201d compiler errors, like syntax errors or failed overload resolution errors, are reported. Compilers usually save all compiled object files after this point. This is very useful because with it you can compile each source code file separately. The advantage this provides is that you don\u2019t need to recompile everything if you only change a single file. Try this command: gcc -c source.c mylib.c -DSPEED_INIT = 5 You can not read the object using normal text editor anymore, as the file content is in binary. We have to use objdump tool. Symbol Table : objdump -t source.o You can see spd object is located at the section data , the main function is at the section text , and the function min is undefined *UND* . All of them are not assigned to any address. source.o: file format elf64 - x86 - 64 SYMBOL TABLE : 0000000000000000 l df * ABS * 0000000000000000 source.c 0000000000000000 l d .text 0000000000000000 .text 0000000000000000 l d .data 0000000000000000 .data 0000000000000000 l d .bss 0000000000000000 .bss 0000000000000000 g O .data 0000000000000004 spd 0000000000000000 g F .text 0000000000000021 main 0000000000000000 * UND * 0000000000000000 _GLOBAL_OFFSET_TABLE_ 0000000000000000 * UND * 0000000000000000 min Disassembly : objdump -D source.o The instruction source.o: file format elf64 - x86 - 64 Disassembly of section .text : 0000000000000000 < main > : 0: 55 push % rbp 1: 48 89 e5 mov % rsp , % rbp 4: 8 b 05 00 00 00 00 mov 0x0 ( % rip ), % eax # load spd a: 83 c0 01 add $ 0x1 , % eax # add 1 to spd d: be 0 a 00 00 00 mov $ 0xa , % esi # load 10 12: 89 c7 mov % eax , % edi # load (spd+1) 14: e8 00 00 00 00 callq 19 < main + 0x19 > # call to min() 19: 89 05 00 00 00 00 mov % eax , 0x0 ( % rip ) # save to spd 1 f: eb e3 jmp 4 < main + 0x4 > # loop back Disassembly of section .data : 0000000000000000 < spd > : 0: 05 .byte 0x5 # spd = 5 1: 00 00 add % al ,( % rax ) Linking # The linker is what produces the final compilation output from the object files the compiler produced. This output can be either a shared (or dynamic) library (and while the name is similar, they haven\u2019t got much in common with static libraries mentioned earlier) or an executable. It links all the object files by replacing the references to undefined symbols with the correct addresses. Each of these symbols can be defined in other object files or in libraries. If they are defined in libraries other than the standard library, you need to tell the linker about them. At this stage the most common errors are missing definitions or duplicate definitions. The former means that either the definitions don\u2019t exist (i.e. they are not written), or that the object files or libraries where they reside were not given to the linker. The latter is obvious: the same symbol was defined in two different object files or libraries. Run this command: gcc source.o mylib.o -DSPEED_INIT = 5 The output binary file can be inspected using objdump also. Symbol Table : objdump -t a.out You will see the addresses are assigned to spd object, main , min functions: a.out: file format elf64 - x86 - 64 SYMBOL TABLE : ... 0000000000000000 l df * ABS * 0000000000000000 source.c 0000000000000000 l df * ABS * 0000000000000000 mylib.c 0000000000000000 l df * ABS * 0000000000000000 crtstuff.c 0000000000201010 g O .data 0000000000000004 spd 000000000000061 b g F .text 0000000000000016 min 00000000000005 fa g F .text 0000000000000021 main ... Disassembly : objdump -D source.o All functions, object have assigned addresses, therefore, the function call to min() is also completed by using the min() function\u2019s address. 00000000000005 fa < main > : 5 fa: 55 push % rbp 5 fb: 48 89 e5 mov % rsp , % rbp 5 fe: 8 b 05 0 c 0 a 20 00 mov 0x200a0c ( % rip ), % eax # load spd 604: 83 c0 01 add $ 0x1 , % eax # add 1 to spd 607: be 0 a 00 00 00 mov $ 0xa , % esi # load 10 60 c: 89 c7 mov % eax , % edi # load (spd+1) 60 e: e8 08 00 00 00 callq 61 b < min > # call min(): ok 613: 89 05 f7 09 20 00 mov % eax , 0x2009f7 ( % rip ) # save to spd 619: eb e3 jmp 5 fe < main + 0x4 > # loop back 000000000000061 b < min > : 61 b: 55 push % rbp 61 c: 48 89 e5 mov % rsp , % rbp 61 f: 89 7 d fc mov % edi , - 0x4 ( % rbp ) # pop spd 622: 89 75 f8 mov % esi , - 0x8 ( % rbp ) # pod 10 625: 8 b 45 fc mov - 0x4 ( % rbp ), % eax # load spd 628: 39 45 f8 cmp % eax , - 0x8 ( % rbp ) # compare spd vs 10 62 b: 0 f 4 e 45 f8 cmovle - 0x8 ( % rbp ), % eax # if less, use 10 62 f: 5 d pop % rbp 630: c3 retq 631: 66 2 e 0 f 1 f 84 00 00 nopw % cs : 0x0 ( % rax , % rax , 1 ) 638: 00 00 00 63 b: 0 f 1 f 44 00 00 nopl 0x0 ( % rax , % rax , 1 ) 0000000000201010 < spd > : 201010: 05 .byte 0x5 201011: 00 00 add % al ,( % rax ) Exercise # Above guide show a case of static linking, from mylib.o to source.o . How about the dynamic linking case? Consider to use below simple program, how does compiler link the printf() function? main.c #include <stdio.h> int main () { printf ( \"Hello Workd! \\n \" ); return 0 ; } Further reading # The output executable file is written in Executable and Linkable Format (ELF) format which is a common standard file format for executable files, object code, shared libraries, and core dumps. By design, the ELF format is flexible, extensible, and cross-platform. For instance, it supports different endiannesses and address sizes, so it does not exclude any particular central processing unit (CPU) or instruction set architecture. This has allowed it to be adopted by many operating systems on different hardware platforms. Use objectdump to inspect an executable file, and compare to the ELF format.","title":"Compilation Process"},{"location":"blog/c-cpp/compilation/#preprocessing","text":"The following works will be done by the preprocessor: Expand included files Substitute macros Remove disabled code and comments It works on one C++ source file at a time. It also adds some special markers that tell the compiler where each line came from so that it can use those to produce sensible error messages. Some errors can be produced at this stage with clever use of the #if and #error directives. Find include files : gcc -M source.c /usr/include/stdc-predef.h /usr/lib/gcc/x86_64-linux-gnu/7/include/stdbool.h header.h mylib.h stdc-predef.h contains definitions of global environment and primitives types Output of Preprocessor : Content of mylib.h is copied to header.h , after that, the new content of header.h is copied into source.c . The content of stdbool.h is also copied into source.c Macros are expanded to the final definition. Definition defined in the command line will be generated and added to the source code in this step. If you don\u2019t declare SPEED_INIT , the #ifndef directive will be activated, and SPEED_INIT is declared. All comments are removed gcc -E source.c -DSPEED_INIT = 5 # 1 \"source.c\" # 1 \"<built-in>\" # 1 \"<command-line>\" # 1 \"/usr/include/stdc-predef.h\" 1 3 4 # 1 \"<command-line>\" 2 # 1 \"source.c\" # 1 \"/usr/lib/gcc/x86_64-linux-gnu/7/include/stdbool.h\" 1 3 4 # 2 \"source.c\" 2 # 1 \"header.h\" 1 # 1 \"mylib.h\" 1 int min ( int a , int b ); # 3 \"header.h\" 2 # 3 \"source.c\" 2 int spd = 5 ; void main () { while ( # 7 \"source.c\" 3 4 1 # 7 \"source.c\" ) { spd = min (( spd ) + 1 , 10 ); } } To see macros used in the source.c , run with -E -dU option: Defined -DSPEED_INIT=5 gcc -E -dU source.c -DSPEED_INIT = 5 # 3 \"source.c\" 2 int spd = 5 ; #define SPEED_INIT 5 Undefined SPEED_INIT gcc -E -dU source.c # 3 \"source.c\" 2 #undef SPEED_INIT int spd = 0 ; #define SPEED_INIT 0","title":"Preprocessing"},{"location":"blog/c-cpp/compilation/#compilation","text":"The compilation step is performed on each output of the preprocessor. The compiler parses the pure source code (now without any preprocessor directives) and converts it into assembly code. You will see instructions to declare the object spd , the function main() , and a call to the function min() . Note that there is no implementation of the function min: . gcc -S source.c -DSPEED_INIT = 5 .file \"source.c\" .text .globl spd # symbol spd .data .align 4 .type spd , @ object # is an object .size spd , 4 # size of int = 4 spd: # definiation of spd .long 5 # with init value is 5 .text .globl main # symbol main .type main , @ function # is a function main: # definition of main .LFB0: .cfi_startproc pushq % rbp .cfi_def_cfa_offset 16 .cfi_offset 6 , - 16 movq % rsp , % rbp .cfi_def_cfa_register 6 .L2: movl spd ( % rip ), % eax # load spd to register addl $ 1 , % eax # add 1 to spd in the register movl $ 10 , % esi # load 10 to register movl % eax , % edi # load calculated value of (spd+1) call min@PLT # call to min() movl % eax , spd ( % rip ) # save value back to spd jmp .L2 # loop back to L2 (while(true)) .cfi_endproc .LFE0: .size main , . - main .ident \"GCC: (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\" .section .note.GNU - stack , \"\" , @ progbits","title":"Compilation"},{"location":"blog/c-cpp/compilation/#assembly","text":"The assembler creates an object written in machine code using a formatted structure (ELF, COFF, etc.). This object file contains the compiled code (in binary form) of the symbols defined in the input. Symbols in object files are referred to by name. Object files can refer to symbols that are not defined. This is the case when you use a declaration, and don\u2019t provide a definition for it. All symbols and their definitions are listed, but not assigned to any address in the term of memory space. It means object file don\u2019t provide information of where to find a symbol. The produced object files can be put in special archives called static libraries, for easier reusing later on. It\u2019s at this stage that \u201cregular\u201d compiler errors, like syntax errors or failed overload resolution errors, are reported. Compilers usually save all compiled object files after this point. This is very useful because with it you can compile each source code file separately. The advantage this provides is that you don\u2019t need to recompile everything if you only change a single file. Try this command: gcc -c source.c mylib.c -DSPEED_INIT = 5 You can not read the object using normal text editor anymore, as the file content is in binary. We have to use objdump tool. Symbol Table : objdump -t source.o You can see spd object is located at the section data , the main function is at the section text , and the function min is undefined *UND* . All of them are not assigned to any address. source.o: file format elf64 - x86 - 64 SYMBOL TABLE : 0000000000000000 l df * ABS * 0000000000000000 source.c 0000000000000000 l d .text 0000000000000000 .text 0000000000000000 l d .data 0000000000000000 .data 0000000000000000 l d .bss 0000000000000000 .bss 0000000000000000 g O .data 0000000000000004 spd 0000000000000000 g F .text 0000000000000021 main 0000000000000000 * UND * 0000000000000000 _GLOBAL_OFFSET_TABLE_ 0000000000000000 * UND * 0000000000000000 min Disassembly : objdump -D source.o The instruction source.o: file format elf64 - x86 - 64 Disassembly of section .text : 0000000000000000 < main > : 0: 55 push % rbp 1: 48 89 e5 mov % rsp , % rbp 4: 8 b 05 00 00 00 00 mov 0x0 ( % rip ), % eax # load spd a: 83 c0 01 add $ 0x1 , % eax # add 1 to spd d: be 0 a 00 00 00 mov $ 0xa , % esi # load 10 12: 89 c7 mov % eax , % edi # load (spd+1) 14: e8 00 00 00 00 callq 19 < main + 0x19 > # call to min() 19: 89 05 00 00 00 00 mov % eax , 0x0 ( % rip ) # save to spd 1 f: eb e3 jmp 4 < main + 0x4 > # loop back Disassembly of section .data : 0000000000000000 < spd > : 0: 05 .byte 0x5 # spd = 5 1: 00 00 add % al ,( % rax )","title":"Assembly"},{"location":"blog/c-cpp/compilation/#linking","text":"The linker is what produces the final compilation output from the object files the compiler produced. This output can be either a shared (or dynamic) library (and while the name is similar, they haven\u2019t got much in common with static libraries mentioned earlier) or an executable. It links all the object files by replacing the references to undefined symbols with the correct addresses. Each of these symbols can be defined in other object files or in libraries. If they are defined in libraries other than the standard library, you need to tell the linker about them. At this stage the most common errors are missing definitions or duplicate definitions. The former means that either the definitions don\u2019t exist (i.e. they are not written), or that the object files or libraries where they reside were not given to the linker. The latter is obvious: the same symbol was defined in two different object files or libraries. Run this command: gcc source.o mylib.o -DSPEED_INIT = 5 The output binary file can be inspected using objdump also. Symbol Table : objdump -t a.out You will see the addresses are assigned to spd object, main , min functions: a.out: file format elf64 - x86 - 64 SYMBOL TABLE : ... 0000000000000000 l df * ABS * 0000000000000000 source.c 0000000000000000 l df * ABS * 0000000000000000 mylib.c 0000000000000000 l df * ABS * 0000000000000000 crtstuff.c 0000000000201010 g O .data 0000000000000004 spd 000000000000061 b g F .text 0000000000000016 min 00000000000005 fa g F .text 0000000000000021 main ... Disassembly : objdump -D source.o All functions, object have assigned addresses, therefore, the function call to min() is also completed by using the min() function\u2019s address. 00000000000005 fa < main > : 5 fa: 55 push % rbp 5 fb: 48 89 e5 mov % rsp , % rbp 5 fe: 8 b 05 0 c 0 a 20 00 mov 0x200a0c ( % rip ), % eax # load spd 604: 83 c0 01 add $ 0x1 , % eax # add 1 to spd 607: be 0 a 00 00 00 mov $ 0xa , % esi # load 10 60 c: 89 c7 mov % eax , % edi # load (spd+1) 60 e: e8 08 00 00 00 callq 61 b < min > # call min(): ok 613: 89 05 f7 09 20 00 mov % eax , 0x2009f7 ( % rip ) # save to spd 619: eb e3 jmp 5 fe < main + 0x4 > # loop back 000000000000061 b < min > : 61 b: 55 push % rbp 61 c: 48 89 e5 mov % rsp , % rbp 61 f: 89 7 d fc mov % edi , - 0x4 ( % rbp ) # pop spd 622: 89 75 f8 mov % esi , - 0x8 ( % rbp ) # pod 10 625: 8 b 45 fc mov - 0x4 ( % rbp ), % eax # load spd 628: 39 45 f8 cmp % eax , - 0x8 ( % rbp ) # compare spd vs 10 62 b: 0 f 4 e 45 f8 cmovle - 0x8 ( % rbp ), % eax # if less, use 10 62 f: 5 d pop % rbp 630: c3 retq 631: 66 2 e 0 f 1 f 84 00 00 nopw % cs : 0x0 ( % rax , % rax , 1 ) 638: 00 00 00 63 b: 0 f 1 f 44 00 00 nopl 0x0 ( % rax , % rax , 1 ) 0000000000201010 < spd > : 201010: 05 .byte 0x5 201011: 00 00 add % al ,( % rax )","title":"Linking"},{"location":"blog/c-cpp/compilation/#exercise","text":"Above guide show a case of static linking, from mylib.o to source.o . How about the dynamic linking case? Consider to use below simple program, how does compiler link the printf() function? main.c #include <stdio.h> int main () { printf ( \"Hello Workd! \\n \" ); return 0 ; }","title":"Exercise"},{"location":"blog/c-cpp/compilation/#further-reading","text":"The output executable file is written in Executable and Linkable Format (ELF) format which is a common standard file format for executable files, object code, shared libraries, and core dumps. By design, the ELF format is flexible, extensible, and cross-platform. For instance, it supports different endiannesses and address sizes, so it does not exclude any particular central processing unit (CPU) or instruction set architecture. This has allowed it to be adopted by many operating systems on different hardware platforms. Use objectdump to inspect an executable file, and compare to the ELF format.","title":"Further reading"},{"location":"blog/c-cpp/cross-compilation/","tags":["c/c++"],"text":"Cross-compiler # A cross-compiler is a compiler capable of creating executable code for a platform other than the one on which the compiler is running. For example, a compiler that runs on a PC but generates code that runs on an Android smartphone is a cross-compiler. A cross-compiler is necessary to compile code for multiple platforms from one development host. Direct compilation on the target platform might be infeasible, for example on embedded systems with limited computing resources. Why use cross-compiler? Speed - Target platforms are usually much slower than hosts, by an order of magnitude or more. Most special-purpose embedded hardware is designed for low cost and low power consumption, not high performance. Modern emulators (like qemu ) are actually faster than a lot of the real world hardware they emulate, by virtue of running on high-powered desktop hardware. Capability - Compiling is very resource-intensive. The target platform usually doesn\u2019t have gigabytes of memory and hundreds of gigabytes of disk space the way a desktop does; it may not even have the resources to build \u201chello world\u201d, let alone large and complicated packages. Availability - Bringing Linux up on a hardware platform it has never run on before requires a cross-compiler. Even on long-established platforms like ARM or MIPS, finding an up-to-date full-featured prebuilt native environment for a given target can be hard. However, you can easily set up a host machine to build a new package for your target machine. Flexibility - A fully capable Linux distribution consists of hundreds of packages, but most packages are not used on the target machine. Providing a big system with full-loaded packages clearly is not a good idea on the target system with limited resource. Cross-compilation helps developer to deploy only necessary packages with a small customized system. Convenience - The user interface of headless boxes tends to be a bit cramped. On a powerful host machine, you can easily edit, test, and do more work. How it works # Let talk about a case: Host machine: PC running on x64 Intel hardware (laptop/ desktop) Target machine: Embedded device running on ARM X64 hardware (smartphone/ Raspberry Pi) We have to do 2 big steps: Build a cross-compiler from a native-compiler Cross-compile program for target machine Cross compilation The diagram on the right represents a sample program, a.out , running on the target OS, built using the cross-compiler and linked with the target system\u2019s standard C and C++ libraries. The standard C++ library makes calls to the standard C library, and the C library makes direct system calls to the AArch64 Linux kernel. BinUtils BinUtils are a collection of binary tools. In Compilation process , you see that you only invoke gcc with different options. However, gcc is just a driving program which call other programs in a defined order with corresponding inputs, options and outputs. Let run the example in the Compilation process page, but with -v option to see what are actually run behind the scenes. gcc -v source.c mylib.c You will find some interesting that gcc invoked, detailed comparison in below section. Configuration for default settings Compiler call: /usr/lib/gcc/x86_64-linux-gnu/7/cc1 Assembler call: /usr/bin/as Linker call: /usr/lib/gcc/x86_64-linux-gnu/7/collect2 When you build a cross-compiler, you actually build a compiler and a set of binary utility tools. That is the reason, when you install a prebuilt cross-compiler, you will see the package manager will also install binutils , and lib cross-compiled for the target. For example: sudo apt install gcc-aarch64-linux-gnu binutils-aarch64-linux-gnu 2.30-21ubuntu1~18.04.7 2.8MiB cpp-7-aarch64-linux-gnu 7.5.0-3ubuntu1~18.04cross1 5.5MiB cpp-aarch64-linux-gnu 4:7.4.0-1ubuntu2.3 3.5KiB gcc-7-aarch64-linux-gnu 7.5.0-3ubuntu1~18.04cross1 6.2MiB gcc-7-aarch64-linux-gnu-base 7.5.0-3ubuntu1~18.04cross1 19KiB gcc-7-cross-base 7.5.0-3ubuntu1~18.04cross1 13KiB gcc-8-cross-base 8.4.0-1ubuntu1~18.04cross2 14KiB gcc-aarch64-linux-gnu 4:7.4.0-1ubuntu2.3 1.4KiB libc6-arm64-cross 2.27-3ubuntu1cross1.1 1.1MiB libc6-dev-arm64-cross 2.27-3ubuntu1cross1.1 2.0MiB libgcc1-arm64-cross 1:8.4.0-1ubuntu1~18.04cross2 34KiB libgcc-7-dev-arm64-cross 7.5.0-3ubuntu1~18.04cross1 815KiB libgomp1-arm64-cross 8.4.0-1ubuntu1~18.04cross2 67KiB libitm1-arm64-cross 8.4.0-1ubuntu1~18.04cross2 24KiB libstdc++6-arm64-cross 8.4.0-1ubuntu1~18.04cross2 328KiB linux-libc-dev-arm64-cross 4.15.0-35.38cross1.1 840KiB Example # In this example, we will install a pre-compiled ARM64 cross-compiler. Install the target cross-compiler sudo apt install \\ build-essential \\ gcc-aarch64-linux-gnu \\ Hello from machine cross-compilation.zip This simple program will show the machine type it is running on. hello.c #include <sys/utsname.h> #include <stdio.h> int main () { struct utsname name ; uname ( & name ); printf ( \"Hello from %s \\n \" , name . machine ); return 0 ; } Compile using native compiler gcc hello.c -o hello_native This command builds a program for current host machine, run it, and you should see current host machine type is x86_64 : ./hello_native Hello from x86_64 Compile using ARM64 compiler aarch64-linux-gnu-gcc hello.c -o hello_arm when you run it, it can not execute: ./hello_arm -bash: ./hello_arm: cannot execute binary file: Exec format error Check the differences with native compiler Cross-Compilation: aarch64-linux-gnu-gcc -v hello.c Target: aarch64-linux-gnu Configuration: --host=x86_64-linux-gnu --target=aarch64-linux-gnu --includedir=/usr/aarch64-linux-gnu/include Options: -mlittle-endian -mabi=lp64 Compiler: /usr/lib/gcc-cross/aarch64-linux-gnu/7/cc1 Assembler: /usr/aarch64-linux-gnu/bin/as Linker: /usr/lib/gcc-cross/aarch64-linux-gnu/7/collect2 Native compilation: gcc -v hello.c Target: x86_64-linux-gnu Configuration: --host=x86_64-linux-gnu --target=x86_64-linux-gnu Options: -mtune=generic -march=x86-64 Compiler: /usr/lib/gcc/x86_64-linux-gnu/7/cc1 Assembler: /usr/bin/as Linker: /usr/lib/gcc/x86_64-linux-gnu/7/collect2 Run ARM64 Binary with QEMU You can run hello_cross on ARM64 machine. However, for testing, you can run an ARM64 emulator on qemu . Install qemu-user package which provides qemu-aarch64 emulator: sudo apt install \\ qemu-user \\ Then you can run hello_arm by providing the dynamic libraries of ARM64 machine using -L <dir> option: qemu-aarch64 -L /usr/aarch64-linux-gnu/ ./hello_arm Hello from aarch64 That\u2019s it! You have cross-compiled hello.c using aarch64-linux-gnu-gcc cross-compiler from a host x86_64 PC machine to run on a target aarch64 ARM machine. Static Libraries If you want to run hello_arm directly without sending it to qemu-aarch64 , you can do below steps: Install qemu-user-static package Build hello_arm with -static flag Run directly ./hello_arm","title":"Cross-Compilation"},{"location":"blog/c-cpp/cross-compilation/#cross-compiler","text":"A cross-compiler is a compiler capable of creating executable code for a platform other than the one on which the compiler is running. For example, a compiler that runs on a PC but generates code that runs on an Android smartphone is a cross-compiler. A cross-compiler is necessary to compile code for multiple platforms from one development host. Direct compilation on the target platform might be infeasible, for example on embedded systems with limited computing resources. Why use cross-compiler? Speed - Target platforms are usually much slower than hosts, by an order of magnitude or more. Most special-purpose embedded hardware is designed for low cost and low power consumption, not high performance. Modern emulators (like qemu ) are actually faster than a lot of the real world hardware they emulate, by virtue of running on high-powered desktop hardware. Capability - Compiling is very resource-intensive. The target platform usually doesn\u2019t have gigabytes of memory and hundreds of gigabytes of disk space the way a desktop does; it may not even have the resources to build \u201chello world\u201d, let alone large and complicated packages. Availability - Bringing Linux up on a hardware platform it has never run on before requires a cross-compiler. Even on long-established platforms like ARM or MIPS, finding an up-to-date full-featured prebuilt native environment for a given target can be hard. However, you can easily set up a host machine to build a new package for your target machine. Flexibility - A fully capable Linux distribution consists of hundreds of packages, but most packages are not used on the target machine. Providing a big system with full-loaded packages clearly is not a good idea on the target system with limited resource. Cross-compilation helps developer to deploy only necessary packages with a small customized system. Convenience - The user interface of headless boxes tends to be a bit cramped. On a powerful host machine, you can easily edit, test, and do more work.","title":"Cross-compiler"},{"location":"blog/c-cpp/cross-compilation/#how-it-works","text":"Let talk about a case: Host machine: PC running on x64 Intel hardware (laptop/ desktop) Target machine: Embedded device running on ARM X64 hardware (smartphone/ Raspberry Pi) We have to do 2 big steps: Build a cross-compiler from a native-compiler Cross-compile program for target machine Cross compilation The diagram on the right represents a sample program, a.out , running on the target OS, built using the cross-compiler and linked with the target system\u2019s standard C and C++ libraries. The standard C++ library makes calls to the standard C library, and the C library makes direct system calls to the AArch64 Linux kernel. BinUtils BinUtils are a collection of binary tools. In Compilation process , you see that you only invoke gcc with different options. However, gcc is just a driving program which call other programs in a defined order with corresponding inputs, options and outputs. Let run the example in the Compilation process page, but with -v option to see what are actually run behind the scenes. gcc -v source.c mylib.c You will find some interesting that gcc invoked, detailed comparison in below section. Configuration for default settings Compiler call: /usr/lib/gcc/x86_64-linux-gnu/7/cc1 Assembler call: /usr/bin/as Linker call: /usr/lib/gcc/x86_64-linux-gnu/7/collect2 When you build a cross-compiler, you actually build a compiler and a set of binary utility tools. That is the reason, when you install a prebuilt cross-compiler, you will see the package manager will also install binutils , and lib cross-compiled for the target. For example: sudo apt install gcc-aarch64-linux-gnu binutils-aarch64-linux-gnu 2.30-21ubuntu1~18.04.7 2.8MiB cpp-7-aarch64-linux-gnu 7.5.0-3ubuntu1~18.04cross1 5.5MiB cpp-aarch64-linux-gnu 4:7.4.0-1ubuntu2.3 3.5KiB gcc-7-aarch64-linux-gnu 7.5.0-3ubuntu1~18.04cross1 6.2MiB gcc-7-aarch64-linux-gnu-base 7.5.0-3ubuntu1~18.04cross1 19KiB gcc-7-cross-base 7.5.0-3ubuntu1~18.04cross1 13KiB gcc-8-cross-base 8.4.0-1ubuntu1~18.04cross2 14KiB gcc-aarch64-linux-gnu 4:7.4.0-1ubuntu2.3 1.4KiB libc6-arm64-cross 2.27-3ubuntu1cross1.1 1.1MiB libc6-dev-arm64-cross 2.27-3ubuntu1cross1.1 2.0MiB libgcc1-arm64-cross 1:8.4.0-1ubuntu1~18.04cross2 34KiB libgcc-7-dev-arm64-cross 7.5.0-3ubuntu1~18.04cross1 815KiB libgomp1-arm64-cross 8.4.0-1ubuntu1~18.04cross2 67KiB libitm1-arm64-cross 8.4.0-1ubuntu1~18.04cross2 24KiB libstdc++6-arm64-cross 8.4.0-1ubuntu1~18.04cross2 328KiB linux-libc-dev-arm64-cross 4.15.0-35.38cross1.1 840KiB","title":"How it works"},{"location":"blog/c-cpp/cross-compilation/#example","text":"In this example, we will install a pre-compiled ARM64 cross-compiler. Install the target cross-compiler sudo apt install \\ build-essential \\ gcc-aarch64-linux-gnu \\ Hello from machine cross-compilation.zip This simple program will show the machine type it is running on. hello.c #include <sys/utsname.h> #include <stdio.h> int main () { struct utsname name ; uname ( & name ); printf ( \"Hello from %s \\n \" , name . machine ); return 0 ; } Compile using native compiler gcc hello.c -o hello_native This command builds a program for current host machine, run it, and you should see current host machine type is x86_64 : ./hello_native Hello from x86_64 Compile using ARM64 compiler aarch64-linux-gnu-gcc hello.c -o hello_arm when you run it, it can not execute: ./hello_arm -bash: ./hello_arm: cannot execute binary file: Exec format error Check the differences with native compiler Cross-Compilation: aarch64-linux-gnu-gcc -v hello.c Target: aarch64-linux-gnu Configuration: --host=x86_64-linux-gnu --target=aarch64-linux-gnu --includedir=/usr/aarch64-linux-gnu/include Options: -mlittle-endian -mabi=lp64 Compiler: /usr/lib/gcc-cross/aarch64-linux-gnu/7/cc1 Assembler: /usr/aarch64-linux-gnu/bin/as Linker: /usr/lib/gcc-cross/aarch64-linux-gnu/7/collect2 Native compilation: gcc -v hello.c Target: x86_64-linux-gnu Configuration: --host=x86_64-linux-gnu --target=x86_64-linux-gnu Options: -mtune=generic -march=x86-64 Compiler: /usr/lib/gcc/x86_64-linux-gnu/7/cc1 Assembler: /usr/bin/as Linker: /usr/lib/gcc/x86_64-linux-gnu/7/collect2 Run ARM64 Binary with QEMU You can run hello_cross on ARM64 machine. However, for testing, you can run an ARM64 emulator on qemu . Install qemu-user package which provides qemu-aarch64 emulator: sudo apt install \\ qemu-user \\ Then you can run hello_arm by providing the dynamic libraries of ARM64 machine using -L <dir> option: qemu-aarch64 -L /usr/aarch64-linux-gnu/ ./hello_arm Hello from aarch64 That\u2019s it! You have cross-compiled hello.c using aarch64-linux-gnu-gcc cross-compiler from a host x86_64 PC machine to run on a target aarch64 ARM machine. Static Libraries If you want to run hello_arm directly without sending it to qemu-aarch64 , you can do below steps: Install qemu-user-static package Build hello_arm with -static flag Run directly ./hello_arm","title":"Example"},{"location":"blog/c-cpp/library-linking/","tags":["c/c++"],"text":".row.bordered.compact p:not(:first-child) { margin: 0; } Library Naming Conventions A library known as foo is expected to exist as the file libfoo.so or libfoo.a . When linking against the library, the library can be specified only by its name foo with the -l option as -lfoo When creating the library, the full file name libfoo.so or libfoo.a must be specified Static and Dynamic linking # Developers have a choice of using static or dynamic linking when building applications with fully compiled languages. In general, static linking makes libraries part of the resulting executable file, but dynamic linking keeps these libraries as separate files. Dynamic and static linking can be compared in a number of ways: Resource use Static linking results in larger executable files which contain more code. This additional code coming from libraries cannot be shared across multiple programs on the system, increasing file system usage and memory usage at run time. Multiple processes running the same statically linked program will still share the code. On the other hand, static applications need fewer run-time relocations, leading to reduced startup time, and require less private resident set size (RSS) memory. Generated code for static linking can be more efficient than for dynamic linking due to the overhead introduced by position-independent code (PIC). Security : Dynamically linked libraries which provide ABI compatibility can be updated without changing the executable files depending on these libraries. This is especially important for libraries provided by Red Hat as part of Red Hat Enterprise Linux, where Red Hat provides security updates. Static linking against any such libraries is strongly discouraged. Additionally, security measures such as load address randomization cannot be used with a statically linked executable file. This further reduces security of the resulting application. Compatibility Static linking appears to provide executable files independent of the versions of libraries provided by the operating system. However, most libraries depend on other libraries. With static linking, this dependency becomes inflexible and as a result, both forward and backward compatibility is lost. Static linking is guaranteed to work only on the system where the executable file was built. Example source code # build-lib.zip We are creating a new library name foo in the lib folder: . \u251c\u2500\u2500 app.c \u2514\u2500\u2500 lib \u251c\u2500\u2500 foo.c \u2514\u2500\u2500 foo.h foo.h void setFoo ( int v ); int getFoo (); foo.c #include <stdio.h> #include \"foo.h\" int __foo ; void __attribute__ (( constructor )) constructorFoo (); void __attribute__ (( destructor )) destructorFoo (); void constructorFoo () { printf ( \"Foo is Loaded! \\n \" ); } void destructorFoo () { printf ( \"Foo is Unloaded! \\n \" ); } void setFoo ( int f ) { __foo = f ; } int getFoo () { return __foo ; } app.c #include <stdio.h> #include <foo.h> int main () { printf ( \"Init foo = %d \\n \" , getFoo ()); setFoo ( 5 ); printf ( \"New foo = %d \\n \" , getFoo ()); return 0 ; } Create Static Library # Build a static library in the lib/static : mkdir -p lib/static gcc -c lib/foo.c -o lib/static/libfoo.o ar rcs lib/static/libfoo.a lib/static/libfoo.o Static Lib compilation Local linking Compile: gcc app.c -Ilib -Llib/static -lfoo -o app_static_local Run: ./app_static_local Global linking Install: sudo install -m 755 \\ lib/foo.h \\ /usr/include sudo install -m 755 \\ lib/static/libfoo.a \\ /usr/lib/ Compile: gcc app.c -lfoo -o app_static Run: ./app_static Remove library: sudo rm /usr/lib/libfoo.a sudo rm /usr/include/foo.h sudo rm -rf lib/static Create Dynamic Library # Build a dynamic library in the lib/dynamic : mkdir -p lib/dynamic gcc -c -fPIC lib/foo.c -o lib/dynamic/libfoo.o gcc -shared lib/dynamic/libfoo.o -o lib/dynamic/libfoo.so Dynamic library Linking Local linking Compile: gcc app.c -Ilib -Llib/dynamic -lfoo -o app_dynamic_local Run: LD_LIBRARY_PATH = lib/dynamic ./app_dynamic_local Global linking Install: sudo install -m 755 \\ lib/foo.h \\ /usr/include sudo install -m 755 \\ lib/dynamic/libfoo.so \\ /usr/lib/ Compile: gcc app.c -lfoo -o app_dynamic Run: ./app_dynamic Remove library: sudo rm /usr/lib/libfoo.so sudo rm /usr/include/foo.h sudo rm -rf lib/dynamic Symbol tables Use nm to list all symbols in an object file. Here we compare the symbols in app_static and app_dynamic to see how symbols are declared: Static linked app: 0000000000201010 B __bss_start 0000000000201010 b completed.7698 0000000000000709 T constructorFoo w __cxa_finalize@@GLIBC_2.2.5 0000000000201000 D __data_start 0000000000201000 W data_start 00000000000005 e0 t deregister_tm_clones 000000000000071 c T destructorFoo 0000000000000670 t __do_global_dtors_aux 0000000000200 db 0 t __do_global_dtors_aux_fini_array_entry 0000000000201008 D __dso_handle 0000000000200 dc0 d _DYNAMIC 0000000000201010 D _edata 0000000000201018 B _end 00000000000007 c4 T _fini 0000000000201014 B __foo 00000000000006 b0 t frame_dummy 0000000000200 da0 t __frame_dummy_init_array_entry 00000000000009 f4 r __FRAME_END__ 0000000000000742 T getFoo 0000000000200 fb0 d _GLOBAL_OFFSET_TABLE_ w __gmon_start__ 0000000000000814 r __GNU_EH_FRAME_HDR 0000000000000558 T _init 0000000000200 db 0 t __init_array_end 0000000000200 da0 t __init_array_start 00000000000007 d0 R _IO_stdin_used w _ITM_deregisterTMCloneTable w _ITM_registerTMCloneTable 00000000000007 c0 T __libc_csu_fini 0000000000000750 T __libc_csu_init U __libc_start_main@@GLIBC_2.2.5 00000000000006 ba T main U printf@@GLIBC_2.2.5 U puts@@GLIBC_2.2.5 0000000000000620 t register_tm_clones 000000000000072 f T setFoo 00000000000005 b0 T _start 0000000000201010 D __TMC_END__ Dynamic linked app: 0000000000201010 B __bss_start 0000000000201010 b completed.7698 w __cxa_finalize@@GLIBC_2.2.5 0000000000201000 D __data_start 0000000000201000 W data_start 00000000000006 c0 t deregister_tm_clones 0000000000000750 t __do_global_dtors_aux 0000000000200 da0 t __do_global_dtors_aux_fini_array_entry 0000000000201008 D __dso_handle 0000000000200 da8 d _DYNAMIC 0000000000201010 D _edata 0000000000201018 B _end 0000000000000864 T _fini 0000000000000790 t frame_dummy 0000000000200 d98 t __frame_dummy_init_array_entry 00000000000009 d4 r __FRAME_END__ U getFoo 0000000000200 fa8 d _GLOBAL_OFFSET_TABLE_ w __gmon_start__ 0000000000000894 r __GNU_EH_FRAME_HDR 0000000000000628 T _init 0000000000200 da0 t __init_array_end 0000000000200 d98 t __init_array_start 0000000000000870 R _IO_stdin_used w _ITM_deregisterTMCloneTable w _ITM_registerTMCloneTable 0000000000000860 T __libc_csu_fini 00000000000007 f0 T __libc_csu_init U __libc_start_main@@GLIBC_2.2.5 000000000000079 a T main U printf@@GLIBC_2.2.5 0000000000000700 t register_tm_clones U setFoo 0000000000000690 T _start 0000000000201010 D __TMC_END__ Load library at Runtime # It\u2019s also possible to dynamically load a library from an executable. The necessary functions are dlopen() , dlsym() etc. whose definitions are found in dlfcn.h . app_load_lib.c #include <stdio.h> #include <stdlib.h> #include <dlfcn.h> // do not include foo.h, just know the declaration int main () { void * ptr ; // declare function pointers // according to the target function calls void ( * fptr_set )( int ); // void setFoo(int f); int ( * fptr_get )(); // int getFoo(); // Open the target dynamic lib void * foolib = dlopen ( \"libfoo.so\" , RTLD_LAZY | RTLD_GLOBAL ); if ( ! foolib ) { printf ( \"ERROR! Can not open libfoo.so \\n \" ); exit ( 1 ); } // Get function pointers ptr = dlsym ( foolib , \"setFoo\" ); if ( ! ptr ) { printf ( \"ERROR! Can not find function setFoo \\n \" ); exit ( 1 ); } fptr_set = ( void ( * )( int )) ptr ; ptr = dlsym ( foolib , \"getFoo\" ); if ( ! ptr ) { printf ( \"ERROR! Can not find function getFoo \\n \" ); exit ( 1 ); } fptr_get = ( int ( * )()) ptr ; // Call function via function pointers printf ( \"Init foo = %d \\n \" , fptr_get ()); fptr_set ( 5 ); printf ( \"New foo = %d \\n \" , fptr_get ()); return 0 ; } Compile: gcc app_load_lib.c -ldl -o app_load_lib Run if libfoo.so is not install to system: LD_LIBRARY_PATH = lib/dynamic ./app_load_lib Dynamic Linking Debug # The ldconfig command checks the header and file names of the libraries it encounters when determining which versions should have their links updated. This command also creates a file called /etc/ld.so.cache which is used to speed up linking. sudo ldconfig -v ... /lib/x86_64-linux-gnu: libc.so.6 -> libc-2.27.so /usr/lib: libfoo.so -> libfoo.so ... Use LD_DEBUG=<option> to enable debugging log for dynamic linking. LD_DEBUG = help ./app_dynamic Valid options for the LD_DEBUG environment variable are: libs display library search paths reloc display relocation processing files display progress for input file symbols display symbol table processing bindings display information about symbol binding versions display version dependencies scopes display scope information all all previous options combined statistics display relocation statistics unused determined unused DSOs help display this help message and exit To direct the debugging output into a file instead of standard output a filename can be specified using the LD_DEBUG_OUTPUT environment variable. Example : search paths and loaded libraries: LD_DEBUG = libs ./app_dynamic 3824: find library=libfoo.so [0]; searching 3824: search cache=/etc/ld.so.cache 3824: search path=<system search paths> 3824: trying file=/usr/lib/libfoo.so 3824: calling init: /usr/lib/libfoo.so 3824: initialize program: ./app_dynamic 3824: transferring control: ./app_dynamic 3824: calling fini: ./app_dynamic [0] 3824: calling fini: /usr/lib/libfoo.so [0] Callback in a Library # Symbols of an executable are not exported by default. When you want to export a callback symbol which is defined in main application and will be used in library, you have to explicitly use the option -Wl,-export-dynamic (or -rdynamic ) when compiling it. Example : bar.h void run (); Library bar calls to callback function which is not implemented in library: bar.c #include <stdio.h> // compilable, but not runnable extern void callback (); void run () { printf ( \"Run from BAR! \\n \" ); callback (); } In the main app, the function callback is implemented: app.c #include <stdio.h> #include \"bar.h\" // definition void callback () { printf ( \"Callback in APP! \\n \" ); } void main () { run (); } We build a dynamic libbar.so library, can compile the main app with -rdynamic to export callback symbol: gcc lib/bar.c -fpic -shared -o lib/libbar.so gcc app.c -Ilib -Llib -lbar -rdynamic -o app Try to run the main app, with LD_DEBUG=symbols option to show how symbols are looked up: LD_LIBRARY_PATH = . LD_DEBUG = symbols ./app 4685: calling init: ./libbar.so 4685: initialize program: ./app 4685: transferring control: ./app Run from BAR! 4685: symbol=callback; lookup in file=./app [0] Callback in APP! 4685: calling fini: ./app [0] 4685: calling fini: ./libbar.so [0] Exercise # Do you really know how a dynamic library is loaded into a program? Describe the steps in that order Linker loads a dynamic library! Can we create a global shared variable between applications which load the same library?","title":"Library Linking"},{"location":"blog/c-cpp/library-linking/#static-and-dynamic-linking","text":"Developers have a choice of using static or dynamic linking when building applications with fully compiled languages. In general, static linking makes libraries part of the resulting executable file, but dynamic linking keeps these libraries as separate files. Dynamic and static linking can be compared in a number of ways: Resource use Static linking results in larger executable files which contain more code. This additional code coming from libraries cannot be shared across multiple programs on the system, increasing file system usage and memory usage at run time. Multiple processes running the same statically linked program will still share the code. On the other hand, static applications need fewer run-time relocations, leading to reduced startup time, and require less private resident set size (RSS) memory. Generated code for static linking can be more efficient than for dynamic linking due to the overhead introduced by position-independent code (PIC). Security : Dynamically linked libraries which provide ABI compatibility can be updated without changing the executable files depending on these libraries. This is especially important for libraries provided by Red Hat as part of Red Hat Enterprise Linux, where Red Hat provides security updates. Static linking against any such libraries is strongly discouraged. Additionally, security measures such as load address randomization cannot be used with a statically linked executable file. This further reduces security of the resulting application. Compatibility Static linking appears to provide executable files independent of the versions of libraries provided by the operating system. However, most libraries depend on other libraries. With static linking, this dependency becomes inflexible and as a result, both forward and backward compatibility is lost. Static linking is guaranteed to work only on the system where the executable file was built.","title":"Static and Dynamic linking"},{"location":"blog/c-cpp/library-linking/#example-source-code","text":"build-lib.zip We are creating a new library name foo in the lib folder: . \u251c\u2500\u2500 app.c \u2514\u2500\u2500 lib \u251c\u2500\u2500 foo.c \u2514\u2500\u2500 foo.h foo.h void setFoo ( int v ); int getFoo (); foo.c #include <stdio.h> #include \"foo.h\" int __foo ; void __attribute__ (( constructor )) constructorFoo (); void __attribute__ (( destructor )) destructorFoo (); void constructorFoo () { printf ( \"Foo is Loaded! \\n \" ); } void destructorFoo () { printf ( \"Foo is Unloaded! \\n \" ); } void setFoo ( int f ) { __foo = f ; } int getFoo () { return __foo ; } app.c #include <stdio.h> #include <foo.h> int main () { printf ( \"Init foo = %d \\n \" , getFoo ()); setFoo ( 5 ); printf ( \"New foo = %d \\n \" , getFoo ()); return 0 ; }","title":"Example source code"},{"location":"blog/c-cpp/library-linking/#create-static-library","text":"Build a static library in the lib/static : mkdir -p lib/static gcc -c lib/foo.c -o lib/static/libfoo.o ar rcs lib/static/libfoo.a lib/static/libfoo.o Static Lib compilation Local linking Compile: gcc app.c -Ilib -Llib/static -lfoo -o app_static_local Run: ./app_static_local Global linking Install: sudo install -m 755 \\ lib/foo.h \\ /usr/include sudo install -m 755 \\ lib/static/libfoo.a \\ /usr/lib/ Compile: gcc app.c -lfoo -o app_static Run: ./app_static Remove library: sudo rm /usr/lib/libfoo.a sudo rm /usr/include/foo.h sudo rm -rf lib/static","title":"Create Static Library"},{"location":"blog/c-cpp/library-linking/#create-dynamic-library","text":"Build a dynamic library in the lib/dynamic : mkdir -p lib/dynamic gcc -c -fPIC lib/foo.c -o lib/dynamic/libfoo.o gcc -shared lib/dynamic/libfoo.o -o lib/dynamic/libfoo.so Dynamic library Linking Local linking Compile: gcc app.c -Ilib -Llib/dynamic -lfoo -o app_dynamic_local Run: LD_LIBRARY_PATH = lib/dynamic ./app_dynamic_local Global linking Install: sudo install -m 755 \\ lib/foo.h \\ /usr/include sudo install -m 755 \\ lib/dynamic/libfoo.so \\ /usr/lib/ Compile: gcc app.c -lfoo -o app_dynamic Run: ./app_dynamic Remove library: sudo rm /usr/lib/libfoo.so sudo rm /usr/include/foo.h sudo rm -rf lib/dynamic Symbol tables Use nm to list all symbols in an object file. Here we compare the symbols in app_static and app_dynamic to see how symbols are declared: Static linked app: 0000000000201010 B __bss_start 0000000000201010 b completed.7698 0000000000000709 T constructorFoo w __cxa_finalize@@GLIBC_2.2.5 0000000000201000 D __data_start 0000000000201000 W data_start 00000000000005 e0 t deregister_tm_clones 000000000000071 c T destructorFoo 0000000000000670 t __do_global_dtors_aux 0000000000200 db 0 t __do_global_dtors_aux_fini_array_entry 0000000000201008 D __dso_handle 0000000000200 dc0 d _DYNAMIC 0000000000201010 D _edata 0000000000201018 B _end 00000000000007 c4 T _fini 0000000000201014 B __foo 00000000000006 b0 t frame_dummy 0000000000200 da0 t __frame_dummy_init_array_entry 00000000000009 f4 r __FRAME_END__ 0000000000000742 T getFoo 0000000000200 fb0 d _GLOBAL_OFFSET_TABLE_ w __gmon_start__ 0000000000000814 r __GNU_EH_FRAME_HDR 0000000000000558 T _init 0000000000200 db 0 t __init_array_end 0000000000200 da0 t __init_array_start 00000000000007 d0 R _IO_stdin_used w _ITM_deregisterTMCloneTable w _ITM_registerTMCloneTable 00000000000007 c0 T __libc_csu_fini 0000000000000750 T __libc_csu_init U __libc_start_main@@GLIBC_2.2.5 00000000000006 ba T main U printf@@GLIBC_2.2.5 U puts@@GLIBC_2.2.5 0000000000000620 t register_tm_clones 000000000000072 f T setFoo 00000000000005 b0 T _start 0000000000201010 D __TMC_END__ Dynamic linked app: 0000000000201010 B __bss_start 0000000000201010 b completed.7698 w __cxa_finalize@@GLIBC_2.2.5 0000000000201000 D __data_start 0000000000201000 W data_start 00000000000006 c0 t deregister_tm_clones 0000000000000750 t __do_global_dtors_aux 0000000000200 da0 t __do_global_dtors_aux_fini_array_entry 0000000000201008 D __dso_handle 0000000000200 da8 d _DYNAMIC 0000000000201010 D _edata 0000000000201018 B _end 0000000000000864 T _fini 0000000000000790 t frame_dummy 0000000000200 d98 t __frame_dummy_init_array_entry 00000000000009 d4 r __FRAME_END__ U getFoo 0000000000200 fa8 d _GLOBAL_OFFSET_TABLE_ w __gmon_start__ 0000000000000894 r __GNU_EH_FRAME_HDR 0000000000000628 T _init 0000000000200 da0 t __init_array_end 0000000000200 d98 t __init_array_start 0000000000000870 R _IO_stdin_used w _ITM_deregisterTMCloneTable w _ITM_registerTMCloneTable 0000000000000860 T __libc_csu_fini 00000000000007 f0 T __libc_csu_init U __libc_start_main@@GLIBC_2.2.5 000000000000079 a T main U printf@@GLIBC_2.2.5 0000000000000700 t register_tm_clones U setFoo 0000000000000690 T _start 0000000000201010 D __TMC_END__","title":"Create Dynamic Library"},{"location":"blog/c-cpp/library-linking/#load-library-at-runtime","text":"It\u2019s also possible to dynamically load a library from an executable. The necessary functions are dlopen() , dlsym() etc. whose definitions are found in dlfcn.h . app_load_lib.c #include <stdio.h> #include <stdlib.h> #include <dlfcn.h> // do not include foo.h, just know the declaration int main () { void * ptr ; // declare function pointers // according to the target function calls void ( * fptr_set )( int ); // void setFoo(int f); int ( * fptr_get )(); // int getFoo(); // Open the target dynamic lib void * foolib = dlopen ( \"libfoo.so\" , RTLD_LAZY | RTLD_GLOBAL ); if ( ! foolib ) { printf ( \"ERROR! Can not open libfoo.so \\n \" ); exit ( 1 ); } // Get function pointers ptr = dlsym ( foolib , \"setFoo\" ); if ( ! ptr ) { printf ( \"ERROR! Can not find function setFoo \\n \" ); exit ( 1 ); } fptr_set = ( void ( * )( int )) ptr ; ptr = dlsym ( foolib , \"getFoo\" ); if ( ! ptr ) { printf ( \"ERROR! Can not find function getFoo \\n \" ); exit ( 1 ); } fptr_get = ( int ( * )()) ptr ; // Call function via function pointers printf ( \"Init foo = %d \\n \" , fptr_get ()); fptr_set ( 5 ); printf ( \"New foo = %d \\n \" , fptr_get ()); return 0 ; } Compile: gcc app_load_lib.c -ldl -o app_load_lib Run if libfoo.so is not install to system: LD_LIBRARY_PATH = lib/dynamic ./app_load_lib","title":"Load library at Runtime"},{"location":"blog/c-cpp/library-linking/#dynamic-linking-debug","text":"The ldconfig command checks the header and file names of the libraries it encounters when determining which versions should have their links updated. This command also creates a file called /etc/ld.so.cache which is used to speed up linking. sudo ldconfig -v ... /lib/x86_64-linux-gnu: libc.so.6 -> libc-2.27.so /usr/lib: libfoo.so -> libfoo.so ... Use LD_DEBUG=<option> to enable debugging log for dynamic linking. LD_DEBUG = help ./app_dynamic Valid options for the LD_DEBUG environment variable are: libs display library search paths reloc display relocation processing files display progress for input file symbols display symbol table processing bindings display information about symbol binding versions display version dependencies scopes display scope information all all previous options combined statistics display relocation statistics unused determined unused DSOs help display this help message and exit To direct the debugging output into a file instead of standard output a filename can be specified using the LD_DEBUG_OUTPUT environment variable. Example : search paths and loaded libraries: LD_DEBUG = libs ./app_dynamic 3824: find library=libfoo.so [0]; searching 3824: search cache=/etc/ld.so.cache 3824: search path=<system search paths> 3824: trying file=/usr/lib/libfoo.so 3824: calling init: /usr/lib/libfoo.so 3824: initialize program: ./app_dynamic 3824: transferring control: ./app_dynamic 3824: calling fini: ./app_dynamic [0] 3824: calling fini: /usr/lib/libfoo.so [0]","title":"Dynamic Linking Debug"},{"location":"blog/c-cpp/library-linking/#callback-in-a-library","text":"Symbols of an executable are not exported by default. When you want to export a callback symbol which is defined in main application and will be used in library, you have to explicitly use the option -Wl,-export-dynamic (or -rdynamic ) when compiling it. Example : bar.h void run (); Library bar calls to callback function which is not implemented in library: bar.c #include <stdio.h> // compilable, but not runnable extern void callback (); void run () { printf ( \"Run from BAR! \\n \" ); callback (); } In the main app, the function callback is implemented: app.c #include <stdio.h> #include \"bar.h\" // definition void callback () { printf ( \"Callback in APP! \\n \" ); } void main () { run (); } We build a dynamic libbar.so library, can compile the main app with -rdynamic to export callback symbol: gcc lib/bar.c -fpic -shared -o lib/libbar.so gcc app.c -Ilib -Llib -lbar -rdynamic -o app Try to run the main app, with LD_DEBUG=symbols option to show how symbols are looked up: LD_LIBRARY_PATH = . LD_DEBUG = symbols ./app 4685: calling init: ./libbar.so 4685: initialize program: ./app 4685: transferring control: ./app Run from BAR! 4685: symbol=callback; lookup in file=./app [0] Callback in APP! 4685: calling fini: ./app [0] 4685: calling fini: ./libbar.so [0]","title":"Callback in a Library"},{"location":"blog/c-cpp/library-linking/#exercise","text":"Do you really know how a dynamic library is loaded into a program? Describe the steps in that order Linker loads a dynamic library! Can we create a global shared variable between applications which load the same library?","title":"Exercise"},{"location":"blog/c-cpp/notes/","tags":["c/c++","notes"],"text":"Size of a datatype # The size of a type is determined by the compiler, which doesn\u2019t have anything to do with the actual hardware. The returned value of sizeof(char) is always 1 by definition, and sizeof(int) always returns 4. Starting at C99, bool is present as an 1-byte datatype. Note that, size of a pointer should be 4 bytes on any 32-bit C/C++ compiler, and should be 8 bytes on any 64-bit C/C++ compiler. Use int instead of char or uint8_t ? It depends on the target machine: if it is incapable to access unaligned memory (e.g. Cortex-M0 processors), then using int is much faster. Use int32_t or int ? The primitive datatype char short int long may have different size on different platform (old machine, arduino int is 2 bytes). The stdint.h or cstdint headers define int8_t int16_t int32_t which have a defined size on all platforms. Therefore, it is recommeded to use stdint.h in cases: in embedded system which has to know the size of data exactly code is used for multiple platforms Do NOT use sizeof on array argument # The function fun() below receives a parameter arr[] as an array, then it tries to find out the number of elements in that array, using the sizeof operator. In main, there is also a statement calculating the number of elements in the array arr[] . But 2 methods return different results. int fun ( int arr []) { return sizeof ( arr ) / sizeof ( arr [ 0 ]); // WRONG } void main () { int arr [ 4 ] = { 0 , 0 , 0 , 0 }; int arr_size = sizeof ( arr ) / sizeof ( arr [ 0 ]); // RIGHT if ( arr_size == fun ( arr )) {} // ??? } In C, array parameters are treated as pointers. So the expression: sizeof ( arr ) / sizeof ( arr [ 0 ]) becomes sizeof ( int * ) / sizeof ( int ) Note that sizeof(int *) is the size of a pointer, which can be 4 or 8 depending on the target compiler (32-bit or 64-bit). This leads to a wrong result. Compare with a float number # Below code will run in an infinite loop. Why? #include <iostream> int main () { int i = 0 ; for ( float x = 100000001.0f ; x <= 100000010.0f ; x += 1.0f ) { i ++ ; std :: cout << i << std :: endl ; } return 0 ; } C/C++ compilers use IEEE 754 to represent float and double numbers. Float number is single precision! It means float has precision at 7 degree. The value 100000001.0f has the most accurate representation is 100000000.0 The value 100000010.0f has the most accurate representation is 100000008.0 To fix the loop, use double x . Comparison numbers # When comparing, compiler implicitly cast the type of number: different size: from smaller type to a bigger type same size: from singed to unsigned #include <stdio.h> #include <stdint.h> int main () { uint32_t x = 100 ; int32_t y = -1 ; // y is converted to unin32_t: // y = UINT_MAX if ( x > y ){ printf ( \"OK. Good.\" ); } else { printf ( \"WTF ???\" ); } return 0 ; } #include <stdio.h> #include <stdint.h> int main () { uint32_t x = 100 ; int64_t y = -1 ; // x is converted to int64_t: // x = 100 if ( x > y ) { printf ( \"OK. Good.\" ); } else { printf ( \"WTF ???\" ); } return 0 ; } When comparing with a literal negative number, compiler will implicitly convert literal number to the type of comparing variable. #include <stdio.h> int main () { unsigned int x = 100 ; // -1 is converted to unsigned int // compiler replace with UINT_MAX if ( x > -1 ) { printf ( \"OK. Good.\" ); } else { printf ( \"WTF ???\" ); } return 0 ; } Accessing a[i] is actually pointer accessing # The expression a[i] is translated to *(a+i) . That\u2019s why this weird code printf ( \"%c\" , 3 [ \"abcdef\" ]); still runs. C/C++ does not check the index range, therefore it is easy to access a memory block which is out of range of the array: int a [] = { 1 , 2 }; int b [] = { 3 , 4 , 5 }; // if a and b are allocated next to each other, b[-1] will be a[1] printf ( \"%d\" , b [ -1 ]); There are Buffer overflow exploiting techniques based on this problem of accessing memory block outsides of the array. Short-circuit evaluation # At runtime, in the expression with AND operator if ( a && b && c ) , the part (b) will be calculated only if (a) is true, and (c) will be calculated only if (a) and (b) are both true. The same story about OR operator: in the expression if ( a || b || c ) , if the sub-expression (a) is true, others will not be computed. This helps in case the next condition depends on the previous condition, such as accessing to pointer: if ( pointer != NULL && pointer -> member == 3 ) {} or, checking for a higher priority condition first: if ( flag_a || flag_b ) {} However, as the consequence, do not expect the 2 nd or later conditions are executed in all cases. Increase performance in if conditions To improve the performance, we can place short and simple condition at the first place to make use of Short-circuit Evaluation. For example: if ( a == 1 && objB . getVal () == 2 ) {} can run faster than : if ( objB . getVal () == 2 && a == 1 ) {} Use lookup table instead of if-else or switch # In long if-else if/ switch statement, the conditions are checked with all values in written order. A lookup table can be used to reduce checking, and in some cases, it is easier to maintain. print(\"Delta\") is executed after 4 comparisions in this case, but it might be more if having a lot of values: if ( a == 0 ) { print ( \"Alpha\" ); } else if ( a == 1 ) { print ( \"Beta\" ); } else if ( a == 2 ) { print ( \"Gamma\" ); } else if ( a == 3 ) { print ( \"Delta\" ); } else { // nothing } print() is executed with only 2 comparisons even having more values: static const char * messages [] = { \"Alpha\" , \"Beta\" , \"Gamma\" , \"Delta\" }; if ( a >= 0 && a < 4 ) { printf ( messages [ a ]); } Know the variable scope # Do not repeat to create and destroy an object in a loop for ( int i = 0 ; i < 10 ; i ++ ) { ClassA a ; a . doSomething (); } ClassA a ; for ( int i = 0 ; i < 10 ; i ++ ) { a . doSomething (); } Only create an object if needed for ( int i = 0 ; i < 10 ; i ++ ) { ClassA a ; if ( i == 5 ) { a . doSomething (); } } for ( int i = 0 ; i < 10 ; i ++ ) { if ( i == 5 ) { ClassA a ; a . doSomething (); } } Initialize value of elements in array and struct # We do know some methods to initialize elements in an array as below: int arr [ 5 ] = { 1 , 1 , 1 , 1 , 1 }; // results [1, 1, 1, 1, 1] int arr [ ] = { 1 , 1 , 1 , 1 , 1 }; // results [1, 1, 1, 1, 1] int arr [ 5 ] = { }; // results [0, 0, 0, 0, 0] int arr [ 5 ] = { 1 }; // results [1, 0, 0, 0, 0] However, GCC also supports Designated Initializers to help to initialize array with elements\u2019 indexes. To specify an array index, write [index] = before the element value. For example: int a [ 6 ] = { [ 4 ] = 29 , [ 2 ] = 15 }; // result [0, 0, 15, 0, 29, 0] The index values must be constant expressions, even if the array being initialized is automatic. Each initializer element that does not have a designator applies to the next consecutive element of the array or structure. For example: int a [ 6 ] = { [ 1 ] = v1 , v2 , [ 4 ] = v4 }; // result [0, v1, v2, 0, v4, 0] To initialize a range of elements to the same value, write [first ... last] = value . This is a GNU extension. For example: int widths [] = { [ 0 ... 9 ] = 1 , [ 10 ... 99 ] = 2 , [ 100 ] = 3 }; You may have seen the designator in C for struct: struct point { int x , y ; }; struct point p = { . y = yvalue , . x = xvalue }; // result p = { xvalue, yvalue }; Labeling the elements of an array initializer is especially useful when the indices are characters or belong to an enum type. For example: int whitespace [ 256 ] = { [ ' ' ] = 1 , [ '\\t' ] = 1 , [ '\\h' ] = 1 , [ '\\f' ] = 1 , [ '\\n' ] = 1 , [ '\\r' ] = 1 }; You can also write a series of .fieldname and [index] designators before an = to specify a nested sub-object to initialize; the list is taken relative to the sub-object corresponding to the closest surrounding brace pair. For example, with the struct point declaration above: struct point ptarray [ 10 ] = { [ 2 ]. y = yv2 , [ 2 ]. x = xv2 , [ 0 ]. x = xv0 }; Pass an object as a parameter # If x is a read-only parameter : If x is big , and can be NULL : use constant pointer : function ( const T * x ); If x is big , and NOT be NULL : use constant reference : function ( const T & x ); Other cases: use constant value : function ( const T x ); If x is a output parameter : If x can be NULL , use pointer : function ( T * x ); If x NOT be NULL , use reference : function ( T & x ); Buffered stdout but non-buffered stderr # The stdout or cout is a buffered output, so a user, usually not aware of this, sees the output by portions. Sometimes, the program outputs something and then crashes, and if buffer did not have time to flush into the console, a user will not see anything. This is sometimes inconvenient. Thus, for dumping more important information, including debugging, it is better to use the unbuffered stderr or cerr . Another way is to set unbuffered mode for stdout by calling setbuf ( stdout , NULL ); . Negative error code # The simplest way to indicate to caller about its children\u2019s success is to return a boolean value: false \u2014 in case of error, and true in case of success. However, to indicate more status than just 2 states, a number can be returned. And it can be extended more to indicate different status of failure or success using signed numbers: /** * func() - A function that does something * input: * none * output: * -2: error on buffer * -1: error on transmission * 0: success but no response * 1: success with a response = NACK * 2: success with a response = ACK */ Bitwise operation # A very popular thing in C, and also in programming generally is working with bits. For flags specifying, in order to not make a typo and mess, they can be defined using bit shifting: #define FLAG1 (1 << 0) #define FLAG2 (1 << 1) #define FLAG3 (1 << 2) #define FLAG4 (1 << 3) #define FLAG5 (1 << 4) and some macros can be used to work on bits: #define IS_SET(flag, bit) (((flag) & (bit)) ? true : false) #define SET_BIT(var, bit) ((var) |= (bit)) #define REMOVE_BIT(var, bit) ((var) &= ~(bit)) Macro overloading # A macro is defined to return another macro, depending on the number of argument: #define GET_FUNC(_1, _2, _3, NAME,...) NAME #define FUNC(...) \\ GET_FUNC(__VA_ARGS__, \\ FUNC3, \\ FUNC2 \\ )(__VA_ARGS__) When we use FUNC(x, y) , it will expand to GET_FUNC(x, y, FUNC3, FUNC2, ...)(x, y) , and finally is replaced to FUNC2(x, y) . When we use FUNC(x, y, z) , it will expand to GET_FUNC(x, y, z, FUNC3, FUNC2, ...)(x, y, z) , and finally is replaced to FUNC3(x, y, z) . If you want to expand to support 4 arguments or so on, use: #define GET_FUNC(_1, _2, _3, _4, NAME,...) NAME #define FUNC(...) \\ GET_FUNC(__VA_ARGS__, \\ FUNC4, \\ FUNC3, \\ FUNC2 \\ )(__VA_ARGS__) Use goto if it can reduce the complexity # Using goto is considered as bad and harmful, but if it is used with care, it can be helpful to reduce the complexity. For example: void func (...) { byte * buf1 = malloc (...); byte * buf2 = malloc (...); FILE * f = fopen (...); if ( f == NULL ) goto func_cleanup_and_exit ; ... if ( something_goes_wrong_1 ) goto func_close_file_cleanup_and_exit ; ... func_close_file_cleanup_and_exit : fclose ( f ); func_cleanup_and_exit : free ( buf1 ); free ( buf2 ); func_exit : return ; }; Compiler warnings # Is it worth to turn on -Wall to see all possible problems which usually are small error and hard to get noticed. In GCC, it is also possible to turn all warnings to errors with -Werror . If enabled, any problem marked as error will halt the compiler, and it must be fixed. Example 1 : int f1 ( int a , int b , int c ) { int ret = a + b + c ; printf ( \"%d\" , ret ); } int main () { printf ( \"%d\" , f1 ( 1 , 2 , 3 )); } The main() function still runs but prints out wrong value due to non-returned function. A random value will be seen because compiler still use the return register which is not set the desired value. Example 2 : bool f1 () { return condition ? true : false ; } bool is 1-byte datatype Compiler will generate a code to set the low byte of the AL register to 0x01 or 0x00 , because the return size of 1 byte. Other higher bytes of the AL register won\u2019t change. However, in a different file, f1() is assumed to return int , not bool , therefore compiler generates code to compare 4 bytes of an int which is only updated its lowest byte after f1() returns. There maybe some random value in higher bytes of that int memory block, and it will cause a wrong comparison: void main () { if ( f1 ()) } Cached data # Modern CPUs have L1, L2, and L3 caches. When fetching data from memory, it usually read a whole line of L1 cache. For example, L1 cache has 64-bytes lines, it will fetch 64 bytes from memory at once when it accesses to a memory. So if a data structure is larger than 64 bytes, it is very important to divide it by 2 parts: the most demanded fields and the less demanded ones. It is desirable to place the most demanded fields in the first 64 bytes. C++ classes are also concerned.","title":"Notes for C and C++ Programming"},{"location":"blog/c-cpp/notes/#size-of-a-datatype","text":"The size of a type is determined by the compiler, which doesn\u2019t have anything to do with the actual hardware. The returned value of sizeof(char) is always 1 by definition, and sizeof(int) always returns 4. Starting at C99, bool is present as an 1-byte datatype. Note that, size of a pointer should be 4 bytes on any 32-bit C/C++ compiler, and should be 8 bytes on any 64-bit C/C++ compiler. Use int instead of char or uint8_t ? It depends on the target machine: if it is incapable to access unaligned memory (e.g. Cortex-M0 processors), then using int is much faster. Use int32_t or int ? The primitive datatype char short int long may have different size on different platform (old machine, arduino int is 2 bytes). The stdint.h or cstdint headers define int8_t int16_t int32_t which have a defined size on all platforms. Therefore, it is recommeded to use stdint.h in cases: in embedded system which has to know the size of data exactly code is used for multiple platforms","title":"Size of a datatype"},{"location":"blog/c-cpp/notes/#do-not-use-sizeof-on-array-argument","text":"The function fun() below receives a parameter arr[] as an array, then it tries to find out the number of elements in that array, using the sizeof operator. In main, there is also a statement calculating the number of elements in the array arr[] . But 2 methods return different results. int fun ( int arr []) { return sizeof ( arr ) / sizeof ( arr [ 0 ]); // WRONG } void main () { int arr [ 4 ] = { 0 , 0 , 0 , 0 }; int arr_size = sizeof ( arr ) / sizeof ( arr [ 0 ]); // RIGHT if ( arr_size == fun ( arr )) {} // ??? } In C, array parameters are treated as pointers. So the expression: sizeof ( arr ) / sizeof ( arr [ 0 ]) becomes sizeof ( int * ) / sizeof ( int ) Note that sizeof(int *) is the size of a pointer, which can be 4 or 8 depending on the target compiler (32-bit or 64-bit). This leads to a wrong result.","title":"Do NOT use sizeof on array argument"},{"location":"blog/c-cpp/notes/#compare-with-a-float-number","text":"Below code will run in an infinite loop. Why? #include <iostream> int main () { int i = 0 ; for ( float x = 100000001.0f ; x <= 100000010.0f ; x += 1.0f ) { i ++ ; std :: cout << i << std :: endl ; } return 0 ; } C/C++ compilers use IEEE 754 to represent float and double numbers. Float number is single precision! It means float has precision at 7 degree. The value 100000001.0f has the most accurate representation is 100000000.0 The value 100000010.0f has the most accurate representation is 100000008.0 To fix the loop, use double x .","title":"Compare with a float number"},{"location":"blog/c-cpp/notes/#comparison-numbers","text":"When comparing, compiler implicitly cast the type of number: different size: from smaller type to a bigger type same size: from singed to unsigned #include <stdio.h> #include <stdint.h> int main () { uint32_t x = 100 ; int32_t y = -1 ; // y is converted to unin32_t: // y = UINT_MAX if ( x > y ){ printf ( \"OK. Good.\" ); } else { printf ( \"WTF ???\" ); } return 0 ; } #include <stdio.h> #include <stdint.h> int main () { uint32_t x = 100 ; int64_t y = -1 ; // x is converted to int64_t: // x = 100 if ( x > y ) { printf ( \"OK. Good.\" ); } else { printf ( \"WTF ???\" ); } return 0 ; } When comparing with a literal negative number, compiler will implicitly convert literal number to the type of comparing variable. #include <stdio.h> int main () { unsigned int x = 100 ; // -1 is converted to unsigned int // compiler replace with UINT_MAX if ( x > -1 ) { printf ( \"OK. Good.\" ); } else { printf ( \"WTF ???\" ); } return 0 ; }","title":"Comparison numbers"},{"location":"blog/c-cpp/notes/#accessing-ai-is-actually-pointer-accessing","text":"The expression a[i] is translated to *(a+i) . That\u2019s why this weird code printf ( \"%c\" , 3 [ \"abcdef\" ]); still runs. C/C++ does not check the index range, therefore it is easy to access a memory block which is out of range of the array: int a [] = { 1 , 2 }; int b [] = { 3 , 4 , 5 }; // if a and b are allocated next to each other, b[-1] will be a[1] printf ( \"%d\" , b [ -1 ]); There are Buffer overflow exploiting techniques based on this problem of accessing memory block outsides of the array.","title":"Accessing a[i] is actually pointer accessing"},{"location":"blog/c-cpp/notes/#short-circuit-evaluation","text":"At runtime, in the expression with AND operator if ( a && b && c ) , the part (b) will be calculated only if (a) is true, and (c) will be calculated only if (a) and (b) are both true. The same story about OR operator: in the expression if ( a || b || c ) , if the sub-expression (a) is true, others will not be computed. This helps in case the next condition depends on the previous condition, such as accessing to pointer: if ( pointer != NULL && pointer -> member == 3 ) {} or, checking for a higher priority condition first: if ( flag_a || flag_b ) {} However, as the consequence, do not expect the 2 nd or later conditions are executed in all cases. Increase performance in if conditions To improve the performance, we can place short and simple condition at the first place to make use of Short-circuit Evaluation. For example: if ( a == 1 && objB . getVal () == 2 ) {} can run faster than : if ( objB . getVal () == 2 && a == 1 ) {}","title":"Short-circuit evaluation"},{"location":"blog/c-cpp/notes/#use-lookup-table-instead-of-if-else-or-switch","text":"In long if-else if/ switch statement, the conditions are checked with all values in written order. A lookup table can be used to reduce checking, and in some cases, it is easier to maintain. print(\"Delta\") is executed after 4 comparisions in this case, but it might be more if having a lot of values: if ( a == 0 ) { print ( \"Alpha\" ); } else if ( a == 1 ) { print ( \"Beta\" ); } else if ( a == 2 ) { print ( \"Gamma\" ); } else if ( a == 3 ) { print ( \"Delta\" ); } else { // nothing } print() is executed with only 2 comparisons even having more values: static const char * messages [] = { \"Alpha\" , \"Beta\" , \"Gamma\" , \"Delta\" }; if ( a >= 0 && a < 4 ) { printf ( messages [ a ]); }","title":"Use lookup table instead of if-else or switch"},{"location":"blog/c-cpp/notes/#know-the-variable-scope","text":"Do not repeat to create and destroy an object in a loop for ( int i = 0 ; i < 10 ; i ++ ) { ClassA a ; a . doSomething (); } ClassA a ; for ( int i = 0 ; i < 10 ; i ++ ) { a . doSomething (); } Only create an object if needed for ( int i = 0 ; i < 10 ; i ++ ) { ClassA a ; if ( i == 5 ) { a . doSomething (); } } for ( int i = 0 ; i < 10 ; i ++ ) { if ( i == 5 ) { ClassA a ; a . doSomething (); } }","title":"Know the variable scope"},{"location":"blog/c-cpp/notes/#initialize-value-of-elements-in-array-and-struct","text":"We do know some methods to initialize elements in an array as below: int arr [ 5 ] = { 1 , 1 , 1 , 1 , 1 }; // results [1, 1, 1, 1, 1] int arr [ ] = { 1 , 1 , 1 , 1 , 1 }; // results [1, 1, 1, 1, 1] int arr [ 5 ] = { }; // results [0, 0, 0, 0, 0] int arr [ 5 ] = { 1 }; // results [1, 0, 0, 0, 0] However, GCC also supports Designated Initializers to help to initialize array with elements\u2019 indexes. To specify an array index, write [index] = before the element value. For example: int a [ 6 ] = { [ 4 ] = 29 , [ 2 ] = 15 }; // result [0, 0, 15, 0, 29, 0] The index values must be constant expressions, even if the array being initialized is automatic. Each initializer element that does not have a designator applies to the next consecutive element of the array or structure. For example: int a [ 6 ] = { [ 1 ] = v1 , v2 , [ 4 ] = v4 }; // result [0, v1, v2, 0, v4, 0] To initialize a range of elements to the same value, write [first ... last] = value . This is a GNU extension. For example: int widths [] = { [ 0 ... 9 ] = 1 , [ 10 ... 99 ] = 2 , [ 100 ] = 3 }; You may have seen the designator in C for struct: struct point { int x , y ; }; struct point p = { . y = yvalue , . x = xvalue }; // result p = { xvalue, yvalue }; Labeling the elements of an array initializer is especially useful when the indices are characters or belong to an enum type. For example: int whitespace [ 256 ] = { [ ' ' ] = 1 , [ '\\t' ] = 1 , [ '\\h' ] = 1 , [ '\\f' ] = 1 , [ '\\n' ] = 1 , [ '\\r' ] = 1 }; You can also write a series of .fieldname and [index] designators before an = to specify a nested sub-object to initialize; the list is taken relative to the sub-object corresponding to the closest surrounding brace pair. For example, with the struct point declaration above: struct point ptarray [ 10 ] = { [ 2 ]. y = yv2 , [ 2 ]. x = xv2 , [ 0 ]. x = xv0 };","title":"Initialize value of elements in array and struct"},{"location":"blog/c-cpp/notes/#pass-an-object-as-a-parameter","text":"If x is a read-only parameter : If x is big , and can be NULL : use constant pointer : function ( const T * x ); If x is big , and NOT be NULL : use constant reference : function ( const T & x ); Other cases: use constant value : function ( const T x ); If x is a output parameter : If x can be NULL , use pointer : function ( T * x ); If x NOT be NULL , use reference : function ( T & x );","title":"Pass an object as a parameter"},{"location":"blog/c-cpp/notes/#buffered-stdout-but-non-buffered-stderr","text":"The stdout or cout is a buffered output, so a user, usually not aware of this, sees the output by portions. Sometimes, the program outputs something and then crashes, and if buffer did not have time to flush into the console, a user will not see anything. This is sometimes inconvenient. Thus, for dumping more important information, including debugging, it is better to use the unbuffered stderr or cerr . Another way is to set unbuffered mode for stdout by calling setbuf ( stdout , NULL ); .","title":"Buffered stdout but non-buffered stderr"},{"location":"blog/c-cpp/notes/#negative-error-code","text":"The simplest way to indicate to caller about its children\u2019s success is to return a boolean value: false \u2014 in case of error, and true in case of success. However, to indicate more status than just 2 states, a number can be returned. And it can be extended more to indicate different status of failure or success using signed numbers: /** * func() - A function that does something * input: * none * output: * -2: error on buffer * -1: error on transmission * 0: success but no response * 1: success with a response = NACK * 2: success with a response = ACK */","title":"Negative error code"},{"location":"blog/c-cpp/notes/#bitwise-operation","text":"A very popular thing in C, and also in programming generally is working with bits. For flags specifying, in order to not make a typo and mess, they can be defined using bit shifting: #define FLAG1 (1 << 0) #define FLAG2 (1 << 1) #define FLAG3 (1 << 2) #define FLAG4 (1 << 3) #define FLAG5 (1 << 4) and some macros can be used to work on bits: #define IS_SET(flag, bit) (((flag) & (bit)) ? true : false) #define SET_BIT(var, bit) ((var) |= (bit)) #define REMOVE_BIT(var, bit) ((var) &= ~(bit))","title":"Bitwise operation"},{"location":"blog/c-cpp/notes/#macro-overloading","text":"A macro is defined to return another macro, depending on the number of argument: #define GET_FUNC(_1, _2, _3, NAME,...) NAME #define FUNC(...) \\ GET_FUNC(__VA_ARGS__, \\ FUNC3, \\ FUNC2 \\ )(__VA_ARGS__) When we use FUNC(x, y) , it will expand to GET_FUNC(x, y, FUNC3, FUNC2, ...)(x, y) , and finally is replaced to FUNC2(x, y) . When we use FUNC(x, y, z) , it will expand to GET_FUNC(x, y, z, FUNC3, FUNC2, ...)(x, y, z) , and finally is replaced to FUNC3(x, y, z) . If you want to expand to support 4 arguments or so on, use: #define GET_FUNC(_1, _2, _3, _4, NAME,...) NAME #define FUNC(...) \\ GET_FUNC(__VA_ARGS__, \\ FUNC4, \\ FUNC3, \\ FUNC2 \\ )(__VA_ARGS__)","title":"Macro overloading"},{"location":"blog/c-cpp/notes/#use-goto-if-it-can-reduce-the-complexity","text":"Using goto is considered as bad and harmful, but if it is used with care, it can be helpful to reduce the complexity. For example: void func (...) { byte * buf1 = malloc (...); byte * buf2 = malloc (...); FILE * f = fopen (...); if ( f == NULL ) goto func_cleanup_and_exit ; ... if ( something_goes_wrong_1 ) goto func_close_file_cleanup_and_exit ; ... func_close_file_cleanup_and_exit : fclose ( f ); func_cleanup_and_exit : free ( buf1 ); free ( buf2 ); func_exit : return ; };","title":"Use goto if it can reduce the complexity"},{"location":"blog/c-cpp/notes/#compiler-warnings","text":"Is it worth to turn on -Wall to see all possible problems which usually are small error and hard to get noticed. In GCC, it is also possible to turn all warnings to errors with -Werror . If enabled, any problem marked as error will halt the compiler, and it must be fixed. Example 1 : int f1 ( int a , int b , int c ) { int ret = a + b + c ; printf ( \"%d\" , ret ); } int main () { printf ( \"%d\" , f1 ( 1 , 2 , 3 )); } The main() function still runs but prints out wrong value due to non-returned function. A random value will be seen because compiler still use the return register which is not set the desired value. Example 2 : bool f1 () { return condition ? true : false ; } bool is 1-byte datatype Compiler will generate a code to set the low byte of the AL register to 0x01 or 0x00 , because the return size of 1 byte. Other higher bytes of the AL register won\u2019t change. However, in a different file, f1() is assumed to return int , not bool , therefore compiler generates code to compare 4 bytes of an int which is only updated its lowest byte after f1() returns. There maybe some random value in higher bytes of that int memory block, and it will cause a wrong comparison: void main () { if ( f1 ()) }","title":"Compiler warnings"},{"location":"blog/c-cpp/notes/#cached-data","text":"Modern CPUs have L1, L2, and L3 caches. When fetching data from memory, it usually read a whole line of L1 cache. For example, L1 cache has 64-bytes lines, it will fetch 64 bytes from memory at once when it accesses to a memory. So if a data structure is larger than 64 bytes, it is very important to divide it by 2 parts: the most demanded fields and the less demanded ones. It is desirable to place the most demanded fields in the first 64 bytes. C++ classes are also concerned.","title":"Cached data"},{"location":"blog/c-cpp/print-struct-using-macro/","tags":["c/c++"],"text":"Problem # Here is a struct in C++: typedef struct Person_t { string name ; unsigned int age ; Person_t ( string _name , unsigned int _age ) { name = _name ; age = _age ; } } Person_t ; To print out its field name and value: cout << \"Person_t person_a\" << endl << \" \" << \"string name = \" << person_a . name << endl << \" \" << \"unsigned int age = \" << person_a . age << endl << endl ; To print another object, juts copy, paste, and replace the object person_a , change the field name, and the text? How to use a shorter form of printing? How to apply on different structure types? Macros # Define STRUCT macro to print out the structure types, name of the instance, and struct fields: #define STRUCT(type, pInstance, ... ) \\ { \\ cout << #type << \" \" \\ << #pInstance \\ << endl; \\ type* pStr = pInstance; \\ __VA_ARGS__ \\ cout << endl; \\ } Each field of struct will be wrapped in the FIELD macro: #define FIELD(type, name) \\ { \\ cout << \" \" \\ << #type << \" \" \\ << #name << \" = \" \\ << pStr->name \\ << endl; \\ } And at this point, we can use macro to print out a struct: int main () { Person_t person_a ( \"Human\" , 100 ); STRUCT ( Person_t , & person_a , FIELD ( string , name ); FIELD ( unsigned int , age ); ); } If we have another struct, the macros still can be used: typedef struct Shape_t { string name ; unsigned int edges ; double area ; Shape_t ( string _name , unsigned int _edges ) { name = _name ; edges = _edges ; } } Shape_t ; int main () { Shape_t shape_a ( \"square\" , 4 ); STRUCT ( Shape_t , & shape_a , FIELD ( string , name ); FIELD ( unsigned int , edges ); FIELD ( double , area ); ); } We still be able to shorten the code, if we define a macro which wraps up all field of a struct: #define FIELDS_PERSON \\ FIELD(string, name); \\ FIELD(unsigned int, age); And then, the printing macro is just as short as below: int main () { Person_t person_a ( \"Human\" , 100 ); STRUCT ( Person_t , & person_a , FIELDS_PERSON ); } Example # Here is an example of printing EEPROM data. EEPROM contains multiple structures, and we need to print out all filed and data in bytes of each structure. First, the STRUCT macro print the name, create a pointer, print out all fields, and check CRC data: #define STRUCT(type, offset, ...) \\ { \\ cout << #offset << \": \" << offset << endl; \\ cout << #type << \": \" << endl; \\ type *pStr = (type*) &pEEPROM[offset]; \\ __VA_ARGS__ \\ if (pStr->crc8 \\ == crc_engine.crc8( \\ (unsigned char *)pStr, sizeof(type) - 1)) \\ cout << \" CRC OK!\"; \\ else \\ cout << \">>> CRC ERROR! <<<\"; \\ cout << endl; \\ cout << endl; \\ } A macro is defined to return another macro, depending on the number of argument: #define GET_FIELD(_1, _2, _3, NAME,...) NAME #define FIELD(...) \\ GET_FIELD(__VA_ARGS__, \\ FIELD_ARRAY, \\ FIELD_SINGLE \\ )(__VA_ARGS__) When we use FIELD(x, y) , it will expand to GET_FIELD(x, y, FIELD_ARRAY, FIELD_SINGLE, ...)(x, y) , and finally is replaced to FIELD_SINGLE(x, y) . When we use FIELD(x, y, z) , it will expand to GET_FIELD(x, y, z, FIELD_ARRAY, FIELD_SINGLE, ...)(x, y, z) , and finally is replaced to FIELD_ARRAY(x, y, z) . Finally, we define the macros to process data defend on field types: #define FIELD_ARRAY(type, array, count) \\ { \\ cout << \" \" << #type << \" \"; \\ cout << #array << \"[\" << dec << count << \"] = \"; \\ unsigned char *pArr = (unsigned char*)&pStr->array; \\ for (int i=0; i<(count*sizeof(type)); i++) \\ cout << hex(pArr[i]) << \" \"; \\ cout << endl; \\ } #define FIELD_SINGLE(type, name) \\ { \\ cout << \" \" << #type << \" \"; \\ cout << #name << \" = \"; \\ unsigned char *pArr = (unsigned char*)&pStr->name; \\ for (int i=0; i<sizeof(type); i++) \\ cout << hex(pArr[i]) << \" \"; \\ cout << endl; \\ } Example of usage : typedef struct NVM_Data_t { unsigned char lastMode [ MAX_LAST_MODE ]; unsigned short id ; unsigned int offTime ; unsigned char exception ; unsigned char reserved [ 1 ]; unsigned char crc8 ; } NVM_Data_t ; volatile unsigned char * pEEPROM ; STRUCT ( Mode_NVMLast_t , NVM_EEP_MODE_OFFSET , FIELD ( unsigned char , lastMode , MAX_LAST_MODE ); FIELD ( unsigned short , id ); FIELD ( unsigned int , offTime ); FIELD ( unsigned char , reserved , 1 ); FIELD ( unsigned char , crc8 ); );","title":"Use Macro to Print a Struct with its field"},{"location":"blog/c-cpp/print-struct-using-macro/#problem","text":"Here is a struct in C++: typedef struct Person_t { string name ; unsigned int age ; Person_t ( string _name , unsigned int _age ) { name = _name ; age = _age ; } } Person_t ; To print out its field name and value: cout << \"Person_t person_a\" << endl << \" \" << \"string name = \" << person_a . name << endl << \" \" << \"unsigned int age = \" << person_a . age << endl << endl ; To print another object, juts copy, paste, and replace the object person_a , change the field name, and the text? How to use a shorter form of printing? How to apply on different structure types?","title":"Problem"},{"location":"blog/c-cpp/print-struct-using-macro/#macros","text":"Define STRUCT macro to print out the structure types, name of the instance, and struct fields: #define STRUCT(type, pInstance, ... ) \\ { \\ cout << #type << \" \" \\ << #pInstance \\ << endl; \\ type* pStr = pInstance; \\ __VA_ARGS__ \\ cout << endl; \\ } Each field of struct will be wrapped in the FIELD macro: #define FIELD(type, name) \\ { \\ cout << \" \" \\ << #type << \" \" \\ << #name << \" = \" \\ << pStr->name \\ << endl; \\ } And at this point, we can use macro to print out a struct: int main () { Person_t person_a ( \"Human\" , 100 ); STRUCT ( Person_t , & person_a , FIELD ( string , name ); FIELD ( unsigned int , age ); ); } If we have another struct, the macros still can be used: typedef struct Shape_t { string name ; unsigned int edges ; double area ; Shape_t ( string _name , unsigned int _edges ) { name = _name ; edges = _edges ; } } Shape_t ; int main () { Shape_t shape_a ( \"square\" , 4 ); STRUCT ( Shape_t , & shape_a , FIELD ( string , name ); FIELD ( unsigned int , edges ); FIELD ( double , area ); ); } We still be able to shorten the code, if we define a macro which wraps up all field of a struct: #define FIELDS_PERSON \\ FIELD(string, name); \\ FIELD(unsigned int, age); And then, the printing macro is just as short as below: int main () { Person_t person_a ( \"Human\" , 100 ); STRUCT ( Person_t , & person_a , FIELDS_PERSON ); }","title":"Macros"},{"location":"blog/c-cpp/print-struct-using-macro/#example","text":"Here is an example of printing EEPROM data. EEPROM contains multiple structures, and we need to print out all filed and data in bytes of each structure. First, the STRUCT macro print the name, create a pointer, print out all fields, and check CRC data: #define STRUCT(type, offset, ...) \\ { \\ cout << #offset << \": \" << offset << endl; \\ cout << #type << \": \" << endl; \\ type *pStr = (type*) &pEEPROM[offset]; \\ __VA_ARGS__ \\ if (pStr->crc8 \\ == crc_engine.crc8( \\ (unsigned char *)pStr, sizeof(type) - 1)) \\ cout << \" CRC OK!\"; \\ else \\ cout << \">>> CRC ERROR! <<<\"; \\ cout << endl; \\ cout << endl; \\ } A macro is defined to return another macro, depending on the number of argument: #define GET_FIELD(_1, _2, _3, NAME,...) NAME #define FIELD(...) \\ GET_FIELD(__VA_ARGS__, \\ FIELD_ARRAY, \\ FIELD_SINGLE \\ )(__VA_ARGS__) When we use FIELD(x, y) , it will expand to GET_FIELD(x, y, FIELD_ARRAY, FIELD_SINGLE, ...)(x, y) , and finally is replaced to FIELD_SINGLE(x, y) . When we use FIELD(x, y, z) , it will expand to GET_FIELD(x, y, z, FIELD_ARRAY, FIELD_SINGLE, ...)(x, y, z) , and finally is replaced to FIELD_ARRAY(x, y, z) . Finally, we define the macros to process data defend on field types: #define FIELD_ARRAY(type, array, count) \\ { \\ cout << \" \" << #type << \" \"; \\ cout << #array << \"[\" << dec << count << \"] = \"; \\ unsigned char *pArr = (unsigned char*)&pStr->array; \\ for (int i=0; i<(count*sizeof(type)); i++) \\ cout << hex(pArr[i]) << \" \"; \\ cout << endl; \\ } #define FIELD_SINGLE(type, name) \\ { \\ cout << \" \" << #type << \" \"; \\ cout << #name << \" = \"; \\ unsigned char *pArr = (unsigned char*)&pStr->name; \\ for (int i=0; i<sizeof(type); i++) \\ cout << hex(pArr[i]) << \" \"; \\ cout << endl; \\ } Example of usage : typedef struct NVM_Data_t { unsigned char lastMode [ MAX_LAST_MODE ]; unsigned short id ; unsigned int offTime ; unsigned char exception ; unsigned char reserved [ 1 ]; unsigned char crc8 ; } NVM_Data_t ; volatile unsigned char * pEEPROM ; STRUCT ( Mode_NVMLast_t , NVM_EEP_MODE_OFFSET , FIELD ( unsigned char , lastMode , MAX_LAST_MODE ); FIELD ( unsigned short , id ); FIELD ( unsigned int , offTime ); FIELD ( unsigned char , reserved , 1 ); FIELD ( unsigned char , crc8 ); );","title":"Example"},{"location":"blog/c-cpp/toolchain/","tags":["c/c++"],"text":"GNU Toolchain # A toolchain is a set of distinct software development tools that are linked (or chained) together by specific stages to perform a complex software development task or to create a software product. A simple software development toolchain may consist of a compiler and linker (which transform the source code into an executable program), libraries (which provide interfaces to the operating system), and a debugger (which is used to test and debug created programs). The GNU toolchain is a broad collection of programming tools produced by the GNU Project. These tools form a toolchain (a suite of tools used in a serial manner) used for developing software applications and operating systems. The GNU toolchain plays a vital role in development of Linux, some BSD systems, and software for embedded systems. Components included in the GNU toolchain are: GNU make : an automation tool for compilation and build GNU Compiler Collection (GCC) : a suite of compilers for several programming languages GNU C Library (glibc) : core C library including headers, libraries, and dynamic loader GNU Binutils : a suite of tools including linker, assembler and other tools GNU Bison : a parser generator, often used with the Flex lexical analyzer GNU m4 : an m4 macro processor GNU Debugger (GDB) : a code debugging tool GNU Autotools (GNU Build System) : Autoconf, Automake and Libtool","title":"Toolchain"},{"location":"blog/c-cpp/toolchain/#gnu-toolchain","text":"A toolchain is a set of distinct software development tools that are linked (or chained) together by specific stages to perform a complex software development task or to create a software product. A simple software development toolchain may consist of a compiler and linker (which transform the source code into an executable program), libraries (which provide interfaces to the operating system), and a debugger (which is used to test and debug created programs). The GNU toolchain is a broad collection of programming tools produced by the GNU Project. These tools form a toolchain (a suite of tools used in a serial manner) used for developing software applications and operating systems. The GNU toolchain plays a vital role in development of Linux, some BSD systems, and software for embedded systems. Components included in the GNU toolchain are: GNU make : an automation tool for compilation and build GNU Compiler Collection (GCC) : a suite of compilers for several programming languages GNU C Library (glibc) : core C library including headers, libraries, and dynamic loader GNU Binutils : a suite of tools including linker, assembler and other tools GNU Bison : a parser generator, often used with the Flex lexical analyzer GNU m4 : an m4 macro processor GNU Debugger (GDB) : a code debugging tool GNU Autotools (GNU Build System) : Autoconf, Automake and Libtool","title":"GNU Toolchain"},{"location":"blog/freertos/blink/","tags":["arm","freertos"],"text":"STM32-Tutorials Requirements # Use FreeRTOS to do: Create the first task to Blink a LED at 10 Hz Create the second task to print out a counter value to SWV Use RTOS delay function to not consume CPU You can use any STM32 board because this is just a very simple project. Refer to different types listed in Development boards and choose one suit for you. I choose to use a Nucleo-64 board with STM32F411RE. The Green LED is connected to the pin PA5 of the MCU. Schematic of the Green LED on STM32 Nucleo-64 board FreeRTOS source files # Download FreeRTOS from the official page . At the writing time, it is at the version 202112.00 which includes the FreeRTOS Kernel version 10.4.6 . Extract the source code, then you should understand the source code structure to select files and folder to include into your project. The FreeRTOS download includes source code for every processor port, and every demo application. From the top, the download is split into two sub directories; FreeRTOS, and FreeRTOS-Plus. These are shown below: +- FreeRTOS // Contains the FreeRTOS real time kernel source files and demo projects | + Source // Contains the real time kernel source code. | | | // Select files from here to include to your project | | + include // Kernel header files | | + portable // Target specific immplementation | | + MemMang // Memory Management methods | | + GCC // Compiler | | + ARM - CM4F // Target MCU | + Demo // Contains the demo application projects | // Use demo config files as a base for your project +- FreeRTOS - Plus // Contains FreeRTOS+ components and demo projects. The FreeRTOS/Include directory contains the kernel header files. The core RTOS code is contained in three files, which are called tasks.c , queue.c and list.c . These three files are in the FreeRTOS/Source directory. The same directory contains two optional files called timers.c and croutine.c which implement software timer and co-routine functionality respectively. Each supported processor architecture requires a small amount of architecture specific RTOS code. This is the RTOS portable layer, and it is located in the FreeRTOS/Source/Portable/[compiler]/[architecture] subdirectories, where [compiler] and [architecture] are the compiler used to create the port, and the architecture on which the port runs, respectively. For the reasons stated on the memory management page , the sample heap allocation schemes are also located in the portable layer. The various sample heap_x.c files are located in the FreeRTOS/Source/portable/MemMang directory. The FreeRTOS download also contains a demo application for every processor architecture and compiler port. The FreeRTOS/Demo subdirectories contain pre-configured projects used to build individual demo applications. The directories are named to indicate the port to which they relate. Each RTOS port also has its own web page that details the directory in which the demo application for that port can be found, such as Demos targeting ST Microelectronics products . Select source files for STM32F411RE Here are the files that are necessary for integrate FreeRTOS: FreeRTOS \u2502 croutine . c \u2502 event_groups . c \u2502 list . c \u2502 queue . c \u2502 stream_buffer . c \u2502 tasks . c \u2502 timers . c \u2502 \u251c\u2500\u2500\u2500 include \u2502 atomic . h \u2502 croutine . h \u2502 deprecated_definitions . h \u2502 event_groups . h \u2502 FreeRTOS . h \u2502 list . h \u2502 message_buffer . h \u2502 mpu_prototypes . h \u2502 mpu_wrappers . h \u2502 portable . h \u2502 projdefs . h \u2502 queue . h \u2502 semphr . h \u2502 stack_macros . h \u2502 stream_buffer . h \u2502 task . h \u2502 timers . h \u2502 \u2514\u2500\u2500\u2500 portable \u251c\u2500\u2500\u2500 Common \u2502 mpu_wrappers . c \u251c\u2500\u2500\u2500 GCC \u2502 \u2514\u2500\u2500\u2500 ARM_CM4F \u2502 port . c \u2502 portmacro . h \u2514\u2500\u2500\u2500 MemMang heap_4 . c FreeRTOS APIs # The FreeRTOS API Reference are listed in the below categories: Configuration Task Creation Task Control Kernel Control Task Notifications Task Utilities FreeRTOS-MPU Specific Queue Management Queue Sets Semaphores Software Timers Event Groups Stream Buffers Message Buffers Co-routine specific We will cover all above categories in other guides later. Configuration # FreeRTOS is customised using a configuration file called FreeRTOSConfig.h . Every FreeRTOS application must have a FreeRTOSConfig.h header file in its pre-processor include path. FreeRTOSConfig.h tailors the RTOS kernel to the application being built. It is therefore specific to the application, not the RTOS, and should be located in an application directory, not in one of the RTOS kernel source code directories. Here is a typical FreeRTOSConfig.h definition, followed by an explanation of each parameter: #ifndef FREERTOS_CONFIG_H #define FREERTOS_CONFIG_H #include <stdint.h> #include \"stm32f4xx.h\" extern uint32_t SystemCoreClock ; /* Scheduler settings */ #define configUSE_PREEMPTION ( 1 ) #define configCPU_CLOCK_HZ ( SystemCoreClock ) #define configTICK_RATE_HZ ( ( TickType_t ) 1000 ) #define configUSE_16_BIT_TICKS ( 0 ) /* use 32-bit */ /* Task settings */ #define configMAX_PRIORITIES ( 5 ) #define configMINIMAL_STACK_SIZE ( ( unsigned short ) 130 ) #define configTOTAL_HEAP_SIZE ( ( size_t ) ( 75 * 1024 ) ) #define configMAX_TASK_NAME_LEN ( 10 ) /* Co-routine definitions. */ #define configUSE_CO_ROUTINES ( 0 ) #define configMAX_CO_ROUTINE_PRIORITIES ( 2 ) /* Hook function related definitions. */ #define configUSE_IDLE_HOOK ( 0 ) #define configUSE_TICK_HOOK ( 0 ) #define configCHECK_FOR_STACK_OVERFLOW ( 0 ) #define configUSE_MALLOC_FAILED_HOOK ( 0 ) #define configUSE_DAEMON_TASK_STARTUP_HOOK ( 0 ) /* Optional functions */ #define INCLUDE_vTaskDelay ( 1 ) /* Cortex-M specific definitions. */ #ifdef __NVIC_PRIO_BITS /* __BVIC_PRIO_BITS will be specified when CMSIS is being used. */ #define configPRIO_BITS __NVIC_PRIO_BITS #else #define configPRIO_BITS ( 4 ) /* 15 priority levels */ #endif /* The lowest interrupt priority that can be used in a call to a \"set priority\" function. */ #define configLIBRARY_LOWEST_INTERRUPT_PRIORITY ( 0xf ) /* The highest interrupt priority that can be used by any interrupt service routine that makes calls to interrupt safe FreeRTOS API functions. DO NOT CALL INTERRUPT SAFE FREERTOS API FUNCTIONS FROM ANY INTERRUPT THAT HAS A HIGHER PRIORITY THAN THIS! (higher priorities are lower numeric values. */ #define configLIBRARY_MAX_SYSCALL_INTERRUPT_PRIORITY ( 5 ) /* Interrupt priorities used by the kernel port layer itself. These are generic to all Cortex-M ports, and do not rely on any particular library functions. */ #define configKERNEL_INTERRUPT_PRIORITY \\ ( configLIBRARY_LOWEST_INTERRUPT_PRIORITY << (8 - configPRIO_BITS) ) /* !!!! configMAX_SYSCALL_INTERRUPT_PRIORITY must not be set to zero !!!! See http://www.FreeRTOS.org/RTOS-Cortex-M3-M4.html. */ #define configMAX_SYSCALL_INTERRUPT_PRIORITY \\ ( configLIBRARY_MAX_SYSCALL_INTERRUPT_PRIORITY << (8 - configPRIO_BITS) ) /* Normal assert() semantics without relying on the provision of an assert.h header file. */ #define configASSERT(x) \\ if((x) == 0) { taskDISABLE_INTERRUPTS(); for( ;; ); } /* Definitions that map the FreeRTOS port interrupt handlers to their CMSIS standard names. */ #define vPortSVCHandler SVC_Handler #define xPortPendSVHandler PendSV_Handler #define xPortSysTickHandler SysTick_Handler #endif /* FREERTOS_CONFIG_H */ Task Creation # Each task requires RAM that is used to hold the task state, and used by the task as its stack. If a task is created using xTaskCreate() then the required RAM is automatically allocated from the FreeRTOS heap. If a task is created using xTaskCreateStatic() then the RAM is provided by the application writer, so it can be statically allocated at compile time. Dynamic Allocation: configSUPPORT_DYNAMIC_ALLOCATION = 1 Create a new task and add it to the list of tasks that are ready to run. configSUPPORT_DYNAMIC_ALLOCATION must be set to 1 in FreeRTOSConfig.h , or left undefined (in which case it will default to 1 ), for this RTOS API function to be available. BaseType_t xTaskCreate ( TaskFunction_t pvTaskCode , const char * const pcName , configSTACK_DEPTH_TYPE usStackDepth , void * pvParameters , UBaseType_t uxPriority , TaskHandle_t * pxCreatedTask ); /* Task to be created. */ void vTaskCode ( void * pvParameters ) { /* The parameter value is expected to be 1 as 1 is passed in the pvParameters value in the call to xTaskCreate() below. configASSERT( ( ( uint32_t ) pvParameters ) == 1 ); for( ;; ) { /* Task code goes here. */ } } /* Function that creates a task. */ void vOtherFunction ( void ) { BaseType_t xReturned ; TaskHandle_t xHandle = NULL ; /* Create the task, storing the handle. */ xReturned = xTaskCreate ( vTaskCode , /* Function that implements the task. */ \"NAME\" , /* Text name for the task. */ STACK_SIZE , /* Stack size in words, not bytes. */ ( void * ) 1 , /* Parameter passed into the task. */ tskIDLE_PRIORITY , /* Priority at which the task is created. */ & xHandle ); /* Used to pass out the created task's handle. */ if ( xReturned == pdPASS ) { /* The task was created. Use the task's handle to delete the task. */ vTaskDelete ( xHandle ); } } Task Control # Task Delay Delay a task for a given number of ticks. The actual time that the task remains blocked depends on the tick rate. The constant portTICK_PERIOD_MS can be used to calculate real time from the tick rate - with the resolution of one tick period. INCLUDE_vTaskDelay must be defined as 1 for this function to be available. vTaskDelay() specifies a time at which the task wishes to unblock relative to the time at which vTaskDelay() is called. void vTaskDelay ( const TickType_t xTicksToDelay ); void vTaskFunction ( void * pvParameters ) { /* Block for 500ms. */ const TickType_t xDelay = 500 / portTICK_PERIOD_MS ; for ( ;; ) { /* Simply toggle the LED every 500ms, blocking between each toggle. */ vToggleLED (); vTaskDelay ( xDelay ); } } Kernel Control # The scheduler does not run by default, it must be triggered by the function: void vTaskStartScheduler ( void ); After calling that function, the RTOS kernel has control over registered tasks. The idle task and optionally the timer daemon task are created automatically when the RTOS scheduler is started. vTaskStartScheduler() will only return if there is insufficient RTOS heap available to create the idle or timer daemon tasks. The Idle Task # The idle task is created automatically when the RTOS scheduler is started to ensure there is always at least one task that is able to run. You may know this in the guide A simple implementation of a Task Scheduler . It is created at the lowest possible priority to ensure it does not use any CPU time if there are higher priority application tasks in the ready state. The idle task is responsible for freeing memory allocated by the RTOS to tasks that have since been deleted. It is therefore important in applications that make use of the vTaskDelete() function to ensure the idle task is not starved of processing time. The idle task has no other active functions so can legitimately be starved of microcontroller time under all other conditions. It is possible for application tasks to share the idle task priority ( tskIDLE_PRIORITY ). See the configIDLE_SHOULD_YIELD configuration parameter for information on how this behavior can be configured. Software Timers # A software timer (or just a \u2018timer\u2019) allows a function to be executed at a set time in the future. Timer functionality is optional, and not part of the core FreeRTOS kernel. It is instead provided by a timer service (or daemon) task. Note, a software timer must be explicitly created before it can be used, which is controlled by definitions in FreeRTOSConfig.h : /* Software timer related definitions. */ #define configUSE_TIMERS 1 #define configTIMER_TASK_PRIORITY 3 #define configTIMER_QUEUE_LENGTH 10 #define configTIMER_TASK_STACK_DEPTH configMINIMAL_STACK_SIZE The FreeRTOS implementation does not execute timer callback functions from an interrupt context, does not consume any processing time unless a timer has actually expired, does not add any processing overhead to the tick interrupt, and does not walk any link list structures while interrupts are disabled. Timer callback functions execute in the context of the timer service task. It is therefore essential that timer callback functions never attempt to block. For example, a timer callback function must not call vTaskDelay() , vTaskDelayUntil() , or specify a non zero block time when accessing a queue or a semaphore. Use FreeRTOS in Bare-metal project # F411RE_FreeRTOS_Blink_CMSIS.zip We will learn how to integrate FreeRTOS into a bare-metal project which does NOT use any high-level APIs. You can review the different levels of libraries in the Blink example on STM32 . Create a new project without using STM32CubeMX Add CMSIS files, refer to Integrate CMSIS Pack Copy FreeRTOS files into the projects Add new paths into the Project Paths and Symbols settings Add Paths and Symbols of CMSIS and FreeRTOS Implement project code # Now, this is the step to implement the requirements in our code: Note that we are using CMSIS package, so we can do access to GPIO and SWV through the CMSIS macros: Create the first task to toggle PA5 at 10 Hz void Blink_TaskFunction ( void * pvParameters ) { while ( 1 ) { /* set HIGH value on pin PA5 */ GPIOA -> BSRR |= GPIO_BSRR_BS_5 ; vTaskDelay ( 250 ); /* set LOW value on pin PA5 */ GPIOA -> BSRR |= GPIO_BSRR_BR_5 ; vTaskDelay ( 250 ); } } Create the second task to print out a counter value The parameter is the delay. void Log_TaskFunction ( void * pvParameters ) { uint8_t counter = 0 ; while ( 1 ) { printf ( \"counter = %d \\n \" , counter ); counter ++ ; vTaskDelay (( TickType_t ) pvParameters ); } } Create tasks and register them xTaskCreate ( Blink_TaskFunction , \"Blink\" , configMINIMAL_STACK_SIZE , NULL , 1 , & blinkTaskHandler ); xTaskCreate ( Log_TaskFunction , \"Log\" , configMINIMAL_STACK_SIZE , ( void * ) 500 , /* delay in 500 ticks */ 1 , & logTaskHandler ); Start the scheduler vTaskStartScheduler (); You have to write some extra code to: Redirect Standard IO function to SWV Initialize the PA5 pin as output mode Full source code : #include <stdint.h> #include <stdio.h> #include <stm32f4xx.h> #include \"FreeRTOS.h\" #include \"task.h\" /* Override low-level _write system call */ int _write ( int file , char * ptr , int len ) { int DataIdx ; for ( DataIdx = 0 ; DataIdx < len ; DataIdx ++ ) { ITM_SendChar ( * ptr ++ ); } return len ; } TaskHandle_t blinkTaskHandler ; TaskHandle_t logTaskHandler ; void Blink_TaskFunction ( void * pvParameters ); void Log_TaskFunction ( void * pvParameters ); int main ( void ) { SystemInit (); /* turn on clock on GPIOA */ RCC -> AHB1ENR |= RCC_AHB1ENR_GPIOAEN ; /* set PA5 to output mode */ GPIOA -> MODER &= ~ GPIO_MODER_MODE5_1 ; GPIOA -> MODER |= GPIO_MODER_MODE5_0 ; xTaskCreate ( Blink_TaskFunction , \"Blink\" , configMINIMAL_STACK_SIZE , NULL , 1 , & blinkTaskHandler ); xTaskCreate ( Log_TaskFunction , \"Log\" , configMINIMAL_STACK_SIZE , ( void * ) 500 , 1 , & logTaskHandler ); vTaskStartScheduler (); while ( 1 ); } void Blink_TaskFunction ( void * pvParameters ) { while ( 1 ) { /* set HIGH value on pin PA5 */ GPIOA -> BSRR |= GPIO_BSRR_BS_5 ; vTaskDelay ( 250 ); /* set LOW value on pin PA5 */ GPIOA -> BSRR |= GPIO_BSRR_BR_5 ; vTaskDelay ( 250 ); } } void Log_TaskFunction ( void * pvParameters ) { uint8_t counter ; while ( 1 ) { printf ( \"counter = %d \\n \" , counter ); counter ++ ; vTaskDelay (( TickType_t ) pvParameters ); } } Debug # Compile and run the project in Debug mode. Note to enable SWV in debugger, and open the SWV Data Console for channel 0 . For FreeRTOS, the is also some special windows to debug FreeRTOS, go to Windows \u2192 FreeRTOS \u2192 FreeRTOS Task List . Show SWV data and Task List You should notice that, the IDLE task is automatically created and run. The LED on PA5 should be blinking also. Use FreeRTOS with STM32CubeMX project # F411RE_FreeRTOS_Blink_Cube_HAL.zip STM32CubeMX can generate source code with FreeRTOS integration. Configure FreeRTOS # In the Pinout & Configuration tab, select Middeware \u2192 FreeRTOS then configure the FreeRTOS as below: Interface: CMSIS V2 (version 1 is quite old) Config parameters: Version: 10.3.1 (you can not change it, and the version usually is not the latest version) MPU/FPU: set the core functions The configuration in FreeRTOSConfig.h header: USE_PREEMPTION : Enabled CPU_CLOCK_HZ : SystemCoreClock TICK_RATE_HZ : 1000 Hooks functions Software Timer service: force to Enabled in CMSIS V2 Library settings Newlib: USE_NEWLIB_REENTRANT : should be Enabled then a newlib reent structure will be allocated for each created task. Newlib support has been included by popular demand, but is not used by the FreeRTOS maintainers themselves. HAL Timers The HAL library uses its own delay function which also needs a hardware timer to keep tracking time. Under the System Core , select SYS and choose a General Timer for Timebase Source , do not use SysTick as it is used by FreeRTOS. Configure FreeRTOS in STM32CubeMX Generated and copied files for FreeRTOS When generating a new project from STM32CubeMX, there will be a popup saying that: Prompt asking about set another time base source What does this mean? SysTick SysTick is apart of the ARM Core, that counts down from the reload value to zero, and fire an interrupt to make a periodical event. SysTick is mainly used for delay function in non-RTOS firmware, and is used as the interrupt for RTOS scheduler. In case STM32 HAL code also uses SysTick as its time base, RTOS will be generated to use HAL\u2019s Handler. If STM32 HAL utilizes another timer as its time base, RTOS has its own right to initialize and handler SysTick. It is recommended to use SysTick for RTOS only, and set a basic timer as the time base for HAL.\u201d By default, STM32 projects generated by STM32CubeIDE use Newlib-nano . Whenever FreeRTOS is enabled, IDE will prompt to enable Newlib Reentrant attribute: A prompt asking to enable Newlib reentrant To understand more about Reentrant, please read Reentrant example. Add Task # Add tasks information Generated code main.c /* Definitions for blinkTask */ osThreadId_t blinkTaskHandle ; const osThreadAttr_t blinkTask_attributes = { . name = \"blinkTask\" , . stack_size = 128 * 4 , . priority = ( osPriority_t ) osPriorityNormal , }; /* Definitions for logTask */ osThreadId_t logTaskHandle ; const osThreadAttr_t logTask_attributes = { . name = \"logTask\" , . stack_size = 128 * 4 , . priority = ( osPriority_t ) osPriorityLow , }; /* Task functions */ void blinkTaskFunction ( void * argument ); void logTaskFunction ( void * argument ); int main ( void ) { ... /* Init scheduler */ osKernelInitialize (); /* creation of blinkTask */ blinkTaskHandle = osThreadNew ( blinkTaskFunction , NULL , & blinkTask_attributes ); /* creation of logTask */ logTaskHandle = osThreadNew ( logTaskFunction , ( void * ) 500 , & logTask_attributes ); /* Start scheduler */ osKernelStart (); } Implement Task functions main.c void blinkTaskFunction ( void * argument ) { for (;;) { HAL_GPIO_TogglePin ( LED_GPIO_Port , LED_Pin ); osDelay ( 50 ); } } void logTaskFunction ( void * argument ) { uint8_t counter = 0 ; for (;;) { printf ( \"log: counter = %d \\n \" , counter ); counter ++ ; osDelay (( uint32_t ) argument ); } } You have to write some extra code to redirect Standard IO function to SWV in order to see printf() data. CMSIS Interface You should notice that the functions to work with FreeRTOS are wrappted in CMSIS calls. API category CMSIS_RTOS API FreeRTOS API Kernel control osKernelStart vTaskStartScheduler Thread management osThreadCreate xTaskCreate Semaphore osSemaphoreCreate vSemaphoreCreateBinary , xSemaphoreCreateCounting Mutex osMutexWait xSemaphoreTake Message queue osMessagePut xQueueSend , xQueueSendFromISR Timer osTimerCreate xTimerCreate Most of the functions returns osStatus value, which allows checking whether the function is completed or there was some issue (defined in the cmsis_os.h file). Each OS component has its own ID: Tasks: osThreadId (mapped to TaskHandle_t within FreeRTOS API) Queues: osMessageQId (mapped to QueueHandle_t within FreeRTOS API) Semaphores: osSemaphoreId (mapped to SemaphoreHandle_t within FreeRTOS API) Mutexes: osMutexId (mapped to SemaphoreHandle_t within FreeRTOS API) SW timers: osTimerId (mapped to TimerHandle_t within FreeRTOS API) Delays and timeouts are given in ms: 0 \u2014 no delay >0 \u2014 delay in ms 0xFFFFFFFF \u2014 wait forever (defined in osWaitForever within cmsis_os.h file) Delay The function osDelay() is part of CMSIS Library and uses vTaskDelay() internally to introduce delay with the difference that input argument of osDelay is delay time in milliseconds while the input argument of _vTaskDelay() is a number of Ticks to be delayed. Using osDelay() function, OS will be notified about the delay and OS will change the status of task to blocked for that particular time period. You may know this in the guide A simple implementation of a Task Scheduler . The function HAL_Delay() is part of the hardware abstraction layer. It basically uses polling to introduce delay. Using HAL_Delay() function, OS won\u2019t be notified about the delay, and the code is in polling mode. FreeRTOS delay functions: vTaskDelay() or vTaskDelayUntil() only take effect after the scheduler has started. Debug # Compile and run the project in Debug mode. Note to enable SWV in debugger, and open the SWV Data Console for channel 0. For FreeRTOS, the is also some special windows to debug FreeRTOS, go to Windows \u2192 FreeRTOS \u2192 FreeRTOS Task List . Show SWV data and Task List You now see one more extra task TmrSvc which is the Software Timer Service.","title":"Blink - say Hello to the World"},{"location":"blog/freertos/blink/#requirements","text":"Use FreeRTOS to do: Create the first task to Blink a LED at 10 Hz Create the second task to print out a counter value to SWV Use RTOS delay function to not consume CPU You can use any STM32 board because this is just a very simple project. Refer to different types listed in Development boards and choose one suit for you. I choose to use a Nucleo-64 board with STM32F411RE. The Green LED is connected to the pin PA5 of the MCU. Schematic of the Green LED on STM32 Nucleo-64 board","title":"Requirements"},{"location":"blog/freertos/blink/#freertos-source-files","text":"Download FreeRTOS from the official page . At the writing time, it is at the version 202112.00 which includes the FreeRTOS Kernel version 10.4.6 . Extract the source code, then you should understand the source code structure to select files and folder to include into your project. The FreeRTOS download includes source code for every processor port, and every demo application. From the top, the download is split into two sub directories; FreeRTOS, and FreeRTOS-Plus. These are shown below: +- FreeRTOS // Contains the FreeRTOS real time kernel source files and demo projects | + Source // Contains the real time kernel source code. | | | // Select files from here to include to your project | | + include // Kernel header files | | + portable // Target specific immplementation | | + MemMang // Memory Management methods | | + GCC // Compiler | | + ARM - CM4F // Target MCU | + Demo // Contains the demo application projects | // Use demo config files as a base for your project +- FreeRTOS - Plus // Contains FreeRTOS+ components and demo projects. The FreeRTOS/Include directory contains the kernel header files. The core RTOS code is contained in three files, which are called tasks.c , queue.c and list.c . These three files are in the FreeRTOS/Source directory. The same directory contains two optional files called timers.c and croutine.c which implement software timer and co-routine functionality respectively. Each supported processor architecture requires a small amount of architecture specific RTOS code. This is the RTOS portable layer, and it is located in the FreeRTOS/Source/Portable/[compiler]/[architecture] subdirectories, where [compiler] and [architecture] are the compiler used to create the port, and the architecture on which the port runs, respectively. For the reasons stated on the memory management page , the sample heap allocation schemes are also located in the portable layer. The various sample heap_x.c files are located in the FreeRTOS/Source/portable/MemMang directory. The FreeRTOS download also contains a demo application for every processor architecture and compiler port. The FreeRTOS/Demo subdirectories contain pre-configured projects used to build individual demo applications. The directories are named to indicate the port to which they relate. Each RTOS port also has its own web page that details the directory in which the demo application for that port can be found, such as Demos targeting ST Microelectronics products . Select source files for STM32F411RE Here are the files that are necessary for integrate FreeRTOS: FreeRTOS \u2502 croutine . c \u2502 event_groups . c \u2502 list . c \u2502 queue . c \u2502 stream_buffer . c \u2502 tasks . c \u2502 timers . c \u2502 \u251c\u2500\u2500\u2500 include \u2502 atomic . h \u2502 croutine . h \u2502 deprecated_definitions . h \u2502 event_groups . h \u2502 FreeRTOS . h \u2502 list . h \u2502 message_buffer . h \u2502 mpu_prototypes . h \u2502 mpu_wrappers . h \u2502 portable . h \u2502 projdefs . h \u2502 queue . h \u2502 semphr . h \u2502 stack_macros . h \u2502 stream_buffer . h \u2502 task . h \u2502 timers . h \u2502 \u2514\u2500\u2500\u2500 portable \u251c\u2500\u2500\u2500 Common \u2502 mpu_wrappers . c \u251c\u2500\u2500\u2500 GCC \u2502 \u2514\u2500\u2500\u2500 ARM_CM4F \u2502 port . c \u2502 portmacro . h \u2514\u2500\u2500\u2500 MemMang heap_4 . c","title":"FreeRTOS source files"},{"location":"blog/freertos/blink/#freertos-apis","text":"The FreeRTOS API Reference are listed in the below categories: Configuration Task Creation Task Control Kernel Control Task Notifications Task Utilities FreeRTOS-MPU Specific Queue Management Queue Sets Semaphores Software Timers Event Groups Stream Buffers Message Buffers Co-routine specific We will cover all above categories in other guides later.","title":"FreeRTOS APIs"},{"location":"blog/freertos/blink/#configuration","text":"FreeRTOS is customised using a configuration file called FreeRTOSConfig.h . Every FreeRTOS application must have a FreeRTOSConfig.h header file in its pre-processor include path. FreeRTOSConfig.h tailors the RTOS kernel to the application being built. It is therefore specific to the application, not the RTOS, and should be located in an application directory, not in one of the RTOS kernel source code directories. Here is a typical FreeRTOSConfig.h definition, followed by an explanation of each parameter: #ifndef FREERTOS_CONFIG_H #define FREERTOS_CONFIG_H #include <stdint.h> #include \"stm32f4xx.h\" extern uint32_t SystemCoreClock ; /* Scheduler settings */ #define configUSE_PREEMPTION ( 1 ) #define configCPU_CLOCK_HZ ( SystemCoreClock ) #define configTICK_RATE_HZ ( ( TickType_t ) 1000 ) #define configUSE_16_BIT_TICKS ( 0 ) /* use 32-bit */ /* Task settings */ #define configMAX_PRIORITIES ( 5 ) #define configMINIMAL_STACK_SIZE ( ( unsigned short ) 130 ) #define configTOTAL_HEAP_SIZE ( ( size_t ) ( 75 * 1024 ) ) #define configMAX_TASK_NAME_LEN ( 10 ) /* Co-routine definitions. */ #define configUSE_CO_ROUTINES ( 0 ) #define configMAX_CO_ROUTINE_PRIORITIES ( 2 ) /* Hook function related definitions. */ #define configUSE_IDLE_HOOK ( 0 ) #define configUSE_TICK_HOOK ( 0 ) #define configCHECK_FOR_STACK_OVERFLOW ( 0 ) #define configUSE_MALLOC_FAILED_HOOK ( 0 ) #define configUSE_DAEMON_TASK_STARTUP_HOOK ( 0 ) /* Optional functions */ #define INCLUDE_vTaskDelay ( 1 ) /* Cortex-M specific definitions. */ #ifdef __NVIC_PRIO_BITS /* __BVIC_PRIO_BITS will be specified when CMSIS is being used. */ #define configPRIO_BITS __NVIC_PRIO_BITS #else #define configPRIO_BITS ( 4 ) /* 15 priority levels */ #endif /* The lowest interrupt priority that can be used in a call to a \"set priority\" function. */ #define configLIBRARY_LOWEST_INTERRUPT_PRIORITY ( 0xf ) /* The highest interrupt priority that can be used by any interrupt service routine that makes calls to interrupt safe FreeRTOS API functions. DO NOT CALL INTERRUPT SAFE FREERTOS API FUNCTIONS FROM ANY INTERRUPT THAT HAS A HIGHER PRIORITY THAN THIS! (higher priorities are lower numeric values. */ #define configLIBRARY_MAX_SYSCALL_INTERRUPT_PRIORITY ( 5 ) /* Interrupt priorities used by the kernel port layer itself. These are generic to all Cortex-M ports, and do not rely on any particular library functions. */ #define configKERNEL_INTERRUPT_PRIORITY \\ ( configLIBRARY_LOWEST_INTERRUPT_PRIORITY << (8 - configPRIO_BITS) ) /* !!!! configMAX_SYSCALL_INTERRUPT_PRIORITY must not be set to zero !!!! See http://www.FreeRTOS.org/RTOS-Cortex-M3-M4.html. */ #define configMAX_SYSCALL_INTERRUPT_PRIORITY \\ ( configLIBRARY_MAX_SYSCALL_INTERRUPT_PRIORITY << (8 - configPRIO_BITS) ) /* Normal assert() semantics without relying on the provision of an assert.h header file. */ #define configASSERT(x) \\ if((x) == 0) { taskDISABLE_INTERRUPTS(); for( ;; ); } /* Definitions that map the FreeRTOS port interrupt handlers to their CMSIS standard names. */ #define vPortSVCHandler SVC_Handler #define xPortPendSVHandler PendSV_Handler #define xPortSysTickHandler SysTick_Handler #endif /* FREERTOS_CONFIG_H */","title":"Configuration"},{"location":"blog/freertos/blink/#task-creation","text":"Each task requires RAM that is used to hold the task state, and used by the task as its stack. If a task is created using xTaskCreate() then the required RAM is automatically allocated from the FreeRTOS heap. If a task is created using xTaskCreateStatic() then the RAM is provided by the application writer, so it can be statically allocated at compile time. Dynamic Allocation: configSUPPORT_DYNAMIC_ALLOCATION = 1 Create a new task and add it to the list of tasks that are ready to run. configSUPPORT_DYNAMIC_ALLOCATION must be set to 1 in FreeRTOSConfig.h , or left undefined (in which case it will default to 1 ), for this RTOS API function to be available. BaseType_t xTaskCreate ( TaskFunction_t pvTaskCode , const char * const pcName , configSTACK_DEPTH_TYPE usStackDepth , void * pvParameters , UBaseType_t uxPriority , TaskHandle_t * pxCreatedTask ); /* Task to be created. */ void vTaskCode ( void * pvParameters ) { /* The parameter value is expected to be 1 as 1 is passed in the pvParameters value in the call to xTaskCreate() below. configASSERT( ( ( uint32_t ) pvParameters ) == 1 ); for( ;; ) { /* Task code goes here. */ } } /* Function that creates a task. */ void vOtherFunction ( void ) { BaseType_t xReturned ; TaskHandle_t xHandle = NULL ; /* Create the task, storing the handle. */ xReturned = xTaskCreate ( vTaskCode , /* Function that implements the task. */ \"NAME\" , /* Text name for the task. */ STACK_SIZE , /* Stack size in words, not bytes. */ ( void * ) 1 , /* Parameter passed into the task. */ tskIDLE_PRIORITY , /* Priority at which the task is created. */ & xHandle ); /* Used to pass out the created task's handle. */ if ( xReturned == pdPASS ) { /* The task was created. Use the task's handle to delete the task. */ vTaskDelete ( xHandle ); } }","title":"Task Creation"},{"location":"blog/freertos/blink/#task-control","text":"Task Delay Delay a task for a given number of ticks. The actual time that the task remains blocked depends on the tick rate. The constant portTICK_PERIOD_MS can be used to calculate real time from the tick rate - with the resolution of one tick period. INCLUDE_vTaskDelay must be defined as 1 for this function to be available. vTaskDelay() specifies a time at which the task wishes to unblock relative to the time at which vTaskDelay() is called. void vTaskDelay ( const TickType_t xTicksToDelay ); void vTaskFunction ( void * pvParameters ) { /* Block for 500ms. */ const TickType_t xDelay = 500 / portTICK_PERIOD_MS ; for ( ;; ) { /* Simply toggle the LED every 500ms, blocking between each toggle. */ vToggleLED (); vTaskDelay ( xDelay ); } }","title":"Task Control"},{"location":"blog/freertos/blink/#kernel-control","text":"The scheduler does not run by default, it must be triggered by the function: void vTaskStartScheduler ( void ); After calling that function, the RTOS kernel has control over registered tasks. The idle task and optionally the timer daemon task are created automatically when the RTOS scheduler is started. vTaskStartScheduler() will only return if there is insufficient RTOS heap available to create the idle or timer daemon tasks.","title":"Kernel Control"},{"location":"blog/freertos/blink/#the-idle-task","text":"The idle task is created automatically when the RTOS scheduler is started to ensure there is always at least one task that is able to run. You may know this in the guide A simple implementation of a Task Scheduler . It is created at the lowest possible priority to ensure it does not use any CPU time if there are higher priority application tasks in the ready state. The idle task is responsible for freeing memory allocated by the RTOS to tasks that have since been deleted. It is therefore important in applications that make use of the vTaskDelete() function to ensure the idle task is not starved of processing time. The idle task has no other active functions so can legitimately be starved of microcontroller time under all other conditions. It is possible for application tasks to share the idle task priority ( tskIDLE_PRIORITY ). See the configIDLE_SHOULD_YIELD configuration parameter for information on how this behavior can be configured.","title":"The Idle Task"},{"location":"blog/freertos/blink/#software-timers","text":"A software timer (or just a \u2018timer\u2019) allows a function to be executed at a set time in the future. Timer functionality is optional, and not part of the core FreeRTOS kernel. It is instead provided by a timer service (or daemon) task. Note, a software timer must be explicitly created before it can be used, which is controlled by definitions in FreeRTOSConfig.h : /* Software timer related definitions. */ #define configUSE_TIMERS 1 #define configTIMER_TASK_PRIORITY 3 #define configTIMER_QUEUE_LENGTH 10 #define configTIMER_TASK_STACK_DEPTH configMINIMAL_STACK_SIZE The FreeRTOS implementation does not execute timer callback functions from an interrupt context, does not consume any processing time unless a timer has actually expired, does not add any processing overhead to the tick interrupt, and does not walk any link list structures while interrupts are disabled. Timer callback functions execute in the context of the timer service task. It is therefore essential that timer callback functions never attempt to block. For example, a timer callback function must not call vTaskDelay() , vTaskDelayUntil() , or specify a non zero block time when accessing a queue or a semaphore.","title":"Software Timers"},{"location":"blog/freertos/blink/#use-freertos-in-bare-metal-project","text":"F411RE_FreeRTOS_Blink_CMSIS.zip We will learn how to integrate FreeRTOS into a bare-metal project which does NOT use any high-level APIs. You can review the different levels of libraries in the Blink example on STM32 . Create a new project without using STM32CubeMX Add CMSIS files, refer to Integrate CMSIS Pack Copy FreeRTOS files into the projects Add new paths into the Project Paths and Symbols settings Add Paths and Symbols of CMSIS and FreeRTOS","title":"Use FreeRTOS in Bare-metal project"},{"location":"blog/freertos/blink/#implement-project-code","text":"Now, this is the step to implement the requirements in our code: Note that we are using CMSIS package, so we can do access to GPIO and SWV through the CMSIS macros: Create the first task to toggle PA5 at 10 Hz void Blink_TaskFunction ( void * pvParameters ) { while ( 1 ) { /* set HIGH value on pin PA5 */ GPIOA -> BSRR |= GPIO_BSRR_BS_5 ; vTaskDelay ( 250 ); /* set LOW value on pin PA5 */ GPIOA -> BSRR |= GPIO_BSRR_BR_5 ; vTaskDelay ( 250 ); } } Create the second task to print out a counter value The parameter is the delay. void Log_TaskFunction ( void * pvParameters ) { uint8_t counter = 0 ; while ( 1 ) { printf ( \"counter = %d \\n \" , counter ); counter ++ ; vTaskDelay (( TickType_t ) pvParameters ); } } Create tasks and register them xTaskCreate ( Blink_TaskFunction , \"Blink\" , configMINIMAL_STACK_SIZE , NULL , 1 , & blinkTaskHandler ); xTaskCreate ( Log_TaskFunction , \"Log\" , configMINIMAL_STACK_SIZE , ( void * ) 500 , /* delay in 500 ticks */ 1 , & logTaskHandler ); Start the scheduler vTaskStartScheduler (); You have to write some extra code to: Redirect Standard IO function to SWV Initialize the PA5 pin as output mode Full source code : #include <stdint.h> #include <stdio.h> #include <stm32f4xx.h> #include \"FreeRTOS.h\" #include \"task.h\" /* Override low-level _write system call */ int _write ( int file , char * ptr , int len ) { int DataIdx ; for ( DataIdx = 0 ; DataIdx < len ; DataIdx ++ ) { ITM_SendChar ( * ptr ++ ); } return len ; } TaskHandle_t blinkTaskHandler ; TaskHandle_t logTaskHandler ; void Blink_TaskFunction ( void * pvParameters ); void Log_TaskFunction ( void * pvParameters ); int main ( void ) { SystemInit (); /* turn on clock on GPIOA */ RCC -> AHB1ENR |= RCC_AHB1ENR_GPIOAEN ; /* set PA5 to output mode */ GPIOA -> MODER &= ~ GPIO_MODER_MODE5_1 ; GPIOA -> MODER |= GPIO_MODER_MODE5_0 ; xTaskCreate ( Blink_TaskFunction , \"Blink\" , configMINIMAL_STACK_SIZE , NULL , 1 , & blinkTaskHandler ); xTaskCreate ( Log_TaskFunction , \"Log\" , configMINIMAL_STACK_SIZE , ( void * ) 500 , 1 , & logTaskHandler ); vTaskStartScheduler (); while ( 1 ); } void Blink_TaskFunction ( void * pvParameters ) { while ( 1 ) { /* set HIGH value on pin PA5 */ GPIOA -> BSRR |= GPIO_BSRR_BS_5 ; vTaskDelay ( 250 ); /* set LOW value on pin PA5 */ GPIOA -> BSRR |= GPIO_BSRR_BR_5 ; vTaskDelay ( 250 ); } } void Log_TaskFunction ( void * pvParameters ) { uint8_t counter ; while ( 1 ) { printf ( \"counter = %d \\n \" , counter ); counter ++ ; vTaskDelay (( TickType_t ) pvParameters ); } }","title":"Implement project code"},{"location":"blog/freertos/blink/#debug","text":"Compile and run the project in Debug mode. Note to enable SWV in debugger, and open the SWV Data Console for channel 0 . For FreeRTOS, the is also some special windows to debug FreeRTOS, go to Windows \u2192 FreeRTOS \u2192 FreeRTOS Task List . Show SWV data and Task List You should notice that, the IDLE task is automatically created and run. The LED on PA5 should be blinking also.","title":"Debug"},{"location":"blog/freertos/blink/#use-freertos-with-stm32cubemx-project","text":"F411RE_FreeRTOS_Blink_Cube_HAL.zip STM32CubeMX can generate source code with FreeRTOS integration.","title":"Use FreeRTOS with STM32CubeMX project"},{"location":"blog/freertos/blink/#configure-freertos","text":"In the Pinout & Configuration tab, select Middeware \u2192 FreeRTOS then configure the FreeRTOS as below: Interface: CMSIS V2 (version 1 is quite old) Config parameters: Version: 10.3.1 (you can not change it, and the version usually is not the latest version) MPU/FPU: set the core functions The configuration in FreeRTOSConfig.h header: USE_PREEMPTION : Enabled CPU_CLOCK_HZ : SystemCoreClock TICK_RATE_HZ : 1000 Hooks functions Software Timer service: force to Enabled in CMSIS V2 Library settings Newlib: USE_NEWLIB_REENTRANT : should be Enabled then a newlib reent structure will be allocated for each created task. Newlib support has been included by popular demand, but is not used by the FreeRTOS maintainers themselves. HAL Timers The HAL library uses its own delay function which also needs a hardware timer to keep tracking time. Under the System Core , select SYS and choose a General Timer for Timebase Source , do not use SysTick as it is used by FreeRTOS. Configure FreeRTOS in STM32CubeMX Generated and copied files for FreeRTOS When generating a new project from STM32CubeMX, there will be a popup saying that: Prompt asking about set another time base source What does this mean? SysTick SysTick is apart of the ARM Core, that counts down from the reload value to zero, and fire an interrupt to make a periodical event. SysTick is mainly used for delay function in non-RTOS firmware, and is used as the interrupt for RTOS scheduler. In case STM32 HAL code also uses SysTick as its time base, RTOS will be generated to use HAL\u2019s Handler. If STM32 HAL utilizes another timer as its time base, RTOS has its own right to initialize and handler SysTick. It is recommended to use SysTick for RTOS only, and set a basic timer as the time base for HAL.\u201d By default, STM32 projects generated by STM32CubeIDE use Newlib-nano . Whenever FreeRTOS is enabled, IDE will prompt to enable Newlib Reentrant attribute: A prompt asking to enable Newlib reentrant To understand more about Reentrant, please read Reentrant example.","title":"Configure FreeRTOS"},{"location":"blog/freertos/blink/#add-task","text":"Add tasks information Generated code main.c /* Definitions for blinkTask */ osThreadId_t blinkTaskHandle ; const osThreadAttr_t blinkTask_attributes = { . name = \"blinkTask\" , . stack_size = 128 * 4 , . priority = ( osPriority_t ) osPriorityNormal , }; /* Definitions for logTask */ osThreadId_t logTaskHandle ; const osThreadAttr_t logTask_attributes = { . name = \"logTask\" , . stack_size = 128 * 4 , . priority = ( osPriority_t ) osPriorityLow , }; /* Task functions */ void blinkTaskFunction ( void * argument ); void logTaskFunction ( void * argument ); int main ( void ) { ... /* Init scheduler */ osKernelInitialize (); /* creation of blinkTask */ blinkTaskHandle = osThreadNew ( blinkTaskFunction , NULL , & blinkTask_attributes ); /* creation of logTask */ logTaskHandle = osThreadNew ( logTaskFunction , ( void * ) 500 , & logTask_attributes ); /* Start scheduler */ osKernelStart (); } Implement Task functions main.c void blinkTaskFunction ( void * argument ) { for (;;) { HAL_GPIO_TogglePin ( LED_GPIO_Port , LED_Pin ); osDelay ( 50 ); } } void logTaskFunction ( void * argument ) { uint8_t counter = 0 ; for (;;) { printf ( \"log: counter = %d \\n \" , counter ); counter ++ ; osDelay (( uint32_t ) argument ); } } You have to write some extra code to redirect Standard IO function to SWV in order to see printf() data. CMSIS Interface You should notice that the functions to work with FreeRTOS are wrappted in CMSIS calls. API category CMSIS_RTOS API FreeRTOS API Kernel control osKernelStart vTaskStartScheduler Thread management osThreadCreate xTaskCreate Semaphore osSemaphoreCreate vSemaphoreCreateBinary , xSemaphoreCreateCounting Mutex osMutexWait xSemaphoreTake Message queue osMessagePut xQueueSend , xQueueSendFromISR Timer osTimerCreate xTimerCreate Most of the functions returns osStatus value, which allows checking whether the function is completed or there was some issue (defined in the cmsis_os.h file). Each OS component has its own ID: Tasks: osThreadId (mapped to TaskHandle_t within FreeRTOS API) Queues: osMessageQId (mapped to QueueHandle_t within FreeRTOS API) Semaphores: osSemaphoreId (mapped to SemaphoreHandle_t within FreeRTOS API) Mutexes: osMutexId (mapped to SemaphoreHandle_t within FreeRTOS API) SW timers: osTimerId (mapped to TimerHandle_t within FreeRTOS API) Delays and timeouts are given in ms: 0 \u2014 no delay >0 \u2014 delay in ms 0xFFFFFFFF \u2014 wait forever (defined in osWaitForever within cmsis_os.h file) Delay The function osDelay() is part of CMSIS Library and uses vTaskDelay() internally to introduce delay with the difference that input argument of osDelay is delay time in milliseconds while the input argument of _vTaskDelay() is a number of Ticks to be delayed. Using osDelay() function, OS will be notified about the delay and OS will change the status of task to blocked for that particular time period. You may know this in the guide A simple implementation of a Task Scheduler . The function HAL_Delay() is part of the hardware abstraction layer. It basically uses polling to introduce delay. Using HAL_Delay() function, OS won\u2019t be notified about the delay, and the code is in polling mode. FreeRTOS delay functions: vTaskDelay() or vTaskDelayUntil() only take effect after the scheduler has started.","title":"Add Task"},{"location":"blog/freertos/blink/#debug_1","text":"Compile and run the project in Debug mode. Note to enable SWV in debugger, and open the SWV Data Console for channel 0. For FreeRTOS, the is also some special windows to debug FreeRTOS, go to Windows \u2192 FreeRTOS \u2192 FreeRTOS Task List . Show SWV data and Task List You now see one more extra task TmrSvc which is the Software Timer Service.","title":"Debug"},{"location":"blog/freertos/memory/","tags":["arm","freertos"],"text":"Dynamic Memory Management # FreeRTOS uses a region of memory called Heap (into the RAM) to allocate memory for tasks, queues, timers, semaphores, mutexes and when dynamically creating variables. FreeRTOS heap is different from the system heap defined at the compiler level. For example, in heap_4.c , the RTOS Heap is defined as: PRIVILEGED_DATA static uint8_t ucHeap [ configTOTAL_HEAP_SIZE ]; So, RTOS Heap is located in BSS section. Memory Heap in RTOS When FreeRTOS requires RAM, instead of calling the standard malloc() , it calls PvPortMalloc() . When it needs to free memory it calls PvPortFree() instead of the standard free() . These functions works on RTOS Heap only. FreeRTOS offers several heap management schemes that range in complexity and features. The FreeRTOS download includes five sample memory allocation implementations, each of which are described in the following subsections. The subsections also include information on when each of the provided implementations might be the most appropriate to select. Heap management schemes: heap_1 \u2014 the very simplest, does not permit memory to be freed. heap_2 \u2014 permits memory to be freed, but does not coalescence adjacent free blocks. heap_3 \u2014 simply wraps the standard malloc() and free() for thread safety. heap_4 \u2014 coalescence adjacent free blocks to avoid fragmentation. Includes absolute address placement option. heap_5 \u2014 as per heap_4 , with the ability to span the heap across multiple non-adjacent memory areas. Notes: heap_1 is less useful since FreeRTOS added support for static allocation. heap_2 is now considered legacy as the newer heap_4 implementation is preferred. Heap_1 # This implementation uses first fit algorithm to allocate memory. It is the simplest allocation method (deterministic), but does not allow freeing of allocated memory. This could be interesting when no memory freeing is necessary. Heap_1 method Heap_2 # This implementation is not recommended to new projects. It\u2019s kept due to backward compatibility. This method implements the best fit algorithm for allocation. It allows memory free() operation but doesn\u2019t combine adjacent free blocks. This method has risk of fragmentation. Heap_2 method Heap_3 # This method implements simple wrapper for standard C library malloc() and free() ; wrapper makes these functions thread safe, but makes code increase and not deterministic It uses linker heap region. The configTOTAL_HEAP_SIZE setting has no effect when this model is used Heap_3 method Heap_4 # This method uses first fit algorithm to allocate memory. It is able to combine adjacent free memory blocks into a single block . Heap_4 method The heap is organized as a linked list: for better efficiency when dynamically allocating/Freeing memory. As consequence when allocating N bytes in the heap memory using pvPortMalloc() API it consumes: Size of BlockLink_t (structure of the heap linked list) : 8 bytes. Data to be allocated itself : N bytes. Add padding to total allocated size (N + 8) to be 8 bytes aligned The memory array used by heap_4 is declared within heap_4.c file and its start address is configured by the linker automatically. To manually set the memory array address: Set configAPPLICATION_ALLOCATED_HEAP to 1 Declared a memory array: uint8_t ucHeap [ configTOTAL_HEAP_SIZE ] Heap_5 # The Fit algorithm in this method is able to combine adjacent free memory blocks into a single block using the same algorithms as in heap_4 , but supporting different memory regions (i.e. SRAM1, SRAM2) being not in linear memory space It is the only memory allocation scheme that must be explicitly initialized before any OS object can be created (before first call of pvPortMalloc() ). Application specifies start address and size of each separate memory area. Lower address appears in the array first To initialize this scheme, vPortDefineHeapRegions() function should be called. An example for STM32L476 device with SRAM1 and SRAM2 areas: #define SRAM1_OS_START (uint8_t *)0x2000 1000 #define SRAM1_OS_SIZE 0x0800 //2kB #define SRAM2_OS_START (uint8_t *)0x1000 0000 #define SRAM2_OS_SIZE 0x1000 //4kB /* Define */ Const HeapRegion_t xHeapRegions [] = { { SRAM2_OS_START , SRAM2_OS_SIZE }, { SRAM1_OS_START , SRAM1_OS_SIZE }, { NULL , 0 } /*terminates the array*/ } /* Initialize */ vPortDefineHeapRegions ( HeapRegions ); Manual allocation # There is an option to use alternative functions for memory management, however it is not recommended (inefficient) way of operation: void StartTask1 ( void const * argument ) { osPoolDef ( Memory , 0x100 , uint8_t ); PoolHandle = osPoolCreate ( osPool ( Memory )); uint8_t * buffer = osPoolAlloc ( PoolHandle ); for (;;) { osDelay ( 5000 ); } }","title":"Dynamic Memory Management"},{"location":"blog/freertos/memory/#dynamic-memory-management","text":"FreeRTOS uses a region of memory called Heap (into the RAM) to allocate memory for tasks, queues, timers, semaphores, mutexes and when dynamically creating variables. FreeRTOS heap is different from the system heap defined at the compiler level. For example, in heap_4.c , the RTOS Heap is defined as: PRIVILEGED_DATA static uint8_t ucHeap [ configTOTAL_HEAP_SIZE ]; So, RTOS Heap is located in BSS section. Memory Heap in RTOS When FreeRTOS requires RAM, instead of calling the standard malloc() , it calls PvPortMalloc() . When it needs to free memory it calls PvPortFree() instead of the standard free() . These functions works on RTOS Heap only. FreeRTOS offers several heap management schemes that range in complexity and features. The FreeRTOS download includes five sample memory allocation implementations, each of which are described in the following subsections. The subsections also include information on when each of the provided implementations might be the most appropriate to select. Heap management schemes: heap_1 \u2014 the very simplest, does not permit memory to be freed. heap_2 \u2014 permits memory to be freed, but does not coalescence adjacent free blocks. heap_3 \u2014 simply wraps the standard malloc() and free() for thread safety. heap_4 \u2014 coalescence adjacent free blocks to avoid fragmentation. Includes absolute address placement option. heap_5 \u2014 as per heap_4 , with the ability to span the heap across multiple non-adjacent memory areas. Notes: heap_1 is less useful since FreeRTOS added support for static allocation. heap_2 is now considered legacy as the newer heap_4 implementation is preferred.","title":"Dynamic Memory Management"},{"location":"blog/freertos/memory/#heap_1","text":"This implementation uses first fit algorithm to allocate memory. It is the simplest allocation method (deterministic), but does not allow freeing of allocated memory. This could be interesting when no memory freeing is necessary. Heap_1 method","title":"Heap_1"},{"location":"blog/freertos/memory/#heap_2","text":"This implementation is not recommended to new projects. It\u2019s kept due to backward compatibility. This method implements the best fit algorithm for allocation. It allows memory free() operation but doesn\u2019t combine adjacent free blocks. This method has risk of fragmentation. Heap_2 method","title":"Heap_2"},{"location":"blog/freertos/memory/#heap_3","text":"This method implements simple wrapper for standard C library malloc() and free() ; wrapper makes these functions thread safe, but makes code increase and not deterministic It uses linker heap region. The configTOTAL_HEAP_SIZE setting has no effect when this model is used Heap_3 method","title":"Heap_3"},{"location":"blog/freertos/memory/#heap_4","text":"This method uses first fit algorithm to allocate memory. It is able to combine adjacent free memory blocks into a single block . Heap_4 method The heap is organized as a linked list: for better efficiency when dynamically allocating/Freeing memory. As consequence when allocating N bytes in the heap memory using pvPortMalloc() API it consumes: Size of BlockLink_t (structure of the heap linked list) : 8 bytes. Data to be allocated itself : N bytes. Add padding to total allocated size (N + 8) to be 8 bytes aligned The memory array used by heap_4 is declared within heap_4.c file and its start address is configured by the linker automatically. To manually set the memory array address: Set configAPPLICATION_ALLOCATED_HEAP to 1 Declared a memory array: uint8_t ucHeap [ configTOTAL_HEAP_SIZE ]","title":"Heap_4"},{"location":"blog/freertos/memory/#heap_5","text":"The Fit algorithm in this method is able to combine adjacent free memory blocks into a single block using the same algorithms as in heap_4 , but supporting different memory regions (i.e. SRAM1, SRAM2) being not in linear memory space It is the only memory allocation scheme that must be explicitly initialized before any OS object can be created (before first call of pvPortMalloc() ). Application specifies start address and size of each separate memory area. Lower address appears in the array first To initialize this scheme, vPortDefineHeapRegions() function should be called. An example for STM32L476 device with SRAM1 and SRAM2 areas: #define SRAM1_OS_START (uint8_t *)0x2000 1000 #define SRAM1_OS_SIZE 0x0800 //2kB #define SRAM2_OS_START (uint8_t *)0x1000 0000 #define SRAM2_OS_SIZE 0x1000 //4kB /* Define */ Const HeapRegion_t xHeapRegions [] = { { SRAM2_OS_START , SRAM2_OS_SIZE }, { SRAM1_OS_START , SRAM1_OS_SIZE }, { NULL , 0 } /*terminates the array*/ } /* Initialize */ vPortDefineHeapRegions ( HeapRegions );","title":"Heap_5"},{"location":"blog/freertos/memory/#manual-allocation","text":"There is an option to use alternative functions for memory management, however it is not recommended (inefficient) way of operation: void StartTask1 ( void const * argument ) { osPoolDef ( Memory , 0x100 , uint8_t ); PoolHandle = osPoolCreate ( osPool ( Memory )); uint8_t * buffer = osPoolAlloc ( PoolHandle ); for (;;) { osDelay ( 5000 ); } }","title":"Manual allocation"},{"location":"blog/freertos/notification/","tags":["arm","freertos"],"text":"STM32-Tutorials Task Notifications # RTOS task notification functionality is enabled by default, and can be excluded from a build by setting configUSE_TASK_NOTIFICATIONS to 0 in FreeRTOSConfig.h . Each RTOS task has an array of task notifications. Prior to FreeRTOS V10.4.0, tasks only had a single task notification, not an array of notifications. The constant configTASK_NOTIFICATION_ARRAY_ENTRIES sets the number of indexes in the task notification array. Each task notification has a notification state that can be either: taskNOT_WAITING_NOTIFICATION taskWAITING_NOTIFICATION taskNOTIFICATION_RECEIVED typedef struct tskTaskControlBlock { ... #if ( configUSE_TASK_NOTIFICATIONS == 1 ) volatile uint32_t ulNotifiedValue [ configTASK_NOTIFICATION_ARRAY_ENTRIES ]; volatile uint8_t ucNotifyState [ configTASK_NOTIFICATION_ARRAY_ENTRIES ]; #endif ... } Notify # Task notification is an event sent directly to a task, rather than indirectly to a task via an intermediary object such as a queue, event group or semaphore. Sending a task notification to a task will unblock that task if the task is in the blocked state specifically to wait for a notification. BaseType_t xTaskGenericNotify () ( TaskHandle_t xTaskToNotify , UBaseType_t uxIndexToNotify , uint32_t ulValue , eNotifyAction eAction , uint32_t * pulPreviousNotificationValue ) { pxTCB = xTaskToNotify ; if ( pulPreviousNotificationValue != NULL ) { * pulPreviousNotificationValue = pxTCB -> ulNotifiedValue [ uxIndexToNotify ]; } ucOriginalNotifyState = pxTCB -> ucNotifyState [ uxIndexToNotify ]; pxTCB -> ucNotifyState [ uxIndexToNotify ] = taskNOTIFICATION_RECEIVED ; switch ( eAction ) { // update pxTCB->ulNotifiedValue[ uxIndexToNotify ] using ulValue } if ( ucOriginalNotifyState == taskWAITING_NOTIFICATION ) { listREMOVE_ITEM ( & ( pxTCB -> xStateListItem ) ); prvAddTaskToReadyList ( pxTCB ); if ( pxTCB -> uxPriority > pxCurrentTCB -> uxPriority ) { taskYIELD_IF_USING_PREEMPTION (); } } } Waiting # When a task is set to wait for a notification, it is put to delay task list and moved to blocked state. Each notification within the array operates independently - a task can only block on one notification within the array at a time and will not be unblocked by a notification sent to any other array index. BaseType_t xTaskGenericNotifyWait ( UBaseType_t uxIndexToWaitOn , uint32_t ulBitsToClearOnEntry , uint32_t ulBitsToClearOnExit , uint32_t * pulNotificationValue , TickType_t xTicksToWait ) { if ( pxCurrentTCB -> ucNotifyState [ uxIndexToWait ] != taskNOTIFICATION_RECEIVED ) { pxCurrentTCB -> ulNotifiedValue [ uxIndexToWait ] &= ~ ulBitsToClearOnEntry ; pxCurrentTCB -> ucNotifyState [ uxIndexToWait ] = taskWAITING_NOTIFICATION ; if ( xTicksToWait > ( TickType_t ) 0 ) { prvAddCurrentTaskToDelayedList ( xTicksToWait , pdTRUE ); portYIELD_WITHIN_API (); } if ( pulNotificationValue != NULL ) { * pulNotificationValue = pxCurrentTCB -> ulNotifiedValue [ uxIndexToWait ]; } } } Limitation # Unblocking an RTOS task with a direct notification is 45% faster and uses less RAM than unblocking a task using an intermediary object such as a binary semaphore. However, it has some limitations that it only be used when there is only one task that can be the recipient of the event. This condition is however met in the majority of real world use cases, such as an interrupt unblocking a task that will process the data received by the interrupt. Usage # As Binary Semaphores # A binary semaphore is a semaphore that has a maximum count of 1, hence the \u2018binary\u2019 name. A task can only \u2018take\u2019 the semaphore if it is available, and the semaphore is only available if its count is 1. When a task notification is used in place of a binary semaphore the receiving task\u2019s notification value is used in place of the binary semaphore\u2019s count value, and the ulTaskNotifyTake() (or ulTaskNotifyTakeIndexed() ) API function is used in place of the semaphore\u2019s xSemaphoreTake() API function. The ulTaskNotifyTake() function\u2019s xClearOnExit parameter is set to pdTRUE , so the count value is returned to zero each time the notification is taken - emulating a binary semaphore. Example : This is an example of a transmit function in a generic peripheral driver. An RTOS task calls the transmit function, then waits in the Blocked state (so not using an CPU time) until it is notified that the transmission is complete. The transmission is performed by a DMA, and the DMA end interrupt is used to notify the task. static TaskHandle_t xTaskToNotify = NULL ; const UBaseType_t xArrayIndex = 1 ; // Transmit function void vStartTransmission ( uint8_t * pcData , size_t xDataLength ) { configASSERT ( xTaskToNotify == NULL ); xTaskToNotify = xTaskGetCurrentTaskHandle (); vStartTransmit ( pcData , xDatalength ); } // A task that transmits data and the enters blocked state void vTask (...) { StartTransmission ( pcData , xDataLength ); const TickType_t xMaxBlockTime = pdMS_TO_TICS ( 500 ); ulTaskNotifyTakeIndexed ( xArrayIndex , pdTRUE , /* xClearCountOnExit */ xMaxBlockTime ); } // The transmit end interrupt void vTransmitEndISR ( void ) { BaseType_t xHigherPriorityTaskWoken = pdFALSE ; prvClearInterruptSource (); configASSERT ( xTaskToNotify != NULL ); vTaskNotifyGiveIndexedFromISR ( xTaskToNotify , xArrayIndex , & xHigherPriorityTaskWoken ); xTaskToNotify = NULL ; portYIELD_FROM_ISR ( xHigherPriorityTaskWoken ); } As Counting Semaphores # A counting semaphore is a semaphore that can have a count value of zero up to a maximum value set when the semaphore is created. A task can only \u2018take\u2019 the semaphore if it is available, and the semaphore is only available if its count is greater than zero. When a task notification is used in place of a counting semaphore the receiving task\u2019s notification value is used in place of the counting semaphore\u2019s count value, and the ulTaskNotifyTake() (or ulTaskNotifyTakeIndexed() ) API function is used in place of the semaphore\u2019s xSemaphoreTake() API function. The ulTaskNotifyTake() function\u2019s xClearOnExit parameter is set to pdFALSE so the count value is only decremented (rather than cleared) each time the notification is taken - emulating a counting semaphore. Example : The value returned from ulTaskNotifyTake() is used to know how many outstanding ISR events must be processed, allowing the RTOS task\u2019s notification count to be cleared back to zero each time ulTaskNotifyTake() is called. const UBaseType_t xArrayIndex = 0 ; /* The ISR does not process data directly. It unblocks the handling task, and increase notification value */ void vISR () { BaseType_t xHigherPriorityTaskWoken = pdFALSE ; prvClearInterruptSource (); vTaskNotifyGiveIndexedFromISR ( xHandlingTask , xArrayIndex , & xHigherPriorityTaskWoken ); portYIELD_FROM_ISR ( xHigherPriorityTaskWoken ); } /* A task that blocks waiting to be notified and processes data */ void vHandlingTask () { BaseType_t xEvent ; const TickType_t xBlockTime = pdMS_TO_TICS ( 500 ); uint32_t ulNotifiedValue ; while ( 1 ) { ulNotifiedValue = ulTaskNotifyTakeIndexed ( xArrayIndex , pdTRUE , /* xClearOnExit */ xBlockTime ); if ( ulNotifiedValue == 0 ) { // no notification } else { // process outstanding interrupts while ( ulNotifiedValue ) { xEvent = xQueryPeripheral (); if ( xEvent != NO_MORE_EVENTS ) { vProcessEvent ( xEvent ); ulNotifiedValue -- ; } else { break ; } } } } } As Event Group # An event group is a set of binary flags (or bits), to each of which the application writer can assign a meaning. An RTOS task can enter the Blocked state to wait for one or more flags within the group to become active. The RTOS task does not consume any CPU time while it is in the Blocked state. When a task notification is used in place of an event group the receiving task\u2019s notification value is used in place of the event group, bits within the receiving task\u2019s notification value are used as event flags, and the xTaskNotifyWait() API function is used in place of the event group\u2019s xEventGroupWaitBits() API function. Likewise, bits are set using the xTaskNotify() and xTaskNotifyFromISR() API functions (with their eAction parameter set to eSetBits ) in place of the xEventGroupSetBits() and xEventGroupSetBitsFromISR() functions respectively. xTaskNotifyFromISR() has significant performance benefits when compared to xEventGroupSetBitsFromISR() because xTaskNotifyFromISR() executes entirely in the ISR, whereas xEventGroupSetBitsFromISR() must defer some processing to the RTOS daemon task. Unlike when using an event group the receiving task cannot specify that it only wants to leave the Blocked state when a combination of bits are active at the same time. Instead, the task is unblocked when any bit becomes active, and must test for bit combinations itself. Example : Two ISR for transmitting and receiving will notify to a task handler. #define TX_BIT 0x01 #define RX_BIT 0x02 static TaskHandle_t xHandlingTask ; void vTxISR ( void ) { BaseType_t xHigherPriorityTaskWoken = pdFALSE ; prvClearInterrupt (); xTaskNotifyFromISR ( xHandlingTask , TX_BIT , eSetBits , & xHigherPriorityTaskWoken ); portYIELD_FROM_ISR ( xHigherPriorityTaskWoken ); } void vRxISR ( void ) { BaseType_t xHigherPriorityTaskWoken = pdFALSE ; prvClearInterrupt (); xTaskNotifyFromISR ( xHandlingTask , RX_BIT , eSetBits , & xHigherPriorityTaskWoken ); portYIELD_FROM_ISR ( xHigherPriorityTaskWoken ); } static void prvHandlingTask ( void * pvParameter ) { const TickType_t xMaxBlockTime = pdMS_TO_TICKS ( 500 ); BaseType_t xResult ; uint32_t ulNotifiedValue ; while ( 1 ) { xResult = xTaskNotifyWait ( pdFALSE , /* Don't clear bits on entry. */ ULONG_MAX , /* Clear all bits on exit. */ & ulNotifiedValue , /* Stores the notified value. */ xMaxBlockTime ); if ( xResult == pdPASS ) { if ( ( ulNotifiedValue & TX_BIT ) != 0 ) vProcessTX (); if ( ( ulNotifiedValue & RX_BIT ) != 0 ) vProcessRX (); } } } As Mailbox # RTOS task notifications can be used to send data to a task, but in a much more restricted way than can be achieved with an RTOS queue because: Only 32-bit values can be sent The value is saved as the receiving task\u2019s notification value, and there can only be one notification value at any one time The task\u2019s notification value is the mailbox value. Data is sent to a task using the xTaskNotify() (or xTaskNotifyIndexed() ) and xTaskNotifyFromISR() (or xTaskNotifyIndexedFromISR() ) API functions with their eAction parameter set to: eSetValueWithOverwrite : the receiving task\u2019s notification value is updated even if the receiving task already had a notification pending. eSetValueWithoutOverwrite : the receiving task\u2019s notification value is only updated if the receiving task did not already have a notification pending - as to update the notification value would overwrite the previous value before the receiving task had processed it. A task can read its own notification value using xTaskNotifyWait() (or xTaskNotifyWaitIndexed() ). Example # F411RE_FreeRTOS_Task_Notification.zip Here is a simple project to demonstrate notification which help to save processor\u2019s time. A Button task monitors the input button on PC13 and notify the button\u2019s state A LED task turns on or off the LED on PA5 based on the Button\u2019s state Below example uses SEGGER SystemView to visualize the RTOS activities. Performance comparision Here is the result of process\u2019s usage on 3 below implementation methods: Method %Load %Idle Note Button task and LED task use loops 94% (buton: 47%, led: 47%) 0% Consume all processor\u2019s time Button task loops to check input, then notifies LED task 96% (buton: 96%, led: 0%) 0% Consume all processor\u2019s time Remove button task, button interrupt notifies LED task 0.3% (isr: 0.2%, led: 0.1%) 90.6% Not consume processor\u2019s time Two looping tasks # Button task and LED task use loops to process input and internal state. Define tasks and shared variable : volatile unsigned int button_pressed = 0 ; TaskHandle_t buttonTaskHandler ; TaskHandle_t ledTaskHandler ; Button task void Button_Task () { while ( 1 ) { if (( GPIOC -> IDR & GPIO_IDR_ID13 ) == 0 ) { button_pressed = 1 ; } else { button_pressed = 0 ; } } } LED task void LED_Task () { while ( 1 ) { if ( button_pressed ) { GPIOA -> BSRR |= GPIO_BSRR_BS_5 ; } else { GPIOA -> BSRR |= GPIO_BSRR_BR_5 ; } } } Main program int main ( void ) { SystemInit (); SEGGER_SYSVIEW_Conf (); /* turn on clock for GPIOA, GPIOC */ RCC -> AHB1ENR |= ( RCC_AHB1ENR_GPIOAEN | RCC_AHB1ENR_GPIOCEN ); /* set PA5 to output mode */ GPIOA -> MODER &= ~ GPIO_MODER_MODE5_1 ; GPIOA -> MODER |= GPIO_MODER_MODE5_0 ; /* set PC13 to input mode */ GPIOC -> MODER &= ~ GPIO_MODER_MODE13_1 ; GPIOC -> MODER &= ~ GPIO_MODER_MODE13_0 ; xTaskCreate ( Button_Task , \"Button_Task\" , configMINIMAL_STACK_SIZE , NULL , 1 , & buttonTaskHandler ); xTaskCreate ( LED_Task , \"LED_Task\" , configMINIMAL_STACK_SIZE , NULL , 1 , & ledTaskHandler ); vTaskStartScheduler (); for (;;); } Result : Two task\u2019s loops consume all processor\u2019s time. Can use vTaskDelay() to push tasks into blocked state and reserve processor for other tasks. Two tasks using loop consume all processor\u2019s time One looping task uses Notification # Button task loops to check input, then notifies LED task. Define tasks and shared variable : volatile unsigned int button_pressed = 0 ; TaskHandle_t buttonTaskHandler ; TaskHandle_t ledTaskHandler ; Button task void Button_Task () { volatile unsigned int button_changed = 0 ; while ( 1 ) { if (( GPIOC -> IDR & GPIO_IDR_ID13 ) == 0 ) { if ( ! button_pressed ) { button_pressed = 1 ; button_changed = 1 ; } } else { if ( button_pressed ) { button_pressed = 0 ; button_changed = 1 ; } } if ( button_changed ) { SEGGER_SYSVIEW_PrintfTarget ( \"pressed=%u\" , button_pressed ); xTaskGenericNotify ( ledTaskHandler /* xTaskToNotify */ , 0 /* uxIndexToNotify */ , 0 /* ulValue */ , eNoAction /* eAction */ , NULL /* pulPreviousNotificationValue */ ); button_changed = 0 ; } } } LED task void LED_Task () { while ( 1 ) { xTaskGenericNotifyWait ( 0 /* uxIndexToWaitOn */ , 0 /* ulBitsToClearOnEntry */ , 0 /* ulBitsToClearOnExit */ , NULL /* pulNotificationValue */ , portMAX_DELAY /* xTicksToWait*/ ); if ( button_pressed ) { GPIOA -> BSRR |= GPIO_BSRR_BS_5 ; } else { GPIOA -> BSRR |= GPIO_BSRR_BR_5 ; } } } Main program int main ( void ) { SystemInit (); SEGGER_SYSVIEW_Conf (); /* turn on clock for GPIOA, GPIOC */ RCC -> AHB1ENR |= ( RCC_AHB1ENR_GPIOAEN | RCC_AHB1ENR_GPIOCEN ); /* set PA5 to output mode */ GPIOA -> MODER &= ~ GPIO_MODER_MODE5_1 ; GPIOA -> MODER |= GPIO_MODER_MODE5_0 ; /* set PC13 to input mode */ GPIOC -> MODER &= ~ GPIO_MODER_MODE13_1 ; GPIOC -> MODER &= ~ GPIO_MODER_MODE13_0 ; xTaskCreate ( Button_Task , \"Button_Task\" , configMINIMAL_STACK_SIZE , NULL , 1 , & buttonTaskHandler ); xTaskCreate ( LED_Task , \"LED_Task\" , configMINIMAL_STACK_SIZE , NULL , 1 , & ledTaskHandler ); vTaskStartScheduler (); for (;;); } Result : The LED task is put to blocked state when it waits for a notification. However, the Button task still consumes all processor\u2019s time in its loop. Two tasks using notification reduce activation, and change the portion of processor\u2019s time Interrupt sends Notification # Remove button task, button interrupt notifies LED task. Define tasks and shared variable : volatile unsigned int button_pressed = 0 ; TaskHandle_t ledTaskHandler ; Interrupt Handler void EXTI15_10_IRQHandler () { SEGGER_SYSVIEW_RecordEnterISR (); if ( EXTI -> PR & ( 1UL << 13 )) { /* clear pending bit */ EXTI -> PR |= ( 1UL << 13 ); if (( GPIOC -> IDR & GPIO_IDR_ID13 ) == 0 ) { button_pressed = 1 ; } else { button_pressed = 0 ; } SEGGER_SYSVIEW_PrintfTarget ( \"pressed=%u\" , button_pressed ); xTaskGenericNotifyFromISR ( ledTaskHandler /* xTaskToNotify */ , 0 /* uxIndexToNotify */ , 0 /* ulValue */ , eNoAction /* eAction */ , NULL /* pulPreviousNotificationValue */ , NULL /*pxHigherPriorityTaskWoken, set to NULL to not switch task immediately */ ); } SEGGER_SYSVIEW_RecordExitISR (); } LED task void LED_Task () { while ( 1 ) { xTaskGenericNotifyWait ( 0 /* uxIndexToWaitOn */ , 0 /* ulBitsToClearOnEntry */ , 0 /* ulBitsToClearOnExit */ , NULL /* pulNotificationValue */ , portMAX_DELAY /* xTicksToWait*/ ); if ( button_pressed ) { GPIOA -> BSRR |= GPIO_BSRR_BS_5 ; } else { GPIOA -> BSRR |= GPIO_BSRR_BR_5 ; } } } Main program int main ( void ) { SystemInit (); SEGGER_SYSVIEW_Conf (); /* turn on clock for GPIOA, GPIOC */ RCC -> AHB1ENR |= ( RCC_AHB1ENR_GPIOAEN | RCC_AHB1ENR_GPIOCEN ); /* set PA5 to output mode */ GPIOA -> MODER &= ~ GPIO_MODER_MODE5_1 ; GPIOA -> MODER |= GPIO_MODER_MODE5_0 ; /* set PC13 to input mode */ GPIOC -> MODER &= ~ GPIO_MODER_MODE13_1 ; GPIOC -> MODER &= ~ GPIO_MODER_MODE13_0 ; /* turn on clock for SYSCONFIG */ RCC -> APB2ENR |= RCC_APB2ENR_SYSCFGEN ; /* select PC13 as source for EXTI */ SYSCFG -> EXTICR [ 3 ] &= ~ SYSCFG_EXTICR4_EXTI13_Msk ; SYSCFG -> EXTICR [ 3 ] |= SYSCFG_EXTICR4_EXTI13_PC ; /* enable interrupt on EXTI13 */ EXTI -> IMR |= EXTI_IMR_IM13 ; /* set up PC13 interruption on 2 edges */ EXTI -> RTSR |= EXTI_RTSR_TR13 ; EXTI -> FTSR |= EXTI_FTSR_TR13 ; /* enable NVIC */ __NVIC_SetPriority ( EXTI15_10_IRQn , configLIBRARY_MAX_SYSCALL_INTERRUPT_PRIORITY + 1 ); __NVIC_EnableIRQ ( EXTI15_10_IRQn ); xTaskCreate ( LED_Task , \"LED_Task\" , configMINIMAL_STACK_SIZE , NULL , 1 , & ledTaskHandler ); vTaskStartScheduler (); for (;;); } Result : The LED task does not react to the change of input right after receiving a notification. It is activated in next SysTick, which is a delay time so the reaction time is increased. One task and an interrupt using notification reduce a lot of process\u2019s time Reduce reaction time # If LED Task is requested to run immediately after the notification received, the reaction time of system is reduced. Use pxHigherPriorityTaskWoken to know if there is a higher priority task need can run to call portYIELD_FROM_ISR() . void EXTI15_10_IRQHandler () { SEGGER_SYSVIEW_RecordEnterISR (); BaseType_t aTaskWoken = pdFALSE ; if ( EXTI -> PR & ( 1UL << 13 )) { /* clear pending bit */ EXTI -> PR |= ( 1UL << 13 ); if (( GPIOC -> IDR & GPIO_IDR_ID13 ) == 0 ) { button_pressed = 1 ; } else { button_pressed = 0 ; } SEGGER_SYSVIEW_PrintfTarget ( \"pressed=%u\" , button_pressed ); xTaskGenericNotifyFromISR ( ledTaskHandler /* xTaskToNotify */ , 0 /* uxIndexToNotify */ , 0 /* ulValue */ , eNoAction /* eAction */ , NULL /* pulPreviousNotificationValue */ , & aTaskWoken /*pxHigherPriorityTaskWoken, set to NULL to not switch task immediately */ ); portYIELD_FROM_ISR ( aTaskWoken ); } SEGGER_SYSVIEW_RecordExitISR (); } Result : Task which is notified can be run immediately to reduce waiting time","title":"Notifications - Inter-task Communication and Synchronization"},{"location":"blog/freertos/notification/#task-notifications","text":"RTOS task notification functionality is enabled by default, and can be excluded from a build by setting configUSE_TASK_NOTIFICATIONS to 0 in FreeRTOSConfig.h . Each RTOS task has an array of task notifications. Prior to FreeRTOS V10.4.0, tasks only had a single task notification, not an array of notifications. The constant configTASK_NOTIFICATION_ARRAY_ENTRIES sets the number of indexes in the task notification array. Each task notification has a notification state that can be either: taskNOT_WAITING_NOTIFICATION taskWAITING_NOTIFICATION taskNOTIFICATION_RECEIVED typedef struct tskTaskControlBlock { ... #if ( configUSE_TASK_NOTIFICATIONS == 1 ) volatile uint32_t ulNotifiedValue [ configTASK_NOTIFICATION_ARRAY_ENTRIES ]; volatile uint8_t ucNotifyState [ configTASK_NOTIFICATION_ARRAY_ENTRIES ]; #endif ... }","title":"Task Notifications"},{"location":"blog/freertos/notification/#notify","text":"Task notification is an event sent directly to a task, rather than indirectly to a task via an intermediary object such as a queue, event group or semaphore. Sending a task notification to a task will unblock that task if the task is in the blocked state specifically to wait for a notification. BaseType_t xTaskGenericNotify () ( TaskHandle_t xTaskToNotify , UBaseType_t uxIndexToNotify , uint32_t ulValue , eNotifyAction eAction , uint32_t * pulPreviousNotificationValue ) { pxTCB = xTaskToNotify ; if ( pulPreviousNotificationValue != NULL ) { * pulPreviousNotificationValue = pxTCB -> ulNotifiedValue [ uxIndexToNotify ]; } ucOriginalNotifyState = pxTCB -> ucNotifyState [ uxIndexToNotify ]; pxTCB -> ucNotifyState [ uxIndexToNotify ] = taskNOTIFICATION_RECEIVED ; switch ( eAction ) { // update pxTCB->ulNotifiedValue[ uxIndexToNotify ] using ulValue } if ( ucOriginalNotifyState == taskWAITING_NOTIFICATION ) { listREMOVE_ITEM ( & ( pxTCB -> xStateListItem ) ); prvAddTaskToReadyList ( pxTCB ); if ( pxTCB -> uxPriority > pxCurrentTCB -> uxPriority ) { taskYIELD_IF_USING_PREEMPTION (); } } }","title":"Notify"},{"location":"blog/freertos/notification/#waiting","text":"When a task is set to wait for a notification, it is put to delay task list and moved to blocked state. Each notification within the array operates independently - a task can only block on one notification within the array at a time and will not be unblocked by a notification sent to any other array index. BaseType_t xTaskGenericNotifyWait ( UBaseType_t uxIndexToWaitOn , uint32_t ulBitsToClearOnEntry , uint32_t ulBitsToClearOnExit , uint32_t * pulNotificationValue , TickType_t xTicksToWait ) { if ( pxCurrentTCB -> ucNotifyState [ uxIndexToWait ] != taskNOTIFICATION_RECEIVED ) { pxCurrentTCB -> ulNotifiedValue [ uxIndexToWait ] &= ~ ulBitsToClearOnEntry ; pxCurrentTCB -> ucNotifyState [ uxIndexToWait ] = taskWAITING_NOTIFICATION ; if ( xTicksToWait > ( TickType_t ) 0 ) { prvAddCurrentTaskToDelayedList ( xTicksToWait , pdTRUE ); portYIELD_WITHIN_API (); } if ( pulNotificationValue != NULL ) { * pulNotificationValue = pxCurrentTCB -> ulNotifiedValue [ uxIndexToWait ]; } } }","title":"Waiting"},{"location":"blog/freertos/notification/#limitation","text":"Unblocking an RTOS task with a direct notification is 45% faster and uses less RAM than unblocking a task using an intermediary object such as a binary semaphore. However, it has some limitations that it only be used when there is only one task that can be the recipient of the event. This condition is however met in the majority of real world use cases, such as an interrupt unblocking a task that will process the data received by the interrupt.","title":"Limitation"},{"location":"blog/freertos/notification/#usage","text":"","title":"Usage"},{"location":"blog/freertos/notification/#as-binary-semaphores","text":"A binary semaphore is a semaphore that has a maximum count of 1, hence the \u2018binary\u2019 name. A task can only \u2018take\u2019 the semaphore if it is available, and the semaphore is only available if its count is 1. When a task notification is used in place of a binary semaphore the receiving task\u2019s notification value is used in place of the binary semaphore\u2019s count value, and the ulTaskNotifyTake() (or ulTaskNotifyTakeIndexed() ) API function is used in place of the semaphore\u2019s xSemaphoreTake() API function. The ulTaskNotifyTake() function\u2019s xClearOnExit parameter is set to pdTRUE , so the count value is returned to zero each time the notification is taken - emulating a binary semaphore. Example : This is an example of a transmit function in a generic peripheral driver. An RTOS task calls the transmit function, then waits in the Blocked state (so not using an CPU time) until it is notified that the transmission is complete. The transmission is performed by a DMA, and the DMA end interrupt is used to notify the task. static TaskHandle_t xTaskToNotify = NULL ; const UBaseType_t xArrayIndex = 1 ; // Transmit function void vStartTransmission ( uint8_t * pcData , size_t xDataLength ) { configASSERT ( xTaskToNotify == NULL ); xTaskToNotify = xTaskGetCurrentTaskHandle (); vStartTransmit ( pcData , xDatalength ); } // A task that transmits data and the enters blocked state void vTask (...) { StartTransmission ( pcData , xDataLength ); const TickType_t xMaxBlockTime = pdMS_TO_TICS ( 500 ); ulTaskNotifyTakeIndexed ( xArrayIndex , pdTRUE , /* xClearCountOnExit */ xMaxBlockTime ); } // The transmit end interrupt void vTransmitEndISR ( void ) { BaseType_t xHigherPriorityTaskWoken = pdFALSE ; prvClearInterruptSource (); configASSERT ( xTaskToNotify != NULL ); vTaskNotifyGiveIndexedFromISR ( xTaskToNotify , xArrayIndex , & xHigherPriorityTaskWoken ); xTaskToNotify = NULL ; portYIELD_FROM_ISR ( xHigherPriorityTaskWoken ); }","title":"As Binary Semaphores"},{"location":"blog/freertos/notification/#as-counting-semaphores","text":"A counting semaphore is a semaphore that can have a count value of zero up to a maximum value set when the semaphore is created. A task can only \u2018take\u2019 the semaphore if it is available, and the semaphore is only available if its count is greater than zero. When a task notification is used in place of a counting semaphore the receiving task\u2019s notification value is used in place of the counting semaphore\u2019s count value, and the ulTaskNotifyTake() (or ulTaskNotifyTakeIndexed() ) API function is used in place of the semaphore\u2019s xSemaphoreTake() API function. The ulTaskNotifyTake() function\u2019s xClearOnExit parameter is set to pdFALSE so the count value is only decremented (rather than cleared) each time the notification is taken - emulating a counting semaphore. Example : The value returned from ulTaskNotifyTake() is used to know how many outstanding ISR events must be processed, allowing the RTOS task\u2019s notification count to be cleared back to zero each time ulTaskNotifyTake() is called. const UBaseType_t xArrayIndex = 0 ; /* The ISR does not process data directly. It unblocks the handling task, and increase notification value */ void vISR () { BaseType_t xHigherPriorityTaskWoken = pdFALSE ; prvClearInterruptSource (); vTaskNotifyGiveIndexedFromISR ( xHandlingTask , xArrayIndex , & xHigherPriorityTaskWoken ); portYIELD_FROM_ISR ( xHigherPriorityTaskWoken ); } /* A task that blocks waiting to be notified and processes data */ void vHandlingTask () { BaseType_t xEvent ; const TickType_t xBlockTime = pdMS_TO_TICS ( 500 ); uint32_t ulNotifiedValue ; while ( 1 ) { ulNotifiedValue = ulTaskNotifyTakeIndexed ( xArrayIndex , pdTRUE , /* xClearOnExit */ xBlockTime ); if ( ulNotifiedValue == 0 ) { // no notification } else { // process outstanding interrupts while ( ulNotifiedValue ) { xEvent = xQueryPeripheral (); if ( xEvent != NO_MORE_EVENTS ) { vProcessEvent ( xEvent ); ulNotifiedValue -- ; } else { break ; } } } } }","title":"As Counting Semaphores"},{"location":"blog/freertos/notification/#as-event-group","text":"An event group is a set of binary flags (or bits), to each of which the application writer can assign a meaning. An RTOS task can enter the Blocked state to wait for one or more flags within the group to become active. The RTOS task does not consume any CPU time while it is in the Blocked state. When a task notification is used in place of an event group the receiving task\u2019s notification value is used in place of the event group, bits within the receiving task\u2019s notification value are used as event flags, and the xTaskNotifyWait() API function is used in place of the event group\u2019s xEventGroupWaitBits() API function. Likewise, bits are set using the xTaskNotify() and xTaskNotifyFromISR() API functions (with their eAction parameter set to eSetBits ) in place of the xEventGroupSetBits() and xEventGroupSetBitsFromISR() functions respectively. xTaskNotifyFromISR() has significant performance benefits when compared to xEventGroupSetBitsFromISR() because xTaskNotifyFromISR() executes entirely in the ISR, whereas xEventGroupSetBitsFromISR() must defer some processing to the RTOS daemon task. Unlike when using an event group the receiving task cannot specify that it only wants to leave the Blocked state when a combination of bits are active at the same time. Instead, the task is unblocked when any bit becomes active, and must test for bit combinations itself. Example : Two ISR for transmitting and receiving will notify to a task handler. #define TX_BIT 0x01 #define RX_BIT 0x02 static TaskHandle_t xHandlingTask ; void vTxISR ( void ) { BaseType_t xHigherPriorityTaskWoken = pdFALSE ; prvClearInterrupt (); xTaskNotifyFromISR ( xHandlingTask , TX_BIT , eSetBits , & xHigherPriorityTaskWoken ); portYIELD_FROM_ISR ( xHigherPriorityTaskWoken ); } void vRxISR ( void ) { BaseType_t xHigherPriorityTaskWoken = pdFALSE ; prvClearInterrupt (); xTaskNotifyFromISR ( xHandlingTask , RX_BIT , eSetBits , & xHigherPriorityTaskWoken ); portYIELD_FROM_ISR ( xHigherPriorityTaskWoken ); } static void prvHandlingTask ( void * pvParameter ) { const TickType_t xMaxBlockTime = pdMS_TO_TICKS ( 500 ); BaseType_t xResult ; uint32_t ulNotifiedValue ; while ( 1 ) { xResult = xTaskNotifyWait ( pdFALSE , /* Don't clear bits on entry. */ ULONG_MAX , /* Clear all bits on exit. */ & ulNotifiedValue , /* Stores the notified value. */ xMaxBlockTime ); if ( xResult == pdPASS ) { if ( ( ulNotifiedValue & TX_BIT ) != 0 ) vProcessTX (); if ( ( ulNotifiedValue & RX_BIT ) != 0 ) vProcessRX (); } } }","title":"As Event Group"},{"location":"blog/freertos/notification/#as-mailbox","text":"RTOS task notifications can be used to send data to a task, but in a much more restricted way than can be achieved with an RTOS queue because: Only 32-bit values can be sent The value is saved as the receiving task\u2019s notification value, and there can only be one notification value at any one time The task\u2019s notification value is the mailbox value. Data is sent to a task using the xTaskNotify() (or xTaskNotifyIndexed() ) and xTaskNotifyFromISR() (or xTaskNotifyIndexedFromISR() ) API functions with their eAction parameter set to: eSetValueWithOverwrite : the receiving task\u2019s notification value is updated even if the receiving task already had a notification pending. eSetValueWithoutOverwrite : the receiving task\u2019s notification value is only updated if the receiving task did not already have a notification pending - as to update the notification value would overwrite the previous value before the receiving task had processed it. A task can read its own notification value using xTaskNotifyWait() (or xTaskNotifyWaitIndexed() ).","title":"As Mailbox"},{"location":"blog/freertos/notification/#example","text":"F411RE_FreeRTOS_Task_Notification.zip Here is a simple project to demonstrate notification which help to save processor\u2019s time. A Button task monitors the input button on PC13 and notify the button\u2019s state A LED task turns on or off the LED on PA5 based on the Button\u2019s state Below example uses SEGGER SystemView to visualize the RTOS activities. Performance comparision Here is the result of process\u2019s usage on 3 below implementation methods: Method %Load %Idle Note Button task and LED task use loops 94% (buton: 47%, led: 47%) 0% Consume all processor\u2019s time Button task loops to check input, then notifies LED task 96% (buton: 96%, led: 0%) 0% Consume all processor\u2019s time Remove button task, button interrupt notifies LED task 0.3% (isr: 0.2%, led: 0.1%) 90.6% Not consume processor\u2019s time","title":"Example"},{"location":"blog/freertos/notification/#two-looping-tasks","text":"Button task and LED task use loops to process input and internal state. Define tasks and shared variable : volatile unsigned int button_pressed = 0 ; TaskHandle_t buttonTaskHandler ; TaskHandle_t ledTaskHandler ; Button task void Button_Task () { while ( 1 ) { if (( GPIOC -> IDR & GPIO_IDR_ID13 ) == 0 ) { button_pressed = 1 ; } else { button_pressed = 0 ; } } } LED task void LED_Task () { while ( 1 ) { if ( button_pressed ) { GPIOA -> BSRR |= GPIO_BSRR_BS_5 ; } else { GPIOA -> BSRR |= GPIO_BSRR_BR_5 ; } } } Main program int main ( void ) { SystemInit (); SEGGER_SYSVIEW_Conf (); /* turn on clock for GPIOA, GPIOC */ RCC -> AHB1ENR |= ( RCC_AHB1ENR_GPIOAEN | RCC_AHB1ENR_GPIOCEN ); /* set PA5 to output mode */ GPIOA -> MODER &= ~ GPIO_MODER_MODE5_1 ; GPIOA -> MODER |= GPIO_MODER_MODE5_0 ; /* set PC13 to input mode */ GPIOC -> MODER &= ~ GPIO_MODER_MODE13_1 ; GPIOC -> MODER &= ~ GPIO_MODER_MODE13_0 ; xTaskCreate ( Button_Task , \"Button_Task\" , configMINIMAL_STACK_SIZE , NULL , 1 , & buttonTaskHandler ); xTaskCreate ( LED_Task , \"LED_Task\" , configMINIMAL_STACK_SIZE , NULL , 1 , & ledTaskHandler ); vTaskStartScheduler (); for (;;); } Result : Two task\u2019s loops consume all processor\u2019s time. Can use vTaskDelay() to push tasks into blocked state and reserve processor for other tasks. Two tasks using loop consume all processor\u2019s time","title":"Two looping tasks"},{"location":"blog/freertos/notification/#one-looping-task-uses-notification","text":"Button task loops to check input, then notifies LED task. Define tasks and shared variable : volatile unsigned int button_pressed = 0 ; TaskHandle_t buttonTaskHandler ; TaskHandle_t ledTaskHandler ; Button task void Button_Task () { volatile unsigned int button_changed = 0 ; while ( 1 ) { if (( GPIOC -> IDR & GPIO_IDR_ID13 ) == 0 ) { if ( ! button_pressed ) { button_pressed = 1 ; button_changed = 1 ; } } else { if ( button_pressed ) { button_pressed = 0 ; button_changed = 1 ; } } if ( button_changed ) { SEGGER_SYSVIEW_PrintfTarget ( \"pressed=%u\" , button_pressed ); xTaskGenericNotify ( ledTaskHandler /* xTaskToNotify */ , 0 /* uxIndexToNotify */ , 0 /* ulValue */ , eNoAction /* eAction */ , NULL /* pulPreviousNotificationValue */ ); button_changed = 0 ; } } } LED task void LED_Task () { while ( 1 ) { xTaskGenericNotifyWait ( 0 /* uxIndexToWaitOn */ , 0 /* ulBitsToClearOnEntry */ , 0 /* ulBitsToClearOnExit */ , NULL /* pulNotificationValue */ , portMAX_DELAY /* xTicksToWait*/ ); if ( button_pressed ) { GPIOA -> BSRR |= GPIO_BSRR_BS_5 ; } else { GPIOA -> BSRR |= GPIO_BSRR_BR_5 ; } } } Main program int main ( void ) { SystemInit (); SEGGER_SYSVIEW_Conf (); /* turn on clock for GPIOA, GPIOC */ RCC -> AHB1ENR |= ( RCC_AHB1ENR_GPIOAEN | RCC_AHB1ENR_GPIOCEN ); /* set PA5 to output mode */ GPIOA -> MODER &= ~ GPIO_MODER_MODE5_1 ; GPIOA -> MODER |= GPIO_MODER_MODE5_0 ; /* set PC13 to input mode */ GPIOC -> MODER &= ~ GPIO_MODER_MODE13_1 ; GPIOC -> MODER &= ~ GPIO_MODER_MODE13_0 ; xTaskCreate ( Button_Task , \"Button_Task\" , configMINIMAL_STACK_SIZE , NULL , 1 , & buttonTaskHandler ); xTaskCreate ( LED_Task , \"LED_Task\" , configMINIMAL_STACK_SIZE , NULL , 1 , & ledTaskHandler ); vTaskStartScheduler (); for (;;); } Result : The LED task is put to blocked state when it waits for a notification. However, the Button task still consumes all processor\u2019s time in its loop. Two tasks using notification reduce activation, and change the portion of processor\u2019s time","title":"One looping task uses Notification"},{"location":"blog/freertos/notification/#interrupt-sends-notification","text":"Remove button task, button interrupt notifies LED task. Define tasks and shared variable : volatile unsigned int button_pressed = 0 ; TaskHandle_t ledTaskHandler ; Interrupt Handler void EXTI15_10_IRQHandler () { SEGGER_SYSVIEW_RecordEnterISR (); if ( EXTI -> PR & ( 1UL << 13 )) { /* clear pending bit */ EXTI -> PR |= ( 1UL << 13 ); if (( GPIOC -> IDR & GPIO_IDR_ID13 ) == 0 ) { button_pressed = 1 ; } else { button_pressed = 0 ; } SEGGER_SYSVIEW_PrintfTarget ( \"pressed=%u\" , button_pressed ); xTaskGenericNotifyFromISR ( ledTaskHandler /* xTaskToNotify */ , 0 /* uxIndexToNotify */ , 0 /* ulValue */ , eNoAction /* eAction */ , NULL /* pulPreviousNotificationValue */ , NULL /*pxHigherPriorityTaskWoken, set to NULL to not switch task immediately */ ); } SEGGER_SYSVIEW_RecordExitISR (); } LED task void LED_Task () { while ( 1 ) { xTaskGenericNotifyWait ( 0 /* uxIndexToWaitOn */ , 0 /* ulBitsToClearOnEntry */ , 0 /* ulBitsToClearOnExit */ , NULL /* pulNotificationValue */ , portMAX_DELAY /* xTicksToWait*/ ); if ( button_pressed ) { GPIOA -> BSRR |= GPIO_BSRR_BS_5 ; } else { GPIOA -> BSRR |= GPIO_BSRR_BR_5 ; } } } Main program int main ( void ) { SystemInit (); SEGGER_SYSVIEW_Conf (); /* turn on clock for GPIOA, GPIOC */ RCC -> AHB1ENR |= ( RCC_AHB1ENR_GPIOAEN | RCC_AHB1ENR_GPIOCEN ); /* set PA5 to output mode */ GPIOA -> MODER &= ~ GPIO_MODER_MODE5_1 ; GPIOA -> MODER |= GPIO_MODER_MODE5_0 ; /* set PC13 to input mode */ GPIOC -> MODER &= ~ GPIO_MODER_MODE13_1 ; GPIOC -> MODER &= ~ GPIO_MODER_MODE13_0 ; /* turn on clock for SYSCONFIG */ RCC -> APB2ENR |= RCC_APB2ENR_SYSCFGEN ; /* select PC13 as source for EXTI */ SYSCFG -> EXTICR [ 3 ] &= ~ SYSCFG_EXTICR4_EXTI13_Msk ; SYSCFG -> EXTICR [ 3 ] |= SYSCFG_EXTICR4_EXTI13_PC ; /* enable interrupt on EXTI13 */ EXTI -> IMR |= EXTI_IMR_IM13 ; /* set up PC13 interruption on 2 edges */ EXTI -> RTSR |= EXTI_RTSR_TR13 ; EXTI -> FTSR |= EXTI_FTSR_TR13 ; /* enable NVIC */ __NVIC_SetPriority ( EXTI15_10_IRQn , configLIBRARY_MAX_SYSCALL_INTERRUPT_PRIORITY + 1 ); __NVIC_EnableIRQ ( EXTI15_10_IRQn ); xTaskCreate ( LED_Task , \"LED_Task\" , configMINIMAL_STACK_SIZE , NULL , 1 , & ledTaskHandler ); vTaskStartScheduler (); for (;;); } Result : The LED task does not react to the change of input right after receiving a notification. It is activated in next SysTick, which is a delay time so the reaction time is increased. One task and an interrupt using notification reduce a lot of process\u2019s time","title":"Interrupt sends Notification"},{"location":"blog/freertos/notification/#reduce-reaction-time","text":"If LED Task is requested to run immediately after the notification received, the reaction time of system is reduced. Use pxHigherPriorityTaskWoken to know if there is a higher priority task need can run to call portYIELD_FROM_ISR() . void EXTI15_10_IRQHandler () { SEGGER_SYSVIEW_RecordEnterISR (); BaseType_t aTaskWoken = pdFALSE ; if ( EXTI -> PR & ( 1UL << 13 )) { /* clear pending bit */ EXTI -> PR |= ( 1UL << 13 ); if (( GPIOC -> IDR & GPIO_IDR_ID13 ) == 0 ) { button_pressed = 1 ; } else { button_pressed = 0 ; } SEGGER_SYSVIEW_PrintfTarget ( \"pressed=%u\" , button_pressed ); xTaskGenericNotifyFromISR ( ledTaskHandler /* xTaskToNotify */ , 0 /* uxIndexToNotify */ , 0 /* ulValue */ , eNoAction /* eAction */ , NULL /* pulPreviousNotificationValue */ , & aTaskWoken /*pxHigherPriorityTaskWoken, set to NULL to not switch task immediately */ ); portYIELD_FROM_ISR ( aTaskWoken ); } SEGGER_SYSVIEW_RecordExitISR (); } Result : Task which is notified can be run immediately to reduce waiting time","title":"Reduce reaction time"},{"location":"blog/freertos/overview/","tags":["arm","freertos"],"text":"Real-time Operating System # The main purpose of an OS is to have the functionality, of running multiple tasks at the same time, which obviously isn\u2019t possible with bare metal. Multitask Execution A Real-time Operating System (RTOS) is designed to do manage different tasks to guarantee that all critical operations must be performed on time, and within a given time. Critical operations include: Exceptions and Interrupts Prioritized functions Scheduling Having a RTOS system means: Timeliness is more important than performance It\u2019s guaranteed on data processing within a timing constraint Hard real-time functions must complete within a given time The core of a RTOS is an advanced algorithm for scheduling , with the key factors are minimal interrupt latency and minimal thread switching latency . Examples of RTOS system: VxWorks QNX Neutrino FreeRTOS Azure RTOS (ThreadX) Integrity RTOS embOS A Task # A Task is a piece of code, or a function, that does a specific job when it is allowed to run. A Task has its own Stack to create its local variables. Its stack can be used to store addition information which is needed to save or restore the task from running state. Usually, a task is an infinite loop which can repeatedly do multiple steps. void task_main ( void * param ) { // init task ... // main loop while ( 1 ) { // do things over and over } } A Task should be put into some states: INACTIVE : not to be run READY : in queue to be run RUNNING : is being executed WAITING or BLOCKED : is paused, put in run queue, but not to be run in next time slot The Scheduler # This is the core of an RTOS, which decides which task will be run in next time slot. Some types of a scheduler: Cooperative : task by task, each task does its work until it finishes Round-robin : each task has a time slice to run, there is no priority for task execution Pre-emptive/ Priority-based : task has priority which has high number can interrupt the running task and takes place of execution Round-robin scheduler Priority-based scheduler A simple Round-robin Scheduler In this guide A simple implementation of a Task Scheduler , we have understood about how a Round-robin Scheduler works with its main reponsibilities: Run a task Select a next task to be run Switch tasks Priority Inversion In Pre-emptive RTOS, when a High Priority task is waiting for a Low Priority task to run because the Low Priority is blocked by a shared resource that High Priority is also depent on. The SysTick # SysTick is a part of the ARM Core, that counts down from the reload value to zero, and fire an interrupt to make a periodical event. SysTick is mainly used for delay function in non-RTOS firmware, and is used as the timing interrupt for RTOS scheduler. SysTick is also used as countable time span of a waiting task. For example, a task need to read an input, and it should wait for 50 ms, if nothing comes, task should move to other work. This task will use SysTick, which is fired every 1 ms, to count up a waiting counter, if the counter reaches 50 ticks, task quits the waiting loop and runs other code. Non-blocking delay Using SysTick as a counter, a task can be moved to the BLOCKED state and it can not run until the waiting period is over. See a simple implementation of non-blocking delay in the example A simple implementation of a Task Scheduler . Memory Allocation # Real time operating system supports static and dynamic memory allocation, with different strategies and algorithm. Creating RTOS objects dynamically has the benefit of greater simplicity, and the potential to minimize the application\u2019s maximum RAM usage: The memory allocation occurs automatically. The RAM used by an RTOS object can be re-used if the object is deleted. The memory allocation scheme used can be chosen to the best suite the application. Creating RTOS objects using statically allocated RAM has the benefit of providing the application more control: RTOS objects can be placed at specific memory locations. It allows the RTOS to be used in applications that simply don\u2019t allow any dynamic memory allocation. Avoid memory-related issues such as leak memory, dangling pointer, and undefined objects. Memory layout in FreeRTOS Shared Memory # Tasks are usually a work to do in a loop, and it thinks it can control all resource. In a system, there are many tasks run together, and in many cases, they work with condition from others. Inter-task communication is defined as some type: Signal : tell other task to start doing something, to synchronize tasks Message Queue/Mailbox : send data between tasks Mutex/Semaphore : synchronize access to a shared resource, lock resource which is in-use Queue between tasks Signal between tasks Shared resource between tasks FreeRTOS # FreeRTOS is a market-leading real-time operating system (RTOS) for microcontrollers and small microprocessors. Distributed freely under the MIT open source license, FreeRTOS includes a kernel and a growing set of IoT libraries suitable for use across all industry sectors. FreeRTOS is built with an emphasis on reliability and ease of use. FreeRTOS provides methods for multiple threads or tasks, mutexes, semaphores and software timers. Thread priorities are supported. FreeRTOS applications can be statically allocated, but objects can also be dynamically allocated with five schemes of memory management (allocation). A tickless mode is provided for low power applications. SafeRTOS The Safety functionality is not guaranteed in FreeRTOS as it is not the main focus of the free version. FreeRTOS is designed to be small and simple. Integration # FreeRTOS is designed to be run on many MCUs, therefore, it defines interfaces which will be implemented on a target MCU platform. For ARM cores, CMSIS also has a porting layer for FreeRTOS. Download the source code of RTOS from FreeRTOS . FreeRTOS and LTS support A normal release of FreeRTOS includes Kernel, Libraries, and examples, A LTS version only contains the Kernel and IoT libraries. Library Git repo (including zip download) FreeRTOS Kernel (RTOS kernel) https://github.com/FreeRTOS/FreeRTOS-Kernel FreeRTOS+TCP (TCP/IP stack) https://github.com/FreeRTOS/FreeRTOS-Plus-TCP coreMQTT-Agent (multi-threaded MQTT client) https://github.com/FreeRTOS/coreMQTT-Agent (includes coreMQTT) coreMQTT (base MQTT client) https://github.com/FreeRTOS/coreMQTT coreHTTP (HTTP client) https://github.com/FreeRTOS/coreHTTP corePKCS11 (software mock of PKCS#11) https://github.com/FreeRTOS/corePKCS11 coreJSON (JSON) https://github.com/FreeRTOS/coreJSON coreSNTP (SNTP) https://github.com/FreeRTOS/coreSNTP AWS IoT Device Shadow https://github.com/aws/device-shadow-for-aws-iot-embedded-sdk AWS IoT OTA https://github.com/aws/ota-for-aws-iot-embedded-sdk AWS IoT Jobs https://github.com/aws/jobs-for-aws-iot-embedded-sdk AWS IoT Device Defender https://github.com/aws/device-defender-for-aws-iot-embedded-sdk Main features # Preemptive or cooperative real-time kernel Tiny memory footprint (less than 10 KB ROM) and easy scalable Includes a tickless mode for low power applications Synchronization and inter-task communication using message queues binary and counting semaphores mutexes group events (flags) stream buffer Hardware timer or Software timer for tasks scheduling Execution trace functionality CMSIS-RTOS API port Used resources # Core resources: Hardware System Timer ( SysTick ) \u2014 generate system time (time slice) Two stack pointers: MSP for main RTOS and ISR, PSP for Tasks Interrupt vectors: SVC \u2014 Supervisor call to access privileged resources (like SWI in ARM7) PendSV \u2014 Pendable System Call for context switching SysTick \u2014 Hardware system timer for scheduling Memory: Flash: 6-10 KB Flash + RAM memory: 0.5 KB + task stacks Main source files # File Description task.c ask functions and utilities definition list.c List implementation used by the scheduler queue.c Queue implementation used by tasks timers.c Software timers functions definition port.c Low level functions supporting SysTick timer, context switch, interrupt management on low HW level \u2014 strongly depends on the platform (core and SW tool set). Mostly written in assembly FreeRTOS.h Configuration file which collect whole FreeRTOS sources heap_x.c Different implementation of dynamic memory management coroutine.c Co-routines functions definitions. Efficient in 8 and 16bit architecture. In 32bit architecture usage of tasks is suggested event_groups.c Flags to notify tasks about am event Memory Management # FreeRTOS uses a region of memory called Heap (into the RAM) to allocate memory for tasks, queues, timers, semaphores, mutexes and when dynamically creating variables. FreeRTOS heap is different from the system heap defined at the compiler level. When FreeRTOS requires RAM, instead of calling the standard malloc() , it calls PvPortMalloc() . When it needs to free memory it calls PvPortFree() instead of the standard free() . FreeRTOS offers several heap management schemes that range in complexity and features. The FreeRTOS download includes five sample memory allocation implementations, each of which are described in the following subsections. The subsections also include information on when each of the provided implementations might be the most appropriate to select. Heap management schemes: heap_1 \u2014 the very simplest, does not permit memory to be freed. heap_2 \u2014 permits memory to be freed, but does not coalescence adjacent free blocks. heap_3 \u2014 simply wraps the standard malloc() and free() for thread safety. heap_4 \u2014 coalescence adjacent free blocks to avoid fragmentation. Includes absolute address placement option. heap_5 \u2014 as per heap_4 , with the ability to span the heap across multiple non-adjacent memory areas. Notes: heap_1 is less useful since FreeRTOS added support for static allocation. heap_2 is now considered as the legacy method because the newer heap_4 implementation is preferred. For more detail, refer to RTOS Memory Management . Overridden Interrupts # PendSV interrupt Used for task switching before tick rate Lowest NVIC interrupt priority Not triggered by any peripheral SVC interrupt Interrupt risen by SVC instruction SVC 0 call used only once, to start the scheduler (within vPortStartFirstTask() which is used to start the kernel) SysTick timer Lowest NVIC interrupt priority Used for task switching on configTICK_RATE_HZ regular time base Set PendSV if context switch is necessary API conventions # Prefixes at variable names: c \u2014 char / s \u2014 short / l \u2014 long / u \u2014 unsigned x \u2014 portBASE_TYPE defined in portmacro.h for each platform (in STM32 it is long) p \u2014 pointer Functions name structure: prefix + filename + function name . For example: vTaskPrioritySet() . Prefixes at macros defines their definition location and names. For example: portMAX_DELAY","title":"RTOS Overview and FreeRTOS introduction"},{"location":"blog/freertos/overview/#real-time-operating-system","text":"The main purpose of an OS is to have the functionality, of running multiple tasks at the same time, which obviously isn\u2019t possible with bare metal. Multitask Execution A Real-time Operating System (RTOS) is designed to do manage different tasks to guarantee that all critical operations must be performed on time, and within a given time. Critical operations include: Exceptions and Interrupts Prioritized functions Scheduling Having a RTOS system means: Timeliness is more important than performance It\u2019s guaranteed on data processing within a timing constraint Hard real-time functions must complete within a given time The core of a RTOS is an advanced algorithm for scheduling , with the key factors are minimal interrupt latency and minimal thread switching latency . Examples of RTOS system: VxWorks QNX Neutrino FreeRTOS Azure RTOS (ThreadX) Integrity RTOS embOS","title":"Real-time Operating System"},{"location":"blog/freertos/overview/#a-task","text":"A Task is a piece of code, or a function, that does a specific job when it is allowed to run. A Task has its own Stack to create its local variables. Its stack can be used to store addition information which is needed to save or restore the task from running state. Usually, a task is an infinite loop which can repeatedly do multiple steps. void task_main ( void * param ) { // init task ... // main loop while ( 1 ) { // do things over and over } } A Task should be put into some states: INACTIVE : not to be run READY : in queue to be run RUNNING : is being executed WAITING or BLOCKED : is paused, put in run queue, but not to be run in next time slot","title":"A Task"},{"location":"blog/freertos/overview/#the-scheduler","text":"This is the core of an RTOS, which decides which task will be run in next time slot. Some types of a scheduler: Cooperative : task by task, each task does its work until it finishes Round-robin : each task has a time slice to run, there is no priority for task execution Pre-emptive/ Priority-based : task has priority which has high number can interrupt the running task and takes place of execution Round-robin scheduler Priority-based scheduler A simple Round-robin Scheduler In this guide A simple implementation of a Task Scheduler , we have understood about how a Round-robin Scheduler works with its main reponsibilities: Run a task Select a next task to be run Switch tasks Priority Inversion In Pre-emptive RTOS, when a High Priority task is waiting for a Low Priority task to run because the Low Priority is blocked by a shared resource that High Priority is also depent on.","title":"The Scheduler"},{"location":"blog/freertos/overview/#the-systick","text":"SysTick is a part of the ARM Core, that counts down from the reload value to zero, and fire an interrupt to make a periodical event. SysTick is mainly used for delay function in non-RTOS firmware, and is used as the timing interrupt for RTOS scheduler. SysTick is also used as countable time span of a waiting task. For example, a task need to read an input, and it should wait for 50 ms, if nothing comes, task should move to other work. This task will use SysTick, which is fired every 1 ms, to count up a waiting counter, if the counter reaches 50 ticks, task quits the waiting loop and runs other code. Non-blocking delay Using SysTick as a counter, a task can be moved to the BLOCKED state and it can not run until the waiting period is over. See a simple implementation of non-blocking delay in the example A simple implementation of a Task Scheduler .","title":"The SysTick"},{"location":"blog/freertos/overview/#memory-allocation","text":"Real time operating system supports static and dynamic memory allocation, with different strategies and algorithm. Creating RTOS objects dynamically has the benefit of greater simplicity, and the potential to minimize the application\u2019s maximum RAM usage: The memory allocation occurs automatically. The RAM used by an RTOS object can be re-used if the object is deleted. The memory allocation scheme used can be chosen to the best suite the application. Creating RTOS objects using statically allocated RAM has the benefit of providing the application more control: RTOS objects can be placed at specific memory locations. It allows the RTOS to be used in applications that simply don\u2019t allow any dynamic memory allocation. Avoid memory-related issues such as leak memory, dangling pointer, and undefined objects. Memory layout in FreeRTOS","title":"Memory Allocation"},{"location":"blog/freertos/overview/#shared-memory","text":"Tasks are usually a work to do in a loop, and it thinks it can control all resource. In a system, there are many tasks run together, and in many cases, they work with condition from others. Inter-task communication is defined as some type: Signal : tell other task to start doing something, to synchronize tasks Message Queue/Mailbox : send data between tasks Mutex/Semaphore : synchronize access to a shared resource, lock resource which is in-use Queue between tasks Signal between tasks Shared resource between tasks","title":"Shared Memory"},{"location":"blog/freertos/overview/#freertos","text":"FreeRTOS is a market-leading real-time operating system (RTOS) for microcontrollers and small microprocessors. Distributed freely under the MIT open source license, FreeRTOS includes a kernel and a growing set of IoT libraries suitable for use across all industry sectors. FreeRTOS is built with an emphasis on reliability and ease of use. FreeRTOS provides methods for multiple threads or tasks, mutexes, semaphores and software timers. Thread priorities are supported. FreeRTOS applications can be statically allocated, but objects can also be dynamically allocated with five schemes of memory management (allocation). A tickless mode is provided for low power applications. SafeRTOS The Safety functionality is not guaranteed in FreeRTOS as it is not the main focus of the free version. FreeRTOS is designed to be small and simple.","title":"FreeRTOS"},{"location":"blog/freertos/overview/#integration","text":"FreeRTOS is designed to be run on many MCUs, therefore, it defines interfaces which will be implemented on a target MCU platform. For ARM cores, CMSIS also has a porting layer for FreeRTOS. Download the source code of RTOS from FreeRTOS . FreeRTOS and LTS support A normal release of FreeRTOS includes Kernel, Libraries, and examples, A LTS version only contains the Kernel and IoT libraries. Library Git repo (including zip download) FreeRTOS Kernel (RTOS kernel) https://github.com/FreeRTOS/FreeRTOS-Kernel FreeRTOS+TCP (TCP/IP stack) https://github.com/FreeRTOS/FreeRTOS-Plus-TCP coreMQTT-Agent (multi-threaded MQTT client) https://github.com/FreeRTOS/coreMQTT-Agent (includes coreMQTT) coreMQTT (base MQTT client) https://github.com/FreeRTOS/coreMQTT coreHTTP (HTTP client) https://github.com/FreeRTOS/coreHTTP corePKCS11 (software mock of PKCS#11) https://github.com/FreeRTOS/corePKCS11 coreJSON (JSON) https://github.com/FreeRTOS/coreJSON coreSNTP (SNTP) https://github.com/FreeRTOS/coreSNTP AWS IoT Device Shadow https://github.com/aws/device-shadow-for-aws-iot-embedded-sdk AWS IoT OTA https://github.com/aws/ota-for-aws-iot-embedded-sdk AWS IoT Jobs https://github.com/aws/jobs-for-aws-iot-embedded-sdk AWS IoT Device Defender https://github.com/aws/device-defender-for-aws-iot-embedded-sdk","title":"Integration"},{"location":"blog/freertos/overview/#main-features","text":"Preemptive or cooperative real-time kernel Tiny memory footprint (less than 10 KB ROM) and easy scalable Includes a tickless mode for low power applications Synchronization and inter-task communication using message queues binary and counting semaphores mutexes group events (flags) stream buffer Hardware timer or Software timer for tasks scheduling Execution trace functionality CMSIS-RTOS API port","title":"Main features"},{"location":"blog/freertos/overview/#used-resources","text":"Core resources: Hardware System Timer ( SysTick ) \u2014 generate system time (time slice) Two stack pointers: MSP for main RTOS and ISR, PSP for Tasks Interrupt vectors: SVC \u2014 Supervisor call to access privileged resources (like SWI in ARM7) PendSV \u2014 Pendable System Call for context switching SysTick \u2014 Hardware system timer for scheduling Memory: Flash: 6-10 KB Flash + RAM memory: 0.5 KB + task stacks","title":"Used resources"},{"location":"blog/freertos/overview/#main-source-files","text":"File Description task.c ask functions and utilities definition list.c List implementation used by the scheduler queue.c Queue implementation used by tasks timers.c Software timers functions definition port.c Low level functions supporting SysTick timer, context switch, interrupt management on low HW level \u2014 strongly depends on the platform (core and SW tool set). Mostly written in assembly FreeRTOS.h Configuration file which collect whole FreeRTOS sources heap_x.c Different implementation of dynamic memory management coroutine.c Co-routines functions definitions. Efficient in 8 and 16bit architecture. In 32bit architecture usage of tasks is suggested event_groups.c Flags to notify tasks about am event","title":"Main source files"},{"location":"blog/freertos/overview/#memory-management","text":"FreeRTOS uses a region of memory called Heap (into the RAM) to allocate memory for tasks, queues, timers, semaphores, mutexes and when dynamically creating variables. FreeRTOS heap is different from the system heap defined at the compiler level. When FreeRTOS requires RAM, instead of calling the standard malloc() , it calls PvPortMalloc() . When it needs to free memory it calls PvPortFree() instead of the standard free() . FreeRTOS offers several heap management schemes that range in complexity and features. The FreeRTOS download includes five sample memory allocation implementations, each of which are described in the following subsections. The subsections also include information on when each of the provided implementations might be the most appropriate to select. Heap management schemes: heap_1 \u2014 the very simplest, does not permit memory to be freed. heap_2 \u2014 permits memory to be freed, but does not coalescence adjacent free blocks. heap_3 \u2014 simply wraps the standard malloc() and free() for thread safety. heap_4 \u2014 coalescence adjacent free blocks to avoid fragmentation. Includes absolute address placement option. heap_5 \u2014 as per heap_4 , with the ability to span the heap across multiple non-adjacent memory areas. Notes: heap_1 is less useful since FreeRTOS added support for static allocation. heap_2 is now considered as the legacy method because the newer heap_4 implementation is preferred. For more detail, refer to RTOS Memory Management .","title":"Memory Management"},{"location":"blog/freertos/overview/#overridden-interrupts","text":"PendSV interrupt Used for task switching before tick rate Lowest NVIC interrupt priority Not triggered by any peripheral SVC interrupt Interrupt risen by SVC instruction SVC 0 call used only once, to start the scheduler (within vPortStartFirstTask() which is used to start the kernel) SysTick timer Lowest NVIC interrupt priority Used for task switching on configTICK_RATE_HZ regular time base Set PendSV if context switch is necessary","title":"Overridden Interrupts"},{"location":"blog/freertos/overview/#api-conventions","text":"Prefixes at variable names: c \u2014 char / s \u2014 short / l \u2014 long / u \u2014 unsigned x \u2014 portBASE_TYPE defined in portmacro.h for each platform (in STM32 it is long) p \u2014 pointer Functions name structure: prefix + filename + function name . For example: vTaskPrioritySet() . Prefixes at macros defines their definition location and names. For example: portMAX_DELAY","title":"API conventions"},{"location":"blog/freertos/priority/","tags":["arm","freertos"],"text":"Priority # Priority is the key which is informed to the operating system about the importance of a task and the order in which a group of waiting tasks needs to execute. MCU runs user tasks in Thread Mode, interrupt handlers in Handler mode, thus there are two types of Priority. Interrupt Priority # Lower Interrupt Priority Value means higher Interrupt Priority Level __NVIC_PRIO_BITS defines some bits used for Priority Levels. The lowest Interrupt priority is set by configLIBRARY_LOWEST_INTERRUPT_PRIORITY The maximum Interrupt priority is set by configLIBRARY_MAX_SYSCALL_INTERRUPT_PRIORITY \u2192 Priority of a peripheral interrupt should be between them. configKERNEL_INTERRUPT_PRIORITY decides the priority for the kernel interrupts: SysTick : scheduler\u2019s tick PendSV : context switcher SVC : superior call Refer to System-Call Exception . configMAX_SYSCALL_INTERRUPT_PRIORITY decides the maximum priority for APIs that is called from an ISR. FreeRTOS APIs ending with FromISR are interrupt safe, but even these APIs should not be called from ISRs having priority above the priority defined by configMAX_SYSCALL_INTERRUPT_PRIORITY . \u2192 Any ISR that uses RTOS APIs must have priority manually set to a number being equal or greater than configMAX_SYSCALL_INTERRUPT_PRIORITY . Interrupt Safe APIs # FreeRTOS APIs ending with the work FromISR are safe to be called from an ISR. FreeRTOS APIs which do not end with the work FromISR are unsafe to be called from an ISR. Why do we have 2 flavors of the same function? Let\u2019s take an example of changing task in ISR: void ISR_Func () { xTaskGenericNotify (); } void xTaskGenericNotify () { 1. write notification value 2. unblock a higher priorty task ? 2.1 . yes --> do taskYIELD --> Usage Fault Exception } During the ISR function, Task Notification changes the current task to a higher priority task. However, the processor is in the Handler Mode (during ISR), it is NOT ALLOWED to switch to Thread Mode if ISR is not returned. Task Priority # Lower Task Priority Value means lower Task Priority Level In FreeRTOS, task priority is the opposite of interrupt priority. Each task is assigned a priority from 0 to ( configMAX_PRIORITIES - 1), where configMAX_PRIORITIES is defined within FreeRTOSConfig.h . If configUSE_PORT_OPTIMISED_TASK_SELECTION = 1 , an optimized task selection mechanism will use a \u2018count leading zeros\u2019 type instruction (for task selection in a single instruction). In this case, configMAX_PRIORITIES cannot be higher than 32. Low priority numbers denote low priority tasks. The idle task has priority zero ( tskIDLE_PRIORITY ). The FreeRTOS scheduler ensures that tasks in the Ready or Running state will always be given processor (CPU) time in preference to tasks of a lower priority that are also in the ready state. In other words, the task placed into the Running state is always the highest priority task that is able to run. Any number of tasks can share the same priority. If configUSE_TIME_SLICING is not defined, or if configUSE_TIME_SLICING is set to 1, then Ready state tasks of equal priority will share the available processing time using a time sliced round-robin scheduling scheme. Priority Inversion # Original post at Part 11 (Priority Inversion) . Credit to digikey.com . Furter reading in How to use priority inheritance . Priority inversion is a bug that occurs when a high priority task is indirectly preempted by a low priority task. For example, the low priority task holds a lock that the high priority task must wait for to continue executing. How it happens # In the simple case, the high priority task (Task H) would be blocked as long as the low priority task (Task L) held the lock. This is known as \u201cbounded priority inversion,\u201d as the length of time of the inversion is bounded by however long the low priority task is in the critical section (holding the lock). Unbounded priority inversion occurs when a medium priority task (Task M) interrupts Task L while it holds the lock. It\u2019s called \u201cunbounded\u201d because Task M can now effectively block Task H for any amount of time, as Task M is preempting Task L (which still holds the lock). Solution for unbounded priority inversion # There are a few ways to combat unbounded priority inversion. Two popular methods include priority ceiling protocol and priority inheritance. Priority ceiling protocol # Priority ceiling protocol involves assigning a \u201cpriority ceiling level\u201d to each resource or lock. Whenever a task works with a particular resource or takes a lock, the task\u2019s priority level is automatically boosted to that of the priority ceiling associated with the lock or resource. The priority ceiling is determined by the maximum priority of any task that needs to use the resource or lock. Example: As the priority ceiling of the lock is 3, whenever Task L takes the lock, its priority is boosted to 3 so that it will run at the same priority as Task H. This prevents Task M (priority 2) from running until Tasks L and H are done with the lock. Priority inheritance # Priority inheritance involves boosting the priority of a task holding a lock to that of any other (higher priority) task that tries to take the lock. Example: Task L takes the lock. Only when Task H attempts to take the lock is the priority of Task L boosted to that of Task H\u2019s. Once again, Task M can no longer interrupt Task L until both tasks are finished in the critical section. In both priority ceiling protocol and priority inheritance, Task L\u2019s priority is dropped back to its original level once it releases the lock. Also note that both systems only prevent unbounded priority inversion. Bounded priority inversion can still occur. Mutex vs Binary Semaphore Most of RTOS, including FreeRTOS, mutex is implemented with Priority Inheritance. Solution for bounded priority inversion # We can only avoid or mitigate bounded priority inversion through good programming practices. Some possible tips include (pick and choose based on your project\u2019s need): Keep critical sections short to cut down on bounded priority inversion time Avoid using critical sections or locking mechanisms that can block a high priority task Use one task to control a shared resource to avoid the need to create locks to protect it To demonstrate the last point, we could use a \u201cservice task\u201d that was in charge of managing a shared resource. For example, we could use queues to send and receive messages from a task that handled the serial port. Hard blocking critical section Using Semaphore/ Mutex may not totally prevent priority inversion. There is a crude way to hardly block the critical section when it is running: disabling interrupts and scheduler. FreeRTOS provides two functions to enter and exit critical session: taskENTER_CRITICAL() taskEXIT_CRITICAL()","title":"Priority - a key for Scheduler"},{"location":"blog/freertos/priority/#priority","text":"Priority is the key which is informed to the operating system about the importance of a task and the order in which a group of waiting tasks needs to execute. MCU runs user tasks in Thread Mode, interrupt handlers in Handler mode, thus there are two types of Priority.","title":"Priority"},{"location":"blog/freertos/priority/#interrupt-priority","text":"Lower Interrupt Priority Value means higher Interrupt Priority Level __NVIC_PRIO_BITS defines some bits used for Priority Levels. The lowest Interrupt priority is set by configLIBRARY_LOWEST_INTERRUPT_PRIORITY The maximum Interrupt priority is set by configLIBRARY_MAX_SYSCALL_INTERRUPT_PRIORITY \u2192 Priority of a peripheral interrupt should be between them. configKERNEL_INTERRUPT_PRIORITY decides the priority for the kernel interrupts: SysTick : scheduler\u2019s tick PendSV : context switcher SVC : superior call Refer to System-Call Exception . configMAX_SYSCALL_INTERRUPT_PRIORITY decides the maximum priority for APIs that is called from an ISR. FreeRTOS APIs ending with FromISR are interrupt safe, but even these APIs should not be called from ISRs having priority above the priority defined by configMAX_SYSCALL_INTERRUPT_PRIORITY . \u2192 Any ISR that uses RTOS APIs must have priority manually set to a number being equal or greater than configMAX_SYSCALL_INTERRUPT_PRIORITY .","title":"Interrupt Priority"},{"location":"blog/freertos/priority/#interrupt-safe-apis","text":"FreeRTOS APIs ending with the work FromISR are safe to be called from an ISR. FreeRTOS APIs which do not end with the work FromISR are unsafe to be called from an ISR. Why do we have 2 flavors of the same function? Let\u2019s take an example of changing task in ISR: void ISR_Func () { xTaskGenericNotify (); } void xTaskGenericNotify () { 1. write notification value 2. unblock a higher priorty task ? 2.1 . yes --> do taskYIELD --> Usage Fault Exception } During the ISR function, Task Notification changes the current task to a higher priority task. However, the processor is in the Handler Mode (during ISR), it is NOT ALLOWED to switch to Thread Mode if ISR is not returned.","title":"Interrupt Safe APIs"},{"location":"blog/freertos/priority/#task-priority","text":"Lower Task Priority Value means lower Task Priority Level In FreeRTOS, task priority is the opposite of interrupt priority. Each task is assigned a priority from 0 to ( configMAX_PRIORITIES - 1), where configMAX_PRIORITIES is defined within FreeRTOSConfig.h . If configUSE_PORT_OPTIMISED_TASK_SELECTION = 1 , an optimized task selection mechanism will use a \u2018count leading zeros\u2019 type instruction (for task selection in a single instruction). In this case, configMAX_PRIORITIES cannot be higher than 32. Low priority numbers denote low priority tasks. The idle task has priority zero ( tskIDLE_PRIORITY ). The FreeRTOS scheduler ensures that tasks in the Ready or Running state will always be given processor (CPU) time in preference to tasks of a lower priority that are also in the ready state. In other words, the task placed into the Running state is always the highest priority task that is able to run. Any number of tasks can share the same priority. If configUSE_TIME_SLICING is not defined, or if configUSE_TIME_SLICING is set to 1, then Ready state tasks of equal priority will share the available processing time using a time sliced round-robin scheduling scheme.","title":"Task Priority"},{"location":"blog/freertos/priority/#priority-inversion","text":"Original post at Part 11 (Priority Inversion) . Credit to digikey.com . Furter reading in How to use priority inheritance . Priority inversion is a bug that occurs when a high priority task is indirectly preempted by a low priority task. For example, the low priority task holds a lock that the high priority task must wait for to continue executing.","title":"Priority Inversion"},{"location":"blog/freertos/priority/#how-it-happens","text":"In the simple case, the high priority task (Task H) would be blocked as long as the low priority task (Task L) held the lock. This is known as \u201cbounded priority inversion,\u201d as the length of time of the inversion is bounded by however long the low priority task is in the critical section (holding the lock). Unbounded priority inversion occurs when a medium priority task (Task M) interrupts Task L while it holds the lock. It\u2019s called \u201cunbounded\u201d because Task M can now effectively block Task H for any amount of time, as Task M is preempting Task L (which still holds the lock).","title":"How it happens"},{"location":"blog/freertos/priority/#solution-for-unbounded-priority-inversion","text":"There are a few ways to combat unbounded priority inversion. Two popular methods include priority ceiling protocol and priority inheritance.","title":"Solution for unbounded priority inversion"},{"location":"blog/freertos/priority/#priority-ceiling-protocol","text":"Priority ceiling protocol involves assigning a \u201cpriority ceiling level\u201d to each resource or lock. Whenever a task works with a particular resource or takes a lock, the task\u2019s priority level is automatically boosted to that of the priority ceiling associated with the lock or resource. The priority ceiling is determined by the maximum priority of any task that needs to use the resource or lock. Example: As the priority ceiling of the lock is 3, whenever Task L takes the lock, its priority is boosted to 3 so that it will run at the same priority as Task H. This prevents Task M (priority 2) from running until Tasks L and H are done with the lock.","title":"Priority ceiling protocol"},{"location":"blog/freertos/priority/#priority-inheritance","text":"Priority inheritance involves boosting the priority of a task holding a lock to that of any other (higher priority) task that tries to take the lock. Example: Task L takes the lock. Only when Task H attempts to take the lock is the priority of Task L boosted to that of Task H\u2019s. Once again, Task M can no longer interrupt Task L until both tasks are finished in the critical section. In both priority ceiling protocol and priority inheritance, Task L\u2019s priority is dropped back to its original level once it releases the lock. Also note that both systems only prevent unbounded priority inversion. Bounded priority inversion can still occur. Mutex vs Binary Semaphore Most of RTOS, including FreeRTOS, mutex is implemented with Priority Inheritance.","title":"Priority inheritance"},{"location":"blog/freertos/priority/#solution-for-bounded-priority-inversion","text":"We can only avoid or mitigate bounded priority inversion through good programming practices. Some possible tips include (pick and choose based on your project\u2019s need): Keep critical sections short to cut down on bounded priority inversion time Avoid using critical sections or locking mechanisms that can block a high priority task Use one task to control a shared resource to avoid the need to create locks to protect it To demonstrate the last point, we could use a \u201cservice task\u201d that was in charge of managing a shared resource. For example, we could use queues to send and receive messages from a task that handled the serial port. Hard blocking critical section Using Semaphore/ Mutex may not totally prevent priority inversion. There is a crude way to hardly block the critical section when it is running: disabling interrupts and scheduler. FreeRTOS provides two functions to enter and exit critical session: taskENTER_CRITICAL() taskEXIT_CRITICAL()","title":"Solution for bounded priority inversion"},{"location":"blog/freertos/reentrant/","tags":["arm","freertos","stm32"],"text":"STM32-Tutorials Reentrant # Reentrant is an attribute of a piece of code and basically means it can be re-entered by another execution flow, for example by an interrupt or by another task or thread. Generally speaking, a function produces output data based on some input data (though both are optional, in general). Shared data could be accessed by any function at any time. If data can be changed by any function (and none keep track of those changes), there is no guarantee to those that share a datum that that datum is the same as at any time before. Data has a characteristic called scope, which describes where in a program the data may be used. Data scope is either global (outside the scope of any function and with an indefinite extent) or local (created each time a function is called and destroyed upon exit). Local data is not shared by any routines, re-entering or not; therefore, it does not affect re-entrance. Global data is defined outside functions and can be accessed by more than one function, either in the form of global variables (data shared between all functions), or as static variables (data shared by all invocations of the same function). Reentrant is distinct from, but closely related to, thread-safety. A function can be thread-safe and still not reentrant. Rules for reentrant # Reentrant code may not hold any static or global non-constant data. Reentrant code may not modify itself. Reentrant code may not call non-reentrant computer programs or routines. Examples # Two functions below are reentrant: int f ( int i ) { return i + 2 ; } int g ( int i ) { return f ( i ) + 2 ; } However, if f() depends on non-constant global variable, both functions become non-reentrant, such as: int v = 1 ; int f ( int i ) { v += i ; return v ; } int g ( int i ) { return f ( i ) + 2 ; } Some functions are thread-safe, but not reentrant, such as below function. function() can be called by different threads without any problem. But, if the function is used in a reentrant interrupt handler and a second interrupt arises inside the function, the second routine will hang forever. int function () { mutex_lock (); { // function body } mutex_unlock (); } Newlib implementation # GNU ARM libraries use Newlib to provide standard implementation of C libraries. However, to reduce the code size and make it independent to hardware, there is a lightweight version Newlib-nano used in MCUs. The Newlib library maps standard C functions to a specific implementation environment through a chain of functions, for example: write() invokes _write_r() with the current reentrant context (e.g. thread/task-unique errno ); _write_r() invokes _write() and copies errno appropriately; _write() must be provided by something. By default, the Newlib-nano library does not provide an implementation of low-level system calls which are used by C standard libraries, such as _write() or _read() . To make the application compilable, a new library named nosys (enabled with -specs=nosys.specs to the gcc linker command line) should be added. This library just provide a simple implementation of low-level system calls which mostly return a by-pass value. CubeMX, with nosys , will generate syscalls.c and sysmem.c to provide low-level implementation for Newlib-nano interface: Function and data object definitions : char __ environ ; int _chown ( const char * path , uid_t owner , gid_t group ); int_execve ( const char * filename , char * const argv [], char * const envp []); pid_t _fork ( void ); pid_t _getpid ( void ); int _gettimeofday ( struct timeval * tv , struct timezone * tz ); int _kill ( pid_t pid , int sig ); int _link ( const char * oldpath , const char * newpath ); ssize_t _readlink ( const char * path , char * buf , size_t bufsiz ); int _stat ( const char * path , struct stat * buf ); int _symlink ( const char * oldpath , const char * newpath ); clock_t _times ( struct tms * buf ); int _unlink ( const char * pathname ); pid_t _wait ( int * status ); void _exit ( int status ); File Descriptor Operations : int _close ( int fd ); int _fstat ( int fd , struct stat * buf ); int _isatty ( int fd ); off_t _lseek ( int fd , off_t offset , int whence ); int _open ( const char * pathname , int flags ); ssize_t _read ( int fd , void * buf , size_t count ); ssize_t _write ( int fd , const void * buf , size_t count ); Heap Management : void * _sbrk ( ptrdiff_t increment ); Newlib reentrant # The Newlib library does support reentrant, but for Newlib-nano , the reentrant attribute depends on how its interfaces are implemented. The most concerned functions of reentrant support are malloc() and free() which directly are related to dynamic memory management. If these functions are not reentrant, the information of memory layout will be messed up if there are multiple calls to malloc() or free() at a time. Newlib maintains information it needs to support each separate context (thread/task/ISR) in a reentrant structure . This includes things like a thread-specific errno , thread-specific pointers to allocated buffers , etc. The active reentrant structure is pointed at by global pointer _impure_ptr , which initially points to a statically allocated structure instance. Newlib requires below things to complete its reentrant: Switching context. Multiple reentrant structures (one per context) must be created, initialized, cleaned and pointing upon _impure_ptr to the correct context each time the context is switching Concurrency protection. For example of using malloc() , it should be lock() and unlock() in that function to make it thread-safe first FreeRTOS supports Newlib reentrant # Newlib support has been included by popular demand, but is not used by the FreeRTOS maintainers themselves. Switching context # FreeRTOS provides support for Newlib\u2019s context management. In FreeRTOSconfig.h , add: /* The following flag must be enabled only when using Newlib */ #define configUSE_NEWLIB_REENTRANT 1 By default, STM32 projects generated by STM32CubeIDE use Newlib-nano . Whenever FreeRTOS is enabled, IDE will prompt to enable Newlib Reentrant attribute: A prompt asking to enable Newlib reentrant With this option configUSE_NEWLIB_REENTRANT = 1 , FreeRTOS does the following (in task.c ): For each task, allocate and initialize a Newlib reentrant structure in the task control block Each task switch, set _impure_ptr to point to the newly active task\u2019s reentrant structure On task destruction, clean up the reentrant structure (help Newlib free any associated memory) Concurrency protection # There is one more thing to fully support Newlib reentrant: FreeRTOS Memory Management. FreeRTOS internally uses its own memory management scheme with different heap management implementations in heap_x.c , such as heap_1.c , or heap_4.c . If an application only uses FreeRTOS-provided memory management APIs such as pvPortMalloc() and vPortFree() , this application is safe for Newlib reentrant, because FreeRTOS suspends the task-switching and interrupts during memory management . However, many third party libraries do use the standard C malloc() and free() functions. For those cases, the concurrency protection is not guaranteed. That is the reason that Dave Nadler implemented a new heap scheme for Newlib in FreeRTOS. Details in https://nadler.com/embedded/newlibAndFreeRTOS.html FreeRTOS in STM32CubeMX The FreeRTOS version shipped in STM32CubeMX does not fully resolve Memory Management for Newlib. Dave Nadler provides a version for STM32 at heap_useNewlib_ST.c . The usage will be covered in a below section. Non-reentrant cause corrupted output # F411RE_FreeRTOS_Non-Reentrant.zip This example project demonstrates an issue when using printf() function without reentrant enabled for Newlib in FreeRTOS. In that case, the data printed out is corrupted. To setup the project faster, we use STM32CubeMX to configure the projects and generate the source code. Project setup # Let\u2019s create a new FreeRTOS application using STM32CubeMX with below settings: FreeRTOS is enabled with configs: CMSIS-RTOS version: 2.00 FreeRTOS version: 10.3.1 USE_PREEMPTION : Enabled MINIMAL_STACK_SIZE : 256 Words = 1024 Bytes USE_MUTEXES : Enabled Memory Management Scheme: heap_4 Time base Source for HAL is moved to a general timer, such as TIM10 or TIM11 on STM32F411RE. Newlib setting: USE_NEWLIB_REENTRANT : Disabled Create 2 printing tasks # Add 2 tasks: printTask1 and printTask2 which call to a the same function PrintTask but with different input messages message1 and message2 . Note that two tasks have the same priority. Add 2 printing tasks Create a Mutex # We will protect the standard output with a Mutext to ensure that at one time, there is only one Task can print out. Add a mutex for write access Define messages and print out # Two different messages will be prepared. To make the issue happens, the length of messages will be chosen to be long enough, such as 64 bytes. char * message1 = \"................................................................\" ; char * message2 = \"++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\" ; The function PrintTask() will print out a message along with the task name, the Reentrant config, an increasing counter to see new messages clearly. #include \"FreeRTOSConfig.h\" void PrintTask ( void * argument ) { char * name = pcTaskGetName ( NULL ); char * message = ( char * ) argument ; char counter = 0 ; for (;;) { printf ( \"RE=%d %s: %03d %s \\r\\n \" , configUSE_NEWLIB_REENTRANT , name , counter ++ , message ); osDelay ( 500 ); } } Redirect Standard Output to SWV # A final step is to redirect printed data to an SWO port. In this function, before printing out, we request to acquire the mutex. When the printing is done, we release the mutex. int _write ( int file , char * ptr , int len ) { osStatus_t ret ; // wait for other to complete printing ret = osMutexAcquire ( writeAccessMutexHandle , osWaitForever ); if ( ret == osOK ) { int DataIdx ; for ( DataIdx = 0 ; DataIdx < len ; DataIdx ++ ) { ITM_SendChar ( * ptr ++ ); } // done our job osMutexRelease ( writeAccessMutexHandle ); } return len ; } Compile and Run # Build the project and run a target board, the output will be messed up as it can be seen that characters in the messages1 is printed in the line of the messages2 . Output of Task 2 is corrupted Debug # We should find out how the issue happened. Place a breakpoint at the beginning of the function _write to check the passing argument char *ptr . Step 1 : Task 2 starts to write, Task 1 has not started yet Task 2 runs to the _write() function with the argument char *ptr at the address 0x20005210 . Task 2 prints the message at 0x20005210 Step 2 : Task 2 is interrupted by Task 1, Task 1 starts to write When Task 1 runs the _write() function with the argument char *ptr , we notice that the address is still 0x20005210 , but the message at that location is changed. Task 1 prints the message which replaces the content of the Task 2\u2019s message Step 3 : Task 1 is interrupted by Task 2, Task 2 resumes printing At this step, the content at the address 0x20005210 was overwritten by Task 1, therefore Task 2 will print out corrupted data. Turn on Newlib reentrant # Still use the above project, but we set the configuration configUSE_NEWLIB_REENTRANT = 1 . Recompile and run the project, the issue is fixed. Different outputs on different reentrant settings RE Debug # Place a breakpoint at the beginning of the function _write to check the passing argument char *ptr . Step 1 : Task 2 starts to write, Task 1 has not started yet Task 2 runs to the _write() function with the argument char *ptr at the address 0x20005488 . Task 2 prints the message at 0x20005488 Step 2 : Task 2 is interrupted by Task 1, Task 1 starts to write When Task 1 runs the _write() function with the argument char *ptr , we notice that the address is changed to 0x20005a40 . Task 1 prints the message at 0x20005a40 Step 3 : Task 1 is interrupted by Task 2, Task 2 resumes printing At this step, the content at the address 0x20005488 was unchanged therefore Task 2 will print out correct data. Integrate Newlib memory scheme # F411RE_FreeRTOS_Reentrant_Heap_Newlib.zip As mentioned above, Dave Nadler provides a version for STM32 at heap_useNewlib_ST.c . It is not officially supported by ST. A method to ensure thread-safe for malloc() and free() is to wrap Newlib malloc-like functions to use FreeRTOS\u2019s porting memory management functions. However, FreeRTOS heap implementations do not support realloc() . The heap_usNewlib_ST scheme chooses another method to solve malloc-like functions\u2019 thread-safe. This memory scheme implements thread-safe for malloc() and free() in Newlib, and then overwrites FreeRTOS\u2019s memory function to use Newlib\u2019s functions. Here are step to integrate heap_usNewlib_ST into STM32 project: Exclude sysmem.c file from build. This file provides an implementation of _sbrk() which is used by malloc() Exclude FreeRTOS heap management such as heap_4.c which implements pvPortMalloc() and vPortFree() Include heap_useNewlib_ST.c to project. Define 2 configs below to support ISR stack check #define configISR_STACK_SIZE_WORDS (128) // in words #define configSUPPORT_ISR_STACK_CHECK ( 1 ) Set reentrant support #define configUSE_NEWLIB_REENTRANT ( 1 ) References # FreeRTOS Memory Management: https://www.freertos.org/a00111.html Newlib interface: http://pabigot.github.io/bspacm/newlib.html Newlib FreeRTOS Memory Management: https://nadler.com/embedded/newlibAndFreeRTOS.html Thread-safe in C library: https://developer.arm.com/documentation/dui0492/i/the-c-and-c---libraries/thread-safe-c-library-functions","title":"Reentrancy in Newlib"},{"location":"blog/freertos/reentrant/#reentrant","text":"Reentrant is an attribute of a piece of code and basically means it can be re-entered by another execution flow, for example by an interrupt or by another task or thread. Generally speaking, a function produces output data based on some input data (though both are optional, in general). Shared data could be accessed by any function at any time. If data can be changed by any function (and none keep track of those changes), there is no guarantee to those that share a datum that that datum is the same as at any time before. Data has a characteristic called scope, which describes where in a program the data may be used. Data scope is either global (outside the scope of any function and with an indefinite extent) or local (created each time a function is called and destroyed upon exit). Local data is not shared by any routines, re-entering or not; therefore, it does not affect re-entrance. Global data is defined outside functions and can be accessed by more than one function, either in the form of global variables (data shared between all functions), or as static variables (data shared by all invocations of the same function). Reentrant is distinct from, but closely related to, thread-safety. A function can be thread-safe and still not reentrant.","title":"Reentrant"},{"location":"blog/freertos/reentrant/#rules-for-reentrant","text":"Reentrant code may not hold any static or global non-constant data. Reentrant code may not modify itself. Reentrant code may not call non-reentrant computer programs or routines.","title":"Rules for reentrant"},{"location":"blog/freertos/reentrant/#examples","text":"Two functions below are reentrant: int f ( int i ) { return i + 2 ; } int g ( int i ) { return f ( i ) + 2 ; } However, if f() depends on non-constant global variable, both functions become non-reentrant, such as: int v = 1 ; int f ( int i ) { v += i ; return v ; } int g ( int i ) { return f ( i ) + 2 ; } Some functions are thread-safe, but not reentrant, such as below function. function() can be called by different threads without any problem. But, if the function is used in a reentrant interrupt handler and a second interrupt arises inside the function, the second routine will hang forever. int function () { mutex_lock (); { // function body } mutex_unlock (); }","title":"Examples"},{"location":"blog/freertos/reentrant/#newlib-implementation","text":"GNU ARM libraries use Newlib to provide standard implementation of C libraries. However, to reduce the code size and make it independent to hardware, there is a lightweight version Newlib-nano used in MCUs. The Newlib library maps standard C functions to a specific implementation environment through a chain of functions, for example: write() invokes _write_r() with the current reentrant context (e.g. thread/task-unique errno ); _write_r() invokes _write() and copies errno appropriately; _write() must be provided by something. By default, the Newlib-nano library does not provide an implementation of low-level system calls which are used by C standard libraries, such as _write() or _read() . To make the application compilable, a new library named nosys (enabled with -specs=nosys.specs to the gcc linker command line) should be added. This library just provide a simple implementation of low-level system calls which mostly return a by-pass value. CubeMX, with nosys , will generate syscalls.c and sysmem.c to provide low-level implementation for Newlib-nano interface: Function and data object definitions : char __ environ ; int _chown ( const char * path , uid_t owner , gid_t group ); int_execve ( const char * filename , char * const argv [], char * const envp []); pid_t _fork ( void ); pid_t _getpid ( void ); int _gettimeofday ( struct timeval * tv , struct timezone * tz ); int _kill ( pid_t pid , int sig ); int _link ( const char * oldpath , const char * newpath ); ssize_t _readlink ( const char * path , char * buf , size_t bufsiz ); int _stat ( const char * path , struct stat * buf ); int _symlink ( const char * oldpath , const char * newpath ); clock_t _times ( struct tms * buf ); int _unlink ( const char * pathname ); pid_t _wait ( int * status ); void _exit ( int status ); File Descriptor Operations : int _close ( int fd ); int _fstat ( int fd , struct stat * buf ); int _isatty ( int fd ); off_t _lseek ( int fd , off_t offset , int whence ); int _open ( const char * pathname , int flags ); ssize_t _read ( int fd , void * buf , size_t count ); ssize_t _write ( int fd , const void * buf , size_t count ); Heap Management : void * _sbrk ( ptrdiff_t increment );","title":"Newlib implementation"},{"location":"blog/freertos/reentrant/#newlib-reentrant","text":"The Newlib library does support reentrant, but for Newlib-nano , the reentrant attribute depends on how its interfaces are implemented. The most concerned functions of reentrant support are malloc() and free() which directly are related to dynamic memory management. If these functions are not reentrant, the information of memory layout will be messed up if there are multiple calls to malloc() or free() at a time. Newlib maintains information it needs to support each separate context (thread/task/ISR) in a reentrant structure . This includes things like a thread-specific errno , thread-specific pointers to allocated buffers , etc. The active reentrant structure is pointed at by global pointer _impure_ptr , which initially points to a statically allocated structure instance. Newlib requires below things to complete its reentrant: Switching context. Multiple reentrant structures (one per context) must be created, initialized, cleaned and pointing upon _impure_ptr to the correct context each time the context is switching Concurrency protection. For example of using malloc() , it should be lock() and unlock() in that function to make it thread-safe first","title":"Newlib reentrant"},{"location":"blog/freertos/reentrant/#freertos-supports-newlib-reentrant","text":"Newlib support has been included by popular demand, but is not used by the FreeRTOS maintainers themselves.","title":"FreeRTOS supports Newlib reentrant"},{"location":"blog/freertos/reentrant/#switching-context","text":"FreeRTOS provides support for Newlib\u2019s context management. In FreeRTOSconfig.h , add: /* The following flag must be enabled only when using Newlib */ #define configUSE_NEWLIB_REENTRANT 1 By default, STM32 projects generated by STM32CubeIDE use Newlib-nano . Whenever FreeRTOS is enabled, IDE will prompt to enable Newlib Reentrant attribute: A prompt asking to enable Newlib reentrant With this option configUSE_NEWLIB_REENTRANT = 1 , FreeRTOS does the following (in task.c ): For each task, allocate and initialize a Newlib reentrant structure in the task control block Each task switch, set _impure_ptr to point to the newly active task\u2019s reentrant structure On task destruction, clean up the reentrant structure (help Newlib free any associated memory)","title":"Switching context"},{"location":"blog/freertos/reentrant/#concurrency-protection","text":"There is one more thing to fully support Newlib reentrant: FreeRTOS Memory Management. FreeRTOS internally uses its own memory management scheme with different heap management implementations in heap_x.c , such as heap_1.c , or heap_4.c . If an application only uses FreeRTOS-provided memory management APIs such as pvPortMalloc() and vPortFree() , this application is safe for Newlib reentrant, because FreeRTOS suspends the task-switching and interrupts during memory management . However, many third party libraries do use the standard C malloc() and free() functions. For those cases, the concurrency protection is not guaranteed. That is the reason that Dave Nadler implemented a new heap scheme for Newlib in FreeRTOS. Details in https://nadler.com/embedded/newlibAndFreeRTOS.html FreeRTOS in STM32CubeMX The FreeRTOS version shipped in STM32CubeMX does not fully resolve Memory Management for Newlib. Dave Nadler provides a version for STM32 at heap_useNewlib_ST.c . The usage will be covered in a below section.","title":"Concurrency protection"},{"location":"blog/freertos/reentrant/#non-reentrant-cause-corrupted-output","text":"F411RE_FreeRTOS_Non-Reentrant.zip This example project demonstrates an issue when using printf() function without reentrant enabled for Newlib in FreeRTOS. In that case, the data printed out is corrupted. To setup the project faster, we use STM32CubeMX to configure the projects and generate the source code.","title":"Non-reentrant cause corrupted output"},{"location":"blog/freertos/reentrant/#project-setup","text":"Let\u2019s create a new FreeRTOS application using STM32CubeMX with below settings: FreeRTOS is enabled with configs: CMSIS-RTOS version: 2.00 FreeRTOS version: 10.3.1 USE_PREEMPTION : Enabled MINIMAL_STACK_SIZE : 256 Words = 1024 Bytes USE_MUTEXES : Enabled Memory Management Scheme: heap_4 Time base Source for HAL is moved to a general timer, such as TIM10 or TIM11 on STM32F411RE. Newlib setting: USE_NEWLIB_REENTRANT : Disabled","title":"Project setup"},{"location":"blog/freertos/reentrant/#create-2-printing-tasks","text":"Add 2 tasks: printTask1 and printTask2 which call to a the same function PrintTask but with different input messages message1 and message2 . Note that two tasks have the same priority. Add 2 printing tasks","title":"Create 2 printing tasks"},{"location":"blog/freertos/reentrant/#create-a-mutex","text":"We will protect the standard output with a Mutext to ensure that at one time, there is only one Task can print out. Add a mutex for write access","title":"Create a Mutex"},{"location":"blog/freertos/reentrant/#define-messages-and-print-out","text":"Two different messages will be prepared. To make the issue happens, the length of messages will be chosen to be long enough, such as 64 bytes. char * message1 = \"................................................................\" ; char * message2 = \"++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\" ; The function PrintTask() will print out a message along with the task name, the Reentrant config, an increasing counter to see new messages clearly. #include \"FreeRTOSConfig.h\" void PrintTask ( void * argument ) { char * name = pcTaskGetName ( NULL ); char * message = ( char * ) argument ; char counter = 0 ; for (;;) { printf ( \"RE=%d %s: %03d %s \\r\\n \" , configUSE_NEWLIB_REENTRANT , name , counter ++ , message ); osDelay ( 500 ); } }","title":"Define messages and print out"},{"location":"blog/freertos/reentrant/#redirect-standard-output-to-swv","text":"A final step is to redirect printed data to an SWO port. In this function, before printing out, we request to acquire the mutex. When the printing is done, we release the mutex. int _write ( int file , char * ptr , int len ) { osStatus_t ret ; // wait for other to complete printing ret = osMutexAcquire ( writeAccessMutexHandle , osWaitForever ); if ( ret == osOK ) { int DataIdx ; for ( DataIdx = 0 ; DataIdx < len ; DataIdx ++ ) { ITM_SendChar ( * ptr ++ ); } // done our job osMutexRelease ( writeAccessMutexHandle ); } return len ; }","title":"Redirect Standard Output to SWV"},{"location":"blog/freertos/reentrant/#compile-and-run","text":"Build the project and run a target board, the output will be messed up as it can be seen that characters in the messages1 is printed in the line of the messages2 . Output of Task 2 is corrupted","title":"Compile and Run"},{"location":"blog/freertos/reentrant/#debug","text":"We should find out how the issue happened. Place a breakpoint at the beginning of the function _write to check the passing argument char *ptr . Step 1 : Task 2 starts to write, Task 1 has not started yet Task 2 runs to the _write() function with the argument char *ptr at the address 0x20005210 . Task 2 prints the message at 0x20005210 Step 2 : Task 2 is interrupted by Task 1, Task 1 starts to write When Task 1 runs the _write() function with the argument char *ptr , we notice that the address is still 0x20005210 , but the message at that location is changed. Task 1 prints the message which replaces the content of the Task 2\u2019s message Step 3 : Task 1 is interrupted by Task 2, Task 2 resumes printing At this step, the content at the address 0x20005210 was overwritten by Task 1, therefore Task 2 will print out corrupted data.","title":"Debug"},{"location":"blog/freertos/reentrant/#turn-on-newlib-reentrant","text":"Still use the above project, but we set the configuration configUSE_NEWLIB_REENTRANT = 1 . Recompile and run the project, the issue is fixed. Different outputs on different reentrant settings RE","title":"Turn on Newlib reentrant"},{"location":"blog/freertos/reentrant/#debug_1","text":"Place a breakpoint at the beginning of the function _write to check the passing argument char *ptr . Step 1 : Task 2 starts to write, Task 1 has not started yet Task 2 runs to the _write() function with the argument char *ptr at the address 0x20005488 . Task 2 prints the message at 0x20005488 Step 2 : Task 2 is interrupted by Task 1, Task 1 starts to write When Task 1 runs the _write() function with the argument char *ptr , we notice that the address is changed to 0x20005a40 . Task 1 prints the message at 0x20005a40 Step 3 : Task 1 is interrupted by Task 2, Task 2 resumes printing At this step, the content at the address 0x20005488 was unchanged therefore Task 2 will print out correct data.","title":"Debug"},{"location":"blog/freertos/reentrant/#integrate-newlib-memory-scheme","text":"F411RE_FreeRTOS_Reentrant_Heap_Newlib.zip As mentioned above, Dave Nadler provides a version for STM32 at heap_useNewlib_ST.c . It is not officially supported by ST. A method to ensure thread-safe for malloc() and free() is to wrap Newlib malloc-like functions to use FreeRTOS\u2019s porting memory management functions. However, FreeRTOS heap implementations do not support realloc() . The heap_usNewlib_ST scheme chooses another method to solve malloc-like functions\u2019 thread-safe. This memory scheme implements thread-safe for malloc() and free() in Newlib, and then overwrites FreeRTOS\u2019s memory function to use Newlib\u2019s functions. Here are step to integrate heap_usNewlib_ST into STM32 project: Exclude sysmem.c file from build. This file provides an implementation of _sbrk() which is used by malloc() Exclude FreeRTOS heap management such as heap_4.c which implements pvPortMalloc() and vPortFree() Include heap_useNewlib_ST.c to project. Define 2 configs below to support ISR stack check #define configISR_STACK_SIZE_WORDS (128) // in words #define configSUPPORT_ISR_STACK_CHECK ( 1 ) Set reentrant support #define configUSE_NEWLIB_REENTRANT ( 1 )","title":"Integrate Newlib memory scheme"},{"location":"blog/freertos/reentrant/#references","text":"FreeRTOS Memory Management: https://www.freertos.org/a00111.html Newlib interface: http://pabigot.github.io/bspacm/newlib.html Newlib FreeRTOS Memory Management: https://nadler.com/embedded/newlibAndFreeRTOS.html Thread-safe in C library: https://developer.arm.com/documentation/dui0492/i/the-c-and-c---libraries/thread-safe-c-library-functions","title":"References"},{"location":"blog/freertos/segger-systemview/","tags":["arm","freertos","stm32","debug","sysview"],"text":"J-Link System View \u2014 Manual SEGGER_SysView.zip STM32-Tutorials System View # Visit the Official J-Link System View page on SEGGER website for more information. SEGGER\u2019s J-Link System View is written on top of the excellent J-Link Real-Time Transfer to record many types of events in real-time in an embedded system. Those events can be interrupts, timers, task switches and scheduling within an RTOS, API function calls and returns, or user events and messages. The events are retrieved from the target, analyzed and visualized in the System View Application , while the target keeps running. System View may be used with a non-commercial license for evaluation, educational and hobbyist purposes. When using System View under the non-commercial license, no activation is required. How System View works # To keep the communication overhead on the target system low, it only needs to record basic information, such as Function with ID X is called with parameter values y and z at the n ticks after the last event . System View analyzes all information from the events and shows: The recording time or system time when the call happened The task/context in which the call happened The interrupt name, timer ID, and marker name The API function name and its parameters and values The duration of the any pair of start-stop, enter-exit events The timestamps for events can be as accurate as 1 CPU cycle. A regular event is just 4 to 8 bytes long. What System View helps # Issues and inefficiencies in the system can be identified below ways: Incorrect task priorities or priority inversion leading to starvation Incorrect inter-task communication Inefficient delays and timeouts Spurious or unnecessary interrupts Unexpected log run-time of a short task High CPU Load can lead to: Bottlenecks which may lead to delayed execution of important tasks Dropped data or overflow of incoming buffer System View APIs # The SEGGER System View implementation is written in ANSI C on the top of RTT, therefore, it can be easily integrated into any embedded application. The System View needs to be initialized before it can be used. However, it does not automatically run to reduce CPU Load and power usage. System View only runs when it gets request from Host\u2019s System View Application. Control functions Function Description SEGGER_SYSVIEW_Init() Initializes the SYSVIEW module SEGGER_SYSVIEW_Start() Start recording System View events. This function is triggered by the System View Application on connect. SEGGER_SYSVIEW_Stop() Stop recording System View events. This function is triggered by the System View Application on disconnect. Configuration functions Function Description SEGGER_SYSVIEW_Conf() Initialize and configures System View SEGGER_SYSVIEW_SetRAMBase() Sets the RAM base address SEGGER_SYSVIEW_SendSysDesc() Send the system description string to the host SEGGER_SYSVIEW_SendTaskList() Send all tasks descriptors to the host SEGGER_SYSVIEW_SendTaskInfo() Send a Task Info Packet, containing TaskId for identification, task priority and task name SEGGER_SYSVIEW_X_GetTimestamp() Callback called by System View to get the timestamp in cycles Event recording functions Function Description SEGGER_SYSVIEW_RecordEnterISR() Format and send an ISR entry event SEGGER_SYSVIEW_RecordExitISR() Format and send an ISR exit event SEGGER_SYSVIEW_RecordEnterTimer() Format and send a Timer entry event SEGGER_SYSVIEW_RecordExitTimer() Format and send a Timer exit event SEGGER_SYSVIEW_OnIdle() Record an Idle event SEGGER_SYSVIEW_OnTaskCreate() Record a Task Create event SEGGER_SYSVIEW_OnTaskStartExec() Record a Task Start Execution event SEGGER_SYSVIEW_OnTaskStartReady() Record a Task Start Ready event SEGGER_SYSVIEW_OnTaskStopExec() Record a Task Stop Execution event SEGGER_SYSVIEW_OnTaskStopReady() Record a Task Stop Ready event SEGGER_SYSVIEW_OnTaskTerminate() Record a Task termination event SEGGER_SYSVIEW_MarkStart() Record a Performance Marker Start event to start measuring runtime SEGGER_SYSVIEW_Mark() Record a Performance Marker intermediate event SEGGER_SYSVIEW_MarkStop() Record a Performance Marker Stop event to stop measuring runtime User API recording functions Function Description SEGGER_SYSVIEW_RecordVoid() Formats and sends a System View packet with an empty payload SEGGER_SYSVIEW_RecordU32() Formats and sends a System View packet containing a single U32 parameter payload SEGGER_SYSVIEW_RecordU32x[2:10]() Formats and sends a System View packet containing [2:10] U32 parameter payload SEGGER_SYSVIEW_RecordString() Formats and sends a System View packet containing a string SEGGER_SYSVIEW_RecordEndCall() Format and send an End API Call event without return value. SEGGER_SYSVIEW_RecordEndCallU32() Format and send an End API Call event with a return value Message recording functions Function Description SEGGER_SYSVIEW_Print() Print a string to the host SEGGER_SYSVIEW_Warn() Print a warning string to the host SEGGER_SYSVIEW_Error() Print an error string to the host SEGGER_SYSVIEW_PrintfHost() Print a string which is formatted on the host by the System View Application SEGGER_SYSVIEW_WarnfHost() Print a string which is formatted on the host by the System View Application SEGGER_SYSVIEW_ErrorfHost() Print an error string which is formatted on the host by the System View Application To reduce CPU cycles used by System View to format strings, System View function *fHost() just sends a raw string and its params to the host! System View Integration # Install the System View Application firstly at System View download page . After installation, go the application folder to get the latest source code of System View target integration, for example C:\\Program Files\\SEGGER\\System View\\Src . Here is SEGGER_SysView.zip at version 3.32. \u251c\u2500Config \u2502 Global.h # Typedef for data types \u2502 SEGGER_RTT_Conf.h # Default RTT configs \u2502 SEGGER_SYSVIEW_Conf.h # User SysView Configs | \u251c\u2500\u2500SEGGER \u2502 \u2502 SEGGER.h # Segger common defines \u2502 \u2502 SEGGER_RTT.h # RTT Header \u2502 \u2502 SEGGER_RTT.c # RTT implementation \u2502 \u2502 SEGGER_RTT_ASM_ARMv7M.S # for Cortex-M3/M4 \u2502 \u2502 SEGGER_RTT_printf.c # Print functions \u2502 \u2502 SEGGER_SYSVIEW_ConfDefaults.h # SysView Default Configs \u2502 \u2502 SEGGER_SYSVIEW_Int.h # SysView Internal defines \u2502 \u2502 SEGGER_SYSVIEW.h # SysView header \u2502 \u2502 SEGGER_SYSVIEW.c # SysView implementation \u2502 \u2502 \u2502 \u2514\u2500\u2500\u2500Syscalls # Standard IO redirection \u2502 \u2514\u2500Sample # Sample configs for different targets \u251c\u2500\u2500\u2500COMM # Example to record on UART \u251c\u2500\u2500\u2500embOS # \u251c\u2500\u2500\u2500FreeRTOSV10 # \u251c\u2500\u2500\u2500FreeRTOSV8 # \u251c\u2500\u2500\u2500FreeRTOSV9 # \u251c\u2500\u2500\u2500MicriumOSKernel # \u251c\u2500\u2500\u2500uCOS-II # \u251c\u2500\u2500\u2500uCOS-III # \u2514\u2500\u2500\u2500NoOS # Run without OS \u2514\u2500\u2500\u2500Config \u251c\u2500\u2500\u2500RX \u251c\u2500\u2500\u2500Cortex-M # \u2502 SEGGER_SYSVIEW_Config_NoOS.c \u2514\u2500\u2500\u2500Cortex-M0 # Special setup for Cortex-M0 SEGGER_SYSVIEW_Config_NoOS_CM0.c You can copy all files to your projects and add them to Paths and Symbols settings. System View with FreeRTOS # F411RE_FreeRTOS_SysView.zip There is an example of integration System View on FreeRTOS using STM32CubeMX code generator. This guide is to add System View on the latest FreeRTOS version. Import System View files # The published SEGGER_SysView has 3 folders, here are what we will use: Config SEGGER Sample/FreeRTOSV10.4 Copy all of those files to the project. Add System View files for FreeRTOS to project Apply patch # SEGGER provides a patch for FreeRTOS 10.4.3 which can be used or FreeRTOS 10.4.6 also. Configure System View # Include SEGGER_SYSVIEW_FreeRTOS.h at the end of the file FreeRTOSConfig.h to override some RTOS definitions of tracing functions. Finally, configure System View in the file SEGGER_SYSVIEW_Config_FreeRTOS.c which sends System Information, Interrupt ID & Name, Timers and Markers. #define SYSVIEW_APP_NAME \"Demo RTOS Application\" #define SYSVIEW_DEVICE_NAME \"STM32F411RE\" #define SYSVIEW_CORE_NAME \"Cortex-M4\" #define SYSVIEW_OS_NAME \"FreeRTOS\" #define SYSVIEW_RAM_BASE (0x20000000) static void _cbSendSystemDesc ( void ) { SEGGER_SYSVIEW_SendSysDesc ( \"N=\" SYSVIEW_APP_NAME \",\" \"D=\" SYSVIEW_DEVICE_NAME \",\" \"C=\" SYSVIEW_CORE_NAME \",\" \"O=\" SYSVIEW_OS_NAME ); SEGGER_SYSVIEW_SendSysDesc ( \"I#15=SysTick\" ); } Include SEGGER\u2019s headers and call to SEGGER_SYSVIEW_Conf() to initialize System View: #include \"SEGGER_SYSVIEW_Conf.h\" #include \"SEGGER_SYSVIEW.h\" int main () { SEGGER_SYSVIEW_Conf (); ... } Implement an application # We will create 2 tasks which print out 2 different messages to a shared Serial Wire Output using a Mutex. Declare 2 messages, 2 tasks, and a mutex : main.c char * message1 = \"................................................................\" ; char * message2 = \"++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\" ; TaskHandle_t task1Handler ; TaskHandle_t task2Handler ; SemaphoreHandle_t writeAccessMutex ; Redirect printf to SWO : We add two logs to see the content of the message before and after the loop of writing out. We know that if reentrant is not enable, the printing buffer might be replaced. The log will help us to confirm the issue. main.c int _write ( int file , char * ptr , int len ) { char * msg = ptr ; SEGGER_SYSVIEW_Print ( msg ); // wait for other to complete printing if ( xSemaphoreTake ( writeAccessMutex , ( TickType_t ) portMAX_DELAY ) == pdTRUE ) { int DataIdx ; for ( DataIdx = 0 ; DataIdx < len ; DataIdx ++ ) { ITM_SendChar ( * ptr ++ ); } SEGGER_SYSVIEW_Print ( msg ); // done our job xSemaphoreGive ( writeAccessMutex ); } return len ; } The PrintTask prints out the selected messages main.c void PrintTask ( void * argument ) { char * name = pcTaskGetName ( NULL ); char * message = ( char * ) argument ; char counter = 0 ; for (;;) { printf ( \"%s: %03d %s \\r\\n \" , name , counter ++ , message ); vTaskDelay ( 100 ); } } The main program initializes 2 tasks, 1 mutex, and starts the scheduler main.c int main ( void ) { SystemInit (); writeAccessMutex = xSemaphoreCreateMutex (); xTaskCreate ( PrintTask , \"Task1\" , configMINIMAL_STACK_SIZE , ( void * ) message1 , 1 , & task1Handler ); xTaskCreate ( PrintTask , \"Task2\" , configMINIMAL_STACK_SIZE , ( void * ) message2 , 1 , & task2Handler ); vTaskStartScheduler (); for (;;); } Build and run # When build and run, you will see the messages printed out on SWC channel 0 as below: Corrupted messages from Task 2 We will use System View to debug the issue by follow one of below modes. System View mode # The SEGGER System View provides 3 modes: Real-time (continuous) recording: this mode streams the system view events through a debugger to an application to visualize data in real-time. A debugger must be attached to the target. Single-shot recording: this mode is started manually by calling SEGGER_SYSVIEW_Start() , then events are recorded until the System View buffer is filled or SEGGER_SYSVIEW_Stop() is called. Debugger is not needed while recording. Any debugger can e used to download recorded data into System View data file. Postmortem recording: this mode is started manually by calling SEGGER_SYSVIEW_Start() , then events are recorded SEGGER_SYSVIEW_Stop() is called. Older events are overwritten when the System View buffer is filled. Debugger is not needed while recording. Any debugger can e used to download recorded data into System View data file. System View recording modes Real-time mode # Run SEGGER System Viewer and connect a J-Link debugger to the target. If you pause the recording, and trace the Task 2, you will notice that the second log in the _write() function of Task 2 prints out the content of Task 1\u2019s message. Refer to the Reentrant Debug section to understand how issue happens. Continuously record data Single-shot # We need to investigate the saved System View data in memory. In single-shot mode, we call to SEGGER_SYSVIEW_Start() after the call to SEGGER_SYSVIEW_Config() . Find the address of UP BUFFER Get the address of RTT Buffers Dump System View buffer Dump memory to raw binary file Load saved System View single-shot data Loaded System View data The number of events recorded is not much, but they are enough to see the problem in the Task 2 as discussed above. Postmortem # This mode is similar to the Single-shot mode. To enable this mode, set the below definition: #define SEGGER_SYSVIEW_POST_MORTEM_MODE 1 And doing the same steps as Single-shot mode to dump System View data and open it.","title":"SEGGER SystemView - Record and Visualize System Activities"},{"location":"blog/freertos/segger-systemview/#system-view","text":"Visit the Official J-Link System View page on SEGGER website for more information. SEGGER\u2019s J-Link System View is written on top of the excellent J-Link Real-Time Transfer to record many types of events in real-time in an embedded system. Those events can be interrupts, timers, task switches and scheduling within an RTOS, API function calls and returns, or user events and messages. The events are retrieved from the target, analyzed and visualized in the System View Application , while the target keeps running. System View may be used with a non-commercial license for evaluation, educational and hobbyist purposes. When using System View under the non-commercial license, no activation is required.","title":"System View"},{"location":"blog/freertos/segger-systemview/#how-system-view-works","text":"To keep the communication overhead on the target system low, it only needs to record basic information, such as Function with ID X is called with parameter values y and z at the n ticks after the last event . System View analyzes all information from the events and shows: The recording time or system time when the call happened The task/context in which the call happened The interrupt name, timer ID, and marker name The API function name and its parameters and values The duration of the any pair of start-stop, enter-exit events The timestamps for events can be as accurate as 1 CPU cycle. A regular event is just 4 to 8 bytes long.","title":"How System View works"},{"location":"blog/freertos/segger-systemview/#what-system-view-helps","text":"Issues and inefficiencies in the system can be identified below ways: Incorrect task priorities or priority inversion leading to starvation Incorrect inter-task communication Inefficient delays and timeouts Spurious or unnecessary interrupts Unexpected log run-time of a short task High CPU Load can lead to: Bottlenecks which may lead to delayed execution of important tasks Dropped data or overflow of incoming buffer","title":"What System View helps"},{"location":"blog/freertos/segger-systemview/#system-view-apis","text":"The SEGGER System View implementation is written in ANSI C on the top of RTT, therefore, it can be easily integrated into any embedded application. The System View needs to be initialized before it can be used. However, it does not automatically run to reduce CPU Load and power usage. System View only runs when it gets request from Host\u2019s System View Application. Control functions Function Description SEGGER_SYSVIEW_Init() Initializes the SYSVIEW module SEGGER_SYSVIEW_Start() Start recording System View events. This function is triggered by the System View Application on connect. SEGGER_SYSVIEW_Stop() Stop recording System View events. This function is triggered by the System View Application on disconnect. Configuration functions Function Description SEGGER_SYSVIEW_Conf() Initialize and configures System View SEGGER_SYSVIEW_SetRAMBase() Sets the RAM base address SEGGER_SYSVIEW_SendSysDesc() Send the system description string to the host SEGGER_SYSVIEW_SendTaskList() Send all tasks descriptors to the host SEGGER_SYSVIEW_SendTaskInfo() Send a Task Info Packet, containing TaskId for identification, task priority and task name SEGGER_SYSVIEW_X_GetTimestamp() Callback called by System View to get the timestamp in cycles Event recording functions Function Description SEGGER_SYSVIEW_RecordEnterISR() Format and send an ISR entry event SEGGER_SYSVIEW_RecordExitISR() Format and send an ISR exit event SEGGER_SYSVIEW_RecordEnterTimer() Format and send a Timer entry event SEGGER_SYSVIEW_RecordExitTimer() Format and send a Timer exit event SEGGER_SYSVIEW_OnIdle() Record an Idle event SEGGER_SYSVIEW_OnTaskCreate() Record a Task Create event SEGGER_SYSVIEW_OnTaskStartExec() Record a Task Start Execution event SEGGER_SYSVIEW_OnTaskStartReady() Record a Task Start Ready event SEGGER_SYSVIEW_OnTaskStopExec() Record a Task Stop Execution event SEGGER_SYSVIEW_OnTaskStopReady() Record a Task Stop Ready event SEGGER_SYSVIEW_OnTaskTerminate() Record a Task termination event SEGGER_SYSVIEW_MarkStart() Record a Performance Marker Start event to start measuring runtime SEGGER_SYSVIEW_Mark() Record a Performance Marker intermediate event SEGGER_SYSVIEW_MarkStop() Record a Performance Marker Stop event to stop measuring runtime User API recording functions Function Description SEGGER_SYSVIEW_RecordVoid() Formats and sends a System View packet with an empty payload SEGGER_SYSVIEW_RecordU32() Formats and sends a System View packet containing a single U32 parameter payload SEGGER_SYSVIEW_RecordU32x[2:10]() Formats and sends a System View packet containing [2:10] U32 parameter payload SEGGER_SYSVIEW_RecordString() Formats and sends a System View packet containing a string SEGGER_SYSVIEW_RecordEndCall() Format and send an End API Call event without return value. SEGGER_SYSVIEW_RecordEndCallU32() Format and send an End API Call event with a return value Message recording functions Function Description SEGGER_SYSVIEW_Print() Print a string to the host SEGGER_SYSVIEW_Warn() Print a warning string to the host SEGGER_SYSVIEW_Error() Print an error string to the host SEGGER_SYSVIEW_PrintfHost() Print a string which is formatted on the host by the System View Application SEGGER_SYSVIEW_WarnfHost() Print a string which is formatted on the host by the System View Application SEGGER_SYSVIEW_ErrorfHost() Print an error string which is formatted on the host by the System View Application To reduce CPU cycles used by System View to format strings, System View function *fHost() just sends a raw string and its params to the host!","title":"System View APIs"},{"location":"blog/freertos/segger-systemview/#system-view-integration","text":"Install the System View Application firstly at System View download page . After installation, go the application folder to get the latest source code of System View target integration, for example C:\\Program Files\\SEGGER\\System View\\Src . Here is SEGGER_SysView.zip at version 3.32. \u251c\u2500Config \u2502 Global.h # Typedef for data types \u2502 SEGGER_RTT_Conf.h # Default RTT configs \u2502 SEGGER_SYSVIEW_Conf.h # User SysView Configs | \u251c\u2500\u2500SEGGER \u2502 \u2502 SEGGER.h # Segger common defines \u2502 \u2502 SEGGER_RTT.h # RTT Header \u2502 \u2502 SEGGER_RTT.c # RTT implementation \u2502 \u2502 SEGGER_RTT_ASM_ARMv7M.S # for Cortex-M3/M4 \u2502 \u2502 SEGGER_RTT_printf.c # Print functions \u2502 \u2502 SEGGER_SYSVIEW_ConfDefaults.h # SysView Default Configs \u2502 \u2502 SEGGER_SYSVIEW_Int.h # SysView Internal defines \u2502 \u2502 SEGGER_SYSVIEW.h # SysView header \u2502 \u2502 SEGGER_SYSVIEW.c # SysView implementation \u2502 \u2502 \u2502 \u2514\u2500\u2500\u2500Syscalls # Standard IO redirection \u2502 \u2514\u2500Sample # Sample configs for different targets \u251c\u2500\u2500\u2500COMM # Example to record on UART \u251c\u2500\u2500\u2500embOS # \u251c\u2500\u2500\u2500FreeRTOSV10 # \u251c\u2500\u2500\u2500FreeRTOSV8 # \u251c\u2500\u2500\u2500FreeRTOSV9 # \u251c\u2500\u2500\u2500MicriumOSKernel # \u251c\u2500\u2500\u2500uCOS-II # \u251c\u2500\u2500\u2500uCOS-III # \u2514\u2500\u2500\u2500NoOS # Run without OS \u2514\u2500\u2500\u2500Config \u251c\u2500\u2500\u2500RX \u251c\u2500\u2500\u2500Cortex-M # \u2502 SEGGER_SYSVIEW_Config_NoOS.c \u2514\u2500\u2500\u2500Cortex-M0 # Special setup for Cortex-M0 SEGGER_SYSVIEW_Config_NoOS_CM0.c You can copy all files to your projects and add them to Paths and Symbols settings.","title":"System View Integration"},{"location":"blog/freertos/segger-systemview/#system-view-with-freertos","text":"F411RE_FreeRTOS_SysView.zip There is an example of integration System View on FreeRTOS using STM32CubeMX code generator. This guide is to add System View on the latest FreeRTOS version.","title":"System View with FreeRTOS"},{"location":"blog/freertos/segger-systemview/#import-system-view-files","text":"The published SEGGER_SysView has 3 folders, here are what we will use: Config SEGGER Sample/FreeRTOSV10.4 Copy all of those files to the project. Add System View files for FreeRTOS to project","title":"Import System View files"},{"location":"blog/freertos/segger-systemview/#apply-patch","text":"SEGGER provides a patch for FreeRTOS 10.4.3 which can be used or FreeRTOS 10.4.6 also.","title":"Apply patch"},{"location":"blog/freertos/segger-systemview/#configure-system-view","text":"Include SEGGER_SYSVIEW_FreeRTOS.h at the end of the file FreeRTOSConfig.h to override some RTOS definitions of tracing functions. Finally, configure System View in the file SEGGER_SYSVIEW_Config_FreeRTOS.c which sends System Information, Interrupt ID & Name, Timers and Markers. #define SYSVIEW_APP_NAME \"Demo RTOS Application\" #define SYSVIEW_DEVICE_NAME \"STM32F411RE\" #define SYSVIEW_CORE_NAME \"Cortex-M4\" #define SYSVIEW_OS_NAME \"FreeRTOS\" #define SYSVIEW_RAM_BASE (0x20000000) static void _cbSendSystemDesc ( void ) { SEGGER_SYSVIEW_SendSysDesc ( \"N=\" SYSVIEW_APP_NAME \",\" \"D=\" SYSVIEW_DEVICE_NAME \",\" \"C=\" SYSVIEW_CORE_NAME \",\" \"O=\" SYSVIEW_OS_NAME ); SEGGER_SYSVIEW_SendSysDesc ( \"I#15=SysTick\" ); } Include SEGGER\u2019s headers and call to SEGGER_SYSVIEW_Conf() to initialize System View: #include \"SEGGER_SYSVIEW_Conf.h\" #include \"SEGGER_SYSVIEW.h\" int main () { SEGGER_SYSVIEW_Conf (); ... }","title":"Configure System View"},{"location":"blog/freertos/segger-systemview/#implement-an-application","text":"We will create 2 tasks which print out 2 different messages to a shared Serial Wire Output using a Mutex. Declare 2 messages, 2 tasks, and a mutex : main.c char * message1 = \"................................................................\" ; char * message2 = \"++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\" ; TaskHandle_t task1Handler ; TaskHandle_t task2Handler ; SemaphoreHandle_t writeAccessMutex ; Redirect printf to SWO : We add two logs to see the content of the message before and after the loop of writing out. We know that if reentrant is not enable, the printing buffer might be replaced. The log will help us to confirm the issue. main.c int _write ( int file , char * ptr , int len ) { char * msg = ptr ; SEGGER_SYSVIEW_Print ( msg ); // wait for other to complete printing if ( xSemaphoreTake ( writeAccessMutex , ( TickType_t ) portMAX_DELAY ) == pdTRUE ) { int DataIdx ; for ( DataIdx = 0 ; DataIdx < len ; DataIdx ++ ) { ITM_SendChar ( * ptr ++ ); } SEGGER_SYSVIEW_Print ( msg ); // done our job xSemaphoreGive ( writeAccessMutex ); } return len ; } The PrintTask prints out the selected messages main.c void PrintTask ( void * argument ) { char * name = pcTaskGetName ( NULL ); char * message = ( char * ) argument ; char counter = 0 ; for (;;) { printf ( \"%s: %03d %s \\r\\n \" , name , counter ++ , message ); vTaskDelay ( 100 ); } } The main program initializes 2 tasks, 1 mutex, and starts the scheduler main.c int main ( void ) { SystemInit (); writeAccessMutex = xSemaphoreCreateMutex (); xTaskCreate ( PrintTask , \"Task1\" , configMINIMAL_STACK_SIZE , ( void * ) message1 , 1 , & task1Handler ); xTaskCreate ( PrintTask , \"Task2\" , configMINIMAL_STACK_SIZE , ( void * ) message2 , 1 , & task2Handler ); vTaskStartScheduler (); for (;;); }","title":"Implement an application"},{"location":"blog/freertos/segger-systemview/#build-and-run","text":"When build and run, you will see the messages printed out on SWC channel 0 as below: Corrupted messages from Task 2 We will use System View to debug the issue by follow one of below modes.","title":"Build and run"},{"location":"blog/freertos/segger-systemview/#system-view-mode","text":"The SEGGER System View provides 3 modes: Real-time (continuous) recording: this mode streams the system view events through a debugger to an application to visualize data in real-time. A debugger must be attached to the target. Single-shot recording: this mode is started manually by calling SEGGER_SYSVIEW_Start() , then events are recorded until the System View buffer is filled or SEGGER_SYSVIEW_Stop() is called. Debugger is not needed while recording. Any debugger can e used to download recorded data into System View data file. Postmortem recording: this mode is started manually by calling SEGGER_SYSVIEW_Start() , then events are recorded SEGGER_SYSVIEW_Stop() is called. Older events are overwritten when the System View buffer is filled. Debugger is not needed while recording. Any debugger can e used to download recorded data into System View data file. System View recording modes","title":"System View mode"},{"location":"blog/freertos/segger-systemview/#real-time-mode","text":"Run SEGGER System Viewer and connect a J-Link debugger to the target. If you pause the recording, and trace the Task 2, you will notice that the second log in the _write() function of Task 2 prints out the content of Task 1\u2019s message. Refer to the Reentrant Debug section to understand how issue happens. Continuously record data","title":"Real-time mode"},{"location":"blog/freertos/segger-systemview/#single-shot","text":"We need to investigate the saved System View data in memory. In single-shot mode, we call to SEGGER_SYSVIEW_Start() after the call to SEGGER_SYSVIEW_Config() . Find the address of UP BUFFER Get the address of RTT Buffers Dump System View buffer Dump memory to raw binary file Load saved System View single-shot data Loaded System View data The number of events recorded is not much, but they are enough to see the problem in the Task 2 as discussed above.","title":"Single-shot"},{"location":"blog/freertos/segger-systemview/#postmortem","text":"This mode is similar to the Single-shot mode. To enable this mode, set the below definition: #define SEGGER_SYSVIEW_POST_MORTEM_MODE 1 And doing the same steps as Single-shot mode to dump System View data and open it.","title":"Postmortem"},{"location":"blog/jetson/","tags":["jetson"],"text":"Jetson platform # The Jetson platform includes small, power-efficient developer kits and production modules that offer high-performance acceleration of the NVIDIA CUDA-X\u2122 software stack. They have 2 main product lines: Jetson development kits Each developer kit includes a non-production specification Jetson module attached to a reference carrier board with standard hardware interfaces for flexible development and rapid prototyping. The development module usually has a micro-SD Card . These kits are not intended for production use. Jetson modules Jetson modules come with production specification which usually has built-in eMMC storage, more advanced parts, and longer operating lifetime. Each Jetson module ships with no software pre-installed; need to be attached to a carrier board designed or procured for your end product, and flash it with the software image you\u2019ve developed. Jetson modules have many signals in common, but the connector pin-out and electromechanical footprints do vary: Jetson Nano, Jetson TX2 NX, and Jetson Xavier NX modules are pin compatible. These Jetson TX2 series modules are pin compatible, including Jetson TX2, Jetson TX2 4GB, and Jetson TX2i Jetson AGX Xavier series modules (Jetson AGX Xavier and Jetson AGX Xavier Industrial) are pin compatible. Comparison between Developement Kits and Modules JetPack # NVIDIA JetPack SDK is the most comprehensive solution for building AI applications. All Jetson modules and developer kits are supported by JetPack SDK. JetPack SDK includes the Jetson Linux Driver Package ( L4T ) with Linux operating system and CUDA-X accelerated libraries and APIs for Deep Learning, Computer Vision, Accelerated Computing and Multimedia. It also includes samples, documentation, and developer tools for both host computer and developer kit, and supports higher level SDKs such as DeepStream for streaming video analytics and Isaac for robotics. JetPack is available at https://developer.nvidia.com/embedded/jetpack . JetPack is included either in the Nvidia SD card Images which run on Jetson modules, or in SDK Manager which runs on a Host Machine (usually an Ubuntu OS machine). System size The default developement system images provided by Nvidia are quite large, at about 13 GB. SDK Manager can make a smaller system image, at about 5 GB, which will not include JetPack developement tools and libraries, and suitable to be flashed on eMMC storage. If you want a smaller image size, you can build a custome image from a minial RootFS base . Get started # You should start with the provided image from Nvidia by following the starter guide, such as Jetson Nano Developer Kit . After the first boot, you should start reading the documents, which are provided in the Jetson Download Center . One important point you have to learn is to customize the system image which only contains what you need. Read Linux for Tegra .","title":"NVIDIA Jetson"},{"location":"blog/jetson/#jetson-platform","text":"The Jetson platform includes small, power-efficient developer kits and production modules that offer high-performance acceleration of the NVIDIA CUDA-X\u2122 software stack. They have 2 main product lines: Jetson development kits Each developer kit includes a non-production specification Jetson module attached to a reference carrier board with standard hardware interfaces for flexible development and rapid prototyping. The development module usually has a micro-SD Card . These kits are not intended for production use. Jetson modules Jetson modules come with production specification which usually has built-in eMMC storage, more advanced parts, and longer operating lifetime. Each Jetson module ships with no software pre-installed; need to be attached to a carrier board designed or procured for your end product, and flash it with the software image you\u2019ve developed. Jetson modules have many signals in common, but the connector pin-out and electromechanical footprints do vary: Jetson Nano, Jetson TX2 NX, and Jetson Xavier NX modules are pin compatible. These Jetson TX2 series modules are pin compatible, including Jetson TX2, Jetson TX2 4GB, and Jetson TX2i Jetson AGX Xavier series modules (Jetson AGX Xavier and Jetson AGX Xavier Industrial) are pin compatible. Comparison between Developement Kits and Modules","title":"Jetson platform"},{"location":"blog/jetson/#jetpack","text":"NVIDIA JetPack SDK is the most comprehensive solution for building AI applications. All Jetson modules and developer kits are supported by JetPack SDK. JetPack SDK includes the Jetson Linux Driver Package ( L4T ) with Linux operating system and CUDA-X accelerated libraries and APIs for Deep Learning, Computer Vision, Accelerated Computing and Multimedia. It also includes samples, documentation, and developer tools for both host computer and developer kit, and supports higher level SDKs such as DeepStream for streaming video analytics and Isaac for robotics. JetPack is available at https://developer.nvidia.com/embedded/jetpack . JetPack is included either in the Nvidia SD card Images which run on Jetson modules, or in SDK Manager which runs on a Host Machine (usually an Ubuntu OS machine). System size The default developement system images provided by Nvidia are quite large, at about 13 GB. SDK Manager can make a smaller system image, at about 5 GB, which will not include JetPack developement tools and libraries, and suitable to be flashed on eMMC storage. If you want a smaller image size, you can build a custome image from a minial RootFS base .","title":"JetPack"},{"location":"blog/jetson/#get-started","text":"You should start with the provided image from Nvidia by following the starter guide, such as Jetson Nano Developer Kit . After the first boot, you should start reading the documents, which are provided in the Jetson Download Center . One important point you have to learn is to customize the system image which only contains what you need. Read Linux for Tegra .","title":"Get started"},{"location":"blog/jetson/custom-image/","tags":["jetson"],"text":"Check out the script # jetson-custom-image git clone https://github.com/vuquangtrong/jetson-custom-image.git You have to edit some variables in the step0_env.sh script, and some additional options in other scripts ! Set up environment # Run sudo ./step0_env.sh Detail Chose the directories for the project: ROOT_DIR = /home/vqtrong/jetson-custom/rootfs WORK_DIR = /home/vqtrong/jetson-custom/build The Linux platform and Ubuntu version: ARCH = arm64 RELEASE = bionic REPO = To find a fast repo, use find_mirrors.sh script. By default, http://ports.ubuntu.com/ubuntu-ports will be used. The Jetson platform and its BSP version: JETSON_BOARD = jetson-nano-devkit JETSON_BOARD_IMG = jetson-nano JETSON_BOARD_REV = 300 JETSON_PLAT = t210 JETSON_REL = r32.6 JETSON_BSP = jetson-210_linux_r32.6.1_aarch64.tbz2 JETSON_BSP_URL = https://developer.nvidia.com/embedded/l4t/r32_release_v6.1/t210/jetson-210_linux_r32.6.1_aarch64.tbz2 And select a desktop environment, for example: # leave empty for CLI, or use openbox, lxde, xubuntu, or ubuntu-mate JETSON_DESKTOP = xubuntu Check root permission All scripts need root permission to make new RootFS, therefore, check the permission at the beginning of the script: if [ \"x $( whoami ) \" ! = \"xroot\" ] ; then echo \"This script requires root privilege!!!\" exit 1 fi Make a RootFS # Run sudo ./step1_make_rootfs.sh Detail Host machine must have below packages: apt install -y --no-install-recommends \\ qemu-user-static \\ debootstrap \\ binfmt-support \\ libxml2-utils qemu-user-static is used by chroot to emulate the target machine. debootstrap is used to download and unpack new RootFS binfmt-support and libxml2-utils are used by Jetson tools For faster download, use apt-fast . Run debootstrap : debootstrap \\ --verbose \\ --foreign \\ --arch = $ARCH \\ $RELEASE \\ $ROOT_DIR \\ $REPO QEMU will be used to initialize system, we copy it to the new RootFS: install -Dm755 $( which qemu-aarch64-static ) $ROOT_DIR /usr/bin/qemu-aarch64-static Ubuntu packages have a signing key, so copy the key to the new RootFS: install -Dm644 /usr/share/keyrings/ubuntu-archive-keyring.gpg $ROOT_DIR /usr/share/keyrings/ubuntu-archive-keyring.gpg Finally, unpack the new RootFS: chroot $ROOT_DIR /debootstrap/debootstrap --second-stage Customize the RootFS # At this step, we can change the root to ROOT_DIR and work inside its environment: sudo chroot ` $ROOT_DIR ` Run sudo ./step2_customize_rootfs.sh Detail However, we will keep making script to customize the new RootFS. There are some mount points needed for running new root, we use binding on host RootFS: for mnt in sys proc dev dev/pts tmp ; do mount -o bind \"/ $mnt \" \" $ROOT_DIR / $mnt \" done First, we generate locale: chroot $ROOT_DIR locale-gen en_US chroot $ROOT_DIR locale-gen en_US.UTF-8 chroot $ROOT_DIR update-locale LC_ALL = en_US.UTF-8 Add DNS, add repo list, and update package list: cat << EOF > $ROOT_DIR/etc/resolv.conf nameserver 1.1.1.1 EOF cat << EOF > $ROOT_DIR/etc/apt/sources.list deb [arch=$ARCH] $REPO ${RELEASE} main restricted universe multiverse deb [arch=$ARCH] $REPO ${RELEASE}-updates main restricted universe multiverse deb [arch=$ARCH] $REPO ${RELEASE}-security main restricted universe multiverse EOF chroot $ROOT_DIR apt update Then, we can install additional packages to RootFS which are needed for installing Jetson packages in the next step: chroot ${ ROOT_DIR } apt install -y --no-install-recommends \\ libasound2 \\ libcairo2 \\ libdatrie1 \\ libegl1 \\ libegl1-mesa \\ libevdev2 \\ libfontconfig1 \\ libgles2 \\ libgstreamer1.0-0 \\ libgstreamer-plugins-base1.0-0 \\ libgstreamer-plugins-bad1.0-0 \\ libgtk-3-0 \\ libharfbuzz0b \\ libinput10 \\ libjpeg-turbo8 \\ libpango-1.0-0 \\ libpangocairo-1.0-0 \\ libpangoft2-1.0-0 \\ libpixman-1-0 \\ libpng16-16 \\ libunwind8 \\ libwayland-client0 \\ libwayland-cursor0 \\ libwayland-egl1-mesa \\ libx11-6 \\ libxext6 \\ libxkbcommon0 \\ libxrender1 \\ python \\ python3 device-tree-compiler \\ Below packages are for network settings with default kernel drivers: chroot ${ ROOT_DIR } apt install -y --no-install-recommends \\ wget \\ curl \\ linux-firmware \\ network-manager \\ net-tools \\ wireless-tools \\ ssh Then we install X GUI server: chroot ${ ROOT_DIR } apt install -y --no-install-recommends \\ xorg Next, install a Desktop Manager is it is selected: if [ ${ JETSON_DESKTOP } == 'openbox' ] ; then echo \"Install Openbox\" # minimal desktop, only greeter, no taskbar and background chroot ${ ROOT_DIR } apt install -y --no-install-recommends \\ lightdm-gtk-greeter \\ lightdm \\ openbox \\ fi if [ ${ JETSON_DESKTOP } == 'lxde' ] ; then echo \"Install LXDE core\" # lxde with some components chroot ${ ROOT_DIR } apt install -y --no-install-recommends \\ lightdm-gtk-greeter \\ lightdm \\ lxde-icon-theme \\ lxde-core \\ lxde-common \\ policykit-1 lxpolkit \\ lxsession-logout \\ gvfs-backends \\ fi if [ ${ JETSON_DESKTOP } == 'xubuntu' ] ; then echo \"Install Xubuntu core\" # Xubuntu, better than lxde chroot ${ ROOT_DIR } apt install -y --no-install-recommends \\ xubuntu-core \\ fi if [ ${ JETSON_DESKTOP } == 'ubuntu-mate' ] ; then echo \"Install Ubuntu Mate\" # Ubuntu-Mate, similar to Ubuntu chroot ${ ROOT_DIR } apt install -y --no-install-recommends \\ ubuntu-mate-core \\ fi And, last but not least, set up network interface. We prefer using Ethernet. Ubuntu 18.04 us Netplan, so it does not use /etc/network/interfaces anymore: cat << EOF > ${ROOT_DIR}/etc/netplan/01-netconf.yaml network: ethernets: eth0: dhcp4: true EOF cat << EOF > ${ROOT_DIR}/etc/hostname ${JETSON_NAME} EOF After installing new packages, we can unmount the binding files: echo \"Unmount dependency points\" for mnt in tmp dev/pts dev proc sys ; do umount \" $ROOT_DIR / $mnt \" done Apply Jetson BSP # Run sudo ./step3_apply_bsp.sh Detail Nvidia provides BSP which include everything to boot up their board, include CBoot, U-Boot, Linux Kernel, Device Tree, etc. Download and extract the BSP: if [ ! -f $JETSON_BSP ] then wget $JETSON_BSP_URL fi if [ ! -d $WORK_DIR /Linux_for_Tegra ] then tar jxpf $JETSON_BSP -C $WORK_DIR fi We copy our customized RootFS to the BSP RootFS: rm -rf $WORK_DIR /Linux_for_Tegra/rootfs cp -rf $ROOT_DIR $WORK_DIR /Linux_for_Tegra/ Then we install Jetson packages: pushd ${ WORK_DIR } /Linux_for_Tegra/ ./apply_binaries.sh popd Then we set the flag for sudo: chroot ${ WORK_DIR } /Linux_for_Tegra/rootfs bash -c \"echo root: $ROOT_PWD | chpasswd\" chroot ${ WORK_DIR } /Linux_for_Tegra/rootfs bash -c \"chown root:root /usr/bin/sudo\" chroot ${ WORK_DIR } /Linux_for_Tegra/rootfs bash -c \"chmod u+s /usr/bin/sudo\" And fix the error when install package: chroot ${ WORK_DIR } /Linux_for_Tegra/rootfs bash -c \"chown -R man:man /var/cache/man\" chroot ${ WORK_DIR } /Linux_for_Tegra/rootfs bash -c \"chmod -R 775 /var/cache/man\" And finally, add a user: pushd $WORK_DIR /Linux_for_Tegra/tools ./l4t_create_default_user.sh -u $JETSON_USR -p $JETSON_PWD -n $JETSON_NAME --accept-license Add --autologin if needed To skip entering password when running as sudo , add a new file: cat << EOF > ${WORK_DIR}/Linux_for_Tegra/rootfs/etc/sudoers.d/${JETSON_USR} ${JETSON_USR} ALL=(ALL) NOPASSWD: ALL EOF Customize BSP If you need to update U-boot or any modififcation of image, update them at this step after the base BSP is applied. For example: custom_bsp_for_nano_dev_kit . Flash the image # Run sudo ./step4_flash.sh Detail Put the board into Recovery Mode, and call flash.sh : pushd ${ WORK_DIR } /Linux_for_Tegra ./flash.sh ${ JETSON_BOARD } mmcblk0p1 Create image # Run sudo ./step5_create_image.sh Detail The image will be used to flash to a micro-SD Card: IMAGE = ${ JETSON_BOARD } _ ${ RELEASE } _ ${ JETSON_PLAT } _ ${ JETSON_REL } _ ${ JETSON_DESKTOP } .img pushd ${ WORK_DIR } /Linux_for_Tegra/tools ./jetson-disk-image-creator.sh -o ${ IMAGE } -b ${ JETSON_BOARD_IMG } -r ${ JETSON_BOARD_REV } Flash to SD # Run sudo ./step6_flash_SD.sh Detail Check that the target device is a block device: if [ ! -b $1 ] || [ \" $( lsblk | grep -w $( basename $1 ) | awk '{print $6}' ) \" ! = \"disk\" ] ; then echo \" $1 is not a block device!!!\" exit 1 fi Then unmount it: if [ \" $( mount | grep $1 ) \" ] ; then echo \"Unmount $1 \" for mount_point in $( mount | grep $1 | awk '{ print $1}' ) ; do sudo umount $mount_point > /dev/null done fi And flash it using dd : dd if = ${ IMAGE } of = $1 bs = 4M conv = fsync status = progress Next is to extend the partition: partprobe $1 sgdisk -e $1 end_sector = $( sgdisk -p $1 | grep -i \"Total free space is\" | awk '{ print $5 }' ) start_sector = $( sgdisk -i 1 $1 | grep \"First sector\" | awk '{print $3}' ) sgdisk -d 1 $1 sgdisk -n 1 : ${ start_sector } : ${ end_sector } $1 sgdisk -c 1 :APP $1 Finally, extend the filesystem: if [[ $( basename $1 ) = ~ mmc ]] ; then e2fsck -fp $1 \"p1\" resize2fs $1 \"p1\" fi if [[ $( basename $1 ) = ~ sd ]] ; then e2fsck -fp $1 \"1\" resize2fs $1 \"1\" fi sync Reference sources # find_mirror.sh Ubuntu arm64 installation guide Minimal RootFS Create your own image for Jetson Nano board How can I install Debian the arch way TX2 Ubuntu Base How do you run Ubuntu Server with a GUI?","title":"Debootstrap a minimal Image for Jetson boards"},{"location":"blog/jetson/custom-image/#check-out-the-script","text":"jetson-custom-image git clone https://github.com/vuquangtrong/jetson-custom-image.git You have to edit some variables in the step0_env.sh script, and some additional options in other scripts !","title":"Check out the script"},{"location":"blog/jetson/custom-image/#set-up-environment","text":"Run sudo ./step0_env.sh Detail Chose the directories for the project: ROOT_DIR = /home/vqtrong/jetson-custom/rootfs WORK_DIR = /home/vqtrong/jetson-custom/build The Linux platform and Ubuntu version: ARCH = arm64 RELEASE = bionic REPO = To find a fast repo, use find_mirrors.sh script. By default, http://ports.ubuntu.com/ubuntu-ports will be used. The Jetson platform and its BSP version: JETSON_BOARD = jetson-nano-devkit JETSON_BOARD_IMG = jetson-nano JETSON_BOARD_REV = 300 JETSON_PLAT = t210 JETSON_REL = r32.6 JETSON_BSP = jetson-210_linux_r32.6.1_aarch64.tbz2 JETSON_BSP_URL = https://developer.nvidia.com/embedded/l4t/r32_release_v6.1/t210/jetson-210_linux_r32.6.1_aarch64.tbz2 And select a desktop environment, for example: # leave empty for CLI, or use openbox, lxde, xubuntu, or ubuntu-mate JETSON_DESKTOP = xubuntu Check root permission All scripts need root permission to make new RootFS, therefore, check the permission at the beginning of the script: if [ \"x $( whoami ) \" ! = \"xroot\" ] ; then echo \"This script requires root privilege!!!\" exit 1 fi","title":"Set up environment"},{"location":"blog/jetson/custom-image/#make-a-rootfs","text":"Run sudo ./step1_make_rootfs.sh Detail Host machine must have below packages: apt install -y --no-install-recommends \\ qemu-user-static \\ debootstrap \\ binfmt-support \\ libxml2-utils qemu-user-static is used by chroot to emulate the target machine. debootstrap is used to download and unpack new RootFS binfmt-support and libxml2-utils are used by Jetson tools For faster download, use apt-fast . Run debootstrap : debootstrap \\ --verbose \\ --foreign \\ --arch = $ARCH \\ $RELEASE \\ $ROOT_DIR \\ $REPO QEMU will be used to initialize system, we copy it to the new RootFS: install -Dm755 $( which qemu-aarch64-static ) $ROOT_DIR /usr/bin/qemu-aarch64-static Ubuntu packages have a signing key, so copy the key to the new RootFS: install -Dm644 /usr/share/keyrings/ubuntu-archive-keyring.gpg $ROOT_DIR /usr/share/keyrings/ubuntu-archive-keyring.gpg Finally, unpack the new RootFS: chroot $ROOT_DIR /debootstrap/debootstrap --second-stage","title":"Make a RootFS"},{"location":"blog/jetson/custom-image/#customize-the-rootfs","text":"At this step, we can change the root to ROOT_DIR and work inside its environment: sudo chroot ` $ROOT_DIR ` Run sudo ./step2_customize_rootfs.sh Detail However, we will keep making script to customize the new RootFS. There are some mount points needed for running new root, we use binding on host RootFS: for mnt in sys proc dev dev/pts tmp ; do mount -o bind \"/ $mnt \" \" $ROOT_DIR / $mnt \" done First, we generate locale: chroot $ROOT_DIR locale-gen en_US chroot $ROOT_DIR locale-gen en_US.UTF-8 chroot $ROOT_DIR update-locale LC_ALL = en_US.UTF-8 Add DNS, add repo list, and update package list: cat << EOF > $ROOT_DIR/etc/resolv.conf nameserver 1.1.1.1 EOF cat << EOF > $ROOT_DIR/etc/apt/sources.list deb [arch=$ARCH] $REPO ${RELEASE} main restricted universe multiverse deb [arch=$ARCH] $REPO ${RELEASE}-updates main restricted universe multiverse deb [arch=$ARCH] $REPO ${RELEASE}-security main restricted universe multiverse EOF chroot $ROOT_DIR apt update Then, we can install additional packages to RootFS which are needed for installing Jetson packages in the next step: chroot ${ ROOT_DIR } apt install -y --no-install-recommends \\ libasound2 \\ libcairo2 \\ libdatrie1 \\ libegl1 \\ libegl1-mesa \\ libevdev2 \\ libfontconfig1 \\ libgles2 \\ libgstreamer1.0-0 \\ libgstreamer-plugins-base1.0-0 \\ libgstreamer-plugins-bad1.0-0 \\ libgtk-3-0 \\ libharfbuzz0b \\ libinput10 \\ libjpeg-turbo8 \\ libpango-1.0-0 \\ libpangocairo-1.0-0 \\ libpangoft2-1.0-0 \\ libpixman-1-0 \\ libpng16-16 \\ libunwind8 \\ libwayland-client0 \\ libwayland-cursor0 \\ libwayland-egl1-mesa \\ libx11-6 \\ libxext6 \\ libxkbcommon0 \\ libxrender1 \\ python \\ python3 device-tree-compiler \\ Below packages are for network settings with default kernel drivers: chroot ${ ROOT_DIR } apt install -y --no-install-recommends \\ wget \\ curl \\ linux-firmware \\ network-manager \\ net-tools \\ wireless-tools \\ ssh Then we install X GUI server: chroot ${ ROOT_DIR } apt install -y --no-install-recommends \\ xorg Next, install a Desktop Manager is it is selected: if [ ${ JETSON_DESKTOP } == 'openbox' ] ; then echo \"Install Openbox\" # minimal desktop, only greeter, no taskbar and background chroot ${ ROOT_DIR } apt install -y --no-install-recommends \\ lightdm-gtk-greeter \\ lightdm \\ openbox \\ fi if [ ${ JETSON_DESKTOP } == 'lxde' ] ; then echo \"Install LXDE core\" # lxde with some components chroot ${ ROOT_DIR } apt install -y --no-install-recommends \\ lightdm-gtk-greeter \\ lightdm \\ lxde-icon-theme \\ lxde-core \\ lxde-common \\ policykit-1 lxpolkit \\ lxsession-logout \\ gvfs-backends \\ fi if [ ${ JETSON_DESKTOP } == 'xubuntu' ] ; then echo \"Install Xubuntu core\" # Xubuntu, better than lxde chroot ${ ROOT_DIR } apt install -y --no-install-recommends \\ xubuntu-core \\ fi if [ ${ JETSON_DESKTOP } == 'ubuntu-mate' ] ; then echo \"Install Ubuntu Mate\" # Ubuntu-Mate, similar to Ubuntu chroot ${ ROOT_DIR } apt install -y --no-install-recommends \\ ubuntu-mate-core \\ fi And, last but not least, set up network interface. We prefer using Ethernet. Ubuntu 18.04 us Netplan, so it does not use /etc/network/interfaces anymore: cat << EOF > ${ROOT_DIR}/etc/netplan/01-netconf.yaml network: ethernets: eth0: dhcp4: true EOF cat << EOF > ${ROOT_DIR}/etc/hostname ${JETSON_NAME} EOF After installing new packages, we can unmount the binding files: echo \"Unmount dependency points\" for mnt in tmp dev/pts dev proc sys ; do umount \" $ROOT_DIR / $mnt \" done","title":"Customize the RootFS"},{"location":"blog/jetson/custom-image/#apply-jetson-bsp","text":"Run sudo ./step3_apply_bsp.sh Detail Nvidia provides BSP which include everything to boot up their board, include CBoot, U-Boot, Linux Kernel, Device Tree, etc. Download and extract the BSP: if [ ! -f $JETSON_BSP ] then wget $JETSON_BSP_URL fi if [ ! -d $WORK_DIR /Linux_for_Tegra ] then tar jxpf $JETSON_BSP -C $WORK_DIR fi We copy our customized RootFS to the BSP RootFS: rm -rf $WORK_DIR /Linux_for_Tegra/rootfs cp -rf $ROOT_DIR $WORK_DIR /Linux_for_Tegra/ Then we install Jetson packages: pushd ${ WORK_DIR } /Linux_for_Tegra/ ./apply_binaries.sh popd Then we set the flag for sudo: chroot ${ WORK_DIR } /Linux_for_Tegra/rootfs bash -c \"echo root: $ROOT_PWD | chpasswd\" chroot ${ WORK_DIR } /Linux_for_Tegra/rootfs bash -c \"chown root:root /usr/bin/sudo\" chroot ${ WORK_DIR } /Linux_for_Tegra/rootfs bash -c \"chmod u+s /usr/bin/sudo\" And fix the error when install package: chroot ${ WORK_DIR } /Linux_for_Tegra/rootfs bash -c \"chown -R man:man /var/cache/man\" chroot ${ WORK_DIR } /Linux_for_Tegra/rootfs bash -c \"chmod -R 775 /var/cache/man\" And finally, add a user: pushd $WORK_DIR /Linux_for_Tegra/tools ./l4t_create_default_user.sh -u $JETSON_USR -p $JETSON_PWD -n $JETSON_NAME --accept-license Add --autologin if needed To skip entering password when running as sudo , add a new file: cat << EOF > ${WORK_DIR}/Linux_for_Tegra/rootfs/etc/sudoers.d/${JETSON_USR} ${JETSON_USR} ALL=(ALL) NOPASSWD: ALL EOF Customize BSP If you need to update U-boot or any modififcation of image, update them at this step after the base BSP is applied. For example: custom_bsp_for_nano_dev_kit .","title":"Apply Jetson BSP"},{"location":"blog/jetson/custom-image/#flash-the-image","text":"Run sudo ./step4_flash.sh Detail Put the board into Recovery Mode, and call flash.sh : pushd ${ WORK_DIR } /Linux_for_Tegra ./flash.sh ${ JETSON_BOARD } mmcblk0p1","title":"Flash the image"},{"location":"blog/jetson/custom-image/#create-image","text":"Run sudo ./step5_create_image.sh Detail The image will be used to flash to a micro-SD Card: IMAGE = ${ JETSON_BOARD } _ ${ RELEASE } _ ${ JETSON_PLAT } _ ${ JETSON_REL } _ ${ JETSON_DESKTOP } .img pushd ${ WORK_DIR } /Linux_for_Tegra/tools ./jetson-disk-image-creator.sh -o ${ IMAGE } -b ${ JETSON_BOARD_IMG } -r ${ JETSON_BOARD_REV }","title":"Create image"},{"location":"blog/jetson/custom-image/#flash-to-sd","text":"Run sudo ./step6_flash_SD.sh Detail Check that the target device is a block device: if [ ! -b $1 ] || [ \" $( lsblk | grep -w $( basename $1 ) | awk '{print $6}' ) \" ! = \"disk\" ] ; then echo \" $1 is not a block device!!!\" exit 1 fi Then unmount it: if [ \" $( mount | grep $1 ) \" ] ; then echo \"Unmount $1 \" for mount_point in $( mount | grep $1 | awk '{ print $1}' ) ; do sudo umount $mount_point > /dev/null done fi And flash it using dd : dd if = ${ IMAGE } of = $1 bs = 4M conv = fsync status = progress Next is to extend the partition: partprobe $1 sgdisk -e $1 end_sector = $( sgdisk -p $1 | grep -i \"Total free space is\" | awk '{ print $5 }' ) start_sector = $( sgdisk -i 1 $1 | grep \"First sector\" | awk '{print $3}' ) sgdisk -d 1 $1 sgdisk -n 1 : ${ start_sector } : ${ end_sector } $1 sgdisk -c 1 :APP $1 Finally, extend the filesystem: if [[ $( basename $1 ) = ~ mmc ]] ; then e2fsck -fp $1 \"p1\" resize2fs $1 \"p1\" fi if [[ $( basename $1 ) = ~ sd ]] ; then e2fsck -fp $1 \"1\" resize2fs $1 \"1\" fi sync","title":"Flash to SD"},{"location":"blog/jetson/custom-image/#reference-sources","text":"find_mirror.sh Ubuntu arm64 installation guide Minimal RootFS Create your own image for Jetson Nano board How can I install Debian the arch way TX2 Ubuntu Base How do you run Ubuntu Server with a GUI?","title":"Reference sources"},{"location":"blog/jetson/linux-for-tegra/","tags":["jetson","linux"],"text":"All versions of L4T are listed at https://developer.nvidia.com/embedded/linux-tegra-archive . Components # Each version of L4T has a main release page, such as https://developer.nvidia.com/embedded/linux-tegra-r3261 , in which there are some interesting links: The Jetson Linux Developer Guide for detailed documentation e.g. l4t-3261 The L4T Driver Package (BSP) e.g. jetson-210_linux_r32.6.1_aarch64.tbz2 The Sample Root Filesystem e.g. tegra_linux_sample-root-filesystem_r32.6.1_aarch64.tbz2 The GCC Toolchain for BSP and Kernel e.g. gcc-linaro-7.3.1-2018.05-x86_64_aarch64-linux-gnu.tar.xz Overview # For a full and detailed document, visit the main Jetson Linux Developer Guide . This page is written using JetPack 4.6 with L4T Release 32 version 6.1 . Module name & P\u2011number # Each module and devkit has a code called P-number . This code is used in build commands to select components. For example: Jetson Nano Developer Kit P3450-0000 , which uses a non-production Jetson Nano module P3448-0000 . Refer to Devices Supported \u2026 section. Preparation # Jetson developer kit is powered off, and put into Recovery Mode (RCM) by shorting the pin FC_REC to GND or holding the Force Recovery button. Power input is DC Jack (check Power Selection jumper) A USB cable connect from host machine to the debug USB port on board Host machine\u2019s installed QEMU: sudo apt install -y qemu-user-static libxml2-utils Environment Variables # The directions that follow assume that: ${L4T_RELEASE_PACKAGE} contains the L4T release package\u2019s name formed by target code and Linux version: For Jetson Nano devices and Jetson TX1 modules: Tegra210 For Jetson Xavier NX, Jetson AGX Xavier series, and Jetson TX2 series modules: Tegra186 Linux version in the format Linux_RXX.Y_aarch64.tbz2 ${SAMPLE_FS_PACKAGE} contains the filename of the sample file system package: All Jetson boards use Tegra_Linux_Sample-Root-Filesystem_xxx.tbz2 ${BOARD} contains the name of a configuration supported for your specific Jetson module and carrier board. Some examples are: jetson-nano-devkit jetson-tx2-devkit jetson-xavier-nx-devkit Configuration files\u2019 names follow this format: <board_part_number>+<module_part_number>[-<modifier>].conf where: <board_part_number> is the P\u2011number (the full part number) for the NVIDIA carrier board. <module_part_number> is the P\u2011number for the Jetson module. <modifier> is an optional string that indicates several configurations for example, on a module that may have either eMMC or micro-SD card memory. Build system image # Install packages on host machine: sudo apt install -y build-essential bison flex Download the latest L4T release package and sample file system for your Jetson developer kit from https://developer.nvidia.com/linux-tegra . Enter these commands to decompress the files and assemble the RootFS: tar xf ${ L4T_RELEASE_PACKAGE } && \\ cd Linux_for_Tegra/rootfs/ && \\ sudo tar xpf ../../ ${ SAMPLE_FS_PACKAGE } && \\ cd .. && \\ sudo ./apply_binaries.sh Put your Jetson developer kit into Force Recovery Mode Use lsusb to check if Jetson board is reported as Nvidia APX module e.g.: Bus x Device y: ID 0955: nnnn Nvidia Corp. with nnnn is 7f21 for Jetson Nano module. Enter this command on your Linux host to flash (install) the L4T release onto the Jetson developer kit: sudo ./flash.sh ${ BOARD } mmcblk0p1 SD Card Image To generate an image for flashing on SD Card, run jetson-disk-image-creator.sh : Linux_for_Tegra/tools/ sudo ./jetson-disk-image-creator.sh -o jetson-nano-oem.img -b jetson-nano -r 300 Skipping oem-config The boot process runs oem\u2011config if no default user is defined. If you don\u2019t want to run oem-config to set up your system, you can run the host script l4t_create_default_user.sh to create a default user, and thus prevents oem\u2011config from running. l4t_create_default_user.sh [ \u2011u <user> ] [ \u2011p <password> ] [ \u2011n <hostname> ] [ \u2011\u2011autologin ] [ --accept-license ] How system image is built Nvidia provides 2 packages, an L4T Driver Package (BSP) which contains all prebuild components for Jetson boards (bootloader, kernel, nvidia tools, scripts), and a Sample Root Filesystem which contains Ubuntu filesystem with prebuilt binaries (rootfs). Unzipped L4T packages At first, extract the sample RootFs to the L4T BSP. Next, running apply_binaries.sh will install nvidia packages into the rootfd: vqtrong@ubuntu:~/Jetson/Linux_for_Tegra$ sudo ./apply_binaries.sh Using rootfs directory of: /home/vqtrong/Jetson/Linux_for_Tegra/rootfs Installing extlinux.conf into /boot/extlinux in target rootfs /home/vqtrong/Jetson/Linux_for_Tegra/nv_tegra/nv-apply-debs.sh Root file system directory is /home/vqtrong/Jetson/Linux_for_Tegra/rootfs Copying public debian packages to rootfs Start L4T BSP package installation QEMU binary is not available, looking for QEMU from host system Found /usr/bin/qemu-aarch64-static Installing QEMU binary in rootfs ~/Jetson/Linux_for_Tegra/rootfs ~/Jetson/Linux_for_Tegra Installing BSP Debian packages in /home/vqtrong/Jetson/Linux_for_Tegra/rootfs ... Finally, the command flash.sh will assemble the system image from bootloader, DTS, RootFS: Edit rootfs/boot by copying corresponding bootloader files from bootloader Edit initrd for booting storage A blank image system.img.raw is created in bootloader , which is loopback formatted as ext4 and mounted. All the content in rootfs will be copied into the image file. The raw system file is converted to a sparse file named system.img is smaller than system.img.raw , and expands during flash to become the APP partition. Board ID(3448) version(400) copying bctfile(/home/vqtrong/Jetson/Linux_for_Tegra/bootloader/t210ref/BCT/P3448_A00_lpddr4_204Mhz_P987.cfg)... done. copying bootloader(/home/vqtrong/Jetson/Linux_for_Tegra/bootloader/t210ref/cboot.bin)... done. copying initrd(/home/vqtrong/Jetson/Linux_for_Tegra/bootloader/l4t_initrd.img)... done. Making Boot image... done. Existing sosfile(/home/vqtrong/Jetson/Linux_for_Tegra/bootloader/nvtboot_recovery.bin) reused. copying tegraboot(/home/vqtrong/Jetson/Linux_for_Tegra/bootloader/t210ref/nvtboot.bin)... done. copying cpu_bootloader(/home/vqtrong/Jetson/Linux_for_Tegra/bootloader/t210ref/cboot.bin)... done. copying bpffile(/home/vqtrong/Jetson/Linux_for_Tegra/bootloader/t210ref/sc7entry-firmware.bin)... done. copying wb0boot(/home/vqtrong/Jetson/Linux_for_Tegra/bootloader/t210ref/warmboot.bin)... done. Existing tosfile(/home/vqtrong/Jetson/Linux_for_Tegra/bootloader/tos-mon-only.img) reused. Existing eksfile(/home/vqtrong/Jetson/Linux_for_Tegra/bootloader/eks.img) reused. copying dtbfile(/home/vqtrong/Jetson/Linux_for_Tegra/kernel/dtb/tegra210-p3448-0000-p3449-0000-b00.dtb)... done. Copying nv_boot_control.conf to rootfs populating kernel to rootfs... done. populating initrd to rootfs... done. populating kernel_tegra210-p3448-0000-p3449-0000-b00.dtb to rootfs... done. Making system.img... populating rootfs from /home/vqtrong/Jetson/Linux_for_Tegra/rootfs ... populating /boot/extlinux/extlinux.conf ... done. Sync'ing system.img ... done. Converting RAW image to Sparse image... done. system.img built successfully. Understanding this procedure enables us to make a custom system image which is shown in custom image guide . Nvidia also provides a script to generate a base RootFS in /Linux_for_Tegra/tools/samplefs folder (This method uses full Ubuntu desktop RootFS, so the size is not small). For example, run: sudo ./nv_build_samplefs.sh --abi aarch64 --distro ubuntu --version bionic Architecture # NVIDIA\u00ae Jetson\u2122 Board Support Package (BSP) architecture Jetson Board Support Package: Linux Kernel : A UNIX-like computer operating system kernel mostly used for mobile devices. Sample Root Filesystem derived from Ubuntu: A sample root filesystem of the Ubuntu distribution. Helps you create root filesystem for different configurations. Toolchain : A set of development tools chained together by stages that runs on various architectures. Bootloader : Boot software boot for initializing the system on the chip. Sources : Source code for kernel and multimedia applications. NVIDIA\u00ae Jetson\u2122 User Space Drivers : Provides the NVIDIA drivers that run in the user-space. Flashing Support Scripts and Tools : A set of scripts and associated tools to assist in flashing your system. Sample Source Code and Applications : Sample source code for developing embedded applications for the Jetson platform. Package Manifest # This note some important information of the provided packages: Bootloader extlinux.conf : Boot configuration file. l4t_initrd.img : L4T initrd image based on minimal Ubuntu environment. XXXref/pYYYY-YYYY/u-boot.bin : U-Boot Bootloader binary. Kernel dtb/xxx-*.dtb : Device Tree Binary (DTB) files. Image : Kernel binary image. Image.gz is a compressed version. kernel_headers.tbz2 : Kernel header files needed for compiling kernel modules. kernel_supplements.tbz2 : Loadable kernel modules specific to the included kernel zImage that was built with the default configs enabled for the device. nvidia-l4t-kernel*.deb : DEB packages containing L4T dependencies and associated components. Tools jetson-disk-image-creator.sh : Creates a disk image for the target system based on specified command line options. Image can be flashed to a micro-SD card. l4t_create_default_user.sh : Creates a default user and skips running oem-config at first boot. l4t_extract_deb.sh : Extracts Jetson Linux Debian packages. *-jetson-gpio-*.deb : Jetson GPIO packages. NV_Tegra install-nv-debs , nv-apply-debs.sh : Installs BSP packages on the target. l4t_deb_packages/* : Packages containing L4T dependencies and associated -components. nv_sample_apps/ : NVIDIA sample applications. config.tbz2 : Configuration files specific to the sample filesystem. nvidia_drivers.tbz2 : NVIDIA driver components. weston.tbz2 : NVIDIA Wayland support. Hardware configuration # Headers # Each Jetson developer kit includes several expansion headers and connectors (collectively, \u201cheaders\u201d): 40\u2011pin expansion header : Lets you connect a Jetson developer kit to off-the-shelf Raspberry Pi HATs (Hardware Attached on Top) such as Seeed Grove modules, SparkFun Qwiic products, and others. Many of the pins can be used either as GPIO or as \u201cspecial function I/O\u201d (SFIO) such as I2C, I2S, etc. 30\u2011pin expansion header : An NVIDIA custom header similar to the 40-pin header, available on NVIDIA\u00ae Jetson\u2122 TX2 and Jetson TX1 platforms. Its pins can also be used as GPIO or as \u201cspecial function I/O\u201d (SFIO). CSI connector for camera input M.2 Key express slot for extra Bluetooth module or SSD Memory storage The configuration of all the I/O pins on Jetson developer kits is statically defined, and is programmed into the device when it is flashed. NVIDIA provides the Jetson Expansion Header Tool (also known as Jetson\u2011IO), a Python script that runs on a Jetson developer kit and lets you change pin configurations through a graphic user interface. Jetson\u2011IO modifies the Device Tree Blob (DTB) firmware so that a new configuration for the expansion headers is applied when the developer kit is rebooted. To launch Jetson\u2011IO, enter this command on the developer kit: sudo /opt/nvidia/jetson-io/jetson-io.py Follow the instructions to configure headers and GPIO pins. Voltage and Current Monitor # Jetson modules include an on-board power monitor, the INA3221, to monitor the voltage and current of certain rails. The Jetson module feeds INA3221 outputs into SOC_THERM input. When one or more alert outputs are asserted, the SOC_THERM hardware reduces module power consumption to avoid violating current limits. The power monitor accepts configuration data from powermon.dtsi (the source file) The Voltage and Current can be read from sysfs . The powermon.dtsi file for the Jetson Nano module is located at: hardware/nvidia/platform/t210/porg/kernel-dts/porg-platforms/tegra210-porg-powermon-p3448-0000-a00.dtsi which defines the address for ina3221x , and the reporting channels: channel 0: POM_5V_IN channel 1: POM_5V_GPU channel 2: POM_5V_CPU i2c @ 546 c0000 { ina3221x : ina3221x @ 40 { compatible = \"ti,ina3221x\" ; reg = < 0x40 > ; status = \"okay\" ; ti , trigger - config = < 0x7003 > ; ti , continuous - config = < 0x7607 > ; ti , enable - forced - continuous ; # io - channel - cells = < 1 > ; # address - cells = < 1 > ; # size - cells = < 0 > ; channel @ 0 { reg = < 0x0 > ; ti , rail - name = \"POM_5V_IN\" ; ti , shunt - resistor - mohm = < 5 > ; }; channel @ 1 { reg = < 0x1 > ; ti , rail - name = \"POM_5V_GPU\" ; ti , shunt - resistor - mohm = < 5 > ; }; channel @ 2 { reg = < 0x2 > ; ti , rail - name = \"POM_5V_CPU\" ; ti , shunt - resistor - mohm = < 5 > ; }; }; }; Find the mounted point of ina3221x in i2c bus: head /sys/bus/i2c/devices/*/name ==> /sys/bus/i2c/devices/6-0040/name <== ina3221x This means, ina3221x is mounted at bus i2c-6 , address 0x40 . To read the mapping channel, find the rail name: sudo head /sys/bus/i2c/devices/6-0040/iio \\: device0/rail_name_* ==> /sys/bus/i2c/devices/6-0040/iio:device0/rail_name_0 <== POM_5V_IN ==> /sys/bus/i2c/devices/6-0040/iio:device0/rail_name_1 <== POM_5V_GPU ==> /sys/bus/i2c/devices/6-0040/iio:device0/rail_name_2 <== POM_5V_CPU To read total power, check the IN rail: sudo cat /sys/bus/i2c/devices/6-0040/iio \\: device0/in_voltage0_input sudo cat /sys/bus/i2c/devices/6-0040/iio \\: device0/in_current0_input sudo cat /sys/bus/i2c/devices/6-0040/iio \\: device0/in_power0_input Note: use watch to monitor: sudo watch -n1 \"cat /sys/bus/i2c/devices/6-0040/iio\\:device0/in_power0_input\" Improving System Performance # The window system installed with L4T is Gnome, the standard Ubuntu window manager. In many cases you can reduce boot time, response time, memory consumption, and CPU utilization by replacing Gnome with a lightweight window manager. NVIDIA recommends the LXDE environment with Compton compositing manager for this purpose. To install and enable LXDE: Enter the commands: sudo apt update && \\ sudo apt install -y lxde compton Create the configuration file /etc/xdg/autostart/lxde-compton.desktop , containing these commands: [Desktop Entry] Type = Application Name = Compton (X Compositor) GenericName = X compositor Comment = A X compositor TryExec = compton Exec = compton --backend glx -b OnlyShowIn = LXDE Flashing and Booting # Locate the most up-to-date usage information by running flash.sh \u2013h (using the flash.sh script included in the release). The basic usage is as follows. sudo ./flash.sh [ options ] <board> <rootdev> Where: options is one or more command line switches. All switches are optional. Switches are described in Flash Script Usage. <board> specifies the configuration to be applied to the device to be flashed. Values are listed in the table of device names in the topic Quick Start. flash.sh gets the configuration from a configuration file named <board>.conf . <rootdev> specifies the type of device that is to be flashed. Use the value mmcblk0p1 to flash a local storage device (eMMC or SD card, depending on platform), as distinguished from NFS server, for example. Flash a Partition only You can flash a specific partition instead of flashing the whole device by using the command line option \u2011k . sudo ./flash.sh -k <partition_name> [ --image <image_name> ] <board> <rootdev> Where: <partition_name> is the name of the partition to be flashed. Possible values depend on the target device. For details, see the section Default Partition Overview in the topic Bootloader. <image_name> is the name of the image file. If omitted, flash.sh chooses the image file that was used to flash whole device. Replace Kernel only Since U\u2011Boot is required for Jetson Nano devices and Jetson TX1, and is the default bootloader for Jetson TX2, the image flashed to the kernel partition is actually a U\u2011Boot image. U\u2011Boot loads the Linux kernel from /boot/Image in the root file system. For this reason, you cannot update Linux kernel image using the \u2011k kernel option. You may update /boot/Image by either of these means: Modify /boot/extlinux/extlinux.conf to add a new boot entry. Follow the instructions and example provided in /boot/extlinux/extlinux.conf . By this means you can always use cp or scp to replace /boot/Image with a custom-built kernel and launch it with U\u2011Boot. On T210 (Jetson Nano devices and Jetson TX1) devices only, connect the Jetson device\u2019s recovery USB port to your host. Enter this command at the U\u2011Boot command prompt: ums 0 mmc 1 This connects eMMC (or a Jetson Nano with SD card) to the host as a set of USB mass storage devices (each partition as a device). You then can copy your custom kernel to /boot/Image directly. U-Boot Customization # U-Boot is the default bootloader for NVIDIA\u00ae Jetson\u2122 Linux Driver Package (L4T) on supported platforms. Install packages on host machine: sudo apt install -y build-essential bison flex bc Nvidia uses the Linaro Aarch64 toolchain: wget http://releases.linaro.org/components/toolchain/binaries/7.3-2018.05/aarch64-linux-gnu/gcc-linaro-7.3.1-2018.05-x86_64_aarch64-linux-gnu.tar.xz Extract toolchain: mkdir $HOME /l4t-gcc && \\ tar xf gcc-linaro-7.3.1-2018.05-x86_64_aarch64-linux-gnu.tar.xz -C $HOME /l4t-gcc Set the build environment: export CROSS_COMPILE = $HOME /l4t-gcc/gcc-linaro-7.3.1-2018.05-x86_64_aarch64-linux-gnu/bin/aarch64-linux-gnu- Move to Linux_for_Tegra/sources folder. Download source code: git clone -n git://nv-tegra.nvidia.com/3rdparty/u-boot.git Go to the source folder and check the tag: cd u-boot && \\ git tag Checkout a tag that\u2019s corresponding to the JetPack version, for example: git checkout -b myuboot tegra-l4t-r32.6.1 Build U-Boot by executing: make distclean make <board_and_rev>_defconfig make Where <board_and_rev> is described in the P-number of Jetson modules. For example, the Jetson Nano: make p3450-0000_defconfig After compiling, copy the binary file u-boot.bin to the corresponding folder in bootloader , such as t210ref/p3450-0000 for Jetson Nano. To flash the new version of U-Boot, run the command: sudo ./flash.sh -k LNX <platform> mmcblk0p1 Where <platform> is the SoC name or platform. Kernel Customization # You can manually rebuild the kernel used for the NVIDIA\u00ae Jetson\u2122 Linux Driver Package. Build Kernel # Install packages on host machine: sudo apt install -y build-essential bison flex bc Nvidia uses the Linaro Aarch64 toolchain: wget http://releases.linaro.org/components/toolchain/binaries/7.3-2018.05/aarch64-linux-gnu/gcc-linaro-7.3.1-2018.05-x86_64_aarch64-linux-gnu.tar.xz Extract toolchain: mkdir $HOME /l4t-gcc && \\ tar xf gcc-linaro-7.3.1-2018.05-x86_64_aarch64-linux-gnu.tar.xz -C $HOME /l4t-gcc Set the build environment: export CROSS_COMPILE = $HOME /l4t-gcc/gcc-linaro-7.3.1-2018.05-x86_64_aarch64-linux-gnu/bin/aarch64-linux-gnu- To manually download and expand the kernel sources, in a browser, navigate to https://developer.nvidia.com/embedded/downloads , to locate and download the L4T source files for your release. Extract the TBZ2 file. tar -xjf public_sources.tbz2 Extract the kernel source file. cd Linux_for_Tegra/source/public && \\ tar \u2013xjf kernel_src.tbz2 The kernel source is extracted to the kernel subdirectory. Set the shell variable with the command: export TEGRA_KERNEL_OUT = $HOME /Jetson/build Execute the following commands to create the .config file: cd <kernel_source> mkdir -p $TEGRA_KERNEL_OUT make ARCH = arm64 O = $TEGRA_KERNEL_OUT tegra_defconfig Where <kernel_source> directory contains the kernel sources (e.g. kernel-4.9 ). Execute the following commands to build the kernel including all DTBs and modules: make ARCH = arm64 O = $TEGRA_KERNEL_OUT -j<n> Where <n> indicates the number of parallel processes to be used. Replace <release_packagep>/Linux_for_Tegra/kernel/Image with a copy of $TEGRA_KERNEL_OUT/arch/arm64/boot/Image . Replace the contents of Linux_for_Tegra/kernel/dtb/ with the contents of $TEGRA_KERNEL_OUT/arch/arm64/boot/dts/ . Execute the following commands to install the kernel modules: sudo make ARCH = arm64 O = $TEGRA_KERNEL_OUT modules_install INSTALL_MOD_PATH = /Linux_for_Tegra/rootfs/ Optionally, archive the installed kernel modules using the following command: cd <modules_install_path> tar --owner root --group root -cjf kernel_supplements.tbz2 lib/modules The installed modules can be used to provide the contents of /lib/modules/<kernel_version> on the target system. Use the archive to replace the one in the kernel directory of the extracted release package prior to running apply_binaries.sh in Linux_for_Tegra/kernel/kernel_supplements.tbz2 . Kernel Optimization # Disable Console over UART Console printing over UART is a major bottleneck in kernel boot time. To reduce the bottleneck, you can reduce the volume of console printing over UART by removing console=ttyS0 from the platform configuration file, such as p3448-0000.conf . Secondary Bootloader You can remove U\u2011Boot as the secondary bootloader to remove boot time of u-boot. The following modifications are required before flashing: Edit the common configuration file at, such as: <top>/tegra_for_linux/p2771-000.conf Set USE_UBOOT to 0. # To configure whether to use U-Boot, # do either of the following before running flash.sh: # 1) Set environment variable USE_UBOOT to 0 or 1. # 2) Edit the line below to set USE_UBOOT to 0 or 1. if [ -z \" ${ USE_UBOOT } \" ] ; then USE_UBOOT = 0 ; fi ;","title":"Understand Linux for Tegra (L4T) system package"},{"location":"blog/jetson/linux-for-tegra/#components","text":"Each version of L4T has a main release page, such as https://developer.nvidia.com/embedded/linux-tegra-r3261 , in which there are some interesting links: The Jetson Linux Developer Guide for detailed documentation e.g. l4t-3261 The L4T Driver Package (BSP) e.g. jetson-210_linux_r32.6.1_aarch64.tbz2 The Sample Root Filesystem e.g. tegra_linux_sample-root-filesystem_r32.6.1_aarch64.tbz2 The GCC Toolchain for BSP and Kernel e.g. gcc-linaro-7.3.1-2018.05-x86_64_aarch64-linux-gnu.tar.xz","title":"Components"},{"location":"blog/jetson/linux-for-tegra/#overview","text":"For a full and detailed document, visit the main Jetson Linux Developer Guide . This page is written using JetPack 4.6 with L4T Release 32 version 6.1 .","title":"Overview"},{"location":"blog/jetson/linux-for-tegra/#module-name--pnumber","text":"Each module and devkit has a code called P-number . This code is used in build commands to select components. For example: Jetson Nano Developer Kit P3450-0000 , which uses a non-production Jetson Nano module P3448-0000 . Refer to Devices Supported \u2026 section.","title":"Module name &amp; P\u2011number"},{"location":"blog/jetson/linux-for-tegra/#preparation","text":"Jetson developer kit is powered off, and put into Recovery Mode (RCM) by shorting the pin FC_REC to GND or holding the Force Recovery button. Power input is DC Jack (check Power Selection jumper) A USB cable connect from host machine to the debug USB port on board Host machine\u2019s installed QEMU: sudo apt install -y qemu-user-static libxml2-utils","title":"Preparation"},{"location":"blog/jetson/linux-for-tegra/#environment-variables","text":"The directions that follow assume that: ${L4T_RELEASE_PACKAGE} contains the L4T release package\u2019s name formed by target code and Linux version: For Jetson Nano devices and Jetson TX1 modules: Tegra210 For Jetson Xavier NX, Jetson AGX Xavier series, and Jetson TX2 series modules: Tegra186 Linux version in the format Linux_RXX.Y_aarch64.tbz2 ${SAMPLE_FS_PACKAGE} contains the filename of the sample file system package: All Jetson boards use Tegra_Linux_Sample-Root-Filesystem_xxx.tbz2 ${BOARD} contains the name of a configuration supported for your specific Jetson module and carrier board. Some examples are: jetson-nano-devkit jetson-tx2-devkit jetson-xavier-nx-devkit Configuration files\u2019 names follow this format: <board_part_number>+<module_part_number>[-<modifier>].conf where: <board_part_number> is the P\u2011number (the full part number) for the NVIDIA carrier board. <module_part_number> is the P\u2011number for the Jetson module. <modifier> is an optional string that indicates several configurations for example, on a module that may have either eMMC or micro-SD card memory.","title":"Environment Variables"},{"location":"blog/jetson/linux-for-tegra/#build-system-image","text":"Install packages on host machine: sudo apt install -y build-essential bison flex Download the latest L4T release package and sample file system for your Jetson developer kit from https://developer.nvidia.com/linux-tegra . Enter these commands to decompress the files and assemble the RootFS: tar xf ${ L4T_RELEASE_PACKAGE } && \\ cd Linux_for_Tegra/rootfs/ && \\ sudo tar xpf ../../ ${ SAMPLE_FS_PACKAGE } && \\ cd .. && \\ sudo ./apply_binaries.sh Put your Jetson developer kit into Force Recovery Mode Use lsusb to check if Jetson board is reported as Nvidia APX module e.g.: Bus x Device y: ID 0955: nnnn Nvidia Corp. with nnnn is 7f21 for Jetson Nano module. Enter this command on your Linux host to flash (install) the L4T release onto the Jetson developer kit: sudo ./flash.sh ${ BOARD } mmcblk0p1 SD Card Image To generate an image for flashing on SD Card, run jetson-disk-image-creator.sh : Linux_for_Tegra/tools/ sudo ./jetson-disk-image-creator.sh -o jetson-nano-oem.img -b jetson-nano -r 300 Skipping oem-config The boot process runs oem\u2011config if no default user is defined. If you don\u2019t want to run oem-config to set up your system, you can run the host script l4t_create_default_user.sh to create a default user, and thus prevents oem\u2011config from running. l4t_create_default_user.sh [ \u2011u <user> ] [ \u2011p <password> ] [ \u2011n <hostname> ] [ \u2011\u2011autologin ] [ --accept-license ] How system image is built Nvidia provides 2 packages, an L4T Driver Package (BSP) which contains all prebuild components for Jetson boards (bootloader, kernel, nvidia tools, scripts), and a Sample Root Filesystem which contains Ubuntu filesystem with prebuilt binaries (rootfs). Unzipped L4T packages At first, extract the sample RootFs to the L4T BSP. Next, running apply_binaries.sh will install nvidia packages into the rootfd: vqtrong@ubuntu:~/Jetson/Linux_for_Tegra$ sudo ./apply_binaries.sh Using rootfs directory of: /home/vqtrong/Jetson/Linux_for_Tegra/rootfs Installing extlinux.conf into /boot/extlinux in target rootfs /home/vqtrong/Jetson/Linux_for_Tegra/nv_tegra/nv-apply-debs.sh Root file system directory is /home/vqtrong/Jetson/Linux_for_Tegra/rootfs Copying public debian packages to rootfs Start L4T BSP package installation QEMU binary is not available, looking for QEMU from host system Found /usr/bin/qemu-aarch64-static Installing QEMU binary in rootfs ~/Jetson/Linux_for_Tegra/rootfs ~/Jetson/Linux_for_Tegra Installing BSP Debian packages in /home/vqtrong/Jetson/Linux_for_Tegra/rootfs ... Finally, the command flash.sh will assemble the system image from bootloader, DTS, RootFS: Edit rootfs/boot by copying corresponding bootloader files from bootloader Edit initrd for booting storage A blank image system.img.raw is created in bootloader , which is loopback formatted as ext4 and mounted. All the content in rootfs will be copied into the image file. The raw system file is converted to a sparse file named system.img is smaller than system.img.raw , and expands during flash to become the APP partition. Board ID(3448) version(400) copying bctfile(/home/vqtrong/Jetson/Linux_for_Tegra/bootloader/t210ref/BCT/P3448_A00_lpddr4_204Mhz_P987.cfg)... done. copying bootloader(/home/vqtrong/Jetson/Linux_for_Tegra/bootloader/t210ref/cboot.bin)... done. copying initrd(/home/vqtrong/Jetson/Linux_for_Tegra/bootloader/l4t_initrd.img)... done. Making Boot image... done. Existing sosfile(/home/vqtrong/Jetson/Linux_for_Tegra/bootloader/nvtboot_recovery.bin) reused. copying tegraboot(/home/vqtrong/Jetson/Linux_for_Tegra/bootloader/t210ref/nvtboot.bin)... done. copying cpu_bootloader(/home/vqtrong/Jetson/Linux_for_Tegra/bootloader/t210ref/cboot.bin)... done. copying bpffile(/home/vqtrong/Jetson/Linux_for_Tegra/bootloader/t210ref/sc7entry-firmware.bin)... done. copying wb0boot(/home/vqtrong/Jetson/Linux_for_Tegra/bootloader/t210ref/warmboot.bin)... done. Existing tosfile(/home/vqtrong/Jetson/Linux_for_Tegra/bootloader/tos-mon-only.img) reused. Existing eksfile(/home/vqtrong/Jetson/Linux_for_Tegra/bootloader/eks.img) reused. copying dtbfile(/home/vqtrong/Jetson/Linux_for_Tegra/kernel/dtb/tegra210-p3448-0000-p3449-0000-b00.dtb)... done. Copying nv_boot_control.conf to rootfs populating kernel to rootfs... done. populating initrd to rootfs... done. populating kernel_tegra210-p3448-0000-p3449-0000-b00.dtb to rootfs... done. Making system.img... populating rootfs from /home/vqtrong/Jetson/Linux_for_Tegra/rootfs ... populating /boot/extlinux/extlinux.conf ... done. Sync'ing system.img ... done. Converting RAW image to Sparse image... done. system.img built successfully. Understanding this procedure enables us to make a custom system image which is shown in custom image guide . Nvidia also provides a script to generate a base RootFS in /Linux_for_Tegra/tools/samplefs folder (This method uses full Ubuntu desktop RootFS, so the size is not small). For example, run: sudo ./nv_build_samplefs.sh --abi aarch64 --distro ubuntu --version bionic","title":"Build system image"},{"location":"blog/jetson/linux-for-tegra/#architecture","text":"NVIDIA\u00ae Jetson\u2122 Board Support Package (BSP) architecture Jetson Board Support Package: Linux Kernel : A UNIX-like computer operating system kernel mostly used for mobile devices. Sample Root Filesystem derived from Ubuntu: A sample root filesystem of the Ubuntu distribution. Helps you create root filesystem for different configurations. Toolchain : A set of development tools chained together by stages that runs on various architectures. Bootloader : Boot software boot for initializing the system on the chip. Sources : Source code for kernel and multimedia applications. NVIDIA\u00ae Jetson\u2122 User Space Drivers : Provides the NVIDIA drivers that run in the user-space. Flashing Support Scripts and Tools : A set of scripts and associated tools to assist in flashing your system. Sample Source Code and Applications : Sample source code for developing embedded applications for the Jetson platform.","title":"Architecture"},{"location":"blog/jetson/linux-for-tegra/#package-manifest","text":"This note some important information of the provided packages: Bootloader extlinux.conf : Boot configuration file. l4t_initrd.img : L4T initrd image based on minimal Ubuntu environment. XXXref/pYYYY-YYYY/u-boot.bin : U-Boot Bootloader binary. Kernel dtb/xxx-*.dtb : Device Tree Binary (DTB) files. Image : Kernel binary image. Image.gz is a compressed version. kernel_headers.tbz2 : Kernel header files needed for compiling kernel modules. kernel_supplements.tbz2 : Loadable kernel modules specific to the included kernel zImage that was built with the default configs enabled for the device. nvidia-l4t-kernel*.deb : DEB packages containing L4T dependencies and associated components. Tools jetson-disk-image-creator.sh : Creates a disk image for the target system based on specified command line options. Image can be flashed to a micro-SD card. l4t_create_default_user.sh : Creates a default user and skips running oem-config at first boot. l4t_extract_deb.sh : Extracts Jetson Linux Debian packages. *-jetson-gpio-*.deb : Jetson GPIO packages. NV_Tegra install-nv-debs , nv-apply-debs.sh : Installs BSP packages on the target. l4t_deb_packages/* : Packages containing L4T dependencies and associated -components. nv_sample_apps/ : NVIDIA sample applications. config.tbz2 : Configuration files specific to the sample filesystem. nvidia_drivers.tbz2 : NVIDIA driver components. weston.tbz2 : NVIDIA Wayland support.","title":"Package Manifest"},{"location":"blog/jetson/linux-for-tegra/#hardware-configuration","text":"","title":"Hardware configuration"},{"location":"blog/jetson/linux-for-tegra/#headers","text":"Each Jetson developer kit includes several expansion headers and connectors (collectively, \u201cheaders\u201d): 40\u2011pin expansion header : Lets you connect a Jetson developer kit to off-the-shelf Raspberry Pi HATs (Hardware Attached on Top) such as Seeed Grove modules, SparkFun Qwiic products, and others. Many of the pins can be used either as GPIO or as \u201cspecial function I/O\u201d (SFIO) such as I2C, I2S, etc. 30\u2011pin expansion header : An NVIDIA custom header similar to the 40-pin header, available on NVIDIA\u00ae Jetson\u2122 TX2 and Jetson TX1 platforms. Its pins can also be used as GPIO or as \u201cspecial function I/O\u201d (SFIO). CSI connector for camera input M.2 Key express slot for extra Bluetooth module or SSD Memory storage The configuration of all the I/O pins on Jetson developer kits is statically defined, and is programmed into the device when it is flashed. NVIDIA provides the Jetson Expansion Header Tool (also known as Jetson\u2011IO), a Python script that runs on a Jetson developer kit and lets you change pin configurations through a graphic user interface. Jetson\u2011IO modifies the Device Tree Blob (DTB) firmware so that a new configuration for the expansion headers is applied when the developer kit is rebooted. To launch Jetson\u2011IO, enter this command on the developer kit: sudo /opt/nvidia/jetson-io/jetson-io.py Follow the instructions to configure headers and GPIO pins.","title":"Headers"},{"location":"blog/jetson/linux-for-tegra/#voltage-and-current-monitor","text":"Jetson modules include an on-board power monitor, the INA3221, to monitor the voltage and current of certain rails. The Jetson module feeds INA3221 outputs into SOC_THERM input. When one or more alert outputs are asserted, the SOC_THERM hardware reduces module power consumption to avoid violating current limits. The power monitor accepts configuration data from powermon.dtsi (the source file) The Voltage and Current can be read from sysfs . The powermon.dtsi file for the Jetson Nano module is located at: hardware/nvidia/platform/t210/porg/kernel-dts/porg-platforms/tegra210-porg-powermon-p3448-0000-a00.dtsi which defines the address for ina3221x , and the reporting channels: channel 0: POM_5V_IN channel 1: POM_5V_GPU channel 2: POM_5V_CPU i2c @ 546 c0000 { ina3221x : ina3221x @ 40 { compatible = \"ti,ina3221x\" ; reg = < 0x40 > ; status = \"okay\" ; ti , trigger - config = < 0x7003 > ; ti , continuous - config = < 0x7607 > ; ti , enable - forced - continuous ; # io - channel - cells = < 1 > ; # address - cells = < 1 > ; # size - cells = < 0 > ; channel @ 0 { reg = < 0x0 > ; ti , rail - name = \"POM_5V_IN\" ; ti , shunt - resistor - mohm = < 5 > ; }; channel @ 1 { reg = < 0x1 > ; ti , rail - name = \"POM_5V_GPU\" ; ti , shunt - resistor - mohm = < 5 > ; }; channel @ 2 { reg = < 0x2 > ; ti , rail - name = \"POM_5V_CPU\" ; ti , shunt - resistor - mohm = < 5 > ; }; }; }; Find the mounted point of ina3221x in i2c bus: head /sys/bus/i2c/devices/*/name ==> /sys/bus/i2c/devices/6-0040/name <== ina3221x This means, ina3221x is mounted at bus i2c-6 , address 0x40 . To read the mapping channel, find the rail name: sudo head /sys/bus/i2c/devices/6-0040/iio \\: device0/rail_name_* ==> /sys/bus/i2c/devices/6-0040/iio:device0/rail_name_0 <== POM_5V_IN ==> /sys/bus/i2c/devices/6-0040/iio:device0/rail_name_1 <== POM_5V_GPU ==> /sys/bus/i2c/devices/6-0040/iio:device0/rail_name_2 <== POM_5V_CPU To read total power, check the IN rail: sudo cat /sys/bus/i2c/devices/6-0040/iio \\: device0/in_voltage0_input sudo cat /sys/bus/i2c/devices/6-0040/iio \\: device0/in_current0_input sudo cat /sys/bus/i2c/devices/6-0040/iio \\: device0/in_power0_input Note: use watch to monitor: sudo watch -n1 \"cat /sys/bus/i2c/devices/6-0040/iio\\:device0/in_power0_input\"","title":"Voltage and Current Monitor"},{"location":"blog/jetson/linux-for-tegra/#improving-system-performance","text":"The window system installed with L4T is Gnome, the standard Ubuntu window manager. In many cases you can reduce boot time, response time, memory consumption, and CPU utilization by replacing Gnome with a lightweight window manager. NVIDIA recommends the LXDE environment with Compton compositing manager for this purpose. To install and enable LXDE: Enter the commands: sudo apt update && \\ sudo apt install -y lxde compton Create the configuration file /etc/xdg/autostart/lxde-compton.desktop , containing these commands: [Desktop Entry] Type = Application Name = Compton (X Compositor) GenericName = X compositor Comment = A X compositor TryExec = compton Exec = compton --backend glx -b OnlyShowIn = LXDE","title":"Improving System Performance"},{"location":"blog/jetson/linux-for-tegra/#flashing-and-booting","text":"Locate the most up-to-date usage information by running flash.sh \u2013h (using the flash.sh script included in the release). The basic usage is as follows. sudo ./flash.sh [ options ] <board> <rootdev> Where: options is one or more command line switches. All switches are optional. Switches are described in Flash Script Usage. <board> specifies the configuration to be applied to the device to be flashed. Values are listed in the table of device names in the topic Quick Start. flash.sh gets the configuration from a configuration file named <board>.conf . <rootdev> specifies the type of device that is to be flashed. Use the value mmcblk0p1 to flash a local storage device (eMMC or SD card, depending on platform), as distinguished from NFS server, for example. Flash a Partition only You can flash a specific partition instead of flashing the whole device by using the command line option \u2011k . sudo ./flash.sh -k <partition_name> [ --image <image_name> ] <board> <rootdev> Where: <partition_name> is the name of the partition to be flashed. Possible values depend on the target device. For details, see the section Default Partition Overview in the topic Bootloader. <image_name> is the name of the image file. If omitted, flash.sh chooses the image file that was used to flash whole device. Replace Kernel only Since U\u2011Boot is required for Jetson Nano devices and Jetson TX1, and is the default bootloader for Jetson TX2, the image flashed to the kernel partition is actually a U\u2011Boot image. U\u2011Boot loads the Linux kernel from /boot/Image in the root file system. For this reason, you cannot update Linux kernel image using the \u2011k kernel option. You may update /boot/Image by either of these means: Modify /boot/extlinux/extlinux.conf to add a new boot entry. Follow the instructions and example provided in /boot/extlinux/extlinux.conf . By this means you can always use cp or scp to replace /boot/Image with a custom-built kernel and launch it with U\u2011Boot. On T210 (Jetson Nano devices and Jetson TX1) devices only, connect the Jetson device\u2019s recovery USB port to your host. Enter this command at the U\u2011Boot command prompt: ums 0 mmc 1 This connects eMMC (or a Jetson Nano with SD card) to the host as a set of USB mass storage devices (each partition as a device). You then can copy your custom kernel to /boot/Image directly.","title":"Flashing and Booting"},{"location":"blog/jetson/linux-for-tegra/#u-boot-customization","text":"U-Boot is the default bootloader for NVIDIA\u00ae Jetson\u2122 Linux Driver Package (L4T) on supported platforms. Install packages on host machine: sudo apt install -y build-essential bison flex bc Nvidia uses the Linaro Aarch64 toolchain: wget http://releases.linaro.org/components/toolchain/binaries/7.3-2018.05/aarch64-linux-gnu/gcc-linaro-7.3.1-2018.05-x86_64_aarch64-linux-gnu.tar.xz Extract toolchain: mkdir $HOME /l4t-gcc && \\ tar xf gcc-linaro-7.3.1-2018.05-x86_64_aarch64-linux-gnu.tar.xz -C $HOME /l4t-gcc Set the build environment: export CROSS_COMPILE = $HOME /l4t-gcc/gcc-linaro-7.3.1-2018.05-x86_64_aarch64-linux-gnu/bin/aarch64-linux-gnu- Move to Linux_for_Tegra/sources folder. Download source code: git clone -n git://nv-tegra.nvidia.com/3rdparty/u-boot.git Go to the source folder and check the tag: cd u-boot && \\ git tag Checkout a tag that\u2019s corresponding to the JetPack version, for example: git checkout -b myuboot tegra-l4t-r32.6.1 Build U-Boot by executing: make distclean make <board_and_rev>_defconfig make Where <board_and_rev> is described in the P-number of Jetson modules. For example, the Jetson Nano: make p3450-0000_defconfig After compiling, copy the binary file u-boot.bin to the corresponding folder in bootloader , such as t210ref/p3450-0000 for Jetson Nano. To flash the new version of U-Boot, run the command: sudo ./flash.sh -k LNX <platform> mmcblk0p1 Where <platform> is the SoC name or platform.","title":"U-Boot Customization"},{"location":"blog/jetson/linux-for-tegra/#kernel-customization","text":"You can manually rebuild the kernel used for the NVIDIA\u00ae Jetson\u2122 Linux Driver Package.","title":"Kernel Customization"},{"location":"blog/jetson/linux-for-tegra/#build-kernel","text":"Install packages on host machine: sudo apt install -y build-essential bison flex bc Nvidia uses the Linaro Aarch64 toolchain: wget http://releases.linaro.org/components/toolchain/binaries/7.3-2018.05/aarch64-linux-gnu/gcc-linaro-7.3.1-2018.05-x86_64_aarch64-linux-gnu.tar.xz Extract toolchain: mkdir $HOME /l4t-gcc && \\ tar xf gcc-linaro-7.3.1-2018.05-x86_64_aarch64-linux-gnu.tar.xz -C $HOME /l4t-gcc Set the build environment: export CROSS_COMPILE = $HOME /l4t-gcc/gcc-linaro-7.3.1-2018.05-x86_64_aarch64-linux-gnu/bin/aarch64-linux-gnu- To manually download and expand the kernel sources, in a browser, navigate to https://developer.nvidia.com/embedded/downloads , to locate and download the L4T source files for your release. Extract the TBZ2 file. tar -xjf public_sources.tbz2 Extract the kernel source file. cd Linux_for_Tegra/source/public && \\ tar \u2013xjf kernel_src.tbz2 The kernel source is extracted to the kernel subdirectory. Set the shell variable with the command: export TEGRA_KERNEL_OUT = $HOME /Jetson/build Execute the following commands to create the .config file: cd <kernel_source> mkdir -p $TEGRA_KERNEL_OUT make ARCH = arm64 O = $TEGRA_KERNEL_OUT tegra_defconfig Where <kernel_source> directory contains the kernel sources (e.g. kernel-4.9 ). Execute the following commands to build the kernel including all DTBs and modules: make ARCH = arm64 O = $TEGRA_KERNEL_OUT -j<n> Where <n> indicates the number of parallel processes to be used. Replace <release_packagep>/Linux_for_Tegra/kernel/Image with a copy of $TEGRA_KERNEL_OUT/arch/arm64/boot/Image . Replace the contents of Linux_for_Tegra/kernel/dtb/ with the contents of $TEGRA_KERNEL_OUT/arch/arm64/boot/dts/ . Execute the following commands to install the kernel modules: sudo make ARCH = arm64 O = $TEGRA_KERNEL_OUT modules_install INSTALL_MOD_PATH = /Linux_for_Tegra/rootfs/ Optionally, archive the installed kernel modules using the following command: cd <modules_install_path> tar --owner root --group root -cjf kernel_supplements.tbz2 lib/modules The installed modules can be used to provide the contents of /lib/modules/<kernel_version> on the target system. Use the archive to replace the one in the kernel directory of the extracted release package prior to running apply_binaries.sh in Linux_for_Tegra/kernel/kernel_supplements.tbz2 .","title":"Build Kernel"},{"location":"blog/jetson/linux-for-tegra/#kernel-optimization","text":"Disable Console over UART Console printing over UART is a major bottleneck in kernel boot time. To reduce the bottleneck, you can reduce the volume of console printing over UART by removing console=ttyS0 from the platform configuration file, such as p3448-0000.conf . Secondary Bootloader You can remove U\u2011Boot as the secondary bootloader to remove boot time of u-boot. The following modifications are required before flashing: Edit the common configuration file at, such as: <top>/tegra_for_linux/p2771-000.conf Set USE_UBOOT to 0. # To configure whether to use U-Boot, # do either of the following before running flash.sh: # 1) Set environment variable USE_UBOOT to 0 or 1. # 2) Edit the line below to set USE_UBOOT to 0 or 1. if [ -z \" ${ USE_UBOOT } \" ] ; then USE_UBOOT = 0 ; fi ;","title":"Kernel Optimization"},{"location":"blog/linux/","text":"","title":"Linux"},{"location":"blog/linux/bootup-sequence/","tags":["linux"],"text":"Overview # A Linux system mainly goes through 3 main stages at the boot-up: BIOS stage : When the machine is powered on BIOS firmware on motherboard is the first one to be called. BIOS runs Power On Self Test (POST) to verify if the hardware is present in the machine and if it is functioning. After POST succeeds, BIOS checks the Master Boot Record (MBR) on boot device to locate and run the bootloader Bootloader stage : Bootloader will list available OS installed on the machine, and run the default one if user does not select any item manually. Bootloader reads the boot command to load the kernel image, initial ramdisk, and temporaty filesystem, to prepare for kernel to run on real filesystem Kernel stage : Kernel which is transferred from bootloader will mount the real root filesystem. It calls the first initial process to setting up system and then spawn background daemon processes System services are called based on run-level. Graphical or console UI will start to present system to users. Overview of Linux Bootup sequence BIOS Stage # Reset # Right after when user presses the power button, Switching Mode Power Supply (SMPS) checks voltage level on outputs of power supplier, and send POWER_GOOD signal to the motherboard which in turn, releases the CPU from reset state. CPU is set to start at an address called the RESET_VECTOR . This is the memory location at which the CPU expects to find the first instruction to execute after reset. At the RESET_VECTOR address, there is only one JUMP instruction which tells the location of BIOS program in ROM. RESET_VECTOR in 80386 and later x86, x86_64, IA is at 0xFFFFFFF0 [IP=0xfff0 CS.selector=0xf000 CS.base=0xffff0000] See source code of BIOS, in reset16.inc and reset16.ld and coreboot/src/cpu/x86/16bit/ Processor starts working in REAL_MODE . Real mode is also called Real Address mode with 20-bit segmented memory address (1 MB) and limitation of direct access to memory or hardware. BIOS firmware file is copied to RAM in low-memory space. Memory layout after power-on Bootstrap # BIOS stands for Basic Input Output System, located in a ROM on Motherboard of system. BIOS will do the below processes: Call POST (Power-on Self-Test) to confirm the integrity of hardware components: Timers, DMA Controllers, CPU, Video ROM\u2026 Read settings from a CMOS memory, if BIOS Setup is called, save back settings to CMOS memory Look for a boot order and lists all bootable devices Find a boot sector on the chosen boot device, i.e /dev/hda or /dev/sda Load MBR and give it control (copy 512 B of Boot sector to address starting at 0x00007C00 . If 2 last bytes of boot sector is 0xAA55 , BIOS jump to 0x00007C00 and from that point, CPU actually executes MBR). You can download source code of OpenBIOS for further information. Memory layout after BIOS stage Bootloader stage # Master Boot Record # Master Boot Record is on Hard drives with MBR partition layout, which will execute the primary bootloader and call the second bootloader. MBR is the first 512 B of a hard drive (Sector 0), contains: Primary Boot Loader Code (446 B) This code provides bootloader information and location details of actual bootloader code on the hard disk. This is helpful for CPU to load second stage of Boot loader Primary Partition Table (64 B) Maximum of 4 partition entries is listed start and end of each partition, size of partition, and type of partition Magic Number: 0x55 0xaa at the end of MB Refer to a sample MBR code in the Appendix . The first bootloader # The MBR itself contains the first stage of the bootloader. GRUB calls this stage 1. Due to its tiny size, the code in the MBR does just enough to load another sector from disk that contains additional bootstrap code. This sector might be the boot sector for a partition, but could also be a sector that was hard-coded into the MBR code when the MBR was installed. The first bootloader now has ability to read filesystem, which can scan hard disk directory and find the second bootloader which is usually bigger (located at sector 1-62) with Graphical UI, diagnostic, recovery features. Memory layout after MBR (First Bootloader) The second bootloader # GRUB calls this stage 2. This stage can load many drivers such as VGA, EXT2 filesystem, OS Loader. This stage uses a config file grub.conf to locate the path of Kernel image vmlinux , boot command and boot options, initial RAM image initrd . Because Kernel image is a compressed image, there will be a tiny routine to decompress the kernel image. This routine is in setup.bin image which is placed into RAM by second bootloader. Memory layout after GRUB (Second Bootloader) Kernel stage # Kernel decompression # From this part, Linux kernel will take care of booting up system: Decompress the vmlinux image to high memory space (over 1 MB) Decompress the initrd image and mount a temporary filesystem Configure hardware and memory allocation for the system using the boot command and boot options Start Kernel execution Kernel configuration # After all, it starts loading initrd image. Kernel will start in real-mode first at address of kernel boot sector, at _start: in /arch/x86/boot/header.S . Config CPU in real-mode Set up BSS: check the magic number 0x5a5aaa55 (the value is only right if segment register and stack are properly set, defined in /arch/x86/boot/setup.ld). The BSS section is used to store statically allocated, uninitialized data. Linux carefully ensures this area of memory is first blanked Memory layout changes in Kernel stage Jump to C code in /arch/x86/boot/main.c Clone Boot parameters Initialize Console for log/ command Initialize Heap memory for memory management Kernel is started by calling x86_64_start_kernel function in /init/main.c Create task structure and start scheduler Mount Root filesystem System start # After the root file system is loaded, system is ready to run. Run /sbin/init process Check run-level in /etc/inittab and load background daemons from the run-level program list in /etc/rcX.d/ Present the user login interface (CLI or GUI) References # Source code of Linux Kernel Book Linux Inside and the document Inside the Linux boot process Appendix # An example code for MBR will display a string when executed: mbr.nasm ; Simple MBR shows a string then hangs org 0x7c00 ; address of copied MBR in RAM entry: jmp short begin ; Data msg db 'Hello MBR' , 0 ; Function to print string putstr: lodsb ; AL = [DS:SI] or al , al ; Set zero flag if al=0 jz putstrd ; jump to putstrd if zero flag is set mov ah , 0x0e ; video function 0Eh (print char) mov bx , 0x07 ; color int 0x10 ; print the character jmp putstr ; loop putstrd: retn begin: xor ax , ax ; zero out ax mov ds , ax ; set data segment to base of RAM mov si , msg ; load address of our message call putstr ; print the message hang: jmp hang ; just loop forever ; -------------------------------------------- ; Fill zero in unused bytes size equ $ - entry %if size+2 > 512 %error \"code is too large for boot sector\" %endif times ( 512 - size - 2 ) db 0x00 ; -------------------------------------------- ; Mark MBR as bootable at byte 511 and 512 db 0x55 , 0xAA ; 2 bytes of boot signature To run this code, you have to compile it with nasm and run with qemu . nasm -f bin mbr.nasm && qemu-system-x86_64 mbr Example of customized MBR","title":"Bootup Sequence"},{"location":"blog/linux/bootup-sequence/#overview","text":"A Linux system mainly goes through 3 main stages at the boot-up: BIOS stage : When the machine is powered on BIOS firmware on motherboard is the first one to be called. BIOS runs Power On Self Test (POST) to verify if the hardware is present in the machine and if it is functioning. After POST succeeds, BIOS checks the Master Boot Record (MBR) on boot device to locate and run the bootloader Bootloader stage : Bootloader will list available OS installed on the machine, and run the default one if user does not select any item manually. Bootloader reads the boot command to load the kernel image, initial ramdisk, and temporaty filesystem, to prepare for kernel to run on real filesystem Kernel stage : Kernel which is transferred from bootloader will mount the real root filesystem. It calls the first initial process to setting up system and then spawn background daemon processes System services are called based on run-level. Graphical or console UI will start to present system to users. Overview of Linux Bootup sequence","title":"Overview"},{"location":"blog/linux/bootup-sequence/#bios-stage","text":"","title":"BIOS Stage"},{"location":"blog/linux/bootup-sequence/#reset","text":"Right after when user presses the power button, Switching Mode Power Supply (SMPS) checks voltage level on outputs of power supplier, and send POWER_GOOD signal to the motherboard which in turn, releases the CPU from reset state. CPU is set to start at an address called the RESET_VECTOR . This is the memory location at which the CPU expects to find the first instruction to execute after reset. At the RESET_VECTOR address, there is only one JUMP instruction which tells the location of BIOS program in ROM. RESET_VECTOR in 80386 and later x86, x86_64, IA is at 0xFFFFFFF0 [IP=0xfff0 CS.selector=0xf000 CS.base=0xffff0000] See source code of BIOS, in reset16.inc and reset16.ld and coreboot/src/cpu/x86/16bit/ Processor starts working in REAL_MODE . Real mode is also called Real Address mode with 20-bit segmented memory address (1 MB) and limitation of direct access to memory or hardware. BIOS firmware file is copied to RAM in low-memory space. Memory layout after power-on","title":"Reset"},{"location":"blog/linux/bootup-sequence/#bootstrap","text":"BIOS stands for Basic Input Output System, located in a ROM on Motherboard of system. BIOS will do the below processes: Call POST (Power-on Self-Test) to confirm the integrity of hardware components: Timers, DMA Controllers, CPU, Video ROM\u2026 Read settings from a CMOS memory, if BIOS Setup is called, save back settings to CMOS memory Look for a boot order and lists all bootable devices Find a boot sector on the chosen boot device, i.e /dev/hda or /dev/sda Load MBR and give it control (copy 512 B of Boot sector to address starting at 0x00007C00 . If 2 last bytes of boot sector is 0xAA55 , BIOS jump to 0x00007C00 and from that point, CPU actually executes MBR). You can download source code of OpenBIOS for further information. Memory layout after BIOS stage","title":"Bootstrap"},{"location":"blog/linux/bootup-sequence/#bootloader-stage","text":"","title":"Bootloader stage"},{"location":"blog/linux/bootup-sequence/#master-boot-record","text":"Master Boot Record is on Hard drives with MBR partition layout, which will execute the primary bootloader and call the second bootloader. MBR is the first 512 B of a hard drive (Sector 0), contains: Primary Boot Loader Code (446 B) This code provides bootloader information and location details of actual bootloader code on the hard disk. This is helpful for CPU to load second stage of Boot loader Primary Partition Table (64 B) Maximum of 4 partition entries is listed start and end of each partition, size of partition, and type of partition Magic Number: 0x55 0xaa at the end of MB Refer to a sample MBR code in the Appendix .","title":"Master Boot Record"},{"location":"blog/linux/bootup-sequence/#the-first-bootloader","text":"The MBR itself contains the first stage of the bootloader. GRUB calls this stage 1. Due to its tiny size, the code in the MBR does just enough to load another sector from disk that contains additional bootstrap code. This sector might be the boot sector for a partition, but could also be a sector that was hard-coded into the MBR code when the MBR was installed. The first bootloader now has ability to read filesystem, which can scan hard disk directory and find the second bootloader which is usually bigger (located at sector 1-62) with Graphical UI, diagnostic, recovery features. Memory layout after MBR (First Bootloader)","title":"The first bootloader"},{"location":"blog/linux/bootup-sequence/#the-second-bootloader","text":"GRUB calls this stage 2. This stage can load many drivers such as VGA, EXT2 filesystem, OS Loader. This stage uses a config file grub.conf to locate the path of Kernel image vmlinux , boot command and boot options, initial RAM image initrd . Because Kernel image is a compressed image, there will be a tiny routine to decompress the kernel image. This routine is in setup.bin image which is placed into RAM by second bootloader. Memory layout after GRUB (Second Bootloader)","title":"The second bootloader"},{"location":"blog/linux/bootup-sequence/#kernel-stage","text":"","title":"Kernel stage"},{"location":"blog/linux/bootup-sequence/#kernel-decompression","text":"From this part, Linux kernel will take care of booting up system: Decompress the vmlinux image to high memory space (over 1 MB) Decompress the initrd image and mount a temporary filesystem Configure hardware and memory allocation for the system using the boot command and boot options Start Kernel execution","title":"Kernel decompression"},{"location":"blog/linux/bootup-sequence/#kernel-configuration","text":"After all, it starts loading initrd image. Kernel will start in real-mode first at address of kernel boot sector, at _start: in /arch/x86/boot/header.S . Config CPU in real-mode Set up BSS: check the magic number 0x5a5aaa55 (the value is only right if segment register and stack are properly set, defined in /arch/x86/boot/setup.ld). The BSS section is used to store statically allocated, uninitialized data. Linux carefully ensures this area of memory is first blanked Memory layout changes in Kernel stage Jump to C code in /arch/x86/boot/main.c Clone Boot parameters Initialize Console for log/ command Initialize Heap memory for memory management Kernel is started by calling x86_64_start_kernel function in /init/main.c Create task structure and start scheduler Mount Root filesystem","title":"Kernel configuration"},{"location":"blog/linux/bootup-sequence/#system-start","text":"After the root file system is loaded, system is ready to run. Run /sbin/init process Check run-level in /etc/inittab and load background daemons from the run-level program list in /etc/rcX.d/ Present the user login interface (CLI or GUI)","title":"System start"},{"location":"blog/linux/bootup-sequence/#references","text":"Source code of Linux Kernel Book Linux Inside and the document Inside the Linux boot process","title":"References"},{"location":"blog/linux/bootup-sequence/#appendix","text":"An example code for MBR will display a string when executed: mbr.nasm ; Simple MBR shows a string then hangs org 0x7c00 ; address of copied MBR in RAM entry: jmp short begin ; Data msg db 'Hello MBR' , 0 ; Function to print string putstr: lodsb ; AL = [DS:SI] or al , al ; Set zero flag if al=0 jz putstrd ; jump to putstrd if zero flag is set mov ah , 0x0e ; video function 0Eh (print char) mov bx , 0x07 ; color int 0x10 ; print the character jmp putstr ; loop putstrd: retn begin: xor ax , ax ; zero out ax mov ds , ax ; set data segment to base of RAM mov si , msg ; load address of our message call putstr ; print the message hang: jmp hang ; just loop forever ; -------------------------------------------- ; Fill zero in unused bytes size equ $ - entry %if size+2 > 512 %error \"code is too large for boot sector\" %endif times ( 512 - size - 2 ) db 0x00 ; -------------------------------------------- ; Mark MBR as bootable at byte 511 and 512 db 0x55 , 0xAA ; 2 bytes of boot signature To run this code, you have to compile it with nasm and run with qemu . nasm -f bin mbr.nasm && qemu-system-x86_64 mbr Example of customized MBR","title":"Appendix"},{"location":"blog/linux/byobu/","tags":["linux"],"text":"Install Byobu # Byobu is an easy-to-use wrapper around the tmux (or screen ) terminal multiplexer. Byobu\u2019s primary features include multiple console windows, split panes within each window, notifications and status badges to display the status of the host, and persistent sessions across multiple connections. Byobu in action Byobu\u2019s primary features include multiple console windows, split panes within each window, notifications and status badges to display the status of the host, and persistent sessions across multiple connections. Ubuntu should come with Byobu installed by default. To check that Byobu is installed, try running this command to output its version. byobu --version If it is not installed, install it with a simple command: sudo apt install -y byobu Byobu can be configured to run by default at every text login (SSH or TTY). That behavior can be toggled with the byobu-enable and byobu-disable commands. Insert below line to the end of ~/.bashrc will run Byobu whenever a local terminal is run: _byobu_sourced = 1 . /usr/bin/byobu-launch 2 >/dev/null || true When running Byobu for the first time, it will start with just in a single window. The bottom of the screen has the status bar, which displays OS and version, a list of open windows, and various system metrics like pending updates, RAM usage and time and date. A session is simply a running instance of Byobu. A session consists of a collection of windows, which are basically shell sessions, and panes, which are windows split into multiple sections. Press Ctrl-F6 or type exit to end a session. Key Bindings # Byobu is a configuration layer on top of GNU Screen. As such, all of GNU Screen\u2019s keybindings work in Byobu exactly as in Screen. Moreover, Byobu provides a comprehensive, advanced set of commands bound to the F-keys on most keyboards. Windows Management Key Description F2 Create a new window Shift - F2 Split the screen horizontally Ctrl - F2 Split the screen vertically F3 Move to the previous window Shift - F3 Move focus to the next split F4 Move to the next window Shift - F4 Move focus to the previous split Shift - Arrows Move focus Session management Key Description Ctrl - D Exit the session F6 Detach from the session and logout Shift - F6 Detach from the session, but do not log out Ctrl - F5 Reconnect any SSH/GPG sockets or agents Misc. Key Description F5 Refresh all status notifications F7 Enter scroll back/search mode F8 Rename the current window F9 Launch the Byobu Configuration Menu F12 GNU Screen\u2019s Escape Key Alt - Page Up Scroll back through this window\u2019s history Alt - Page Down Scroll forward through this window\u2019s history Shift - F5 Collapse all splits Shift - F12 Toggle all of Byobu\u2019s keybindings on or off Copy & Paste, Search Each window in Byobu has up to 10000 lines of scroll back history, so a user can enter and navigate using the Alt-PageUp and Alt-PageDown keys. Exit this scroll back mode by hitting Enter . Copy and paste text from scroll back mode: Press the Space bar to start highlighting text Use up / down / left / right / page up / page down to select the text Press Enter to copy the text Paste the text using alt-insert or ctrl-a-] Search up and down in scroll back mode: Press / to search down Press ? to search up Actually, in scroll back mode, Byobu support vi -like commands: h - # Move the cursor left by one character j - # Move the cursor down by one line k - # Move the cursor up by one line l - # Move the cursor right by one character 0 - # Move to the beginning of the current line $ - # Move to the end of the current line G - # Moves to the specified line (defaults to the end of the buffer) ctrl + b - # Page up ctrl + f - # Page down / - # Search forward ? - # Search backward n - # Moves to the next match, either forward or backward Mouse mode # Type F12 , then : (to enable the internal terminal), then enter the command set mouse on for other commands, run list-commands Or press Alt-F12 to toggle mouse. Actions in the mouse mode: Switch between active panes and windows. Click on a window name or pane to switch. Scroll, with the mouse wheel or trackpad Resize panes by dragging and dropping To enable mouse support by default for all these operations, add these lines to ~/.byobu/profile.tmux : set -g mouse on set -g mouse-select-pane on set -g mouse-select-window on set -g mouse-resize-pane on set -g mouse-utf8 on The Backend Multiplexer # By default, Byobu will use tmux as the backend multiplexer. However, if a user prefers to use screen, they can easily change the enabled backend. byobu-select-backend Select the byobu backend : 1. tmux 2. screen Tweaks # Byobu uses default border characters from tmux which shows bold borderlines. Those borderlines are made up of rows and columns in the console, and they are indivisible. In a text-based terminal there is no structural element smaller than one character \u201ccell\u201d (which is about the size of that block cursor). The only way to reduce the size of the borders is to reduce the size of all rows/columns. Fortunately, we can manipulate the colors to give the appearance of a thinner border: set the foreground to the desired color and set the background to the background color of panes. For the latter default value is often sufficient. For example, change the borderline to orange, add these lines to ~/.byobu/profile.tmux : set -g pane-active-border-style fg = colour208,bg = default","title":"Byobu - Multiple windows in Terminal"},{"location":"blog/linux/byobu/#install-byobu","text":"Byobu is an easy-to-use wrapper around the tmux (or screen ) terminal multiplexer. Byobu\u2019s primary features include multiple console windows, split panes within each window, notifications and status badges to display the status of the host, and persistent sessions across multiple connections. Byobu in action Byobu\u2019s primary features include multiple console windows, split panes within each window, notifications and status badges to display the status of the host, and persistent sessions across multiple connections. Ubuntu should come with Byobu installed by default. To check that Byobu is installed, try running this command to output its version. byobu --version If it is not installed, install it with a simple command: sudo apt install -y byobu Byobu can be configured to run by default at every text login (SSH or TTY). That behavior can be toggled with the byobu-enable and byobu-disable commands. Insert below line to the end of ~/.bashrc will run Byobu whenever a local terminal is run: _byobu_sourced = 1 . /usr/bin/byobu-launch 2 >/dev/null || true When running Byobu for the first time, it will start with just in a single window. The bottom of the screen has the status bar, which displays OS and version, a list of open windows, and various system metrics like pending updates, RAM usage and time and date. A session is simply a running instance of Byobu. A session consists of a collection of windows, which are basically shell sessions, and panes, which are windows split into multiple sections. Press Ctrl-F6 or type exit to end a session.","title":"Install Byobu"},{"location":"blog/linux/byobu/#key-bindings","text":"Byobu is a configuration layer on top of GNU Screen. As such, all of GNU Screen\u2019s keybindings work in Byobu exactly as in Screen. Moreover, Byobu provides a comprehensive, advanced set of commands bound to the F-keys on most keyboards. Windows Management Key Description F2 Create a new window Shift - F2 Split the screen horizontally Ctrl - F2 Split the screen vertically F3 Move to the previous window Shift - F3 Move focus to the next split F4 Move to the next window Shift - F4 Move focus to the previous split Shift - Arrows Move focus Session management Key Description Ctrl - D Exit the session F6 Detach from the session and logout Shift - F6 Detach from the session, but do not log out Ctrl - F5 Reconnect any SSH/GPG sockets or agents Misc. Key Description F5 Refresh all status notifications F7 Enter scroll back/search mode F8 Rename the current window F9 Launch the Byobu Configuration Menu F12 GNU Screen\u2019s Escape Key Alt - Page Up Scroll back through this window\u2019s history Alt - Page Down Scroll forward through this window\u2019s history Shift - F5 Collapse all splits Shift - F12 Toggle all of Byobu\u2019s keybindings on or off Copy & Paste, Search Each window in Byobu has up to 10000 lines of scroll back history, so a user can enter and navigate using the Alt-PageUp and Alt-PageDown keys. Exit this scroll back mode by hitting Enter . Copy and paste text from scroll back mode: Press the Space bar to start highlighting text Use up / down / left / right / page up / page down to select the text Press Enter to copy the text Paste the text using alt-insert or ctrl-a-] Search up and down in scroll back mode: Press / to search down Press ? to search up Actually, in scroll back mode, Byobu support vi -like commands: h - # Move the cursor left by one character j - # Move the cursor down by one line k - # Move the cursor up by one line l - # Move the cursor right by one character 0 - # Move to the beginning of the current line $ - # Move to the end of the current line G - # Moves to the specified line (defaults to the end of the buffer) ctrl + b - # Page up ctrl + f - # Page down / - # Search forward ? - # Search backward n - # Moves to the next match, either forward or backward","title":"Key Bindings"},{"location":"blog/linux/byobu/#mouse-mode","text":"Type F12 , then : (to enable the internal terminal), then enter the command set mouse on for other commands, run list-commands Or press Alt-F12 to toggle mouse. Actions in the mouse mode: Switch between active panes and windows. Click on a window name or pane to switch. Scroll, with the mouse wheel or trackpad Resize panes by dragging and dropping To enable mouse support by default for all these operations, add these lines to ~/.byobu/profile.tmux : set -g mouse on set -g mouse-select-pane on set -g mouse-select-window on set -g mouse-resize-pane on set -g mouse-utf8 on","title":"Mouse mode"},{"location":"blog/linux/byobu/#the-backend-multiplexer","text":"By default, Byobu will use tmux as the backend multiplexer. However, if a user prefers to use screen, they can easily change the enabled backend. byobu-select-backend Select the byobu backend : 1. tmux 2. screen","title":"The Backend Multiplexer"},{"location":"blog/linux/byobu/#tweaks","text":"Byobu uses default border characters from tmux which shows bold borderlines. Those borderlines are made up of rows and columns in the console, and they are indivisible. In a text-based terminal there is no structural element smaller than one character \u201ccell\u201d (which is about the size of that block cursor). The only way to reduce the size of the borders is to reduce the size of all rows/columns. Fortunately, we can manipulate the colors to give the appearance of a thinner border: set the foreground to the desired color and set the background to the background color of panes. For the latter default value is often sufficient. For example, change the borderline to orange, add these lines to ~/.byobu/profile.tmux : set -g pane-active-border-style fg = colour208,bg = default","title":"Tweaks"},{"location":"blog/linux/dual-boot/","tags":["linux"],"text":"Installation # Below guide can be applied for any common Linux distro. Download an ISO image # Download the latest Ubuntu Desktop version from https://ubuntu.com/download/desktop , or visit https://old-releases.ubuntu.com/releases/ see the list of prebuilt images for older versions. Create bootable USB # USB boot is created using Rufus . Create a bootable USB Boot from live Ubuntu USB # Press F2 or F12 or any special key mentioned in BIOS guide to change the boot device. Start installing Ubuntu # The first few steps are simple as it guides to choose the language and keyboard layout. Installation Mode There are two installation modes: Normal mode All pre-built and packed things will be installed. This mode has smallest installation time Minimal mode All pre-built and packed things will be installed, but many extra packages (office, tools, etc.) will be uninstalled (using apt) to create a lightweight version. Due the un-installation, this mode takes long time to complete No need to download updates or install third-party software just yet. Select destination partition # Most of the time, Ubuntu will automatically detect the pre-installed Windows and offer an option Install Ubuntu alongside Windows Boot Manager . Using this mode, Ubuntu will do everything automatically, for example, it will create one partition then have /root with /home and a swap file of 2 GB in size under /root itself. One other option which is more advanced is Something else . In this mode, user has to create and assign mount points manually. Change default boot order # When booting up, Ubuntu will show a Grub boot menu for user to select the target OS. By default, Ubuntu will be listed on the top with index = 0 . Windows boot entry is located at the index = 2 : Grub boot menu Edit the grub by running: sudo nano /etc/default/grub Then change the default OS entry at GRUB_DEFAULT=2 to select Windows. To reduce the waiting time to 2 seconds, edit GRUB_TIMEOUT=2 . Update grub to apply the configuration changes: sudo update-grub Grub Customizer This GUI tool is an easy-to-use application which can be installed by: sudo apt install -y grub-customizer Grub Customizer Settings # Fix Date time settings # When using dual boot, after switching from and to an OS, the system time will not be the same. Sometimes, Linux shows correct time, but Windows does not. This strange behavior is because of using internet with auto-update date time function. A computer has two main clocks: a system clock and a hardware clock: A hardware clock which is also called RTC or CMOS/BIOS clock. This clock is outside the operating system, on your computer\u2019s motherboard. It keeps on running even after your system is powered off. The system clock is what is shown inside your operating system. When a computer is powered on, the hardware clock is read and used to set the system clock. Afterwards, the system clock is used for tracking time. If the operating system makes any changes to system clock, like changing time zone etc., it tries to sync this information to the hardware clock. By default, Linux assumes that the time stored in the hardware clock is in UTC, not the local time. On the other hand, Windows thinks that the time stored on the hardware clock is local time . That\u2019s where the trouble starts. There are two ways you can go about handling this issue: Make Windows use UTC time for the hardware clock Make Linux use local time for the hardware clock It is easier to make the changes in Linux: timedatectl set-local-rtc 1 That\u2019s simple as it is.","title":"Dual Boot - Using Linux with Windows"},{"location":"blog/linux/dual-boot/#installation","text":"Below guide can be applied for any common Linux distro.","title":"Installation"},{"location":"blog/linux/dual-boot/#download-an-iso-image","text":"Download the latest Ubuntu Desktop version from https://ubuntu.com/download/desktop , or visit https://old-releases.ubuntu.com/releases/ see the list of prebuilt images for older versions.","title":"Download an ISO image"},{"location":"blog/linux/dual-boot/#create-bootable-usb","text":"USB boot is created using Rufus . Create a bootable USB","title":"Create bootable USB"},{"location":"blog/linux/dual-boot/#boot-from-live-ubuntu-usb","text":"Press F2 or F12 or any special key mentioned in BIOS guide to change the boot device.","title":"Boot from live Ubuntu USB"},{"location":"blog/linux/dual-boot/#start-installing-ubuntu","text":"The first few steps are simple as it guides to choose the language and keyboard layout. Installation Mode There are two installation modes: Normal mode All pre-built and packed things will be installed. This mode has smallest installation time Minimal mode All pre-built and packed things will be installed, but many extra packages (office, tools, etc.) will be uninstalled (using apt) to create a lightweight version. Due the un-installation, this mode takes long time to complete No need to download updates or install third-party software just yet.","title":"Start installing Ubuntu"},{"location":"blog/linux/dual-boot/#select-destination-partition","text":"Most of the time, Ubuntu will automatically detect the pre-installed Windows and offer an option Install Ubuntu alongside Windows Boot Manager . Using this mode, Ubuntu will do everything automatically, for example, it will create one partition then have /root with /home and a swap file of 2 GB in size under /root itself. One other option which is more advanced is Something else . In this mode, user has to create and assign mount points manually.","title":"Select destination partition"},{"location":"blog/linux/dual-boot/#change-default-boot-order","text":"When booting up, Ubuntu will show a Grub boot menu for user to select the target OS. By default, Ubuntu will be listed on the top with index = 0 . Windows boot entry is located at the index = 2 : Grub boot menu Edit the grub by running: sudo nano /etc/default/grub Then change the default OS entry at GRUB_DEFAULT=2 to select Windows. To reduce the waiting time to 2 seconds, edit GRUB_TIMEOUT=2 . Update grub to apply the configuration changes: sudo update-grub Grub Customizer This GUI tool is an easy-to-use application which can be installed by: sudo apt install -y grub-customizer Grub Customizer","title":"Change default boot order"},{"location":"blog/linux/dual-boot/#settings","text":"","title":"Settings"},{"location":"blog/linux/dual-boot/#fix-date-time-settings","text":"When using dual boot, after switching from and to an OS, the system time will not be the same. Sometimes, Linux shows correct time, but Windows does not. This strange behavior is because of using internet with auto-update date time function. A computer has two main clocks: a system clock and a hardware clock: A hardware clock which is also called RTC or CMOS/BIOS clock. This clock is outside the operating system, on your computer\u2019s motherboard. It keeps on running even after your system is powered off. The system clock is what is shown inside your operating system. When a computer is powered on, the hardware clock is read and used to set the system clock. Afterwards, the system clock is used for tracking time. If the operating system makes any changes to system clock, like changing time zone etc., it tries to sync this information to the hardware clock. By default, Linux assumes that the time stored in the hardware clock is in UTC, not the local time. On the other hand, Windows thinks that the time stored on the hardware clock is local time . That\u2019s where the trouble starts. There are two ways you can go about handling this issue: Make Windows use UTC time for the hardware clock Make Linux use local time for the hardware clock It is easier to make the changes in Linux: timedatectl set-local-rtc 1 That\u2019s simple as it is.","title":"Fix Date time settings"},{"location":"blog/linux/log-files/","tags":["linux"],"text":"General log files # Log files are a set of records that Linux maintains for the administrators to keep track of important events. They contain messages about the server, including the kernel, services and applications running on it. Most Linux log files are stored in a plain ASCII text file and are in the /var/log directory and subdirectory. Logs are generated by the Linux system daemon log, syslogd or rsyslogd . The log files generated in a Linux environment can typically be classified into four different categories: Application Logs Event Logs Service Logs System Logs Common Linux log files names and usage: /var/log/boot.log : System boot log /var/log/kern.log : Kernel logs /var/log/messages : General message and system related stuff /var/log/secure or /var/log/auth.log : Authentication log Log files are accessed using root privileges. By definition, root is the default account that has access to all Linux files. Use the following example line command to access the respective file: sudo less [ log name here ] .log Note that log files are stored in plain text, so they can be viewed by using the following standard commands: zcat \u2013 Displays all the contents of .gz files zmore \u2013 See the file in pages, without decompressing the files zgrep \u2013 Search inside a compressed file grep \u2013 Find all occurrences of a search term in a file or filter a log file tail \u2013 Output the last few lines of files Linux kernel log # The dmesg command lets you peer into the hidden world of the Linux startup processes to review and monitor hardware device and driver messages from the kernel\u2019s own ring buffer. sudo dmesg To see the timestamp: sudo dmesg -T Watching live events: sudo dmesg --follow Log Level Every message logged to the kernel ring buffer has a level attached to it. The level represents the importance of the information in the message. The levels are: emerg : System is unusable. alert : Action must be taken immediately. crit : Critical conditions. err : Error conditions. warn : Warning conditions. notice : Normal but significant condition. info : Informational. debug : Debug-level messages. We can make dmesg extract messages that match a particular level by using the -l (level) option and passing the name of the level as a command-line parameter. sudo dmesg -l info,notice Log Categories The dmesg messages are grouped into categories called facilities or categories. The list of facilities is: kern : Kernel messages. user : User-level messages. mail : Mail system. daemon : System daemons. auth : Security/authorization messages. syslog : Internal syslogd messages. lpr : Line printer subsystem. news : Network news subsystem. We can ask dmesg to filter its output to only show messages in a specific facility. To do so, we must use the -f (facility) option: sudo dmesg -f syslog,daemon The -x (decode) option makes dmesg show the facility and level as human-readable prefixes to each line. sudo dmesg -x Exercise # Write an application that simply generates an exception (such as divided by 0). Check the log generated in dmesg and appport to understand about generate events. Configure system to generate a coredump file when an exception happens.","title":"Log Files"},{"location":"blog/linux/log-files/#general-log-files","text":"Log files are a set of records that Linux maintains for the administrators to keep track of important events. They contain messages about the server, including the kernel, services and applications running on it. Most Linux log files are stored in a plain ASCII text file and are in the /var/log directory and subdirectory. Logs are generated by the Linux system daemon log, syslogd or rsyslogd . The log files generated in a Linux environment can typically be classified into four different categories: Application Logs Event Logs Service Logs System Logs Common Linux log files names and usage: /var/log/boot.log : System boot log /var/log/kern.log : Kernel logs /var/log/messages : General message and system related stuff /var/log/secure or /var/log/auth.log : Authentication log Log files are accessed using root privileges. By definition, root is the default account that has access to all Linux files. Use the following example line command to access the respective file: sudo less [ log name here ] .log Note that log files are stored in plain text, so they can be viewed by using the following standard commands: zcat \u2013 Displays all the contents of .gz files zmore \u2013 See the file in pages, without decompressing the files zgrep \u2013 Search inside a compressed file grep \u2013 Find all occurrences of a search term in a file or filter a log file tail \u2013 Output the last few lines of files","title":"General log files"},{"location":"blog/linux/log-files/#linux-kernel-log","text":"The dmesg command lets you peer into the hidden world of the Linux startup processes to review and monitor hardware device and driver messages from the kernel\u2019s own ring buffer. sudo dmesg To see the timestamp: sudo dmesg -T Watching live events: sudo dmesg --follow Log Level Every message logged to the kernel ring buffer has a level attached to it. The level represents the importance of the information in the message. The levels are: emerg : System is unusable. alert : Action must be taken immediately. crit : Critical conditions. err : Error conditions. warn : Warning conditions. notice : Normal but significant condition. info : Informational. debug : Debug-level messages. We can make dmesg extract messages that match a particular level by using the -l (level) option and passing the name of the level as a command-line parameter. sudo dmesg -l info,notice Log Categories The dmesg messages are grouped into categories called facilities or categories. The list of facilities is: kern : Kernel messages. user : User-level messages. mail : Mail system. daemon : System daemons. auth : Security/authorization messages. syslog : Internal syslogd messages. lpr : Line printer subsystem. news : Network news subsystem. We can ask dmesg to filter its output to only show messages in a specific facility. To do so, we must use the -f (facility) option: sudo dmesg -f syslog,daemon The -x (decode) option makes dmesg show the facility and level as human-readable prefixes to each line. sudo dmesg -x","title":"Linux kernel log"},{"location":"blog/linux/log-files/#exercise","text":"Write an application that simply generates an exception (such as divided by 0). Check the log generated in dmesg and appport to understand about generate events. Configure system to generate a coredump file when an exception happens.","title":"Exercise"},{"location":"blog/linux/notes/","tags":["linux","notes"],"text":"Find a mirror repo # While doing with Ubuntu on ARM, the default repo for arm64 is ports.ubuntu.com , but it\u2019s quite slow if your location is far from it. Are there alternative repositories to ports.ubuntu.com for ARM? Malte Skoruppa answered that question with a nice script. I have modified it a bit: change connect timeout to 5 seconds add option to show connection speed Download find_mirrors.h and set it executable. To find mirrors : ./find_mirrors.sh arm64 bionic main http://ftp.lanet.kr/ubuntu-ports http://ftp.harukasan.org/ubuntu-ports http://mirror.kumi.systems/ubuntu-ports http://mirror.misakamikoto.network/ubuntu-ports http://mirror.coganng.com/ubuntu-ports http://ftp.tu-chemnitz.de/pub/linux/ubuntu-ports To show the connection speed : ./find_mirrors.sh arm64 bionic main speed 0.203373 http://mirror.coganng.com/ubuntu-ports 0.770989 http://ftp.tu-chemnitz.de/pub/linux/ubuntu-ports 0.240577 http://ftp.lanet.kr/ubuntu-ports 0.572857 http://mirror.kumi.systems/ubuntu-ports 0.264465 http://mirror.misakamikoto.network/ubuntu-ports 0.432951 http://ftp.harukasan.org/ubuntu-ports To sort the connection speed : sort the first column ./find_mirrors.sh arm64 bionic main speed | sort -k 1 0.203373 http://mirror.coganng.com/ubuntu-ports 0.240577 http://ftp.lanet.kr/ubuntu-ports 0.264465 http://mirror.misakamikoto.network/ubuntu-ports 0.432951 http://ftp.harukasan.org/ubuntu-ports 0.572857 http://mirror.kumi.systems/ubuntu-ports 0.770989 http://ftp.tu-chemnitz.de/pub/linux/ubuntu-ports Alias in scripts # Alisa is defined for each user, either directly in .bashrc or in separated file .bash-aliases . alias apt = apt-fast Alias, by default, is enabled in interactive shell, and disabled in scripts. Alias with sudo : To use alias with sudo , define a new alias: alias sudo = \"sudo \" The trailing space after sudo will cause the next word after sudo is interpreted. sudo apt will be: sudo apt-fast Alias in scripts : Enable expand_aliases flag with shopt , and define aliases in the scripts: Must have the shebang #!/bin/bash #!/bin/bash shopt -s expand_aliases alias apt = apt-fast alias sudo = \"sudo \" sudo apt install build-essential Continue to run a bash script # When a bash script run with set -e option, it will stop when any command returns an error. In some cases, we still need to continue the script, here is a way: Wrap the command with true expression umount .... || /bin/true Ignoring exit codes isn\u2019t really safe !!! Fix USB Partition # USB with wrong partition table can not be read. Erase the entire partition table is needed. sudo dd if = /dev/zero of = /dev/sda bs = 512 count = 1 Then use fdisk to create GPT partition table and add new partition. sudo fdisk /dev/sdx The format the partition: sudo mkfs.ext4 /dev/sdxy Visual Studio Code # Visual Studio Code is far better than Sublime Text. Here is a method to install it automatically: wget -qO- https://packages.microsoft.com/keys/microsoft.asc \\ | gpg --dearmor \\ > packages.microsoft.gpg \\ && \\ sudo install -o root -g root -m 644 \\ packages.microsoft.gpg \\ /etc/apt/trusted.gpg.d/ \\ && \\ rm -f packages.microsoft.gpg \\ && \\ sudo sh -c \\ 'echo \"\\ deb [signed-by=/etc/apt/trusted.gpg.d/packages.microsoft.gpg] \\ https://packages.microsoft.com/repos/code stable main\\ \" \\ > /etc/apt/sources.list.d/vscode.list' \\ && \\ sudo apt install -y apt-transport-https \\ && \\ sudo apt update \\ && \\ sudo apt install -y code GDB for Multiple Architectures # Assuming that the target is running on ARM machine, and we need to run GDB on X64 machine. Install gdb-multiarch , and run it: gdb-multiarch Enable core-dump and set target directory on /mnt/xhci-sda1 : ulimit -c unlimited echo \"/mnt/xhci-sda1/coredump_%e_%p_%t\" > /proc/sys/kernel/core_pattern Re-run application to get core-dump. Copy the executable binary, e.g. ivilauncher , and the core-dump to an Ubuntu host. Load the core-dump file to see missing libraries: ( gdb ) core coredump_ivilauncher_xxxx ( gdb ) info shared That will print out path of dynamic libraries, such as /usr/lib , /lib , /opt/share , etc. Copy the rootfs from the target device, for faster, only copy the folders containing missing libraries, for example: mkdir /mnt/xhci-sda1/rootfs cp -rf /usr /mnt/xhci-sda1/rootfs cp -rf /lib /mnt/xhci-sda1/rootfs cp -rf /opt /mnt/xhci-sda1/rootfs Then copy the rootfs to a new folder on the host machine, such as /home/vqtrong/Desktop/issue/rootfs . In GDB, set the sysroot and solib-search-path : set sysroot /home/vqtrong/Desktop/issue/rootfs set solib-search-path /home/vqtrong/Desktop/issue/rootfs Finally, use backtrace to see all call stacks: ( gdb ) bt full #4 0x00118884 in QList<RADIO_UPDATE_LIST_FM_t>::operator(int) () #5 0x00111f68 in HacRadio::updatePresetList() () #6 0x001113a4 in HacRadio::setRadioMode(BAND_e) () #7 0x0010f8fc in HacRadio::prepareRequestAudio() () #8 0x000533f0 in HAppManager::requestHac(HAppComponent::VIEW_MODE_LIST, bool, bool) () #9 0x00070c08 in HAppManager::onAgreeHide() () Take screenshot over SSH terminal # One of unique screenshot utilities is scrot (short for \u201cSCReen shOT\u201d), which is a command-line screenshot utility. sudo apt install scrot It is easy to screen-capture the entire desktop. Simply run scrot command without any argument, and it will save a screenshot of the entire desktop as a (date-stamped) .png file in the current directory. Add a filename if you want to save to a specific one. scrot From SSH, you have to set the DISPLAY environment variable before taking a screenshot: export DISPLAY = :0 && \\ scrot Automount USB on Xubuntu # Install below packages: sudo apt install thunar-volman gvfs udisks2 Then enable Volume Manager feature in Thunar Preferences, and select Automount features: Thunar Volume Manager - Automount features Share keyboard and mouse # Barrier is a software that mimics the functionality of a KVM switch, which would allow you to use a single keyboard and mouse to control multiple computers. Linux On Ubuntu 18.04, install via Ubuntu Snap Software. On Ubuntu 20.04+, install via Ubuntu APT: sudo apt install barrier Run and select Client mode. You have to set the Server\u2019s IP manually because the auto-detect function may not work well. Barrier can not auto-start at boot if it is installed from snap, unless you manually add an entry to Startup Application list. For example: Ubuntu 18.04 /snap/barrier/682/usr/bin/barrierc -f --no-tray --debug INFO --name 2ff17p2 --disable-crypto [ 192 .168.100.221 ] :24800 or Ubuntu 20.04 /usr/bin/barrierc -f --no-tray --debug INFO --name 2ff17p2 --disable-crypto [ 192 .168.100.221 ] :24800 Windows Download the setup file on the GitHub. The installer also automatically install Bonjour service. Run and select Server mode. Click on Configure and add clients by their names. Setting up Barrier on Ubuntu and Windows","title":"Notes for working in Linux"},{"location":"blog/linux/notes/#find-a-mirror-repo","text":"While doing with Ubuntu on ARM, the default repo for arm64 is ports.ubuntu.com , but it\u2019s quite slow if your location is far from it. Are there alternative repositories to ports.ubuntu.com for ARM? Malte Skoruppa answered that question with a nice script. I have modified it a bit: change connect timeout to 5 seconds add option to show connection speed Download find_mirrors.h and set it executable. To find mirrors : ./find_mirrors.sh arm64 bionic main http://ftp.lanet.kr/ubuntu-ports http://ftp.harukasan.org/ubuntu-ports http://mirror.kumi.systems/ubuntu-ports http://mirror.misakamikoto.network/ubuntu-ports http://mirror.coganng.com/ubuntu-ports http://ftp.tu-chemnitz.de/pub/linux/ubuntu-ports To show the connection speed : ./find_mirrors.sh arm64 bionic main speed 0.203373 http://mirror.coganng.com/ubuntu-ports 0.770989 http://ftp.tu-chemnitz.de/pub/linux/ubuntu-ports 0.240577 http://ftp.lanet.kr/ubuntu-ports 0.572857 http://mirror.kumi.systems/ubuntu-ports 0.264465 http://mirror.misakamikoto.network/ubuntu-ports 0.432951 http://ftp.harukasan.org/ubuntu-ports To sort the connection speed : sort the first column ./find_mirrors.sh arm64 bionic main speed | sort -k 1 0.203373 http://mirror.coganng.com/ubuntu-ports 0.240577 http://ftp.lanet.kr/ubuntu-ports 0.264465 http://mirror.misakamikoto.network/ubuntu-ports 0.432951 http://ftp.harukasan.org/ubuntu-ports 0.572857 http://mirror.kumi.systems/ubuntu-ports 0.770989 http://ftp.tu-chemnitz.de/pub/linux/ubuntu-ports","title":"Find a mirror repo"},{"location":"blog/linux/notes/#alias-in-scripts","text":"Alisa is defined for each user, either directly in .bashrc or in separated file .bash-aliases . alias apt = apt-fast Alias, by default, is enabled in interactive shell, and disabled in scripts. Alias with sudo : To use alias with sudo , define a new alias: alias sudo = \"sudo \" The trailing space after sudo will cause the next word after sudo is interpreted. sudo apt will be: sudo apt-fast Alias in scripts : Enable expand_aliases flag with shopt , and define aliases in the scripts: Must have the shebang #!/bin/bash #!/bin/bash shopt -s expand_aliases alias apt = apt-fast alias sudo = \"sudo \" sudo apt install build-essential","title":"Alias in scripts"},{"location":"blog/linux/notes/#continue-to-run-a-bash-script","text":"When a bash script run with set -e option, it will stop when any command returns an error. In some cases, we still need to continue the script, here is a way: Wrap the command with true expression umount .... || /bin/true Ignoring exit codes isn\u2019t really safe !!!","title":"Continue to run a bash script"},{"location":"blog/linux/notes/#fix-usb-partition","text":"USB with wrong partition table can not be read. Erase the entire partition table is needed. sudo dd if = /dev/zero of = /dev/sda bs = 512 count = 1 Then use fdisk to create GPT partition table and add new partition. sudo fdisk /dev/sdx The format the partition: sudo mkfs.ext4 /dev/sdxy","title":"Fix USB Partition"},{"location":"blog/linux/notes/#visual-studio-code","text":"Visual Studio Code is far better than Sublime Text. Here is a method to install it automatically: wget -qO- https://packages.microsoft.com/keys/microsoft.asc \\ | gpg --dearmor \\ > packages.microsoft.gpg \\ && \\ sudo install -o root -g root -m 644 \\ packages.microsoft.gpg \\ /etc/apt/trusted.gpg.d/ \\ && \\ rm -f packages.microsoft.gpg \\ && \\ sudo sh -c \\ 'echo \"\\ deb [signed-by=/etc/apt/trusted.gpg.d/packages.microsoft.gpg] \\ https://packages.microsoft.com/repos/code stable main\\ \" \\ > /etc/apt/sources.list.d/vscode.list' \\ && \\ sudo apt install -y apt-transport-https \\ && \\ sudo apt update \\ && \\ sudo apt install -y code","title":"Visual Studio Code"},{"location":"blog/linux/notes/#gdb-for-multiple-architectures","text":"Assuming that the target is running on ARM machine, and we need to run GDB on X64 machine. Install gdb-multiarch , and run it: gdb-multiarch Enable core-dump and set target directory on /mnt/xhci-sda1 : ulimit -c unlimited echo \"/mnt/xhci-sda1/coredump_%e_%p_%t\" > /proc/sys/kernel/core_pattern Re-run application to get core-dump. Copy the executable binary, e.g. ivilauncher , and the core-dump to an Ubuntu host. Load the core-dump file to see missing libraries: ( gdb ) core coredump_ivilauncher_xxxx ( gdb ) info shared That will print out path of dynamic libraries, such as /usr/lib , /lib , /opt/share , etc. Copy the rootfs from the target device, for faster, only copy the folders containing missing libraries, for example: mkdir /mnt/xhci-sda1/rootfs cp -rf /usr /mnt/xhci-sda1/rootfs cp -rf /lib /mnt/xhci-sda1/rootfs cp -rf /opt /mnt/xhci-sda1/rootfs Then copy the rootfs to a new folder on the host machine, such as /home/vqtrong/Desktop/issue/rootfs . In GDB, set the sysroot and solib-search-path : set sysroot /home/vqtrong/Desktop/issue/rootfs set solib-search-path /home/vqtrong/Desktop/issue/rootfs Finally, use backtrace to see all call stacks: ( gdb ) bt full #4 0x00118884 in QList<RADIO_UPDATE_LIST_FM_t>::operator(int) () #5 0x00111f68 in HacRadio::updatePresetList() () #6 0x001113a4 in HacRadio::setRadioMode(BAND_e) () #7 0x0010f8fc in HacRadio::prepareRequestAudio() () #8 0x000533f0 in HAppManager::requestHac(HAppComponent::VIEW_MODE_LIST, bool, bool) () #9 0x00070c08 in HAppManager::onAgreeHide() ()","title":"GDB for Multiple Architectures"},{"location":"blog/linux/notes/#take-screenshot-over-ssh-terminal","text":"One of unique screenshot utilities is scrot (short for \u201cSCReen shOT\u201d), which is a command-line screenshot utility. sudo apt install scrot It is easy to screen-capture the entire desktop. Simply run scrot command without any argument, and it will save a screenshot of the entire desktop as a (date-stamped) .png file in the current directory. Add a filename if you want to save to a specific one. scrot From SSH, you have to set the DISPLAY environment variable before taking a screenshot: export DISPLAY = :0 && \\ scrot","title":"Take screenshot over SSH terminal"},{"location":"blog/linux/notes/#automount-usb-on-xubuntu","text":"Install below packages: sudo apt install thunar-volman gvfs udisks2 Then enable Volume Manager feature in Thunar Preferences, and select Automount features: Thunar Volume Manager - Automount features","title":"Automount USB on Xubuntu"},{"location":"blog/linux/notes/#share-keyboard-and-mouse","text":"Barrier is a software that mimics the functionality of a KVM switch, which would allow you to use a single keyboard and mouse to control multiple computers. Linux On Ubuntu 18.04, install via Ubuntu Snap Software. On Ubuntu 20.04+, install via Ubuntu APT: sudo apt install barrier Run and select Client mode. You have to set the Server\u2019s IP manually because the auto-detect function may not work well. Barrier can not auto-start at boot if it is installed from snap, unless you manually add an entry to Startup Application list. For example: Ubuntu 18.04 /snap/barrier/682/usr/bin/barrierc -f --no-tray --debug INFO --name 2ff17p2 --disable-crypto [ 192 .168.100.221 ] :24800 or Ubuntu 20.04 /usr/bin/barrierc -f --no-tray --debug INFO --name 2ff17p2 --disable-crypto [ 192 .168.100.221 ] :24800 Windows Download the setup file on the GitHub. The installer also automatically install Bonjour service. Run and select Server mode. Click on Configure and add clients by their names. Setting up Barrier on Ubuntu and Windows","title":"Share keyboard and mouse"},{"location":"blog/linux/samba/","tags":["linux"],"text":"Installation # Samba is available from the official Ubuntu repositories. To install it on Ubuntu system follow the steps below: Start by updating the apt packages index: sudo apt update Install the Samba package with the following command: sudo apt install -y samba Once the installation is completed, the Samba service will start automatically. To check whether the Samba server is running, type: sudo systemctl status smbd smbd.service - Samba SMB Daemon Loaded: loaded (/lib/systemd/system/smbd.service; enabled; vendor preset: enabled) Active: active (running) since Mon 2021-07-12 15:30:57 +07; 1min 41s ago Docs: man:smbd(8) man:samba(7) man:smb.conf(5) Main PID: 4059 (smbd) Status: \"smbd: ready to serve connections...\" Tasks: 4 (limit: 2329) CGroup: /system.slice/smbd.service \u251c\u25004059 /usr/sbin/smbd --foreground --no-process-group \u251c\u25004061 /usr/sbin/smbd --foreground --no-process-group \u251c\u25004062 /usr/sbin/smbd --foreground --no-process-group \u2514\u25004064 /usr/sbin/smbd --foreground --no-process-group Jul 12 15:30:57 ubuntu18 systemd[1]: Starting Samba SMB Daemon... Jul 12 15:30:57 ubuntu18 systemd[1]: Started Samba SMB Daemon. Add a user # Samba has its own user management system. However, any user existing on the samba user list must also exist within /etc/passwd file. Use the smbpasswd command to add a user to Samba user list: sudo smbpasswd -a $USER Configuration # Before making changes to the Samba configuration file, create a backup for future reference purposes: sudo cp /etc/samba/smb.conf { ,.backup } Edit the Samba configuration file sudo nano /etc/samba/smb.conf The default configuration file that ships with the Samba package is configured for standalone Samba server. Open the file and make sure server role is set to standalone server . ... # Most people will want \"standalone sever\" or \"member server\". # Running as \"active directory domain controller\" will require first # running \"samba-tool domain provision\" to wipe databases and create a # new domain. server role = standalone server ... Uncomment the [home] section, then edit its options as below: [homes] comment = Home Directories browseable = yes read only = no create mask = 0700 directory mask = 0700 valid users = %S Use mask 0775 to enable execution permission. Save the file, then test the parameters by running the utility testparm to see the configs: testparm testparm Load smb config files from /etc/samba/smb.conf rlimit_max: increasing rlimit_max (1024) to minimum Windows limit (16384) WARNING: The \"syslog\" option is deprecated Processing section \"[homes]\" Processing section \"[printers]\" Processing section \"[print$]\" Loaded services file OK. Server role: ROLE_STANDALONE Press enter to see a dump of your service definitions # Global parameters [global] dns proxy = No log file = /var/log/samba/log.%m map to guest = Bad User max log size = 1000 obey pam restrictions = Yes pam password change = Yes panic action = /usr/share/samba/panic-action %d passwd chat = *Enter\\snew\\s*\\spassword:* %n\\n *Retype\\snew\\s*\\spassword:* %n\\n *password\\supdated\\ssuccessfully* . passwd program = /usr/bin/passwd %u server role = standalone server server string = %h server (Samba, Ubuntu) syslog = 0 unix password sync = Yes usershare allow guests = Yes idmap config * : backend = tdb [homes] browseable = No comment = Home Directories create mask = 0700 directory mask = 0700 read only = No valid users = %S [work] path = /mnt/work comment = Workspace create mask = 0700 directory mask = 0700 read only = No Then restart the service: sudo service smbd restart Finally, connect to the Samba Server from another computer with username and password set in above steps. The path to the Samba server can be located by IP Address, e.g. \\\\192.168.100.12\\<username> or by a computer name, e.g. \\\\ubuntu\\<username> . Quick clear the config file after making a backup : sudo bash -c 'echo \"\" > /etc/samba/smb.conf'","title":"Samba - Sharing Files in a Network"},{"location":"blog/linux/samba/#installation","text":"Samba is available from the official Ubuntu repositories. To install it on Ubuntu system follow the steps below: Start by updating the apt packages index: sudo apt update Install the Samba package with the following command: sudo apt install -y samba Once the installation is completed, the Samba service will start automatically. To check whether the Samba server is running, type: sudo systemctl status smbd smbd.service - Samba SMB Daemon Loaded: loaded (/lib/systemd/system/smbd.service; enabled; vendor preset: enabled) Active: active (running) since Mon 2021-07-12 15:30:57 +07; 1min 41s ago Docs: man:smbd(8) man:samba(7) man:smb.conf(5) Main PID: 4059 (smbd) Status: \"smbd: ready to serve connections...\" Tasks: 4 (limit: 2329) CGroup: /system.slice/smbd.service \u251c\u25004059 /usr/sbin/smbd --foreground --no-process-group \u251c\u25004061 /usr/sbin/smbd --foreground --no-process-group \u251c\u25004062 /usr/sbin/smbd --foreground --no-process-group \u2514\u25004064 /usr/sbin/smbd --foreground --no-process-group Jul 12 15:30:57 ubuntu18 systemd[1]: Starting Samba SMB Daemon... Jul 12 15:30:57 ubuntu18 systemd[1]: Started Samba SMB Daemon.","title":"Installation"},{"location":"blog/linux/samba/#add-a-user","text":"Samba has its own user management system. However, any user existing on the samba user list must also exist within /etc/passwd file. Use the smbpasswd command to add a user to Samba user list: sudo smbpasswd -a $USER","title":"Add a user"},{"location":"blog/linux/samba/#configuration","text":"Before making changes to the Samba configuration file, create a backup for future reference purposes: sudo cp /etc/samba/smb.conf { ,.backup } Edit the Samba configuration file sudo nano /etc/samba/smb.conf The default configuration file that ships with the Samba package is configured for standalone Samba server. Open the file and make sure server role is set to standalone server . ... # Most people will want \"standalone sever\" or \"member server\". # Running as \"active directory domain controller\" will require first # running \"samba-tool domain provision\" to wipe databases and create a # new domain. server role = standalone server ... Uncomment the [home] section, then edit its options as below: [homes] comment = Home Directories browseable = yes read only = no create mask = 0700 directory mask = 0700 valid users = %S Use mask 0775 to enable execution permission. Save the file, then test the parameters by running the utility testparm to see the configs: testparm testparm Load smb config files from /etc/samba/smb.conf rlimit_max: increasing rlimit_max (1024) to minimum Windows limit (16384) WARNING: The \"syslog\" option is deprecated Processing section \"[homes]\" Processing section \"[printers]\" Processing section \"[print$]\" Loaded services file OK. Server role: ROLE_STANDALONE Press enter to see a dump of your service definitions # Global parameters [global] dns proxy = No log file = /var/log/samba/log.%m map to guest = Bad User max log size = 1000 obey pam restrictions = Yes pam password change = Yes panic action = /usr/share/samba/panic-action %d passwd chat = *Enter\\snew\\s*\\spassword:* %n\\n *Retype\\snew\\s*\\spassword:* %n\\n *password\\supdated\\ssuccessfully* . passwd program = /usr/bin/passwd %u server role = standalone server server string = %h server (Samba, Ubuntu) syslog = 0 unix password sync = Yes usershare allow guests = Yes idmap config * : backend = tdb [homes] browseable = No comment = Home Directories create mask = 0700 directory mask = 0700 read only = No valid users = %S [work] path = /mnt/work comment = Workspace create mask = 0700 directory mask = 0700 read only = No Then restart the service: sudo service smbd restart Finally, connect to the Samba Server from another computer with username and password set in above steps. The path to the Samba server can be located by IP Address, e.g. \\\\192.168.100.12\\<username> or by a computer name, e.g. \\\\ubuntu\\<username> . Quick clear the config file after making a backup : sudo bash -c 'echo \"\" > /etc/samba/smb.conf'","title":"Configuration"},{"location":"blog/linux/shell-script/","tags":["linux"],"text":"Unix Shells # A shell is a command line interpreter that interprets the command line input and instructs the operating system to perform any necessary tasks and commands. Shell commands can be put into scripts to do multi-stages and more complex works. Bourne Shell (sh): a historically first shell C Shell (csh): an C style shell Korn Shell (ksh): a mixed of Bourne Shell and C Shell Bourne Again Shell (bash): an GNU version of Korn Shell Debian Almquist shell (dash): a smaller Bash shell Tenex-extended C Shell (tcsh): an Advanced C Shell Z shell (zsh): the most advanced shell To see available shells in the current system: cat /etc/shells User default shell The file /etc/passwd list all username, groups, and login shell. For example, the root account use bash shell: cat /etc/passwd | grep root root:x:0:0:root:/root:/bin/bash At runtime, to get current shell: ps -p $$ # or echo $0 Change shell To change shell at runtime, Type the name at the command line and then press the enter key. In this example, to change from any shell to the bash , type: bash To change default shell for a user, use chsh command. chsh -s <shell> # or sudo chsh -s <shell> <user> Shell Environment # Environment variables save the properties of the working shell environment. To view environment variables: env # or printenv You can see some familiar variables: PATH , HOME , SHELL , PWD , LANG , etc. Shell scripts # A bash script is a series of commands written in a file. These are read and executed by the bash program. The program executes line by line. By naming conventions, bash scripts end with a .sh. However, bash scripts can run perfectly fine without the sh extension. Scripts are also identified with a shebang . Shebang is a combination of bash # and bang ! followed the bash shell path. This is the first line of the script. Shebang tells the shell to execute it via bash shell. Shebang is simply an absolute path to the bash interpreter. Below is an example of the shebang statement. #! /bin/bash Scripts have execution rights for the user executing them. Set the e x ecution flag with chmod command: chmod +x script.sh Example script to read user input: #!/bin/sh echo \"What is your name?\" read PERSON echo \"Hello, $PERSON \" Another example: Startup Scripts /etc/profile : run first for all users during the login process $HOME/.bashrc : run for individual user\u2019s customized setup when executing bash Advanced Bash-Scripting Guide An in-depth exploration of the art of shell scripting available at https://tldp.org/LDP/abs/html/ . Exercise # The below script randomly creates many .txt files: #!/bin/bash for i in { 1 ..10 } do num = ` expr $RANDOM % 4 ` case $num in 0 ) touch ./RIGHT_CAT_ $i .txt ;; 1 ) touch ./RIGHT_DOG_ $i .txt ;; 2 ) touch ./WRONG_CAT_ $i .txt ;; 3 ) touch ./WRONG_DOG_ $i .txt ;; esac done You have to write a script to do: Replace WRONG to RIGHT in filename. If the target filename already exists, append _new to the filename. For example: Change WRONG_CAT_1.txt to RIGHT_CAT_1_new.txt when RIGHT_CAT_1.txt exists. Create 2 folders CAT and DOG and move all files to corresponding folders","title":"Shell Scripts"},{"location":"blog/linux/shell-script/#unix-shells","text":"A shell is a command line interpreter that interprets the command line input and instructs the operating system to perform any necessary tasks and commands. Shell commands can be put into scripts to do multi-stages and more complex works. Bourne Shell (sh): a historically first shell C Shell (csh): an C style shell Korn Shell (ksh): a mixed of Bourne Shell and C Shell Bourne Again Shell (bash): an GNU version of Korn Shell Debian Almquist shell (dash): a smaller Bash shell Tenex-extended C Shell (tcsh): an Advanced C Shell Z shell (zsh): the most advanced shell To see available shells in the current system: cat /etc/shells User default shell The file /etc/passwd list all username, groups, and login shell. For example, the root account use bash shell: cat /etc/passwd | grep root root:x:0:0:root:/root:/bin/bash At runtime, to get current shell: ps -p $$ # or echo $0 Change shell To change shell at runtime, Type the name at the command line and then press the enter key. In this example, to change from any shell to the bash , type: bash To change default shell for a user, use chsh command. chsh -s <shell> # or sudo chsh -s <shell> <user>","title":"Unix Shells"},{"location":"blog/linux/shell-script/#shell-environment","text":"Environment variables save the properties of the working shell environment. To view environment variables: env # or printenv You can see some familiar variables: PATH , HOME , SHELL , PWD , LANG , etc.","title":"Shell Environment"},{"location":"blog/linux/shell-script/#shell-scripts","text":"A bash script is a series of commands written in a file. These are read and executed by the bash program. The program executes line by line. By naming conventions, bash scripts end with a .sh. However, bash scripts can run perfectly fine without the sh extension. Scripts are also identified with a shebang . Shebang is a combination of bash # and bang ! followed the bash shell path. This is the first line of the script. Shebang tells the shell to execute it via bash shell. Shebang is simply an absolute path to the bash interpreter. Below is an example of the shebang statement. #! /bin/bash Scripts have execution rights for the user executing them. Set the e x ecution flag with chmod command: chmod +x script.sh Example script to read user input: #!/bin/sh echo \"What is your name?\" read PERSON echo \"Hello, $PERSON \" Another example: Startup Scripts /etc/profile : run first for all users during the login process $HOME/.bashrc : run for individual user\u2019s customized setup when executing bash Advanced Bash-Scripting Guide An in-depth exploration of the art of shell scripting available at https://tldp.org/LDP/abs/html/ .","title":"Shell scripts"},{"location":"blog/linux/shell-script/#exercise","text":"The below script randomly creates many .txt files: #!/bin/bash for i in { 1 ..10 } do num = ` expr $RANDOM % 4 ` case $num in 0 ) touch ./RIGHT_CAT_ $i .txt ;; 1 ) touch ./RIGHT_DOG_ $i .txt ;; 2 ) touch ./WRONG_CAT_ $i .txt ;; 3 ) touch ./WRONG_DOG_ $i .txt ;; esac done You have to write a script to do: Replace WRONG to RIGHT in filename. If the target filename already exists, append _new to the filename. For example: Change WRONG_CAT_1.txt to RIGHT_CAT_1_new.txt when RIGHT_CAT_1.txt exists. Create 2 folders CAT and DOG and move all files to corresponding folders","title":"Exercise"},{"location":"blog/linux/system-call/","tags":["linux","c/c++"],"text":"User Space and Kernel Space # A module runs in kernel space , whereas applications run in user space . This concept is at the base of operating system theory. The role of the operating system, in practice, is to provide programs with a consistent view of the computer\u2019s hardware. In addition, the operating system must account for independent operation of programs and protection against unauthorized access to resources. This nontrivial task is possible only if the CPU enforces protection of system software from the applications. Every modern processor is able to enforce this behavior. The chosen approach is to implement different operating modalities (or levels) in the CPU itself. The levels have different roles, and some operations are disallowed at the lower levels; program code can switch from one level to another only through a limited number of gates. Unix systems are designed to take advantage of this hardware feature, using two such levels. All current processors have at least two protection levels, and some, like the x86 family, have more levels; when several levels exist, the highest and lowest levels are used. Under Unix, the kernel executes in the highest level (also called supervisor mode), where everything is allowed, whereas applications execute in the lowest level (the so-called user mode), where the processor regulates direct access to hardware and unauthorized access to memory. We usually refer to the execution modes as kernel space and user space . Processes running in user space also don\u2019t have access to the kernel space. User space processes can only access a small part of the kernel via an interface exposed by the kernel - the system calls . User space vs Kernel space System Calls # A system call is a programmatic way a program requests a service from the kernel. The system call interface includes a number of functions that the operating system exports to the applications running on top of it. These functions allow actions like opening files, creating network connections, reading and writing from files, and so on. System calls are divided into 5 categories mainly : Process Control File Management Device Management Information Maintenance Communication Let go through some primitive system calls: Process Control : This system calls perform the task of process creation, process termination, etc. The Linux System calls under this are fork() , exit() , exec() . fork() A new process is created by the fork() system call. A new process may be created with fork() without a new program being run-the new sub-process simply continues to execute exactly the same program that the first (parent) process was running. exit() The exit() system call is used by a program to terminate its execution. The operating system reclaims resources that were used by the process after the exit() system call. exec() A new program will start executing after a call to exec() Running a new program does not require that a new process be created first: any process may call exec() at any time. The currently running program is immediately terminated, and the new program starts executing in the context of the existing process. File Management : File management system calls handle file manipulation jobs like creating a file, reading, and writing, etc. The Linux System calls under this are open() , read() , write() , close() . open() It is the system call to open a file. This system call just opens the file, to perform operations such as read and write, we need to execute different system call to perform the operations. read() This system call opens the file in reading mode We can not edit the files with this system call. Multiple processes can execute the read() system call on the same file simultaneously. write() This system call opens the file in writing mode We can edit the files with this system call. Multiple processes can not execute the write() system call on the same file simultaneously. close() This system call closes the opened file. Device Management : Device management does the job of device manipulation like reading from device buffers, writing into device buffers, etc. The Linux System calls under this is ioctl() . ioctl() ioctl is referred to as Input and Output Control. ioctl is a system call for device-specific input/output operations and other operations which cannot be expressed by regular system calls. Information Maintenance : It handles information and its transfer between the OS and the user program. In addition, OS keeps the information about all its processes and system calls are used to access this information. The System calls under this are getpid() , alarm() , sleep() . getpid( ) getpid stands for Get the Process ID. The getpid() function shall return the process ID of the calling process. The getpid() function shall always be successful, and no return value is reserved to indicate an error. alarm() This system call sets an alarm clock for the delivery of a signal that when it has to be reached. It arranges for a signal to be delivered to the calling process. sleep() This System call suspends the execution of the currently running process for some interval of time Meanwhile, during this interval, another process is given chance to execute Communication : These types of system calls are specially used for inter-process communications. Two models are used for inter-process communication Message Passing (processes exchange messages with one another) Shared memory(processes share memory region to communicate) The system calls under this are pipe() , shmget() , mmap() . pipe() The pipe() system call is used to communicate between different Linux processes. This system function is used to open file descriptors. shmget() shmget stands for shared memory segment. It is mainly used for Shared memory communication. This system call is used to access the shared memory and access the messages in order to communicate with the process. mmap() This function call is used to map or unmap files or devices into memory. The mmap() system call is responsible for mapping the content of the file to the virtual memory space of the process. System call table System call table is defined in Linux kernel source code. For example, here is the syscall_64.tbl which defines 64-bit system call numbers and entry vectors. # The format is: # <number> <abi> <name> <entry point> # # The __x64_sys_*() stubs are created on-the-fly for sys_*() system calls # # The abi is \"common\", \"64\" or \"x32\" for this file. # 0 common read sys_read 1 common write sys_write 2 common open sys_open 3 common close sys_close 4 common stat sys_newstat 5 common fstat sys_newfstat 6 common lstat sys_newlstat 7 common poll sys_poll 8 common lseek sys_lseek 9 common mmap sys_mmap 10 common mprotect sys_mprotect 11 common munmap sys_munmap Example # syscall.zip Use printf function which is provided in userspace: hello_userspace.c #include <stdio.h> void main () { printf ( \"USER: Hello World! \\n \" ); }} gcc hello_userspace.c -o hello_userspace Example of calling fwrite which invokes sys_write Run with strace : strace ./hello_userspace execve(\"./hello_userspace\", [\"./hello_userspace\"], 0x7ffd769d3740 /* 23 vars */) = 0 openat(AT_FDCWD, \"/etc/ld.so.cache\", O_RDONLY|O_CLOEXEC) = 3 ... read dynamic library linking index openat(AT_FDCWD, \"/lib/x86_64-linux-gnu/libc.so.6\", O_RDONLY|O_CLOEXEC) = 3 ... read symbols in libc library fstat(1, {st_mode=S_IFCHR|0620, st_rdev=makedev(136, 0), ...}) = 0 ... obtain the standard output write(1, \"USER: Hello World!\\n\", 19USER: Hello World!) = 19 You will see a list of system call invoked, including execve , access , open , read , write , close . Function chain in a System Call Use low-level syscall function glibc offers you a function called syscall() that you can use to explore the system call interface. Note to add #define _GNU_SOURCE to access to low-level functions. hello_syscall_glibc.c #define _GNU_SOURCE #include <sys/syscall.h> // implemented in libc.so long syscall ( long number , ...); void main () { syscall ( SYS_write , 1 , \"SYSCALL: Hello World! \\n \" , 22 ); } gcc hello_syscall_glibc.c -o hello_syscall_glibc Call syscall directly using Assembly We know that the ID of system call write is 1 , we can invoke it through syscall instruction. hello_syscall_asm.s .global _start .text _start: # write(1, message, 26) mov $ 1 , % rax # system call ID. 1 is write mov $ 1 , % rdi # file handle 1 is stdout mov $ message , % rsi # address of string to output mov $ 26 , % rdx # string length syscall # system call invocation! # exit(0) mov $ 60 , % rax # system call ID. 60 is exit xor % rdi , % rdi # we want return code 0 syscall # system call invocation! message: .ascii \"ASM SYSCALL: Hello World!\\n\" gcc hello_syscall_asm.s -nostdlib -no-pie -o hello_syscall_asm Run with strace to see only write system call is invoked: strace ./hello_syscall_asm execve(\"./hello_syscall_asm\", [\"./hello_syscall_asm\"], 0x7ffe4fc483a0 /* 23 vars */) = 0 write(1, \"ASM SYSCALL: Hello World!\\n\", 26ASM SYSCALL: Hello World! ) = 26 Exercise # Use ltrace -S instead of strace to investigate the system call order. strace can attach to a running process. Try it.","title":"User-space, Kernel-space, and System Calls"},{"location":"blog/linux/system-call/#user-space-and-kernel-space","text":"A module runs in kernel space , whereas applications run in user space . This concept is at the base of operating system theory. The role of the operating system, in practice, is to provide programs with a consistent view of the computer\u2019s hardware. In addition, the operating system must account for independent operation of programs and protection against unauthorized access to resources. This nontrivial task is possible only if the CPU enforces protection of system software from the applications. Every modern processor is able to enforce this behavior. The chosen approach is to implement different operating modalities (or levels) in the CPU itself. The levels have different roles, and some operations are disallowed at the lower levels; program code can switch from one level to another only through a limited number of gates. Unix systems are designed to take advantage of this hardware feature, using two such levels. All current processors have at least two protection levels, and some, like the x86 family, have more levels; when several levels exist, the highest and lowest levels are used. Under Unix, the kernel executes in the highest level (also called supervisor mode), where everything is allowed, whereas applications execute in the lowest level (the so-called user mode), where the processor regulates direct access to hardware and unauthorized access to memory. We usually refer to the execution modes as kernel space and user space . Processes running in user space also don\u2019t have access to the kernel space. User space processes can only access a small part of the kernel via an interface exposed by the kernel - the system calls . User space vs Kernel space","title":"User Space and Kernel Space"},{"location":"blog/linux/system-call/#system-calls","text":"A system call is a programmatic way a program requests a service from the kernel. The system call interface includes a number of functions that the operating system exports to the applications running on top of it. These functions allow actions like opening files, creating network connections, reading and writing from files, and so on. System calls are divided into 5 categories mainly : Process Control File Management Device Management Information Maintenance Communication Let go through some primitive system calls: Process Control : This system calls perform the task of process creation, process termination, etc. The Linux System calls under this are fork() , exit() , exec() . fork() A new process is created by the fork() system call. A new process may be created with fork() without a new program being run-the new sub-process simply continues to execute exactly the same program that the first (parent) process was running. exit() The exit() system call is used by a program to terminate its execution. The operating system reclaims resources that were used by the process after the exit() system call. exec() A new program will start executing after a call to exec() Running a new program does not require that a new process be created first: any process may call exec() at any time. The currently running program is immediately terminated, and the new program starts executing in the context of the existing process. File Management : File management system calls handle file manipulation jobs like creating a file, reading, and writing, etc. The Linux System calls under this are open() , read() , write() , close() . open() It is the system call to open a file. This system call just opens the file, to perform operations such as read and write, we need to execute different system call to perform the operations. read() This system call opens the file in reading mode We can not edit the files with this system call. Multiple processes can execute the read() system call on the same file simultaneously. write() This system call opens the file in writing mode We can edit the files with this system call. Multiple processes can not execute the write() system call on the same file simultaneously. close() This system call closes the opened file. Device Management : Device management does the job of device manipulation like reading from device buffers, writing into device buffers, etc. The Linux System calls under this is ioctl() . ioctl() ioctl is referred to as Input and Output Control. ioctl is a system call for device-specific input/output operations and other operations which cannot be expressed by regular system calls. Information Maintenance : It handles information and its transfer between the OS and the user program. In addition, OS keeps the information about all its processes and system calls are used to access this information. The System calls under this are getpid() , alarm() , sleep() . getpid( ) getpid stands for Get the Process ID. The getpid() function shall return the process ID of the calling process. The getpid() function shall always be successful, and no return value is reserved to indicate an error. alarm() This system call sets an alarm clock for the delivery of a signal that when it has to be reached. It arranges for a signal to be delivered to the calling process. sleep() This System call suspends the execution of the currently running process for some interval of time Meanwhile, during this interval, another process is given chance to execute Communication : These types of system calls are specially used for inter-process communications. Two models are used for inter-process communication Message Passing (processes exchange messages with one another) Shared memory(processes share memory region to communicate) The system calls under this are pipe() , shmget() , mmap() . pipe() The pipe() system call is used to communicate between different Linux processes. This system function is used to open file descriptors. shmget() shmget stands for shared memory segment. It is mainly used for Shared memory communication. This system call is used to access the shared memory and access the messages in order to communicate with the process. mmap() This function call is used to map or unmap files or devices into memory. The mmap() system call is responsible for mapping the content of the file to the virtual memory space of the process. System call table System call table is defined in Linux kernel source code. For example, here is the syscall_64.tbl which defines 64-bit system call numbers and entry vectors. # The format is: # <number> <abi> <name> <entry point> # # The __x64_sys_*() stubs are created on-the-fly for sys_*() system calls # # The abi is \"common\", \"64\" or \"x32\" for this file. # 0 common read sys_read 1 common write sys_write 2 common open sys_open 3 common close sys_close 4 common stat sys_newstat 5 common fstat sys_newfstat 6 common lstat sys_newlstat 7 common poll sys_poll 8 common lseek sys_lseek 9 common mmap sys_mmap 10 common mprotect sys_mprotect 11 common munmap sys_munmap","title":"System Calls"},{"location":"blog/linux/system-call/#example","text":"syscall.zip Use printf function which is provided in userspace: hello_userspace.c #include <stdio.h> void main () { printf ( \"USER: Hello World! \\n \" ); }} gcc hello_userspace.c -o hello_userspace Example of calling fwrite which invokes sys_write Run with strace : strace ./hello_userspace execve(\"./hello_userspace\", [\"./hello_userspace\"], 0x7ffd769d3740 /* 23 vars */) = 0 openat(AT_FDCWD, \"/etc/ld.so.cache\", O_RDONLY|O_CLOEXEC) = 3 ... read dynamic library linking index openat(AT_FDCWD, \"/lib/x86_64-linux-gnu/libc.so.6\", O_RDONLY|O_CLOEXEC) = 3 ... read symbols in libc library fstat(1, {st_mode=S_IFCHR|0620, st_rdev=makedev(136, 0), ...}) = 0 ... obtain the standard output write(1, \"USER: Hello World!\\n\", 19USER: Hello World!) = 19 You will see a list of system call invoked, including execve , access , open , read , write , close . Function chain in a System Call Use low-level syscall function glibc offers you a function called syscall() that you can use to explore the system call interface. Note to add #define _GNU_SOURCE to access to low-level functions. hello_syscall_glibc.c #define _GNU_SOURCE #include <sys/syscall.h> // implemented in libc.so long syscall ( long number , ...); void main () { syscall ( SYS_write , 1 , \"SYSCALL: Hello World! \\n \" , 22 ); } gcc hello_syscall_glibc.c -o hello_syscall_glibc Call syscall directly using Assembly We know that the ID of system call write is 1 , we can invoke it through syscall instruction. hello_syscall_asm.s .global _start .text _start: # write(1, message, 26) mov $ 1 , % rax # system call ID. 1 is write mov $ 1 , % rdi # file handle 1 is stdout mov $ message , % rsi # address of string to output mov $ 26 , % rdx # string length syscall # system call invocation! # exit(0) mov $ 60 , % rax # system call ID. 60 is exit xor % rdi , % rdi # we want return code 0 syscall # system call invocation! message: .ascii \"ASM SYSCALL: Hello World!\\n\" gcc hello_syscall_asm.s -nostdlib -no-pie -o hello_syscall_asm Run with strace to see only write system call is invoked: strace ./hello_syscall_asm execve(\"./hello_syscall_asm\", [\"./hello_syscall_asm\"], 0x7ffe4fc483a0 /* 23 vars */) = 0 write(1, \"ASM SYSCALL: Hello World!\\n\", 26ASM SYSCALL: Hello World! ) = 26","title":"Example"},{"location":"blog/linux/system-call/#exercise","text":"Use ltrace -S instead of strace to investigate the system call order. strace can attach to a running process. Try it.","title":"Exercise"},{"location":"blog/linux/tweaks/","tags":["linux"],"text":"Disable animation # Ubuntu comes with cool effects, but it consumes system resource. Turn it off is a good way to increase system performance. Open a terminal and enter this command: gsettings set org.gnome.desktop.interface enable-animations false Reduce startup applications # First make all startup applications visible, because in Ubuntu, most of them are hidden by default: cd /etc/xdg/autostart/ sudo sed --in-place 's/NoDisplay=true/NoDisplay=false/g' *.desktop Now check the Startup Applications, uncheck what you don\u2019t need, for example: Evolution Alarm Orca Screen Reader Ubuntu Report Update Notifier Delay the execution by adding sleep x; before the execution command of the applications. Add user to sudoers # To skip entering password on sudo command, add current user to sudoers with the rule NOPASSWD : sudo bash -c \"echo ' $USER ALL=(ALL) NOPASSWD: ALL' > /etc/sudoers.d/ $USER \" Use a faster installation method # Mirror server Ubuntu contacts to many repos to download, update its packages. Choose the best mirror server is a good way to speed up system update or application installation. In Software & Updates \u2192 Ubuntu Software \u2192 Download From and choose Select Best Server . No language translation Suppressing the language translation while updating will slightly increase the apt update speed. To do that, open the following file: sudo nano /etc/apt/apt.conf.d/00aptitude And add the following line at the end of this file: Acquire::Languages \"none\" ; Use apt-fast apt-fast is a shell script wrapper for apt-get that improves updated and package download speed by downloading packages from multiple connections simultaneously. Install apt-fast via official PPA using the following commands: sudo add-apt-repository ppa:apt-fast/stable && \\ sudo apt update && \\ sudo apt install -y apt-fast Automatic installation First, add new repo to source list: sudo bash -c 'echo \"deb http://ppa.launchpad.net/apt-fast/stable/ubuntu bionic main\" > /etc/apt/sources.list.d/apt-fast.list' then use non-interactive method: sudo apt-key adv \\ --keyserver keyserver.ubuntu.com \\ --recv-keys A2166B8DE8BDC3367D1901C11EE2FF37CA8DA16B && \\ sudo apt update && \\ sudo DEBIAN_FRONTEND = noninteractive apt install -y apt-fast Add alias for apt-fast : echo 'alias sudo=\"sudo \"' >> ~/.bash_aliases && \\ echo 'alias apt=apt-fast' >> ~/.bash_aliases && \\ echo 'alias apt-get=apt-fast' >> ~/.bash_aliases && \\ sudo bash -c 'echo \"alias apt=apt-fast\" >> /root/.bash_aliases' && \\ sudo bash -c 'echo \"alias apt-get=apt-fast\" >> /root/.bash_aliases' Source the bash file if you want the alias gets effective immediately: source ~/.bash_aliases Disable unattended update # Ubuntu has a feature named Unattended Upgrades, which installs the latest security (and others) updates automatically whenever they are available. It comes pre-installed and enabled by default in the recent Ubuntu versions. While this feature helps to keep the Ubuntu system up-to-date, it is also quite annoying sometimes. To disable unattended upgrades on Ubuntu and its derivatives, run: sudo dpkg-reconfigure unattended-upgrades Then choose No and hit ENTER to disable unattended upgrades. Change network connection priority # If machine is connected to Wi-Fi and Ethernet simultaneously, here is a method to set priority connection. Install ifmetric tool which can be used to change the metric of any interface: sudo apt install -y ifmetric To use this, first see the metrics using route command: route -n Kernel IP routing table Destination Gateway Genmask Flags Metric Ref Use Iface 0.0.0.0 10.42.0.1 0.0.0.0 UG 100 0 0 eth0 0.0.0.0 10.42.0.2 0.0.0.0 UG 600 0 0 wlan0 The interface with lower metric is preferred for Internet . Here, eth0 has lower metric, so it will be preferred over wlan0 . If you want to prefer wlan0 , then lower its metric: sudo ifmetric wlan0 50 Now, the routing table would look like: route -n Kernel IP routing table Destination Gateway Genmask Flags Metric Ref Use Iface 0.0.0.0 10.42.0.2 0.0.0.0 UG 50 0 0 wlan0 0.0.0.0 10.42.0.1 0.0.0.0 UG 100 0 0 eth0 Now Linux will be using wlan0 for Internet. The change will be reflected immediately. Install a lightweight Desktop Environment # By default, Ubuntu uses GNOME 3 and GDM3, however, they are too heavy. Many users have reported that they can save 1 GB of RAM when using a lightweight desktop environment, such as LXDE, LXQt, XFCE. Here are some choices: MATE (GNOME2) MATE is a lightweight desktop based on GNOME2 base code, it\u2019s fully open source and a very nice option. sudo apt install ubuntu-mate-core Lubuntu (LXDE/LXQt) Lubuntu is another lightweight option which I recommend if your system is low on resources or if you are giving new life to an older computer. Install it using this command: sudo apt install lubuntu-core Xubuntu (XFCE) Xubuntu is an Ubuntu derivative based on the Xfce desktop environment that is light, simple, stable, but it\u2019s also highly customizable. If you want to try it, use the following command: sudo apt install xubuntu-core When asked, select lightdm as the Desktop Manager, instead of gdm . Missing packages in a minimal installation The most happened issue is missing fbdev which shown in the log: ~/.local/share/xorg/Xorg.0.log ... (WW) Warning, couldn't open module fbdev (EE) Failed to load module \"fbdev\" (module does not exist, 0) ... Fatal server error: (EE) no screens found(EE) ... To install fbdev , run: sudo apt install xserver-xorg-video-fbdev Keep the cache in RAM # Computers with at least 12 GB of memory (RAM), will probably benefit by shrinking the cache less aggressively. sudo gedit admin:///etc/sysctl.conf Add below lines at the bottom of the file: # keep the cache vm.vfs_cache_pressure = 50 Use temporary folder in RAM # Turn on tmpfs and mount /tmp on it: sudo cp -v /usr/share/systemd/tmp.mount /etc/systemd/system/ sudo systemctl enable tmp.mount Disable Firewall log # You usually don\u2019t care about this kind of log, so let it go: sudo ufw logging off Disable journal feature # Only disable journal feature on a separated disk which contains only build source code and data. A journaling file system is a file system that keeps track of changes not yet committed to the file system. In the event of a system crash or power failure, such file systems can be brought back online more quickly with a lower likelihood of becoming corrupted. On build server machine, system failure is rare, so you can disable this journaling feature. Press ESC on boot, then select Advanced Boot option \u2192 recovery mode . In the Recovery Menu, select root to enter the command line mode. Trigger the emergency mount, and then turn off the journal feature on the target disk: echo \"u\" > /proc/sysrq-trigger tune2fs -O ^has_journal /dev/<disk> Verify with: debugfs -R features /dev/<disk> If you are disabling on a data storage, do not need to go to Recovert mode. Just unmount the disk and use above tools with sudo. E.g.: sudo umount /dev/sda sudo tune2fs -O ^has_journal /dev/sda Disable access time # Linux writes the access time every you read a file. It\u2019s the very rare program indeed that relies on access time, so disabling access time is safe virtually everywhere. To disable access time, add noatime into the mount option in /etc/fstab on the target device. For example: /dev/disk/by-uuid/<uuid> /mnt/work auto nosuid,nodev,noatime,nofail,x-gvfs-show 0 0 Remove Grub timeout # The grub gives you 10 seconds to change between dual boot OS or to go in recovery. This time can be reduced, by entering below command to open grub configuration: sudo gedit /etc/default/grub & Then change GRUB_TIMEOUT=10 to GRUB_TIMEOUT=1 . And update the settings: sudo update-grub","title":"Tweaks for a better performance"},{"location":"blog/linux/tweaks/#disable-animation","text":"Ubuntu comes with cool effects, but it consumes system resource. Turn it off is a good way to increase system performance. Open a terminal and enter this command: gsettings set org.gnome.desktop.interface enable-animations false","title":"Disable animation"},{"location":"blog/linux/tweaks/#reduce-startup-applications","text":"First make all startup applications visible, because in Ubuntu, most of them are hidden by default: cd /etc/xdg/autostart/ sudo sed --in-place 's/NoDisplay=true/NoDisplay=false/g' *.desktop Now check the Startup Applications, uncheck what you don\u2019t need, for example: Evolution Alarm Orca Screen Reader Ubuntu Report Update Notifier Delay the execution by adding sleep x; before the execution command of the applications.","title":"Reduce startup applications"},{"location":"blog/linux/tweaks/#add-user-to-sudoers","text":"To skip entering password on sudo command, add current user to sudoers with the rule NOPASSWD : sudo bash -c \"echo ' $USER ALL=(ALL) NOPASSWD: ALL' > /etc/sudoers.d/ $USER \"","title":"Add user to sudoers"},{"location":"blog/linux/tweaks/#use-a-faster-installation-method","text":"Mirror server Ubuntu contacts to many repos to download, update its packages. Choose the best mirror server is a good way to speed up system update or application installation. In Software & Updates \u2192 Ubuntu Software \u2192 Download From and choose Select Best Server . No language translation Suppressing the language translation while updating will slightly increase the apt update speed. To do that, open the following file: sudo nano /etc/apt/apt.conf.d/00aptitude And add the following line at the end of this file: Acquire::Languages \"none\" ; Use apt-fast apt-fast is a shell script wrapper for apt-get that improves updated and package download speed by downloading packages from multiple connections simultaneously. Install apt-fast via official PPA using the following commands: sudo add-apt-repository ppa:apt-fast/stable && \\ sudo apt update && \\ sudo apt install -y apt-fast Automatic installation First, add new repo to source list: sudo bash -c 'echo \"deb http://ppa.launchpad.net/apt-fast/stable/ubuntu bionic main\" > /etc/apt/sources.list.d/apt-fast.list' then use non-interactive method: sudo apt-key adv \\ --keyserver keyserver.ubuntu.com \\ --recv-keys A2166B8DE8BDC3367D1901C11EE2FF37CA8DA16B && \\ sudo apt update && \\ sudo DEBIAN_FRONTEND = noninteractive apt install -y apt-fast Add alias for apt-fast : echo 'alias sudo=\"sudo \"' >> ~/.bash_aliases && \\ echo 'alias apt=apt-fast' >> ~/.bash_aliases && \\ echo 'alias apt-get=apt-fast' >> ~/.bash_aliases && \\ sudo bash -c 'echo \"alias apt=apt-fast\" >> /root/.bash_aliases' && \\ sudo bash -c 'echo \"alias apt-get=apt-fast\" >> /root/.bash_aliases' Source the bash file if you want the alias gets effective immediately: source ~/.bash_aliases","title":"Use a faster installation method"},{"location":"blog/linux/tweaks/#disable-unattended-update","text":"Ubuntu has a feature named Unattended Upgrades, which installs the latest security (and others) updates automatically whenever they are available. It comes pre-installed and enabled by default in the recent Ubuntu versions. While this feature helps to keep the Ubuntu system up-to-date, it is also quite annoying sometimes. To disable unattended upgrades on Ubuntu and its derivatives, run: sudo dpkg-reconfigure unattended-upgrades Then choose No and hit ENTER to disable unattended upgrades.","title":"Disable unattended update"},{"location":"blog/linux/tweaks/#change-network-connection-priority","text":"If machine is connected to Wi-Fi and Ethernet simultaneously, here is a method to set priority connection. Install ifmetric tool which can be used to change the metric of any interface: sudo apt install -y ifmetric To use this, first see the metrics using route command: route -n Kernel IP routing table Destination Gateway Genmask Flags Metric Ref Use Iface 0.0.0.0 10.42.0.1 0.0.0.0 UG 100 0 0 eth0 0.0.0.0 10.42.0.2 0.0.0.0 UG 600 0 0 wlan0 The interface with lower metric is preferred for Internet . Here, eth0 has lower metric, so it will be preferred over wlan0 . If you want to prefer wlan0 , then lower its metric: sudo ifmetric wlan0 50 Now, the routing table would look like: route -n Kernel IP routing table Destination Gateway Genmask Flags Metric Ref Use Iface 0.0.0.0 10.42.0.2 0.0.0.0 UG 50 0 0 wlan0 0.0.0.0 10.42.0.1 0.0.0.0 UG 100 0 0 eth0 Now Linux will be using wlan0 for Internet. The change will be reflected immediately.","title":"Change network connection priority"},{"location":"blog/linux/tweaks/#install-a-lightweight-desktop-environment","text":"By default, Ubuntu uses GNOME 3 and GDM3, however, they are too heavy. Many users have reported that they can save 1 GB of RAM when using a lightweight desktop environment, such as LXDE, LXQt, XFCE. Here are some choices: MATE (GNOME2) MATE is a lightweight desktop based on GNOME2 base code, it\u2019s fully open source and a very nice option. sudo apt install ubuntu-mate-core Lubuntu (LXDE/LXQt) Lubuntu is another lightweight option which I recommend if your system is low on resources or if you are giving new life to an older computer. Install it using this command: sudo apt install lubuntu-core Xubuntu (XFCE) Xubuntu is an Ubuntu derivative based on the Xfce desktop environment that is light, simple, stable, but it\u2019s also highly customizable. If you want to try it, use the following command: sudo apt install xubuntu-core When asked, select lightdm as the Desktop Manager, instead of gdm . Missing packages in a minimal installation The most happened issue is missing fbdev which shown in the log: ~/.local/share/xorg/Xorg.0.log ... (WW) Warning, couldn't open module fbdev (EE) Failed to load module \"fbdev\" (module does not exist, 0) ... Fatal server error: (EE) no screens found(EE) ... To install fbdev , run: sudo apt install xserver-xorg-video-fbdev","title":"Install a lightweight Desktop Environment"},{"location":"blog/linux/tweaks/#keep-the-cache-in-ram","text":"Computers with at least 12 GB of memory (RAM), will probably benefit by shrinking the cache less aggressively. sudo gedit admin:///etc/sysctl.conf Add below lines at the bottom of the file: # keep the cache vm.vfs_cache_pressure = 50","title":"Keep the cache in RAM"},{"location":"blog/linux/tweaks/#use-temporary-folder-in-ram","text":"Turn on tmpfs and mount /tmp on it: sudo cp -v /usr/share/systemd/tmp.mount /etc/systemd/system/ sudo systemctl enable tmp.mount","title":"Use temporary folder in RAM"},{"location":"blog/linux/tweaks/#disable-firewall-log","text":"You usually don\u2019t care about this kind of log, so let it go: sudo ufw logging off","title":"Disable Firewall log"},{"location":"blog/linux/tweaks/#disable-journal-feature","text":"Only disable journal feature on a separated disk which contains only build source code and data. A journaling file system is a file system that keeps track of changes not yet committed to the file system. In the event of a system crash or power failure, such file systems can be brought back online more quickly with a lower likelihood of becoming corrupted. On build server machine, system failure is rare, so you can disable this journaling feature. Press ESC on boot, then select Advanced Boot option \u2192 recovery mode . In the Recovery Menu, select root to enter the command line mode. Trigger the emergency mount, and then turn off the journal feature on the target disk: echo \"u\" > /proc/sysrq-trigger tune2fs -O ^has_journal /dev/<disk> Verify with: debugfs -R features /dev/<disk> If you are disabling on a data storage, do not need to go to Recovert mode. Just unmount the disk and use above tools with sudo. E.g.: sudo umount /dev/sda sudo tune2fs -O ^has_journal /dev/sda","title":"Disable journal feature"},{"location":"blog/linux/tweaks/#disable-access-time","text":"Linux writes the access time every you read a file. It\u2019s the very rare program indeed that relies on access time, so disabling access time is safe virtually everywhere. To disable access time, add noatime into the mount option in /etc/fstab on the target device. For example: /dev/disk/by-uuid/<uuid> /mnt/work auto nosuid,nodev,noatime,nofail,x-gvfs-show 0 0","title":"Disable access time"},{"location":"blog/linux/tweaks/#remove-grub-timeout","text":"The grub gives you 10 seconds to change between dual boot OS or to go in recovery. This time can be reduced, by entering below command to open grub configuration: sudo gedit /etc/default/grub & Then change GRUB_TIMEOUT=10 to GRUB_TIMEOUT=1 . And update the settings: sudo update-grub","title":"Remove Grub timeout"},{"location":"blog/pi/","text":"A Raspberry Pi 4 model B Topics # There are thousands of topics on the internet discussing Raspberry Pi. In here, I post some short-and-consistent posts written as guides and notes for a quick reference when learning and doing projects on Raspberry Pi boards. Because Raspberry Pi OS (previously called Raspbian ) is based on the Debian Linux-based OS, a lot of technical knowledge in Linux-OS can be applied to. Communities # Official Homepage: https://www.raspberrypi.org News: https://magpi.raspberrypi.org Sharing: https://projects.raspberrypi.org/en https://www.hackster.io/raspberry-pi/projects https://www.instructables.com/Raspberry-Pi-Projects https://pimylifeup.com/category/projects Forums: https://www.raspberrypi.org/forums","title":"Raspberry Pi"},{"location":"blog/pi/#topics","text":"There are thousands of topics on the internet discussing Raspberry Pi. In here, I post some short-and-consistent posts written as guides and notes for a quick reference when learning and doing projects on Raspberry Pi boards. Because Raspberry Pi OS (previously called Raspbian ) is based on the Debian Linux-based OS, a lot of technical knowledge in Linux-OS can be applied to.","title":"Topics"},{"location":"blog/pi/#communities","text":"Official Homepage: https://www.raspberrypi.org News: https://magpi.raspberrypi.org Sharing: https://projects.raspberrypi.org/en https://www.hackster.io/raspberry-pi/projects https://www.instructables.com/Raspberry-Pi-Projects https://pimylifeup.com/category/projects Forums: https://www.raspberrypi.org/forums","title":"Communities"},{"location":"blog/pi/backup-sdcard/","tags":["raspberry-pi"],"text":"Win32 Disk Imager # Win32 Disk Images is a popular and famous application on Windows to write a raw disk image to a removable device or backup a removable device to a raw image file. Raw image mode Raw image mode means all bits of the device are copied to the image file, therefore the size of the backup file is equal to the device\u2019s total size. This method will take a long time to complete, depending on the size of the storage device. Download it from win32diskimager and run it as administrative right. Backup # Select the Image File to save the SD Card content Select the source Device Click on Read Win32 Disk Imager: save device to image Restore # Select the Image File of the SD Card content Select the target Device Click on Write Win32 Disk Imager: restore from image to device Acronis True Image # Acronis True Image is an application that provides data protection for personal users including, backup, archive, access and recovery for Windows, macOS, iOS, and Android operating systems. This application is a commercial product, try it for free before purchasing a copy. Backup and Restore # Acronis will not back up empty space on the SD Card, it only saves the useful data, therefore the backup progress is much faster than dumping all bits and the file size is smaller. It also has incremental backup mode which only writes modified data, compared to the previous backup, therefore it can save a lot of disk space. The restore process is as simple as the backup. There are buttons and guide to help to do those actions: Acronis True Image: backup/restore disk Conflict with Paragon Linux File Systems for Windows Paragon Linux File Systems for Windows is a powerful system service tool which gives users full access to Linux volumes within Windows. However, Acronis may conflict with mounted partitions as Acronis does have its own reading linux partitions engine. To avoid conflicts when backing up a Linux partition, such as infinite waiting, user has to unmount the partition and gives full control to Acronis. Unmount partition in Paragon Linux File Systems","title":"Backup and Restore SDCard content"},{"location":"blog/pi/backup-sdcard/#win32-disk-imager","text":"Win32 Disk Images is a popular and famous application on Windows to write a raw disk image to a removable device or backup a removable device to a raw image file. Raw image mode Raw image mode means all bits of the device are copied to the image file, therefore the size of the backup file is equal to the device\u2019s total size. This method will take a long time to complete, depending on the size of the storage device. Download it from win32diskimager and run it as administrative right.","title":"Win32 Disk Imager"},{"location":"blog/pi/backup-sdcard/#backup","text":"Select the Image File to save the SD Card content Select the source Device Click on Read Win32 Disk Imager: save device to image","title":"Backup"},{"location":"blog/pi/backup-sdcard/#restore","text":"Select the Image File of the SD Card content Select the target Device Click on Write Win32 Disk Imager: restore from image to device","title":"Restore"},{"location":"blog/pi/backup-sdcard/#acronis-true-image","text":"Acronis True Image is an application that provides data protection for personal users including, backup, archive, access and recovery for Windows, macOS, iOS, and Android operating systems. This application is a commercial product, try it for free before purchasing a copy.","title":"Acronis True Image"},{"location":"blog/pi/backup-sdcard/#backup-and-restore","text":"Acronis will not back up empty space on the SD Card, it only saves the useful data, therefore the backup progress is much faster than dumping all bits and the file size is smaller. It also has incremental backup mode which only writes modified data, compared to the previous backup, therefore it can save a lot of disk space. The restore process is as simple as the backup. There are buttons and guide to help to do those actions: Acronis True Image: backup/restore disk Conflict with Paragon Linux File Systems for Windows Paragon Linux File Systems for Windows is a powerful system service tool which gives users full access to Linux volumes within Windows. However, Acronis may conflict with mounted partitions as Acronis does have its own reading linux partitions engine. To avoid conflicts when backing up a Linux partition, such as infinite waiting, user has to unmount the partition and gives full control to Acronis. Unmount partition in Paragon Linux File Systems","title":"Backup and Restore"},{"location":"blog/pi/check-camera/","tags":["raspberry-pi","camera","i2c"],"text":"Address of Camera modules Scan on the I2C Bus 0, the camera module will response on two addresses 0x10 (camera sensor) and 0x64 (camera board). Missing one of two above addresses means that there is an hardware issue happened. Hardware check # Run the command: vcgencmd get_camera which should print out supported=1 detected=1 with a normal working camera. If the output shows detected=0 , check the ribbon cable first. If other camera module still works after swapping with the problem one, then do a hardware check from software interface as described below. Software check # An interesting topic: Camera not detected despite being plugged in on the official Raspberry forum shows a method to check the connection of the camera board and the camera sensor on an I2C interface. Install I2C tools # Run below command to install I2C tools: sudo apt install -y i2c-tools This package contains a set of I2C tools for Linux: a bus probing tool, a chip dumper, register-level access helpers, EEPROM decoding scripts, and more. i2cdetect # detect I2C chips i2cdump # examine I2C registers i2cget # read from I2C/SMBus chip registers i2cset # set I2C registers i2ctransfer # send user-defined I2C messages in one transfer Load I2C driver # It is able to permanently enable the I2C interface by running sudo raspi-config and enable I2C setting, or by adding i2c-dev declaration in the file /etc/modules . Enable I2C Interface via raspi-config However, for a quick check, just need to load driver temporarily: sudo modprobe i2c-dev Configure GPIO # GPIO Pinout number Please look at PI GPIO document for more information about setting GPIOs. Note that GPIO number is defined in BCM2835 ARM processor, not the number printed on the Pi boards. Read more at BCM2835 Peripherals . Use raspi-gpio get to read the current status of GPIOs. Change GPIO0 and GPIO1 to input (by default they are set to SDA0 and SCL0 ): raspi-gpio set 0 ip raspi-gpio set 1 ip Change the function of GPIO28 , GPIO29 to I2C pins out SDA0 and SCL0 by setting Alternate Function 0 (A0) on those pins. raspi-gpio set 28 a0 raspi-gpio set 29 a0 Power on Camera by setting High on output pin GPIO44 and GPIO45 raspi-gpio set 44 dh raspi-gpio set 40 dh Scan I2C bus # Run i2cdetect on I2C BUS 0 at /dev/i2c-0 : i2cdetect 0 press Y to continue, and it should print out some numbers, for example: 0 1 2 3 4 5 6 7 8 9 a b c d e f 00: -- -- -- -- -- -- -- -- -- -- -- -- -- 10: 10 -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- 20: -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- 30: -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- 40: -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- 50: -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- 60: -- -- -- -- 64 -- -- -- -- -- -- -- -- -- -- -- 70: -- -- -- -- -- -- -- -- Consider that i2cdetect tries to ping every address on a bus and reports whether an address responds. If any number shows up in report, it means there is a working device at that address. Camera\u2019s I2C addresses If having 0x64 , the camera board is connected properly, there is no problem with cable and main connectors on Pi board and camera board. If having 0x10 , it means the camera sensor has responded. there is no problem with sensor and sensor connection (a small cable between camera board and camera sensor).","title":"Diagnostic Camera on I2C Bus"},{"location":"blog/pi/check-camera/#hardware-check","text":"Run the command: vcgencmd get_camera which should print out supported=1 detected=1 with a normal working camera. If the output shows detected=0 , check the ribbon cable first. If other camera module still works after swapping with the problem one, then do a hardware check from software interface as described below.","title":"Hardware check"},{"location":"blog/pi/check-camera/#software-check","text":"An interesting topic: Camera not detected despite being plugged in on the official Raspberry forum shows a method to check the connection of the camera board and the camera sensor on an I2C interface.","title":"Software check"},{"location":"blog/pi/check-camera/#install-i2c-tools","text":"Run below command to install I2C tools: sudo apt install -y i2c-tools This package contains a set of I2C tools for Linux: a bus probing tool, a chip dumper, register-level access helpers, EEPROM decoding scripts, and more. i2cdetect # detect I2C chips i2cdump # examine I2C registers i2cget # read from I2C/SMBus chip registers i2cset # set I2C registers i2ctransfer # send user-defined I2C messages in one transfer","title":"Install I2C tools"},{"location":"blog/pi/check-camera/#load-i2c-driver","text":"It is able to permanently enable the I2C interface by running sudo raspi-config and enable I2C setting, or by adding i2c-dev declaration in the file /etc/modules . Enable I2C Interface via raspi-config However, for a quick check, just need to load driver temporarily: sudo modprobe i2c-dev","title":"Load I2C driver"},{"location":"blog/pi/check-camera/#configure-gpio","text":"GPIO Pinout number Please look at PI GPIO document for more information about setting GPIOs. Note that GPIO number is defined in BCM2835 ARM processor, not the number printed on the Pi boards. Read more at BCM2835 Peripherals . Use raspi-gpio get to read the current status of GPIOs. Change GPIO0 and GPIO1 to input (by default they are set to SDA0 and SCL0 ): raspi-gpio set 0 ip raspi-gpio set 1 ip Change the function of GPIO28 , GPIO29 to I2C pins out SDA0 and SCL0 by setting Alternate Function 0 (A0) on those pins. raspi-gpio set 28 a0 raspi-gpio set 29 a0 Power on Camera by setting High on output pin GPIO44 and GPIO45 raspi-gpio set 44 dh raspi-gpio set 40 dh","title":"Configure GPIO"},{"location":"blog/pi/check-camera/#scan-i2c-bus","text":"Run i2cdetect on I2C BUS 0 at /dev/i2c-0 : i2cdetect 0 press Y to continue, and it should print out some numbers, for example: 0 1 2 3 4 5 6 7 8 9 a b c d e f 00: -- -- -- -- -- -- -- -- -- -- -- -- -- 10: 10 -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- 20: -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- 30: -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- 40: -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- 50: -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- 60: -- -- -- -- 64 -- -- -- -- -- -- -- -- -- -- -- 70: -- -- -- -- -- -- -- -- Consider that i2cdetect tries to ping every address on a bus and reports whether an address responds. If any number shows up in report, it means there is a working device at that address. Camera\u2019s I2C addresses If having 0x64 , the camera board is connected properly, there is no problem with cable and main connectors on Pi board and camera board. If having 0x10 , it means the camera sensor has responded. there is no problem with sensor and sensor connection (a small cable between camera board and camera sensor).","title":"Scan I2C bus"},{"location":"blog/pi/compile-ffmpeg/","tags":["raspberry-pi","ffmpeg"],"text":"Pre-built FFmpeg in Raspberry Pi OS (Recommended) The FFmpeg package in Raspberry Pi OS is built with H264 Hardware Acceleration already, just need to download it from the package manager: sudo apt install -y ffmpeg Manual compilation # The below guide helps to compile FFmpeg from the latest source code to get new features or bug fixes. This build guide is only tested on 32-bit Raspberry OS Update the system # Before starting to build, update system packages to the latest version may help to solve some issues which could happen due to the requirements from the latest source code of FFmpeg. sudo apt update && \\ sudo apt upgrade -y Install build package # To compile a source code, system needs to install build tools, including config parsers, compilers, dependent libraries. Here is the command to install necessary packages: sudo apt install -y \\ autoconf automake build-essential \\ cmake doxygen git graphviz imagemagick \\ libasound2-dev libass-dev libavcodec-dev \\ libavdevice-dev libavfilter-dev libavformat-dev \\ libavutil-dev libfreetype6-dev libgmp-dev \\ libmp3lame-dev libopencore-amrnb-dev libopencore-amrwb-dev \\ libopus-dev librtmp-dev libsdl2-dev \\ libsdl2-image-dev libsdl2-mixer-dev libsdl2-net-dev \\ libsdl2-ttf-dev libsnappy-dev libsoxr-dev \\ libssh-dev libssl-dev libtool \\ libv4l-dev libva-dev libvdpau-dev \\ libvo-amrwbenc-dev libvorbis-dev libwebp-dev \\ libx264-dev libx265-dev libxcb-shape0-dev \\ libxcb-shm0-dev libxcb-xfixes0-dev libxcb1-dev \\ libxml2-dev lzma-dev meson nasm \\ pkg-config python3-dev python3-pip \\ texinfo wget yasm zlib1g-dev libdrm-dev Compile additional libraries # There are some additional libraries required by FFmpeg, which are not pre-built and distributed in OS package manager. Create a folder to get started: mkdir ~/ffmpeg-libraries AAC sound format (fdk-aac) # git clone --depth 1 https://github.com/mstorsjo/fdk-aac.git ~/ffmpeg-libraries/fdk-aac \\ && cd ~/ffmpeg-libraries/fdk-aac \\ && autoreconf -fiv \\ && ./configure \\ && make -j $( nproc ) \\ && sudo make install AV1 video format (dav1d) # git clone --depth 1 https://code.videolan.org/videolan/dav1d.git ~/ffmpeg-libraries/dav1d \\ && mkdir ~/ffmpeg-libraries/dav1d/build \\ && cd ~/ffmpeg-libraries/dav1d/build \\ && meson .. \\ && ninja \\ && sudo ninja install HEVC encoder (kvazaar) # git clone --depth 1 https://github.com/ultravideo/kvazaar.git ~/ffmpeg-libraries/kvazaar \\ && cd ~/ffmpeg-libraries/kvazaar \\ && ./autogen.sh \\ && ./configure \\ && make -j $( nproc ) \\ && sudo make install VP8 and VP9 video codecs (LibVPX) # git clone --depth 1 https://chromium.googlesource.com/webm/libvpx ~/ffmpeg-libraries/libvpx \\ && cd ~/ffmpeg-libraries/libvpx \\ && ./configure --disable-examples --disable-tools --disable-unit_tests --disable-docs \\ && make -j $( nproc ) \\ && sudo make install AP1 video codec (aom) # git clone --depth = 1 https://gitlab.com/AOMediaCodec/SVT-AV1.git ~/ffmpeg-libraries/av1 \\ && cd ~/ffmpeg-libraries/av1/Build \\ && cmake .. -G \"Unix Makefiles\" -DCMAKE_BUILD_TYPE = Release \\ && make -j $( nproc ) \\ && sudo make install Image processing (zimg) # git clone -b release-3.0.3 https://github.com/sekrit-twc/zimg.git ~/ffmpeg-libraries/zimg \\ && cd ~/ffmpeg-libraries/zimg \\ && sh autogen.sh \\ && ./configure \\ && make \\ && sudo make install Link compiled libraries # After installing new libraries, system needs to refresh link cache for new packages. This command ensures system won\u2019t run into linking issues because the compiler can\u2019t find a library. sudo ldconfig Compile FFmpeg # Finally, FFmpeg can be compiled with settings to include additional libraries, and the feature omx-rpi . The command is quite large as it has a lot of options: git clone --depth 1 https://github.com/FFmpeg/FFmpeg.git ~/FFmpeg \\ && cd ~/FFmpeg \\ && ./configure \\ --extra-cflags = \"-I/usr/local/include\" \\ --extra-ldflags = \"-L/usr/local/lib\" \\ --extra-libs = \"-lpthread -lm -latomic\" \\ --arch = armel \\ --enable-gmp \\ --enable-gpl \\ --enable-libaom \\ --enable-libsvtav1 \\ --enable-libass \\ --enable-libdav1d \\ --enable-libdrm \\ --enable-libfdk-aac \\ --enable-libfreetype \\ --enable-libkvazaar \\ --enable-libmp3lame \\ --enable-libopencore-amrnb \\ --enable-libopencore-amrwb \\ --enable-libopus \\ --enable-librtmp \\ --enable-libsnappy \\ --enable-libsoxr \\ --enable-libssh \\ --enable-libvorbis \\ --enable-libvpx \\ --enable-libzimg \\ --enable-libwebp \\ --enable-libx264 \\ --enable-libx265 \\ --enable-libxml2 \\ --disable-mmal \\ --enable-nonfree \\ --enable-omx \\ --enable-omx-rpi \\ --enable-version3 \\ --target-os = linux \\ --enable-pthreads \\ --enable-openssl \\ --enable-hardcoded-tables \\ && make -j $( nproc ) \\ && sudo make install The compilation time is quite long, usually 5 hours on Raspberry Pi Wi-Fi Zero, so be patient. Restart the system when the compilation ends, and check for the supported Hardware Acceleration codec: ffmpeg -hide_banner -encoders | grep -E \"h264|mjpeg\" V..... libx264 libx264 H.264 / AVC / MPEG-4 AVC / MPEG-4 part 10 (codec h264) V..... libx264rgb libx264 H.264 / AVC / MPEG-4 AVC / MPEG-4 part 10 RGB (codec h264) V..... h264_omx OpenMAX IL H.264 video encoder (codec h264) V..... h264_v4l2m2m V4L2 mem2mem H.264 encoder wrapper (codec h264) VFS... mjpeg MJPEG (Motion JPEG) Autobuild script # This build guide is only tested on 32-bit Raspberry OS The script # There are many guides published on the internet but thanks to cdgriffith for the below awesome pi_streaming_setup script. This script is designed to help automate turning a Raspberry Pi with a compatible camera into an MPEG-DASH / HLS streaming server . The steps it will attempt to do: Install FFmpeg (or compile it before install) with H264 hardware acceleration and free libraries Install NGINX for DASH / HLS or install RTSP server if desired (DASH/HLS) Update rc.local to run required setup script on reboot (DASH/HLS) Create index.html file to view video stream Create a systemd service and enable it to start streaming This script requires Python 3.6+ The usage of this script is simple and clear, but to compile FFmpeg only, we just need to add 2 options as below: sudo python3 streaming_setup.py --compile-ffmpeg --compile-only --run-as pi Run script # Install git if not installed: sudo apt install -y git Clone the pi_streaming_setup repo from GitHub: cd ~ git clone https://github.com/cdgriffith/pi_streaming_setup.git Go into the script\u2019s folder: cd pi_streaming_setup and finally, run the script with sudo and python3 as user pi : sudo python3 streaming_setup.py --compile-ffmpeg --compile-only --run-as pi This will take about 4~5 hours on an old and slow Raspberry Pi, such as a Pi Zero. After the compilation finishes, reboot the Pi, and when it\u2019s booted up, run below command to check the compiled tool: ffmpeg -hide_banner -encoders | grep -E \"h264|mjpeg\" and check the supported codecs: V..... libx264 libx264 H.264 / AVC / MPEG-4 AVC / MPEG-4 part 10 (codec h264) V..... libx264rgb libx264 H.264 / AVC / MPEG-4 AVC / MPEG-4 part 10 RGB (codec h264) V..... h264_omx OpenMAX IL H.264 video encoder (codec h264) V..... h264_v4l2m2m V4L2 mem2mem H.264 encoder wrapper (codec h264) VFS... mjpeg MJPEG (Motion JPEG)","title":"Compile FFmpeg with Hardware Acceleration"},{"location":"blog/pi/compile-ffmpeg/#manual-compilation","text":"The below guide helps to compile FFmpeg from the latest source code to get new features or bug fixes. This build guide is only tested on 32-bit Raspberry OS","title":"Manual compilation"},{"location":"blog/pi/compile-ffmpeg/#update-the-system","text":"Before starting to build, update system packages to the latest version may help to solve some issues which could happen due to the requirements from the latest source code of FFmpeg. sudo apt update && \\ sudo apt upgrade -y","title":"Update the system"},{"location":"blog/pi/compile-ffmpeg/#install-build-package","text":"To compile a source code, system needs to install build tools, including config parsers, compilers, dependent libraries. Here is the command to install necessary packages: sudo apt install -y \\ autoconf automake build-essential \\ cmake doxygen git graphviz imagemagick \\ libasound2-dev libass-dev libavcodec-dev \\ libavdevice-dev libavfilter-dev libavformat-dev \\ libavutil-dev libfreetype6-dev libgmp-dev \\ libmp3lame-dev libopencore-amrnb-dev libopencore-amrwb-dev \\ libopus-dev librtmp-dev libsdl2-dev \\ libsdl2-image-dev libsdl2-mixer-dev libsdl2-net-dev \\ libsdl2-ttf-dev libsnappy-dev libsoxr-dev \\ libssh-dev libssl-dev libtool \\ libv4l-dev libva-dev libvdpau-dev \\ libvo-amrwbenc-dev libvorbis-dev libwebp-dev \\ libx264-dev libx265-dev libxcb-shape0-dev \\ libxcb-shm0-dev libxcb-xfixes0-dev libxcb1-dev \\ libxml2-dev lzma-dev meson nasm \\ pkg-config python3-dev python3-pip \\ texinfo wget yasm zlib1g-dev libdrm-dev","title":"Install build package"},{"location":"blog/pi/compile-ffmpeg/#compile-additional-libraries","text":"There are some additional libraries required by FFmpeg, which are not pre-built and distributed in OS package manager. Create a folder to get started: mkdir ~/ffmpeg-libraries","title":"Compile additional libraries"},{"location":"blog/pi/compile-ffmpeg/#aac-sound-format-fdk-aac","text":"git clone --depth 1 https://github.com/mstorsjo/fdk-aac.git ~/ffmpeg-libraries/fdk-aac \\ && cd ~/ffmpeg-libraries/fdk-aac \\ && autoreconf -fiv \\ && ./configure \\ && make -j $( nproc ) \\ && sudo make install","title":"AAC sound format (fdk-aac)"},{"location":"blog/pi/compile-ffmpeg/#av1-video-format-dav1d","text":"git clone --depth 1 https://code.videolan.org/videolan/dav1d.git ~/ffmpeg-libraries/dav1d \\ && mkdir ~/ffmpeg-libraries/dav1d/build \\ && cd ~/ffmpeg-libraries/dav1d/build \\ && meson .. \\ && ninja \\ && sudo ninja install","title":"AV1 video format (dav1d)"},{"location":"blog/pi/compile-ffmpeg/#hevc-encoder-kvazaar","text":"git clone --depth 1 https://github.com/ultravideo/kvazaar.git ~/ffmpeg-libraries/kvazaar \\ && cd ~/ffmpeg-libraries/kvazaar \\ && ./autogen.sh \\ && ./configure \\ && make -j $( nproc ) \\ && sudo make install","title":"HEVC encoder (kvazaar)"},{"location":"blog/pi/compile-ffmpeg/#vp8-and-vp9-video-codecs-libvpx","text":"git clone --depth 1 https://chromium.googlesource.com/webm/libvpx ~/ffmpeg-libraries/libvpx \\ && cd ~/ffmpeg-libraries/libvpx \\ && ./configure --disable-examples --disable-tools --disable-unit_tests --disable-docs \\ && make -j $( nproc ) \\ && sudo make install","title":"VP8 and VP9 video codecs (LibVPX)"},{"location":"blog/pi/compile-ffmpeg/#ap1-video-codec-aom","text":"git clone --depth = 1 https://gitlab.com/AOMediaCodec/SVT-AV1.git ~/ffmpeg-libraries/av1 \\ && cd ~/ffmpeg-libraries/av1/Build \\ && cmake .. -G \"Unix Makefiles\" -DCMAKE_BUILD_TYPE = Release \\ && make -j $( nproc ) \\ && sudo make install","title":"AP1 video codec (aom)"},{"location":"blog/pi/compile-ffmpeg/#image-processing-zimg","text":"git clone -b release-3.0.3 https://github.com/sekrit-twc/zimg.git ~/ffmpeg-libraries/zimg \\ && cd ~/ffmpeg-libraries/zimg \\ && sh autogen.sh \\ && ./configure \\ && make \\ && sudo make install","title":"Image processing (zimg)"},{"location":"blog/pi/compile-ffmpeg/#link-compiled-libraries","text":"After installing new libraries, system needs to refresh link cache for new packages. This command ensures system won\u2019t run into linking issues because the compiler can\u2019t find a library. sudo ldconfig","title":"Link compiled libraries"},{"location":"blog/pi/compile-ffmpeg/#compile-ffmpeg","text":"Finally, FFmpeg can be compiled with settings to include additional libraries, and the feature omx-rpi . The command is quite large as it has a lot of options: git clone --depth 1 https://github.com/FFmpeg/FFmpeg.git ~/FFmpeg \\ && cd ~/FFmpeg \\ && ./configure \\ --extra-cflags = \"-I/usr/local/include\" \\ --extra-ldflags = \"-L/usr/local/lib\" \\ --extra-libs = \"-lpthread -lm -latomic\" \\ --arch = armel \\ --enable-gmp \\ --enable-gpl \\ --enable-libaom \\ --enable-libsvtav1 \\ --enable-libass \\ --enable-libdav1d \\ --enable-libdrm \\ --enable-libfdk-aac \\ --enable-libfreetype \\ --enable-libkvazaar \\ --enable-libmp3lame \\ --enable-libopencore-amrnb \\ --enable-libopencore-amrwb \\ --enable-libopus \\ --enable-librtmp \\ --enable-libsnappy \\ --enable-libsoxr \\ --enable-libssh \\ --enable-libvorbis \\ --enable-libvpx \\ --enable-libzimg \\ --enable-libwebp \\ --enable-libx264 \\ --enable-libx265 \\ --enable-libxml2 \\ --disable-mmal \\ --enable-nonfree \\ --enable-omx \\ --enable-omx-rpi \\ --enable-version3 \\ --target-os = linux \\ --enable-pthreads \\ --enable-openssl \\ --enable-hardcoded-tables \\ && make -j $( nproc ) \\ && sudo make install The compilation time is quite long, usually 5 hours on Raspberry Pi Wi-Fi Zero, so be patient. Restart the system when the compilation ends, and check for the supported Hardware Acceleration codec: ffmpeg -hide_banner -encoders | grep -E \"h264|mjpeg\" V..... libx264 libx264 H.264 / AVC / MPEG-4 AVC / MPEG-4 part 10 (codec h264) V..... libx264rgb libx264 H.264 / AVC / MPEG-4 AVC / MPEG-4 part 10 RGB (codec h264) V..... h264_omx OpenMAX IL H.264 video encoder (codec h264) V..... h264_v4l2m2m V4L2 mem2mem H.264 encoder wrapper (codec h264) VFS... mjpeg MJPEG (Motion JPEG)","title":"Compile FFmpeg"},{"location":"blog/pi/compile-ffmpeg/#autobuild-script","text":"This build guide is only tested on 32-bit Raspberry OS","title":"Autobuild script"},{"location":"blog/pi/compile-ffmpeg/#the-script","text":"There are many guides published on the internet but thanks to cdgriffith for the below awesome pi_streaming_setup script. This script is designed to help automate turning a Raspberry Pi with a compatible camera into an MPEG-DASH / HLS streaming server . The steps it will attempt to do: Install FFmpeg (or compile it before install) with H264 hardware acceleration and free libraries Install NGINX for DASH / HLS or install RTSP server if desired (DASH/HLS) Update rc.local to run required setup script on reboot (DASH/HLS) Create index.html file to view video stream Create a systemd service and enable it to start streaming This script requires Python 3.6+ The usage of this script is simple and clear, but to compile FFmpeg only, we just need to add 2 options as below: sudo python3 streaming_setup.py --compile-ffmpeg --compile-only --run-as pi","title":"The script"},{"location":"blog/pi/compile-ffmpeg/#run-script","text":"Install git if not installed: sudo apt install -y git Clone the pi_streaming_setup repo from GitHub: cd ~ git clone https://github.com/cdgriffith/pi_streaming_setup.git Go into the script\u2019s folder: cd pi_streaming_setup and finally, run the script with sudo and python3 as user pi : sudo python3 streaming_setup.py --compile-ffmpeg --compile-only --run-as pi This will take about 4~5 hours on an old and slow Raspberry Pi, such as a Pi Zero. After the compilation finishes, reboot the Pi, and when it\u2019s booted up, run below command to check the compiled tool: ffmpeg -hide_banner -encoders | grep -E \"h264|mjpeg\" and check the supported codecs: V..... libx264 libx264 H.264 / AVC / MPEG-4 AVC / MPEG-4 part 10 (codec h264) V..... libx264rgb libx264 H.264 / AVC / MPEG-4 AVC / MPEG-4 part 10 RGB (codec h264) V..... h264_omx OpenMAX IL H.264 video encoder (codec h264) V..... h264_v4l2m2m V4L2 mem2mem H.264 encoder wrapper (codec h264) VFS... mjpeg MJPEG (Motion JPEG)","title":"Run script"},{"location":"blog/pi/headless-mode/","tags":["raspberry-pi"],"text":"Download OS Image # Official images for recommended operating systems are available to download from the Raspberry Pi website download page . Headless Mode is usually used on the Raspberry Pi OS Lite version in which the graphical UI is not installed. The release notes of OS are listed in each build version in here . 64-bit OS From 2022 Feb, Raspberry Pi starts supporting 64-bit OS on Model 3, 4, 400, and Zero 2W. Note that some third-party packages may not work on 64-bit OS. Burn Image to an SD Card # OS usually comes in one image file which needs to be written (burned) to SD Card. The content of the image is extracted to the target SD Card, while still preserves partition table and some special attributes such as bootable flag. Raspberry Pi Imager # Raspberry Pi Imager is the official Image Writer from Raspberry Pi. Run the Raspberry Pi Imager, and select the Desktop version but without recommended software. Press Ctrl + Shift + X to show the advanced menu, fill some settings as below: Hostname: raspberrypi or what you want SSH: check the box and set a password WiFi (optional): if you want to use WiFi as the primary network, fill SSID and password Raspberry Pi Imager BalenaEtcher # The application BalenaEtcher is a very good image writer that will write the OS image to an SD Card. Download and install it, then run it. Just follow the guided steps: Select image \u2014 browse to the zip file downloaded above Select drive \u2014 it may find the SD Card drive automatically Click Flash Etcher is writing the OS image After copying the image to the target SD Card, File Explorer may have trouble seeing the content of that SD Card. A simple fix is to pull the SD Card out then plug it back. It should appear with a partition named boot . Enable SSH For security reasons, Secure Socket Shell ( ssh ) is no longer enabled by default. To enable it, place a blank text file called ssh no file extension in the root of the boot partition on the SD Card. Add Wi-Fi Network To add a wireless network which Pi will automatically connect to, create a text file called wpa_supplicant.conf and place that file in the root of the boot partition on SD Card too. In below config file, the ssid field is the Wi-Fi Access Point name, and the psk field is the password of that Wi-Fi. wpa_supplicant.conf country = US ctrl_interface = DIR=/var/run/wpa_supplicant GROUP=netdev update_config = 1 network = { ssid = \"NETWORK-NAME\" psk = \"NETWORK-PASSWORD\" } See ISO 3166-1 country codes to fill into country field. If the target network is a hidden one, an extra option in the wpa_supplicant.conf file, scan_ssid=1 , may help connection. Adding multiple wireless network configurations is allowed, with some extra fields to set the name and the priority (higher number gets connected first): network = { ssid = \"HomeOneSSID\" psk = \"passwordOne\" priority = 1 id_str = \"homeOne\" } network = { ssid = \"HomeTwoSSID\" psk = \"passwordTwo\" priority = 2 id_str = \"homeTwo\" } Added ssh and wpa_supplicant.conf in the boot partition For Pi Zero / Zero W, see the Direct USB connection section to skip setting a Wi-Fi network, as it will setup a virtual network over the USB connection. Direct USB connection # Apply to Pi Zero / Zero W Only On Pi Zero / Zero W only, it\u2019s able to turn on USB OTG mode and the Pi will act as a USB slave with different modes: Serial, Ethernet, Mass storage device, etc. The research was published here and here . This step will set up Pi in USB OTG Ethernet mode, so that when plugging Pi into computer by the Peripheral USB port, labelled __USB__, not PWR , there is virtual network will be created and Pi can be accessed over that network, and no need of an external Wi-Fi network is required. This method also helps to power Pi over the USB port. Add dtoverlay=dwc2 on a new line in the config.txt file. Open up the cmdline.txt file. Insert modules-load=dwc2,g_ether after rootwait with only one space between the text rootwait and the new text!!! Login to Pi # Power Pi up and wait for the power led gets stable. Use any Network Scanner to detect the IP of the Pi. A plugin on MobaXterm can be used too. For the official Raspberry Pi OS, the default username is pi , with password raspberry , on the host raspberrypi.local . If you change the hostname in Raspberry Pi Imager , make sure to use that new hostname, e.g. mypi.local . Bonjour is a service from Apple to discovery devices in a network using hostname. Install it and then Pi can be connected using its default hostname raspberrypi.local . Scan for Pi\u2019s IP Review Network Settings This command should list the network connection in the first line for wlan0 : iwconfig This command should show info for wlan0 : ifconfig This command should list the wlan0 network with details: iwlist wlan0 scan Connect to another Wi-Fi network Open the wpa-supplicant configuration file in nano editor: sudo nano /etc/wpa_supplicant/wpa_supplicant.conf Go to the bottom of the file and add the following: network={ ssid=\"NETWORK-NAME\" psk=\"NETWORK-PASSWORD\" } Reconfigure the interface with: wpa_cli -i wlan0 reconfigure Verify whether it has successfully connected using ifconfig wlan0 Update system (optional) # To get the latest version of Pi OS and its packages, please update the system by entering below commands: sudo apt update && \\ sudo apt upgrade -y Expand File system (optional) # To use all of available space on the SD Card, expand the file system by running: sudo raspi-config Select Advanced Options \u2192 Expand File system Then reboot the system. Serial Console # By default, the primary UART is assigned to the Linux console, and the secondary UART is connected to Bluetooth Module (on model having Bluetooth feature \u2014 Pi Zero W, Pi 3, and Pi 4). Use raspi-config to disable the Linux serial console, then enable UART as a peripheral. Remote access over VNC # If you want to access the GUI, complete with a desktop and floating windows, you\u2019ll need to enable VNC. Note that the Lite OS does not have GUI installed by default, you have to install a Desktop Environment Manager first. Enable VNC # To enable VNC server, it must be turned on though raspi-config . Firstly, run: sudo raspi-config then select Interfacing Options , choose VNC , and select Yes . Access over VNC # On the remote PC, install and launch VNC Viewer Create a New Connection , and enter raspberry.local (or whatever you changed in the setup step) in the VNC Server field. If this does not work, try again with the name raspberrypi without .local After adding new connection, run that session and fill in username and password to login","title":"Guide to set up Headless mode"},{"location":"blog/pi/headless-mode/#download-os-image","text":"Official images for recommended operating systems are available to download from the Raspberry Pi website download page . Headless Mode is usually used on the Raspberry Pi OS Lite version in which the graphical UI is not installed. The release notes of OS are listed in each build version in here . 64-bit OS From 2022 Feb, Raspberry Pi starts supporting 64-bit OS on Model 3, 4, 400, and Zero 2W. Note that some third-party packages may not work on 64-bit OS.","title":"Download OS Image"},{"location":"blog/pi/headless-mode/#burn-image-to-an-sd-card","text":"OS usually comes in one image file which needs to be written (burned) to SD Card. The content of the image is extracted to the target SD Card, while still preserves partition table and some special attributes such as bootable flag.","title":"Burn Image to an SD Card"},{"location":"blog/pi/headless-mode/#raspberry-pi-imager","text":"Raspberry Pi Imager is the official Image Writer from Raspberry Pi. Run the Raspberry Pi Imager, and select the Desktop version but without recommended software. Press Ctrl + Shift + X to show the advanced menu, fill some settings as below: Hostname: raspberrypi or what you want SSH: check the box and set a password WiFi (optional): if you want to use WiFi as the primary network, fill SSID and password Raspberry Pi Imager","title":"Raspberry Pi Imager"},{"location":"blog/pi/headless-mode/#balenaetcher","text":"The application BalenaEtcher is a very good image writer that will write the OS image to an SD Card. Download and install it, then run it. Just follow the guided steps: Select image \u2014 browse to the zip file downloaded above Select drive \u2014 it may find the SD Card drive automatically Click Flash Etcher is writing the OS image After copying the image to the target SD Card, File Explorer may have trouble seeing the content of that SD Card. A simple fix is to pull the SD Card out then plug it back. It should appear with a partition named boot . Enable SSH For security reasons, Secure Socket Shell ( ssh ) is no longer enabled by default. To enable it, place a blank text file called ssh no file extension in the root of the boot partition on the SD Card. Add Wi-Fi Network To add a wireless network which Pi will automatically connect to, create a text file called wpa_supplicant.conf and place that file in the root of the boot partition on SD Card too. In below config file, the ssid field is the Wi-Fi Access Point name, and the psk field is the password of that Wi-Fi. wpa_supplicant.conf country = US ctrl_interface = DIR=/var/run/wpa_supplicant GROUP=netdev update_config = 1 network = { ssid = \"NETWORK-NAME\" psk = \"NETWORK-PASSWORD\" } See ISO 3166-1 country codes to fill into country field. If the target network is a hidden one, an extra option in the wpa_supplicant.conf file, scan_ssid=1 , may help connection. Adding multiple wireless network configurations is allowed, with some extra fields to set the name and the priority (higher number gets connected first): network = { ssid = \"HomeOneSSID\" psk = \"passwordOne\" priority = 1 id_str = \"homeOne\" } network = { ssid = \"HomeTwoSSID\" psk = \"passwordTwo\" priority = 2 id_str = \"homeTwo\" } Added ssh and wpa_supplicant.conf in the boot partition For Pi Zero / Zero W, see the Direct USB connection section to skip setting a Wi-Fi network, as it will setup a virtual network over the USB connection.","title":"BalenaEtcher"},{"location":"blog/pi/headless-mode/#direct-usb-connection","text":"Apply to Pi Zero / Zero W Only On Pi Zero / Zero W only, it\u2019s able to turn on USB OTG mode and the Pi will act as a USB slave with different modes: Serial, Ethernet, Mass storage device, etc. The research was published here and here . This step will set up Pi in USB OTG Ethernet mode, so that when plugging Pi into computer by the Peripheral USB port, labelled __USB__, not PWR , there is virtual network will be created and Pi can be accessed over that network, and no need of an external Wi-Fi network is required. This method also helps to power Pi over the USB port. Add dtoverlay=dwc2 on a new line in the config.txt file. Open up the cmdline.txt file. Insert modules-load=dwc2,g_ether after rootwait with only one space between the text rootwait and the new text!!!","title":"Direct USB connection"},{"location":"blog/pi/headless-mode/#login-to-pi","text":"Power Pi up and wait for the power led gets stable. Use any Network Scanner to detect the IP of the Pi. A plugin on MobaXterm can be used too. For the official Raspberry Pi OS, the default username is pi , with password raspberry , on the host raspberrypi.local . If you change the hostname in Raspberry Pi Imager , make sure to use that new hostname, e.g. mypi.local . Bonjour is a service from Apple to discovery devices in a network using hostname. Install it and then Pi can be connected using its default hostname raspberrypi.local . Scan for Pi\u2019s IP Review Network Settings This command should list the network connection in the first line for wlan0 : iwconfig This command should show info for wlan0 : ifconfig This command should list the wlan0 network with details: iwlist wlan0 scan Connect to another Wi-Fi network Open the wpa-supplicant configuration file in nano editor: sudo nano /etc/wpa_supplicant/wpa_supplicant.conf Go to the bottom of the file and add the following: network={ ssid=\"NETWORK-NAME\" psk=\"NETWORK-PASSWORD\" } Reconfigure the interface with: wpa_cli -i wlan0 reconfigure Verify whether it has successfully connected using ifconfig wlan0","title":"Login to Pi"},{"location":"blog/pi/headless-mode/#update-system-optional","text":"To get the latest version of Pi OS and its packages, please update the system by entering below commands: sudo apt update && \\ sudo apt upgrade -y","title":"Update system (optional)"},{"location":"blog/pi/headless-mode/#expand-file-system-optional","text":"To use all of available space on the SD Card, expand the file system by running: sudo raspi-config Select Advanced Options \u2192 Expand File system Then reboot the system.","title":"Expand File system (optional)"},{"location":"blog/pi/headless-mode/#serial-console","text":"By default, the primary UART is assigned to the Linux console, and the secondary UART is connected to Bluetooth Module (on model having Bluetooth feature \u2014 Pi Zero W, Pi 3, and Pi 4). Use raspi-config to disable the Linux serial console, then enable UART as a peripheral.","title":"Serial Console"},{"location":"blog/pi/headless-mode/#remote-access-over-vnc","text":"If you want to access the GUI, complete with a desktop and floating windows, you\u2019ll need to enable VNC. Note that the Lite OS does not have GUI installed by default, you have to install a Desktop Environment Manager first.","title":"Remote access over VNC"},{"location":"blog/pi/headless-mode/#enable-vnc","text":"To enable VNC server, it must be turned on though raspi-config . Firstly, run: sudo raspi-config then select Interfacing Options , choose VNC , and select Yes .","title":"Enable VNC"},{"location":"blog/pi/headless-mode/#access-over-vnc","text":"On the remote PC, install and launch VNC Viewer Create a New Connection , and enter raspberry.local (or whatever you changed in the setup step) in the VNC Server field. If this does not work, try again with the name raspberrypi without .local After adding new connection, run that session and fill in username and password to login","title":"Access over VNC"},{"location":"blog/pi/notes/","tags":["raspberry-pi","notes"],"text":"Search 1 for a package distributed by Debian: Search Setup Wireless # Refer to the official guide at Raspberry Pi Configuration . Note that there are two types of access points: Routed wireless access point : Create a new local network, which is not connected any other existing network +- RPi -------+ +---+ 10.10.0.2 | +- Laptop ----+ | | WLAN AP +-))) (((-+ WLAN Client | | | 192.168.4.1 | | 192.168.4.2 | | +-------------+ +-------------+ +- Router ----+ | | Firewall | | +- PC#2 ------+ (Internet)--WAN-+ DHCP server +-LAN-+---+ 10.10.0.3 | | 10.10.0.1 | | +-------------+ +-------------+ | | +- PC#1 ------+ +---+ 10.10.0.4 | +-------------+ Bridged wireless access point : Extend an existing Ethernet network to wireless computers and devices +- RPi -------+ +---+ 10.10.0.2 | +- Laptop ----+ | | WLAN AP +-))) (((-+ WLAN Client | | | Bridge | | 10.10.0.5 | | +-------------+ +-------------+ +- Router ----+ | | Firewall | | +- PC#2 ------+ (Internet)--WAN-+ DHCP server +-LAN-+---+ 10.10.0.3 | | 10.10.0.1 | | +-------------+ +-------------+ | | +- PC#1 ------+ +---+ 10.10.0.4 | +-------------+ Python packages # Most packages can be installed using sudo apt install followed by python-<packagename> for Python2 or python3-<packagename> . In some cases, a package is not available on the OS package manager, so install that packages via pip from python package manager. Install pip for both Python 2 and 3: sudo apt install -y python-pip python3-pip Then install the target package. For example: sudo apt install -y python-ws4py python3-ws4py is equivalent to: pip install ws4py pip3 install ws4py Who is logged on? # Use w command from procps package. 08:53:52 up 2:21, 2 users, load average: 0.02, 0.06, 0.07 USER TTY FROM LOGIN@ IDLE JCPU PCPU WHAT pi pts/0 fe80::1936:b4d4: 06:34 0.00s 1.54s 0.05s w Save power # Save power when running on battery by turning off unused peripherals, or features. Turn off USB # Turn OFF the USB chip : echo '1-1' | sudo tee /sys/bus/usb/drivers/usb/unbind Turn ON the USB chip: echo '1-1' | sudo tee /sys/bus/usb/drivers/usb/bind Turn off HDMI # Turn OFF the HDMI output : sudo /opt/vc/bin/tvservice -o Turn ON the HDMI output: sudo /opt/vc/bin/tvservice -p Throttle CPU # Reduce the clock of the core by changing some parameters in the /boot/config.txt file: /boot/config.txt arm_freq_min = 250 core_freq_min = 100 sdram_freq_min = 150 over_voltage_min = 0 Disable Wi-Fi & Bluetooth # Disable Wi-Fi & Bluetooth Starting from Raspberry Pi 3, WiFi and Bluetooth are added on hardware, so Raspbian has its method to control these signals in /boot/config.txt file: /boot/config.txt dtoverlay = pi3-disable-wifi dtoverlay = pi3-disable-bt It\u2019s correct to use the word pi3 in the params\u2019s value, for other version of Raspberry Pi. The rfkill command can be used to soft-block the wireless connections: rfkill list # displays the state of the modules rfkill block wifi rfkill block bluetooth but this does not completely turn off the hardware of the WiFi and the Bluetooth module. They will still draw a little power in the background. Disable on-board LEDs # Disable on-board LEDs Add below parameters to the /boot/config.txt file: /boot/config.txt dtparam = act_led_trigger=none dtparam = act_led_activelow=on Add a form in Markdown: < form role = \"search\" target = \"_blank\" action = \"https://packages.debian.org/search\" > < div > < input type = \"search\" id = \"mySearch\" name = \"keywords\" placeholder = \"Enter package name...\" aria-label = \"Search for a package name\" style = \"border:1px solid gray; padding: .25em .5em;\" /> < button type = \"submit\" class = \"md-button\" > Search </ button > </ div > </ form > \u21a9","title":"Notes for Raspberry Pi"},{"location":"blog/pi/notes/#setup-wireless","text":"Refer to the official guide at Raspberry Pi Configuration . Note that there are two types of access points: Routed wireless access point : Create a new local network, which is not connected any other existing network +- RPi -------+ +---+ 10.10.0.2 | +- Laptop ----+ | | WLAN AP +-))) (((-+ WLAN Client | | | 192.168.4.1 | | 192.168.4.2 | | +-------------+ +-------------+ +- Router ----+ | | Firewall | | +- PC#2 ------+ (Internet)--WAN-+ DHCP server +-LAN-+---+ 10.10.0.3 | | 10.10.0.1 | | +-------------+ +-------------+ | | +- PC#1 ------+ +---+ 10.10.0.4 | +-------------+ Bridged wireless access point : Extend an existing Ethernet network to wireless computers and devices +- RPi -------+ +---+ 10.10.0.2 | +- Laptop ----+ | | WLAN AP +-))) (((-+ WLAN Client | | | Bridge | | 10.10.0.5 | | +-------------+ +-------------+ +- Router ----+ | | Firewall | | +- PC#2 ------+ (Internet)--WAN-+ DHCP server +-LAN-+---+ 10.10.0.3 | | 10.10.0.1 | | +-------------+ +-------------+ | | +- PC#1 ------+ +---+ 10.10.0.4 | +-------------+","title":"Setup Wireless"},{"location":"blog/pi/notes/#python-packages","text":"Most packages can be installed using sudo apt install followed by python-<packagename> for Python2 or python3-<packagename> . In some cases, a package is not available on the OS package manager, so install that packages via pip from python package manager. Install pip for both Python 2 and 3: sudo apt install -y python-pip python3-pip Then install the target package. For example: sudo apt install -y python-ws4py python3-ws4py is equivalent to: pip install ws4py pip3 install ws4py","title":"Python packages"},{"location":"blog/pi/notes/#who-is-logged-on","text":"Use w command from procps package. 08:53:52 up 2:21, 2 users, load average: 0.02, 0.06, 0.07 USER TTY FROM LOGIN@ IDLE JCPU PCPU WHAT pi pts/0 fe80::1936:b4d4: 06:34 0.00s 1.54s 0.05s w","title":"Who is logged on?"},{"location":"blog/pi/notes/#save-power","text":"Save power when running on battery by turning off unused peripherals, or features.","title":"Save power"},{"location":"blog/pi/notes/#turn-off-usb","text":"Turn OFF the USB chip : echo '1-1' | sudo tee /sys/bus/usb/drivers/usb/unbind Turn ON the USB chip: echo '1-1' | sudo tee /sys/bus/usb/drivers/usb/bind","title":"Turn off USB"},{"location":"blog/pi/notes/#turn-off-hdmi","text":"Turn OFF the HDMI output : sudo /opt/vc/bin/tvservice -o Turn ON the HDMI output: sudo /opt/vc/bin/tvservice -p","title":"Turn off HDMI"},{"location":"blog/pi/notes/#throttle-cpu","text":"Reduce the clock of the core by changing some parameters in the /boot/config.txt file: /boot/config.txt arm_freq_min = 250 core_freq_min = 100 sdram_freq_min = 150 over_voltage_min = 0","title":"Throttle CPU"},{"location":"blog/pi/notes/#disable-wi-fi--bluetooth","text":"Disable Wi-Fi & Bluetooth Starting from Raspberry Pi 3, WiFi and Bluetooth are added on hardware, so Raspbian has its method to control these signals in /boot/config.txt file: /boot/config.txt dtoverlay = pi3-disable-wifi dtoverlay = pi3-disable-bt It\u2019s correct to use the word pi3 in the params\u2019s value, for other version of Raspberry Pi. The rfkill command can be used to soft-block the wireless connections: rfkill list # displays the state of the modules rfkill block wifi rfkill block bluetooth but this does not completely turn off the hardware of the WiFi and the Bluetooth module. They will still draw a little power in the background.","title":"Disable Wi-Fi &amp; Bluetooth"},{"location":"blog/pi/notes/#disable-on-board-leds","text":"Disable on-board LEDs Add below parameters to the /boot/config.txt file: /boot/config.txt dtparam = act_led_trigger=none dtparam = act_led_activelow=on Add a form in Markdown: < form role = \"search\" target = \"_blank\" action = \"https://packages.debian.org/search\" > < div > < input type = \"search\" id = \"mySearch\" name = \"keywords\" placeholder = \"Enter package name...\" aria-label = \"Search for a package name\" style = \"border:1px solid gray; padding: .25em .5em;\" /> < button type = \"submit\" class = \"md-button\" > Search </ button > </ div > </ form > \u21a9","title":"Disable on-board LEDs"},{"location":"blog/pi/resource-usage/","tags":["raspberry-pi","performance"],"text":"The final script Download monitor.sh then save to ~/monitor.sh . Add below line to ~/.bashrc : source monitor.sh Usage: monitor \"title\" program parameters This post is written as a walk through guide, step by step, to help to understand how the script was made. Export a function in bash # In a bash file, a function with a name and its body can be defined and then exported with export -f command: myfunc.sh #!/bin/bash myfunc () { echo \"parameters: $@ \" } export -f myfunc To make function available outside the script, run source command before calling the function: source myfunc.sh myfunc abc All parameters are implicit saved into local macros. Refer to Advanced Bash-Scripting Guide : Macro Description $BASHPID Process ID of the current instance of Bash. This is not the same as the $$ variable, but it often gives the same result. $PPID Process ID of the parent process $$ Process ID of the script itself $! Process ID of last job run in background $PWD The current directory that process is in at the time $SECONDS The number of seconds the script has been running $1 , $2 , $n The first, the second and the n-th parameter $# The number of command-line arguments $* All the positional parameters, seen as a single word, must be quoted $@ Same as $* , but each parameter is a quoted string, that is, the parameters are passed on intact, without interpretation or expansion. This means, among other things, that each parameter in the argument list is seen as a separate word $? Exit status of a command, function, or the script itself Command-Grouping # Refer to Bash Manual \u2014 Command Grouping . Bash provides two ways to group a list of commands to be executed as a unit. When commands are grouped, re-directions may be applied to the entire command list. ( list ) Placing a list of commands between parentheses causes a sub-shell environment to be created (see Command Execution Environment ), and each of the commands in list to be executed in that sub-shell. Since the list is executed in a sub-shell, variable assignments do not remain in effect after the sub-shell completes. { list; } Placing a list of commands between curly braces causes the list to be executed in the current shell context. No sub-shell is created. The semicolon (or newline) following list is required. In addition to the creation of a sub-shell, there is a subtle difference between these two constructs due to historical reasons: The braces are reserved words, so they must be separated from the list by blanks or other shell meta-characters The parentheses are operators, and are recognized as separate tokens by the shell even if they are not separated from the list by whitespace Run a process # The basic idea is to run a process in background and while it\u2019s running, report its resource usage: monitor.sh #!/bin/bash monitor () ( # run process in background echo \"Executing $* \" $* & # get PID of last job in background pid = $! echo \"Executed in PID: $pid \" ps --no-headers -p $pid echo 'CPU MEM' # check if a process is running while [ -e /proc/ $pid ] do # use ps to get cpu and memory usage ps --no-headers -o '%cpu,%mem' -p $pid sleep 1 done ) export -f monitor ps or top # Both ps and top report CPU Usage, but the returned values are different. Let\u2019s check the manual of each command: ps CPU usage is currently expressed as the percentage of time spent running during the entire lifetime of a process. This is not ideal, and it does not conform to the standards that ps otherwise conforms to. CPU usage is unlikely to add up to exactly 100%. It means ps does not show the instant CPU usage, it shows an average CPU usage over the lifetime of the process. top %CPU \u2013 CPU Usage, The task\u2019s share of the elapsed CPU time since the last screen update, expressed as a percentage of total CPU time. It means if interval is 1 second, top will report CPU usage for the last 1 second. That can be considered as instant report. Let\u2019s check top \u2018s options -b : Batch-mode operation Starts top in Batch mode, which could be useful for sending output from top to other programs or to a file. In this mode, top will not accept input and runs until the iterations limit set with the `-n\u2019 command-line option or until killed. -d : Delay-time interval as: -d ss.t (secs.tenths) Specifies the delay between screen updates, and overrides the corresponding value in one\u2019s personal configuration file or the startup default. Later this can be changed with the d or s interactive commands. -p : Monitor-PIDs mode as: -pN1 -pN2 ... or -pN1,N2,N3 ... Monitor only processes with specified process IDs. Switch to use top get the process information: monitor.sh #!/bin/bash monitor () ( # run process in background $* & # get PID of last job in background pid = $! # use top to monitor the process top -b -d 1 -p $pid & # save top PID to control it toppid = $! echo 'CPU MEM' # check if a process is running while [ -e /proc/ $pid ] do sleep 1 done # kill top sleep 1 kill -9 $toppid ) export -f monitor Run a test: monitor ffmpeg -y -hide_banner -i /dev/video0 -c:v h264_omx -t 10 test.mp4 and the result: PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 2286 pi 20 0 336612 129848 121960 R 34.5 52.5 0:03.36 ffmpeg grep and awk # Refer to grep manual Use grep to extract process information lines using pid number as the keyword: top -b -d 1 -p $pid | grep $pid & Refer to awk manual Use awk to cut out 2 columns: %CPU and %MEM (at the 9 th and 10 th column) from the filtered lines: top -b -d 1 -p $pid | grep $pid | awk '{print $9, $10}' & So, this is a modified version: monitor.sh #!/bin/bash monitor () ( # run process in background $* & # get PID of last job in background pid = $! # use top to monitor the process # use grep to catch useful lines # use awk to extract data columns top -b -d 1 -p $pid | grep $pid | awk '{print $9, $10}' & # save top PID to control it toppid = $! echo 'CPU MEM' # check if a process is running while [ -e /proc/ $pid ] do sleep 1 done # kill top sleep 1 kill -9 $toppid ) export -f monitor Run a test command: monitor ffmpeg -y -hide_banner -i /dev/video0 -c:v h264_omx -t 10 test.mp4 and the result: CPU MEM Bug: No output value Surprisingly, there is no output for CPU and MEM usage reported in the output. Search on google, there is a glue of missing data when using grep in a pipeline. Line buffered mode # When using pipeline of commands, there is pipeline buffer between them. The output from grep is no longer line buffered, but block buffered, usually the block is 4 KB, leading to the problem that the next awk command cannot see new data immediately on its input. Notes from manuals: --line-buffered in grep manual Use line buffering on output. This can cause a performance penalty. -W interactive in awk manual Set non-buffered writes to stdout and line buffered reads from stdin. Records from stdin are lines regardless of the value of RS. Combining them together and testing again: monitor.sh #!/bin/bash monitor () ( # run process in background $* & # get PID of last job in background pid = $! # use top to monitor the process # use grep to catch useful lines, use line buffered mode # use awk to extract data column, read input in line buffered mode top -b -d 1 -p $pid | grep --line-buffered $pid | awk -W interactive '{print $9, $10}' & # save top PID to control it toppid = $! echo 'CPU MEM' # check if a process is running while [ -e /proc/ $pid ] do sleep 1 done # kill top sleep 1 kill -9 $toppid ) export -f monitor Run a test: monitor ffmpeg -y -hide_banner -i /dev/video0 -c:v h264_omx -t 10 test.mp4 and the result comes with expected values: CPU MEM 20.0 0.8 21.0 3.5 67.3 5.1 89.1 6.0 77.2 9.4 Save log with tee # Use tee to read from the standard input and write to the standard output and a file. That is simple enough to clone the output to a log file: $* | tee log.txt & top -b -d 1 -p $pid | grep --line-buffered $pid | awk -W interactive '{print $9, $10}' | tee usage.txt & Then modify the script: monitor.sh #!/bin/bash monitor () ( # run process in background $* | tee log.txt & # get PID of last job in background pid = $! # use top to monitor the process # use grep to catch useful lines, use line buffered mode # use awk to extract data columns, read input in line buffered mode top -b -d 1 -p $pid | grep --line-buffered $pid | awk -W interactive '{print $9, $10}' | tee usage.txt & # save top PID to control it toppid = $! echo 'CPU MEM' # check if a process is running while [ -e /proc/ $pid ] do sleep 1 done # kill top sleep 1 kill -9 $toppid ) export -f monitor Run a test: monitor ffmpeg -y -hide_banner -i /dev/video0 -c:v h264_omx -t 10 test.mp4 Bug: Empty log and invalid output After using tee , there are twp issues happened: an empty log.txt file the usage.txt content is invalid Fix empty log # When making pipeline to tee , only the STDOUT (1) is forwarded, while ffmpeg prints output on the STDERR (2) not on the STDOUT (1). Fix it by redirect ffmpeg STDERR to STDOUT: $* 2 > & 1 | tee log.txt & Fix wrong data # Add some debug lines ps -p $pid to check the process ID after creating the processes: monitor.sh #!/bin/bash monitor () ( # run process in background $* | tee log.txt & # get PID of last job in background pid = $! ps -p $pid # use top to monitor the process # use grep to catch useful lines, use line buffered mode # use awk to extract data columns, read input in line buffered mode top -b -d 1 -p $pid | grep --line-buffered $pid | awk -W interactive '{print $9, $10}' | tee > usage.txt & # save top PID to control it toppid = $! ps -p $toppid echo 'CPU MEM' # check if a process is running while [ -e /proc/ $pid ] do sleep 1 done # kill top sleep 1 kill -9 $toppid ) export -f monitor Then, it prints out the PID of tee , not the PID of ffmpeg or top . PID TTY TIME CMD 647 pts/0 00:00:00 tee PID TTY TIME CMD 652 pts/0 00:00:00 tee Get PID of a process in pipeline In bash, pipeline cause commands to run in a sub-shell! For example, $* | tee > log.txt & will run $* in a sub-shell, and tee > log.txt will run in current shell, therefore tee\u2019s PID will be saved in the macro $! . The solution is to save the PID in the newly created sub-shell in which $! returns correct PID, then load that PID later: # save to pid.txt ( $* 2 > & 1 & echo $! > pid.txt ) | tee > log.txt & # load from pid.txt pid = $( <pid.txt ) Then modify the script: monitor.sh #!/bin/bash monitor () ( # run process in background ( $* 2 > & 1 & echo $! > pid.txt ) | tee log.txt & # get PID of last job in background pid = $( <pid.txt ) ps -p $pid # use top to monitor the process # use grep to catch useful lines, use line buffered mode # use awk to extract data columns, read input in line buffered mode ( top -b -d 1 -p $pid & echo $! > pid.txt ) | grep --line-buffered $pid | awk -W interactive '{print $9, $10}' | tee usage.txt & # save top PID to control it toppid = $( <pid.txt ) ps -p $toppid echo 'CPU MEM' # check if a process is running while [ -e /proc/ $pid ] do sleep 1 done # kill top sleep 1 kill -9 $toppid # clean up rm pid.txt ) export -f monitor Run a test: monitor ffmpeg -y -hide_banner -i /dev/video0 -c:v h264_omx -t 10 test.mp4 and got correct PIDs for ffmpeg and top : PID TTY TIME CMD 2352 pts/0 00:00:00 ffmpeg PID TTY TIME CMD 2360 pts/0 00:00:00 top Graph with gnuplot # Gnuplot is a portable command-line graph utility for Linux, OS/2, MS Windows, OSX, VMS, and many other platforms. It can produce many types of output, including terminal and file. Terminal output gnuplot -e \" \\ set term dumb; \\ plot \\ 'usage.txt' using 1 title '%CPU' with lines, \\ '' using 2 title 'MEM' with lines \\ \" PNG Image output gnuplot -e \" \\ set term png size 640, 480; \\ set output 'usage.png'; \\ set grid xtics lc rgb '#bbbbbb' lw 1 lt 1; \\ set grid ytics lc rgb '#bbbbbb' lw 1 lt 1; \\ plot \\ 'usage.txt' using 1 title '%CPU' with lines, \\ '' using 2 title 'MEM' with lines \\ \" Run a test: monitor \"test\" \"ffmpeg -y -hide_banner -i /dev/video0 -c:v h264_omx -t 10 test.mp4\" It prints out a good graph in the terminal as well as in a PNG image: .code-fit code { margin: auto !important; width: fit-content; } 100 +--------------------------------------------------------------------+ | *** + + + + + | 90 |-+ * %CPU ****** -| | ** MEM ###### | 80 |-+ +-| | * | 70 |-+ * +-| | * | 60 |-+ * +-| | * | 50 |-+ * +-| | * | 40 |-+ * +-| | * | 30 |-+ #########################################################| | # * | 20 |-+ ## * +-| | # ****** ************************* | 10 |-+ # ********* ******| |###### + + + + + | 0 +--------------------------------------------------------------------+ 0 2 4 6 8 10 12 Resource Usage Some enhancements # Some small modifications to make script run in multiple sessions: 1. Set title for a new session Let\u2019s modify the script to accept parameters in this format: monitor \"title\" command by extracting those parameters at the beginning of the script: monitor () ( # extract parameters title = $1 command = ${ @: 2 } # get parameters from the 2nd one ... ) The title will be used to name the session, to create a folder to save log files. 2. Save output to a separated folder # create result folder if not existed [ ! -d $title ] && mkdir $title 3. Change output format to CPU= X MEM= Y It needs to change the data column index in gnuplot : # *-usage.txt content: # CPU= X MEM= Y # X is at 2nd column, # Y is at 4th column gnuplot -e \" \\ set term dumb; \\ plot \\ ' ${ title } / ${ title } -usage.txt' using 2 title '%CPU' with lines, \\ '' using 4 title 'MEM' with lines \\ \" The final script # Download monitor.sh then save to ~/monitor.sh . Add below line to ~/.bashrc : source monitor.sh Usage: monitor \"title\" program parameters","title":"Monitor the Resource Usage of a Process"},{"location":"blog/pi/resource-usage/#export-a-function-in-bash","text":"In a bash file, a function with a name and its body can be defined and then exported with export -f command: myfunc.sh #!/bin/bash myfunc () { echo \"parameters: $@ \" } export -f myfunc To make function available outside the script, run source command before calling the function: source myfunc.sh myfunc abc All parameters are implicit saved into local macros. Refer to Advanced Bash-Scripting Guide : Macro Description $BASHPID Process ID of the current instance of Bash. This is not the same as the $$ variable, but it often gives the same result. $PPID Process ID of the parent process $$ Process ID of the script itself $! Process ID of last job run in background $PWD The current directory that process is in at the time $SECONDS The number of seconds the script has been running $1 , $2 , $n The first, the second and the n-th parameter $# The number of command-line arguments $* All the positional parameters, seen as a single word, must be quoted $@ Same as $* , but each parameter is a quoted string, that is, the parameters are passed on intact, without interpretation or expansion. This means, among other things, that each parameter in the argument list is seen as a separate word $? Exit status of a command, function, or the script itself","title":"Export a function in bash"},{"location":"blog/pi/resource-usage/#command-grouping","text":"Refer to Bash Manual \u2014 Command Grouping . Bash provides two ways to group a list of commands to be executed as a unit. When commands are grouped, re-directions may be applied to the entire command list. ( list ) Placing a list of commands between parentheses causes a sub-shell environment to be created (see Command Execution Environment ), and each of the commands in list to be executed in that sub-shell. Since the list is executed in a sub-shell, variable assignments do not remain in effect after the sub-shell completes. { list; } Placing a list of commands between curly braces causes the list to be executed in the current shell context. No sub-shell is created. The semicolon (or newline) following list is required. In addition to the creation of a sub-shell, there is a subtle difference between these two constructs due to historical reasons: The braces are reserved words, so they must be separated from the list by blanks or other shell meta-characters The parentheses are operators, and are recognized as separate tokens by the shell even if they are not separated from the list by whitespace","title":"Command-Grouping"},{"location":"blog/pi/resource-usage/#run-a-process","text":"The basic idea is to run a process in background and while it\u2019s running, report its resource usage: monitor.sh #!/bin/bash monitor () ( # run process in background echo \"Executing $* \" $* & # get PID of last job in background pid = $! echo \"Executed in PID: $pid \" ps --no-headers -p $pid echo 'CPU MEM' # check if a process is running while [ -e /proc/ $pid ] do # use ps to get cpu and memory usage ps --no-headers -o '%cpu,%mem' -p $pid sleep 1 done ) export -f monitor","title":"Run a process"},{"location":"blog/pi/resource-usage/#ps-or-top","text":"Both ps and top report CPU Usage, but the returned values are different. Let\u2019s check the manual of each command: ps CPU usage is currently expressed as the percentage of time spent running during the entire lifetime of a process. This is not ideal, and it does not conform to the standards that ps otherwise conforms to. CPU usage is unlikely to add up to exactly 100%. It means ps does not show the instant CPU usage, it shows an average CPU usage over the lifetime of the process. top %CPU \u2013 CPU Usage, The task\u2019s share of the elapsed CPU time since the last screen update, expressed as a percentage of total CPU time. It means if interval is 1 second, top will report CPU usage for the last 1 second. That can be considered as instant report. Let\u2019s check top \u2018s options -b : Batch-mode operation Starts top in Batch mode, which could be useful for sending output from top to other programs or to a file. In this mode, top will not accept input and runs until the iterations limit set with the `-n\u2019 command-line option or until killed. -d : Delay-time interval as: -d ss.t (secs.tenths) Specifies the delay between screen updates, and overrides the corresponding value in one\u2019s personal configuration file or the startup default. Later this can be changed with the d or s interactive commands. -p : Monitor-PIDs mode as: -pN1 -pN2 ... or -pN1,N2,N3 ... Monitor only processes with specified process IDs. Switch to use top get the process information: monitor.sh #!/bin/bash monitor () ( # run process in background $* & # get PID of last job in background pid = $! # use top to monitor the process top -b -d 1 -p $pid & # save top PID to control it toppid = $! echo 'CPU MEM' # check if a process is running while [ -e /proc/ $pid ] do sleep 1 done # kill top sleep 1 kill -9 $toppid ) export -f monitor Run a test: monitor ffmpeg -y -hide_banner -i /dev/video0 -c:v h264_omx -t 10 test.mp4 and the result: PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 2286 pi 20 0 336612 129848 121960 R 34.5 52.5 0:03.36 ffmpeg","title":"ps or top"},{"location":"blog/pi/resource-usage/#grep-and-awk","text":"Refer to grep manual Use grep to extract process information lines using pid number as the keyword: top -b -d 1 -p $pid | grep $pid & Refer to awk manual Use awk to cut out 2 columns: %CPU and %MEM (at the 9 th and 10 th column) from the filtered lines: top -b -d 1 -p $pid | grep $pid | awk '{print $9, $10}' & So, this is a modified version: monitor.sh #!/bin/bash monitor () ( # run process in background $* & # get PID of last job in background pid = $! # use top to monitor the process # use grep to catch useful lines # use awk to extract data columns top -b -d 1 -p $pid | grep $pid | awk '{print $9, $10}' & # save top PID to control it toppid = $! echo 'CPU MEM' # check if a process is running while [ -e /proc/ $pid ] do sleep 1 done # kill top sleep 1 kill -9 $toppid ) export -f monitor Run a test command: monitor ffmpeg -y -hide_banner -i /dev/video0 -c:v h264_omx -t 10 test.mp4 and the result: CPU MEM Bug: No output value Surprisingly, there is no output for CPU and MEM usage reported in the output. Search on google, there is a glue of missing data when using grep in a pipeline.","title":"grep and awk"},{"location":"blog/pi/resource-usage/#line-buffered-mode","text":"When using pipeline of commands, there is pipeline buffer between them. The output from grep is no longer line buffered, but block buffered, usually the block is 4 KB, leading to the problem that the next awk command cannot see new data immediately on its input. Notes from manuals: --line-buffered in grep manual Use line buffering on output. This can cause a performance penalty. -W interactive in awk manual Set non-buffered writes to stdout and line buffered reads from stdin. Records from stdin are lines regardless of the value of RS. Combining them together and testing again: monitor.sh #!/bin/bash monitor () ( # run process in background $* & # get PID of last job in background pid = $! # use top to monitor the process # use grep to catch useful lines, use line buffered mode # use awk to extract data column, read input in line buffered mode top -b -d 1 -p $pid | grep --line-buffered $pid | awk -W interactive '{print $9, $10}' & # save top PID to control it toppid = $! echo 'CPU MEM' # check if a process is running while [ -e /proc/ $pid ] do sleep 1 done # kill top sleep 1 kill -9 $toppid ) export -f monitor Run a test: monitor ffmpeg -y -hide_banner -i /dev/video0 -c:v h264_omx -t 10 test.mp4 and the result comes with expected values: CPU MEM 20.0 0.8 21.0 3.5 67.3 5.1 89.1 6.0 77.2 9.4","title":"Line buffered mode"},{"location":"blog/pi/resource-usage/#save-log-with-tee","text":"Use tee to read from the standard input and write to the standard output and a file. That is simple enough to clone the output to a log file: $* | tee log.txt & top -b -d 1 -p $pid | grep --line-buffered $pid | awk -W interactive '{print $9, $10}' | tee usage.txt & Then modify the script: monitor.sh #!/bin/bash monitor () ( # run process in background $* | tee log.txt & # get PID of last job in background pid = $! # use top to monitor the process # use grep to catch useful lines, use line buffered mode # use awk to extract data columns, read input in line buffered mode top -b -d 1 -p $pid | grep --line-buffered $pid | awk -W interactive '{print $9, $10}' | tee usage.txt & # save top PID to control it toppid = $! echo 'CPU MEM' # check if a process is running while [ -e /proc/ $pid ] do sleep 1 done # kill top sleep 1 kill -9 $toppid ) export -f monitor Run a test: monitor ffmpeg -y -hide_banner -i /dev/video0 -c:v h264_omx -t 10 test.mp4 Bug: Empty log and invalid output After using tee , there are twp issues happened: an empty log.txt file the usage.txt content is invalid","title":"Save log with tee"},{"location":"blog/pi/resource-usage/#fix-empty-log","text":"When making pipeline to tee , only the STDOUT (1) is forwarded, while ffmpeg prints output on the STDERR (2) not on the STDOUT (1). Fix it by redirect ffmpeg STDERR to STDOUT: $* 2 > & 1 | tee log.txt &","title":"Fix empty log"},{"location":"blog/pi/resource-usage/#fix-wrong-data","text":"Add some debug lines ps -p $pid to check the process ID after creating the processes: monitor.sh #!/bin/bash monitor () ( # run process in background $* | tee log.txt & # get PID of last job in background pid = $! ps -p $pid # use top to monitor the process # use grep to catch useful lines, use line buffered mode # use awk to extract data columns, read input in line buffered mode top -b -d 1 -p $pid | grep --line-buffered $pid | awk -W interactive '{print $9, $10}' | tee > usage.txt & # save top PID to control it toppid = $! ps -p $toppid echo 'CPU MEM' # check if a process is running while [ -e /proc/ $pid ] do sleep 1 done # kill top sleep 1 kill -9 $toppid ) export -f monitor Then, it prints out the PID of tee , not the PID of ffmpeg or top . PID TTY TIME CMD 647 pts/0 00:00:00 tee PID TTY TIME CMD 652 pts/0 00:00:00 tee Get PID of a process in pipeline In bash, pipeline cause commands to run in a sub-shell! For example, $* | tee > log.txt & will run $* in a sub-shell, and tee > log.txt will run in current shell, therefore tee\u2019s PID will be saved in the macro $! . The solution is to save the PID in the newly created sub-shell in which $! returns correct PID, then load that PID later: # save to pid.txt ( $* 2 > & 1 & echo $! > pid.txt ) | tee > log.txt & # load from pid.txt pid = $( <pid.txt ) Then modify the script: monitor.sh #!/bin/bash monitor () ( # run process in background ( $* 2 > & 1 & echo $! > pid.txt ) | tee log.txt & # get PID of last job in background pid = $( <pid.txt ) ps -p $pid # use top to monitor the process # use grep to catch useful lines, use line buffered mode # use awk to extract data columns, read input in line buffered mode ( top -b -d 1 -p $pid & echo $! > pid.txt ) | grep --line-buffered $pid | awk -W interactive '{print $9, $10}' | tee usage.txt & # save top PID to control it toppid = $( <pid.txt ) ps -p $toppid echo 'CPU MEM' # check if a process is running while [ -e /proc/ $pid ] do sleep 1 done # kill top sleep 1 kill -9 $toppid # clean up rm pid.txt ) export -f monitor Run a test: monitor ffmpeg -y -hide_banner -i /dev/video0 -c:v h264_omx -t 10 test.mp4 and got correct PIDs for ffmpeg and top : PID TTY TIME CMD 2352 pts/0 00:00:00 ffmpeg PID TTY TIME CMD 2360 pts/0 00:00:00 top","title":"Fix wrong data"},{"location":"blog/pi/resource-usage/#graph-with-gnuplot","text":"Gnuplot is a portable command-line graph utility for Linux, OS/2, MS Windows, OSX, VMS, and many other platforms. It can produce many types of output, including terminal and file. Terminal output gnuplot -e \" \\ set term dumb; \\ plot \\ 'usage.txt' using 1 title '%CPU' with lines, \\ '' using 2 title 'MEM' with lines \\ \" PNG Image output gnuplot -e \" \\ set term png size 640, 480; \\ set output 'usage.png'; \\ set grid xtics lc rgb '#bbbbbb' lw 1 lt 1; \\ set grid ytics lc rgb '#bbbbbb' lw 1 lt 1; \\ plot \\ 'usage.txt' using 1 title '%CPU' with lines, \\ '' using 2 title 'MEM' with lines \\ \" Run a test: monitor \"test\" \"ffmpeg -y -hide_banner -i /dev/video0 -c:v h264_omx -t 10 test.mp4\" It prints out a good graph in the terminal as well as in a PNG image: .code-fit code { margin: auto !important; width: fit-content; } 100 +--------------------------------------------------------------------+ | *** + + + + + | 90 |-+ * %CPU ****** -| | ** MEM ###### | 80 |-+ +-| | * | 70 |-+ * +-| | * | 60 |-+ * +-| | * | 50 |-+ * +-| | * | 40 |-+ * +-| | * | 30 |-+ #########################################################| | # * | 20 |-+ ## * +-| | # ****** ************************* | 10 |-+ # ********* ******| |###### + + + + + | 0 +--------------------------------------------------------------------+ 0 2 4 6 8 10 12 Resource Usage","title":"Graph with gnuplot"},{"location":"blog/pi/resource-usage/#some-enhancements","text":"Some small modifications to make script run in multiple sessions: 1. Set title for a new session Let\u2019s modify the script to accept parameters in this format: monitor \"title\" command by extracting those parameters at the beginning of the script: monitor () ( # extract parameters title = $1 command = ${ @: 2 } # get parameters from the 2nd one ... ) The title will be used to name the session, to create a folder to save log files. 2. Save output to a separated folder # create result folder if not existed [ ! -d $title ] && mkdir $title 3. Change output format to CPU= X MEM= Y It needs to change the data column index in gnuplot : # *-usage.txt content: # CPU= X MEM= Y # X is at 2nd column, # Y is at 4th column gnuplot -e \" \\ set term dumb; \\ plot \\ ' ${ title } / ${ title } -usage.txt' using 2 title '%CPU' with lines, \\ '' using 4 title 'MEM' with lines \\ \"","title":"Some enhancements"},{"location":"blog/pi/resource-usage/#the-final-script","text":"Download monitor.sh then save to ~/monitor.sh . Add below line to ~/.bashrc : source monitor.sh Usage: monitor \"title\" program parameters","title":"The final script"},{"location":"blog/pi/set-up-camera/","tags":["raspberry-pi","camera","v4l2","ffmpeg","picamera"],"text":"Raspberry Pi Camera Module This tutorial is for setting up the official Raspberry Pi Camera module which is attached with a CSI cable. Other types of USB Camera should work on Pi out-of-the-box. Enable Camera module # Run raspi-config configuration tool, Then select Interfacing Options \u2192 Camera then select Yes : sudo raspi-config This method will automatically set start_x=1 in /boot/config.txt file. Increase GPU memory # Some video encoders need a big buffer to process video encoding or decoding. To increase the memory reserved for video processor, in the raspi-config configuration tool, go to Performance Options \u2192 GPU Memory then fill in 256 and select OK . This method does the same thing with setting up gpu_mem=256 in /boot/config.txt . Test Camera # Detect the camera connection by running the checking tool: vcgencmd get_camera Which should print out supported=1 detected=1 telling that the camera is supported and connected. vcgencmd is a command line utility that can get various pieces of information from the VideoCore GPU on the Raspberry Pi. Check more detail in Raspberry Pi/vcgencmd Raspicam commands has a set of tools to work with the camera module: raspistill , raspivid , and raspiyuv . Capture an image: raspistill -o cam.jpg Record a video: raspivid -o vid.h264 Video for Linux 2 \u2014 V4L2 # Under Linux, the standard APIs for cameras (including webcams) is V4L (Video for Linux), and a number of applications have been written that support any camera with a V4L driver. An independent developer has now written a user space V4L driver for the Raspberry Pi camera, but it is closed sourced, and can be a little slow because it runs as a user program rather than a kernel driver. Recognizing that a V4L driver is needed, the Raspberry Pi Foundation reported that they were working with Broadcom to develop an official kernel V4L driver. As a kernel driver, it should be faster than the user space driver. Finally, V4L2 was released under the name bcm2835-v4l2 which is included Raspberry Pi OS by default. Use v4l2-ctl utility tool to capture from the camera. List devices # v4l2-ctl --list-devices bcm2835-codec-decode (platform:bcm2835-codec): /dev/video10 /dev/video11 /dev/video12 bcm2835-isp (platform:bcm2835-isp): /dev/video13 /dev/video14 /dev/video15 /dev/video16 mmal service 16.1 (platform:bcm2835-v4l2): /dev/video0 Driver info # v4l2-ctl -d /dev/video0 --all Driver Info: Driver name : bm2835 mmal Card type : mmal service 16.1 Bus info : platform:bcm2835-v4l2 Driver version : 5.4.79 Capabilities : 0x85200005 Video Capture Video Overlay Read/Write Streaming ... Supported formats # v4l2-ctl --list-formats ioctl: VIDIOC_ENUM_FMT Type: Video Capture [0]: 'YU12' (Planar YUV 4:2:0) [1]: 'YUYV' (YUYV 4:2:2) [2]: 'RGB3' (24-bit RGB 8-8-8) [3]: 'JPEG' (JFIF JPEG, compressed) [4]: 'H264' (H.264, compressed) [5]: 'MJPG' (Motion-JPEG, compressed) [6]: 'YVYU' (YVYU 4:2:2) [7]: 'VYUY' (VYUY 4:2:2) [8]: 'UYVY' (UYVY 4:2:2) [9]: 'NV12' (Y/CbCr 4:2:0) [10]: 'BGR3' (24-bit BGR 8-8-8) [11]: 'YV12' (Planar YVU 4:2:0) [12]: 'NV21' (Y/CrCb 4:2:0) [13]: 'RX24' (32-bit XBGR 8-8-8-8) Please take a note for RGB3 , JPEG , H264 , and MJPEG , which can be used in OpenCV, or streaming directly. Capture JPEG Image # v4l2-ctl --set-fmt-video = width = 2592 ,height = 1944 ,pixelformat = 3 && \\ v4l2-ctl --stream-mmap = 3 --stream-count = 1 --stream-to = somefile.jpg Record H264 Video # Note the value of height is 1088 not 1080 . v4l2-ctl --set-fmt-video = width = 1920 ,height = 1088 ,pixelformat = 4 && \\ v4l2-ctl --stream-mmap = 3 --stream-count = 100 --stream-to = somefile.264 FFmpeg # The pre-built ffmpeg package of Pi already enables hardware accelerator support, with OpenMAX IL H.264 video encoder ( h264_omx ). sudo apt install -y ffmpeg An FFmpeg version with a specific library can be built by following this topic Compile FFmpeg with Hardware Accelerator . Encoders # To see all available encoders: ffmpeg -encoders If interested in h264 and mjpeg , use grep to search for the specific encoders: ffmpeg -hide_banner -encoders | grep -E \"h264|mjpeg\" V..... libx264 libx264 H.264 / AVC / MPEG-4 AVC / MPEG-4 part 10 (codec h264) V..... libx264rgb libx264 H.264 / AVC / MPEG-4 AVC / MPEG-4 part 10 RGB (codec h264) V..... h264_omx OpenMAX IL H.264 video encoder (codec h264) V..... h264_v4l2m2m V4L2 mem2mem H.264 encoder wrapper (codec h264) VFS... mjpeg MJPEG (Motion JPEG) Check encoder options Before using an encoder, check its options by help command in ffmpeg . ffmpeg -h encoder = <format> Here is the list of formats supported by OpenMAX IL H.264 video encoder (h264_omx): ffmpeg -h encoder = h264_omx Encoder h264_omx [OpenMAX IL H.264 video encoder]: General capabilities: delay Threading capabilities: none Supported pixel formats: yuv420p h264_omx AVOptions: -omx_libname <string> ED.V...... OpenMAX library name -omx_libprefix <string> ED.V...... OpenMAX library prefix -zerocopy <int> E..V...... Avoid copying input frames if possible (0 or 1) (default 1) -profile <int> E..V...... Set the encoding profile (from -99 to 100) (default -99) baseline 66 E..V...... main 77 E..V...... high 100 E..V...... Performance # Next, try to record some short video (60 seconds) with H264 format using different encoders. To measure the performance, use a small tool to check CPU and Memory Usage in monitor \u2014 Script to check performance . Video settings All tests below use the same video settings: Video side: 1024x768 Frame rate: 30 fps Input Length: 60 seconds Note that ffmpeg will use v4l2 driver if user does not specify the driver! Raw to MJPEG (.avi) # ffmpeg -y -hide_banner \\ -use_wallclock_as_timestamps 1 \\ -t 60 \\ -i /dev/video0 \\ -c:v mjpeg \\ raw_mjpeg.avi Performance : Total time: 63 seconds Average %CPU: 93 (too high) Average %MEM: 31 Input FPS: 4.8 (dropped input) Output FPS: 30 Quality : Format: JPEG Codec ID: MJPG Bit rate: 839 kb/s Raw to MJPEG Raw to H264_OMX @8Mbps (.mp4) # ffmpeg -y -hide_banner \\ -use_wallclock_as_timestamps 1 \\ -t 60 \\ -i /dev/video0 \\ -c:v h264_omx \\ -b:v 8M \\ raw_h264omx.mp4 Performance : Total time: 63 seconds Average %CPU: 16 (OK) Average %MEM: 27 Input FPS: 30 Output FPS: 30 Quality : Format: AVC (GOP: M=1, N=12) Codec ID: avc1 Bit rate: 2 877 kb/s Raw to H264_OMX @8Mbps Raw to H264_V4L2M2M @8Mbps (.mp4) # ffmpeg -y -hide_banner \\ -use_wallclock_as_timestamps 1 \\ -t 60 \\ -i /dev/video0 \\ -c:v h264_v4l2m2m \\ -b:v 8M \\ raw_h264v4l2m2m.mp4 Performance : Total time: 62 seconds Average %CPU: 23 Average %MEM: 27 Input FPS: 30 Output FPS: 30 Quality : Format: AVC (GPO: M=1, N=60) Codec ID: avc1 Bit rate: 1 783 kb/s Raw to H264_V4L2M2M @8Mbps V4L2 MJPEG direct copy (.avi) # ffmpeg -y -hide_banner \\ -use_wallclock_as_timestamps 1 \\ -t 60 \\ -input_format mjpeg \\ -i /dev/video0 \\ -c:v copy \\ -t 60 \\ mjpeg_avi.avi Performance : Total time: 67 seconds Average %CPU: 10 (Good) Average %MEM: 21 Input FPS: 30 Output FPS: 30 Quality : Format: JPEG Codec ID: MJPG Bit rate: 10.2 Mb/s (very high bandwidth) Save V4L2 MJPEG stream V4L2 H264 direct copy (.mp4) # ffmpeg -y -hide_banner \\ -use_wallclock_as_timestamps 1 \\ -t 60 \\ -input_format h264 \\ -i /dev/video0 \\ -c:v copy \\ -t 60 \\ h264_mp4.mp4 Performance : Total time: 67 seconds Average %CPU: 10 (Good) Average %MEM: 24 Input FPS: 30 Output FPS: 30 Quality : Format: AVC (GPO: M=1, N=60) Codec ID: avc1 Bit rate: 5 506 kb/s (OK) Save V4L2 H264 stream Conclusion # After above tests, it can be said that using compressed input format from v4l2 is much more effective than compressing by a software encoder. Let\u2019s add some timestamp to video by using drawtext filter with built-in expandable localtime variable in Text-expansion option . ffmpeg -y -hide_banner \\ -use_wallclock_as_timestamps 1 \\ -t 10 \\ -i /dev/video0 \\ -vf \"drawtext=text='%{localtime}':fontcolor=white:x=100:y=100\" \\ -c:v h264_omx \\ -b:v 8M \\ raw_h264omx_text.mp4 Filter and stream-copy cannot be used together Text needs inserted and each frame needs re-encoded, therefore, stream-copy is unavailable. # this will not work ffmpeg -y -hide_banner \\ -use_wallclock_as_timestamps 1 \\ -t 10 \\ -input_format h264 \\ -i /dev/video0 \\ -vf \"drawtext=text='%{localtime}':fontcolor=white:x=100:y=100\" \\ -c:v copy \\ -t 10 \\ h264_mp4_text.mp4 PiCamera # The PiCamera package is a pure Python interface to the Raspberry Pi camera module for Python language. If using the Raspbian distro, probably it has picamera installed by default. Run a test to check it is installed or not: python -c \"import picamera\" python3 -c \"import picamera\" If no module found, install picamera from the system\u2019s package manager: sudo apt install -y python-picamera python3-picamera There are a lot of examples in the official guide . Here are some starting points: Get maximum resolution of the camera import picamera with picamera . PiCamera () as cam : print ( cam . MAX_RESOLUTION ) Take a snapshot from time import sleep from picamera import PiCamera # setup a camera camera = PiCamera () camera . resolution = ( 1024 , 768 ) # camera warm-up time sleep ( 2 ) # capture an image camera . capture ( 'snapshot.jpg' ) Now, for the testing purpose, let\u2019s record a 60-second video from the camera and measure the resource usage with monitor , then use ffmpeg to convert raw h264 to mp4: PiCamera H264 (.h264) # Record a raw H264 video file from picamera import PiCamera # setup a camera camera = PiCamera () camera . resolution = ( 1024 , 768 ) camera . framerate = 30 # record a video camera . start_recording ( 'picamera.h264' ) camera . wait_recording ( 60 ) camera . stop_recording () Convert to MP4 video file ffmpeg -i picamera.h264 \\ -c:v copy picamera.mp4 Performance: Total time: 61 seconds Average CPU: 11 (Good) Average MEM: 5 (Good) Input FPS: 30 Output FPS: 25 Quality: Format: AVC (GPO: M=1, N=60) Codec ID: avc1 Bit rate: 3 302 kb/s (Good) PiCamera Picamera H264 (.h264) with Text overlay # Now, try to detect how picamera can draw text on output video. Here is the test code: from picamera import PiCamera import datetime TIMEFMT = '%Y-%m- %d %H:%M:%S. %f ' # setup a camera camera = PiCamera () camera . resolution = ( 1024 , 768 ) camera . annotate_text = datetime . datetime . now () . strftime ( TIMEFMT ) # record a video camera . start_recording ( 'picamera_text.h264' ) start = datetime . datetime . now () while ( datetime . datetime . now () - start ) . seconds < 60 : camera . annotate_text = datetime . datetime . now () . strftime ( TIMEFMT ) camera . wait_recording ( 0.04 ) # 25fps # stop it camera . stop_recording () Using picamera shows an impressive %CPU and %MEM usage, comparing to using FFmpeg. The result shows that the %CPU uses twice as much as it does in non-overlay text, while the %MEM keeps the same percentage.","title":"Set up Camera and test Video Encoders' Performance"},{"location":"blog/pi/set-up-camera/#enable-camera-module","text":"Run raspi-config configuration tool, Then select Interfacing Options \u2192 Camera then select Yes : sudo raspi-config This method will automatically set start_x=1 in /boot/config.txt file.","title":"Enable Camera module"},{"location":"blog/pi/set-up-camera/#increase-gpu-memory","text":"Some video encoders need a big buffer to process video encoding or decoding. To increase the memory reserved for video processor, in the raspi-config configuration tool, go to Performance Options \u2192 GPU Memory then fill in 256 and select OK . This method does the same thing with setting up gpu_mem=256 in /boot/config.txt .","title":"Increase GPU memory"},{"location":"blog/pi/set-up-camera/#test-camera","text":"Detect the camera connection by running the checking tool: vcgencmd get_camera Which should print out supported=1 detected=1 telling that the camera is supported and connected. vcgencmd is a command line utility that can get various pieces of information from the VideoCore GPU on the Raspberry Pi. Check more detail in Raspberry Pi/vcgencmd Raspicam commands has a set of tools to work with the camera module: raspistill , raspivid , and raspiyuv . Capture an image: raspistill -o cam.jpg Record a video: raspivid -o vid.h264","title":"Test Camera"},{"location":"blog/pi/set-up-camera/#video-for-linux-2--v4l2","text":"Under Linux, the standard APIs for cameras (including webcams) is V4L (Video for Linux), and a number of applications have been written that support any camera with a V4L driver. An independent developer has now written a user space V4L driver for the Raspberry Pi camera, but it is closed sourced, and can be a little slow because it runs as a user program rather than a kernel driver. Recognizing that a V4L driver is needed, the Raspberry Pi Foundation reported that they were working with Broadcom to develop an official kernel V4L driver. As a kernel driver, it should be faster than the user space driver. Finally, V4L2 was released under the name bcm2835-v4l2 which is included Raspberry Pi OS by default. Use v4l2-ctl utility tool to capture from the camera.","title":"Video for Linux 2 \u2014 V4L2"},{"location":"blog/pi/set-up-camera/#list-devices","text":"v4l2-ctl --list-devices bcm2835-codec-decode (platform:bcm2835-codec): /dev/video10 /dev/video11 /dev/video12 bcm2835-isp (platform:bcm2835-isp): /dev/video13 /dev/video14 /dev/video15 /dev/video16 mmal service 16.1 (platform:bcm2835-v4l2): /dev/video0","title":"List devices"},{"location":"blog/pi/set-up-camera/#driver-info","text":"v4l2-ctl -d /dev/video0 --all Driver Info: Driver name : bm2835 mmal Card type : mmal service 16.1 Bus info : platform:bcm2835-v4l2 Driver version : 5.4.79 Capabilities : 0x85200005 Video Capture Video Overlay Read/Write Streaming ...","title":"Driver info"},{"location":"blog/pi/set-up-camera/#supported-formats","text":"v4l2-ctl --list-formats ioctl: VIDIOC_ENUM_FMT Type: Video Capture [0]: 'YU12' (Planar YUV 4:2:0) [1]: 'YUYV' (YUYV 4:2:2) [2]: 'RGB3' (24-bit RGB 8-8-8) [3]: 'JPEG' (JFIF JPEG, compressed) [4]: 'H264' (H.264, compressed) [5]: 'MJPG' (Motion-JPEG, compressed) [6]: 'YVYU' (YVYU 4:2:2) [7]: 'VYUY' (VYUY 4:2:2) [8]: 'UYVY' (UYVY 4:2:2) [9]: 'NV12' (Y/CbCr 4:2:0) [10]: 'BGR3' (24-bit BGR 8-8-8) [11]: 'YV12' (Planar YVU 4:2:0) [12]: 'NV21' (Y/CrCb 4:2:0) [13]: 'RX24' (32-bit XBGR 8-8-8-8) Please take a note for RGB3 , JPEG , H264 , and MJPEG , which can be used in OpenCV, or streaming directly.","title":"Supported formats"},{"location":"blog/pi/set-up-camera/#capture-jpeg-image","text":"v4l2-ctl --set-fmt-video = width = 2592 ,height = 1944 ,pixelformat = 3 && \\ v4l2-ctl --stream-mmap = 3 --stream-count = 1 --stream-to = somefile.jpg","title":"Capture JPEG Image"},{"location":"blog/pi/set-up-camera/#record-h264-video","text":"Note the value of height is 1088 not 1080 . v4l2-ctl --set-fmt-video = width = 1920 ,height = 1088 ,pixelformat = 4 && \\ v4l2-ctl --stream-mmap = 3 --stream-count = 100 --stream-to = somefile.264","title":"Record H264 Video"},{"location":"blog/pi/set-up-camera/#ffmpeg","text":"The pre-built ffmpeg package of Pi already enables hardware accelerator support, with OpenMAX IL H.264 video encoder ( h264_omx ). sudo apt install -y ffmpeg An FFmpeg version with a specific library can be built by following this topic Compile FFmpeg with Hardware Accelerator .","title":"FFmpeg"},{"location":"blog/pi/set-up-camera/#encoders","text":"To see all available encoders: ffmpeg -encoders If interested in h264 and mjpeg , use grep to search for the specific encoders: ffmpeg -hide_banner -encoders | grep -E \"h264|mjpeg\" V..... libx264 libx264 H.264 / AVC / MPEG-4 AVC / MPEG-4 part 10 (codec h264) V..... libx264rgb libx264 H.264 / AVC / MPEG-4 AVC / MPEG-4 part 10 RGB (codec h264) V..... h264_omx OpenMAX IL H.264 video encoder (codec h264) V..... h264_v4l2m2m V4L2 mem2mem H.264 encoder wrapper (codec h264) VFS... mjpeg MJPEG (Motion JPEG) Check encoder options Before using an encoder, check its options by help command in ffmpeg . ffmpeg -h encoder = <format> Here is the list of formats supported by OpenMAX IL H.264 video encoder (h264_omx): ffmpeg -h encoder = h264_omx Encoder h264_omx [OpenMAX IL H.264 video encoder]: General capabilities: delay Threading capabilities: none Supported pixel formats: yuv420p h264_omx AVOptions: -omx_libname <string> ED.V...... OpenMAX library name -omx_libprefix <string> ED.V...... OpenMAX library prefix -zerocopy <int> E..V...... Avoid copying input frames if possible (0 or 1) (default 1) -profile <int> E..V...... Set the encoding profile (from -99 to 100) (default -99) baseline 66 E..V...... main 77 E..V...... high 100 E..V......","title":"Encoders"},{"location":"blog/pi/set-up-camera/#performance","text":"Next, try to record some short video (60 seconds) with H264 format using different encoders. To measure the performance, use a small tool to check CPU and Memory Usage in monitor \u2014 Script to check performance . Video settings All tests below use the same video settings: Video side: 1024x768 Frame rate: 30 fps Input Length: 60 seconds Note that ffmpeg will use v4l2 driver if user does not specify the driver!","title":"Performance"},{"location":"blog/pi/set-up-camera/#raw-to-mjpeg-avi","text":"ffmpeg -y -hide_banner \\ -use_wallclock_as_timestamps 1 \\ -t 60 \\ -i /dev/video0 \\ -c:v mjpeg \\ raw_mjpeg.avi Performance : Total time: 63 seconds Average %CPU: 93 (too high) Average %MEM: 31 Input FPS: 4.8 (dropped input) Output FPS: 30 Quality : Format: JPEG Codec ID: MJPG Bit rate: 839 kb/s Raw to MJPEG","title":"Raw to MJPEG (.avi)"},{"location":"blog/pi/set-up-camera/#raw-to-h264_omx-8mbps-mp4","text":"ffmpeg -y -hide_banner \\ -use_wallclock_as_timestamps 1 \\ -t 60 \\ -i /dev/video0 \\ -c:v h264_omx \\ -b:v 8M \\ raw_h264omx.mp4 Performance : Total time: 63 seconds Average %CPU: 16 (OK) Average %MEM: 27 Input FPS: 30 Output FPS: 30 Quality : Format: AVC (GOP: M=1, N=12) Codec ID: avc1 Bit rate: 2 877 kb/s Raw to H264_OMX @8Mbps","title":"Raw to H264_OMX @8Mbps (.mp4)"},{"location":"blog/pi/set-up-camera/#raw-to-h264_v4l2m2m-8mbps-mp4","text":"ffmpeg -y -hide_banner \\ -use_wallclock_as_timestamps 1 \\ -t 60 \\ -i /dev/video0 \\ -c:v h264_v4l2m2m \\ -b:v 8M \\ raw_h264v4l2m2m.mp4 Performance : Total time: 62 seconds Average %CPU: 23 Average %MEM: 27 Input FPS: 30 Output FPS: 30 Quality : Format: AVC (GPO: M=1, N=60) Codec ID: avc1 Bit rate: 1 783 kb/s Raw to H264_V4L2M2M @8Mbps","title":"Raw to H264_V4L2M2M @8Mbps (.mp4)"},{"location":"blog/pi/set-up-camera/#v4l2-mjpeg-direct-copy-avi","text":"ffmpeg -y -hide_banner \\ -use_wallclock_as_timestamps 1 \\ -t 60 \\ -input_format mjpeg \\ -i /dev/video0 \\ -c:v copy \\ -t 60 \\ mjpeg_avi.avi Performance : Total time: 67 seconds Average %CPU: 10 (Good) Average %MEM: 21 Input FPS: 30 Output FPS: 30 Quality : Format: JPEG Codec ID: MJPG Bit rate: 10.2 Mb/s (very high bandwidth) Save V4L2 MJPEG stream","title":"V4L2 MJPEG direct copy (.avi)"},{"location":"blog/pi/set-up-camera/#v4l2-h264-direct-copy-mp4","text":"ffmpeg -y -hide_banner \\ -use_wallclock_as_timestamps 1 \\ -t 60 \\ -input_format h264 \\ -i /dev/video0 \\ -c:v copy \\ -t 60 \\ h264_mp4.mp4 Performance : Total time: 67 seconds Average %CPU: 10 (Good) Average %MEM: 24 Input FPS: 30 Output FPS: 30 Quality : Format: AVC (GPO: M=1, N=60) Codec ID: avc1 Bit rate: 5 506 kb/s (OK) Save V4L2 H264 stream","title":"V4L2 H264 direct copy (.mp4)"},{"location":"blog/pi/set-up-camera/#conclusion","text":"After above tests, it can be said that using compressed input format from v4l2 is much more effective than compressing by a software encoder. Let\u2019s add some timestamp to video by using drawtext filter with built-in expandable localtime variable in Text-expansion option . ffmpeg -y -hide_banner \\ -use_wallclock_as_timestamps 1 \\ -t 10 \\ -i /dev/video0 \\ -vf \"drawtext=text='%{localtime}':fontcolor=white:x=100:y=100\" \\ -c:v h264_omx \\ -b:v 8M \\ raw_h264omx_text.mp4 Filter and stream-copy cannot be used together Text needs inserted and each frame needs re-encoded, therefore, stream-copy is unavailable. # this will not work ffmpeg -y -hide_banner \\ -use_wallclock_as_timestamps 1 \\ -t 10 \\ -input_format h264 \\ -i /dev/video0 \\ -vf \"drawtext=text='%{localtime}':fontcolor=white:x=100:y=100\" \\ -c:v copy \\ -t 10 \\ h264_mp4_text.mp4","title":"Conclusion"},{"location":"blog/pi/set-up-camera/#picamera","text":"The PiCamera package is a pure Python interface to the Raspberry Pi camera module for Python language. If using the Raspbian distro, probably it has picamera installed by default. Run a test to check it is installed or not: python -c \"import picamera\" python3 -c \"import picamera\" If no module found, install picamera from the system\u2019s package manager: sudo apt install -y python-picamera python3-picamera There are a lot of examples in the official guide . Here are some starting points: Get maximum resolution of the camera import picamera with picamera . PiCamera () as cam : print ( cam . MAX_RESOLUTION ) Take a snapshot from time import sleep from picamera import PiCamera # setup a camera camera = PiCamera () camera . resolution = ( 1024 , 768 ) # camera warm-up time sleep ( 2 ) # capture an image camera . capture ( 'snapshot.jpg' ) Now, for the testing purpose, let\u2019s record a 60-second video from the camera and measure the resource usage with monitor , then use ffmpeg to convert raw h264 to mp4:","title":"PiCamera"},{"location":"blog/pi/set-up-camera/#picamera-h264-h264","text":"Record a raw H264 video file from picamera import PiCamera # setup a camera camera = PiCamera () camera . resolution = ( 1024 , 768 ) camera . framerate = 30 # record a video camera . start_recording ( 'picamera.h264' ) camera . wait_recording ( 60 ) camera . stop_recording () Convert to MP4 video file ffmpeg -i picamera.h264 \\ -c:v copy picamera.mp4 Performance: Total time: 61 seconds Average CPU: 11 (Good) Average MEM: 5 (Good) Input FPS: 30 Output FPS: 25 Quality: Format: AVC (GPO: M=1, N=60) Codec ID: avc1 Bit rate: 3 302 kb/s (Good) PiCamera","title":"PiCamera H264 (.h264)"},{"location":"blog/pi/set-up-camera/#picamera-h264-h264-with-text-overlay","text":"Now, try to detect how picamera can draw text on output video. Here is the test code: from picamera import PiCamera import datetime TIMEFMT = '%Y-%m- %d %H:%M:%S. %f ' # setup a camera camera = PiCamera () camera . resolution = ( 1024 , 768 ) camera . annotate_text = datetime . datetime . now () . strftime ( TIMEFMT ) # record a video camera . start_recording ( 'picamera_text.h264' ) start = datetime . datetime . now () while ( datetime . datetime . now () - start ) . seconds < 60 : camera . annotate_text = datetime . datetime . now () . strftime ( TIMEFMT ) camera . wait_recording ( 0.04 ) # 25fps # stop it camera . stop_recording () Using picamera shows an impressive %CPU and %MEM usage, comparing to using FFmpeg. The result shows that the %CPU uses twice as much as it does in non-overlay text, while the %MEM keeps the same percentage.","title":"Picamera H264 (.h264) with Text overlay"},{"location":"blog/pi/stream-ffmpeg-hls-dash/","tags":["raspberry-pi","camera","stream","hls","dash","python"],"text":"stream_ffmpeg_hls Delay when streaming in HLS protocol Big Buck Bunny movie , \u00a9 2008, Blender Foundation Install FFmpeg # Install FFmpeg from the package manager: sudo apt install -y ffmpeg Or compile an executable file by following Compile FFmpeg manually guide. HLS vs. MPEG-DASH # A streaming protocol is a type of technology that is designed to transport video files over the internet. In the past, online video was delivered primarily via the RTMP protocol. RTMP is a Flash-based standard that\u2019s still used today for sending video from an encoder to an online video platform. The RTMP has slowly been replaced by the HLS and MPEG-DASH protocol. HLS # HLS is short for HTTP Live Streaming . Originally developed by Apple, the purpose of HLS was to make the iPhone capable of accessing live streams. HLS can play video encoded with the H.264 or HEVC/H.265 codecs. As the name implies, HLS delivers content via standard HTTP web servers. This means that no special infrastructure is needed to deliver HLS content. Any standard web server or CDN will work. Additionally, content is less likely to be blocked by firewalls with this protocol, which is a plus. How it works is video is chopped up into 10-second segments. Latency for delivery tends to be in the 45-second range. With some settings applied, the delay can be reduced to 3-5 seconds. This protocol also includes several other built-in features. For example, HLS is an adaptive bit rate protocol. This means that the client device and server dynamically detect the internet speed of the user and adjusts video quality accordingly. MPEG-DASH # As a newer standard, MPEG-DASH is an up-and-coming competitor to HLS. This protocol was created as a response to fragmentation in the video streaming market. At the time, Apple\u2019s HLS was competing with several other streaming protocols. The outcome was uncertain, which led standards organizations to develop MPEG-DASH as an alternative, unifying streaming protocol. MPEG-DASH is an open-source standard. Like the HLS streaming protocol, MPEG-DASH is an adaptive bit rate video method. It also supports advertising, and the technology for this is rapidly advancing. However, MPEG-DASH is not supported on the mobile Safari browser. HLS is simply much more widely compatible than MPEG-DASH. Setup web server # Because HLS and MPEG-DASH are HTTP-based protocols, there is no need to install a special web server, what is needed is just a simple web server which can serve video chunk files. Apache # Apache is a popular web server application which can be installed on the Raspberry Pi to allow it to serve web pages. On its own, Apache can serve HTML files over HTTP, and with additional modules can serve dynamic web pages using scripting languages such as PHP. Apache\u2019s design architecture: Process Driven Approach Creates a new thread for each request. sudo apt install -y apache2 By default, Apache puts a test HTML file in the web folder /var/www/html/ . This default web page is served at http://localhost , or on the Pi itself IP address. NGINX # NGINX (pronounced engine x ) is a popular lightweight web server application which can be installed on the Raspberry Pi to allow it to serve web pages. Like Apache, NGINX can serve HTML files over HTTP, and with additional modules can serve dynamic web pages using scripting languages such as PHP. NGINX\u2019s design architecture: Event-Driven approach Handles multiple requests within one thread Nginx can work very fast and wide with limited resources. sudo apt install -y nginx Similar to Apache, NGINX also serves web pages in /var/www/html/ . Go to http://localhost/etc/nginx/sites-available to see the site\u2019s links. As the article Apache Vs NGINX \u2014 Which Is The Best Web Server? mentioned, it should go with NGINX if serving static web page with a high traffic (requests). Stream live video # MPEG-DASH and HLS both create playlist files whose content are list of video chunks. ffmpeg can read from camera and write video chunks as well as update the playlist. To speed up and to protect SD Card, it is better to write video chunks to RAM memory. When the number of chunks go high, clear the old ones to get more space . Let\u2019s do it with HLS first! Create video chunks # Create a new folder in shared memory: mkdir -p /dev/shm/hls and make a soft-link to the web folder: ln -s /dev/shm/hls /var/www/html/hls Use ffmpeg to create HLS playlist: .no-list ul { list-style-type: circle; } -input_format h264 -i /dev/video0 : input from /dev/video0 (Pi Camera) with V4L2 H264 format (see more in V4L2 H264 direct copy ) -c:v copy : directly use H264 video from V4L2 driver -f hls : output in HLS format -hls_time 1 : video chunks are saved in 1-second segments -hls_list_size 30 : playlist has 30 segments -hls_flags delete_segments : delete segments not in the playlist /dev/shm/hls/live.m3u8 : the location of playlist file and video segments ffmpeg -y \\ -input_format h264 -i /dev/video0 \\ -c:v copy \\ -f hls \\ -hls_time 1 \\ -hls_list_size 30 \\ -hls_flags delete_segments \\ /dev/shm/hls/live.m3u8 Use HLS streaming # A JavaScript named hls.js will be used to play HLS stream. /var/www/html/hls.html <!DOCTYPE html> < html > < head > < meta charset = \"utf-8\" /> < title > HLS Live Stream </ title > </ head > < body > < h1 > HLS Live Stream </ h1 > < script src = \"hls.js\" ></ script > < video id = \"video\" controls autoplay ></ video > < script > var video = document . getElementById ( \"video\" ); var videoSrc = \"hls/live.m3u8\" ; // First check for native browser HLS support if ( video . canPlayType ( \"application/vnd.apple.mpegurl\" )) { video . src = videoSrc ; } // If no native HLS support, check if hls.js is supported else if ( Hls . isSupported ()) { var hls = new Hls (); hls . loadSource ( videoSrc ); hls . attachMedia ( video ); } </ script > </ body > </ html > HLS Performance HLS is good to stream over HTTP but it has big delay. At the resolution 1024x768 @ 30fps, 1-second segments, it still shows a delay of ~10 seconds . HLS testing site https://hls-js.netlify.app/demo can measure the performance of a HLS playlist. If testing a local server, it needs to enable CORS in server settings or use CORS unblock extension. Use MPEG-DASH streaming # DASH is the same as HLS, the difference is in the playlist format and the container of segments. Create a new folder in shared memory: mkdir -p /dev/shm/dash and make a soft-link to the web folder: ln -s /dev/shm/dash /var/www/html/dash Use ffmpeg to create DASH playlist: -f dash : DASH format -seg_duration 1 : segment size is 1-second -streaming 1 : streaming enabled -window_size 30 -remove_at_exit 1 : playlist has 30 chunks, delete chunks when exit /dev/shm/dash/live.mpd : playlist file ffmpeg -y \\ -input_format h264 \\ -i /dev/video0 \\ -c:v copy \\ -f dash \\ -seg_duration 1 \\ -streaming 1 \\ -window_size 30 -remove_at_exit 1 \\ /dev/shm/dash/live.mpd And finally, change to Dash.js to play DASH stream: /var/www/html/dash.html <!DOCTYPE html> < html > < head > < meta charset = \"utf-8\" /> < title > MPEG-DASH Live Stream </ title > </ head > < body > < h1 > MPEG-DASH Live Stream </ h1 > < script src = \"dash.all.min.js\" ></ script > < video id = \"videoPlayer\" controls ></ video > < script > ( function () { var url = \"dash/live.mpd\" ; var player = dashjs . MediaPlayer (). create (); player . initialize ( document . querySelector ( \"#videoPlayer\" ), url , true ); player . updateSettings ({ streaming : { lowLatencyEnabled : true , liveDelay : 2 , liveCatchup : { minDrift : 0.05 , playbackRate : 1 , latencyThreshold : 30 , }, }, }); })(); </ script > </ body > </ html > MPEG-DASH Performance MPEG-DASH can achieve ~3 seconds of delay , which is much better than HLS. However, it is still far from real-time live stream. Low latency HLS and MPEG-DASH support Low Latency streaming, but need configured in server and encoder. This topic will be covered later. Python Web Server # Python HTTP server http.server.SimpleHTTPRequestHandler can stream HLS files too. Here listed necessary files to run HLS streaming server with Python: index.html Use hls.js to play HLS Stream. There is extra HLS configs: var config = Hls . DefaultConfig ; config . liveSyncDurationCount = 1 ; config . startFragPrefetch = true ; var hls = new Hls ( config ); hls.js HLS Stream player written in JavaScript for web server.py This implements a simple HTTP Request Handler based on SimpleHTTPRequestHandler run.sh This script creates a temporary folder in shared memory to store video segments. Then it runs ffmpeg to read camera and write video chunks. Finally, it calls server.py to serve the web. Use ffmpeg to generate both HLS and DASH segments, with some options to reduce latency. ffmpeg -y \\ -input_format h264 \\ -f video4linux2 \\ -framerate 25 \\ -use_wallclock_as_timestamps 1 \\ -i /dev/video0 \\ -c:v copy \\ -f dash \\ -ldash 1 \\ -seg_duration 1 \\ -frag_duration 1 \\ -streaming 1 \\ -window_size 30 -remove_at_exit 1 \\ -strict experimental -lhls 1 \\ -hls_playlist 1 -hls_master_name live.m3u8 \\ -utc_timing_url https://time.akamai.com/?iso \\ -write_prft 1 \\ -target_latency 1 \\ /dev/shm/hls/live.mpd & The result is not good as expected, as there is still about 3.3 seconds of delay in a LAN. Delay in HLS streaming Some lines of code to handle exception are also needed, for full source code, please download by clicking on the download button at the beginning of this post. Can NOT bind to port numbers lower than 1024 Port numbers lower than 1024 are for privileged user only . Therefore: Use a port number larger than 1024 (recommended) Or run the script as a privileged user Harder, but more secure solution if it\u2019s really necessary to accept from port numbers lower than 1024: Run the as unprivileged on a higher port, and forward that port to lower port externally.","title":"Camera live streaming using HLS/DASH"},{"location":"blog/pi/stream-ffmpeg-hls-dash/#install-ffmpeg","text":"Install FFmpeg from the package manager: sudo apt install -y ffmpeg Or compile an executable file by following Compile FFmpeg manually guide.","title":"Install FFmpeg"},{"location":"blog/pi/stream-ffmpeg-hls-dash/#hls-vs-mpeg-dash","text":"A streaming protocol is a type of technology that is designed to transport video files over the internet. In the past, online video was delivered primarily via the RTMP protocol. RTMP is a Flash-based standard that\u2019s still used today for sending video from an encoder to an online video platform. The RTMP has slowly been replaced by the HLS and MPEG-DASH protocol.","title":"HLS vs. MPEG-DASH"},{"location":"blog/pi/stream-ffmpeg-hls-dash/#hls","text":"HLS is short for HTTP Live Streaming . Originally developed by Apple, the purpose of HLS was to make the iPhone capable of accessing live streams. HLS can play video encoded with the H.264 or HEVC/H.265 codecs. As the name implies, HLS delivers content via standard HTTP web servers. This means that no special infrastructure is needed to deliver HLS content. Any standard web server or CDN will work. Additionally, content is less likely to be blocked by firewalls with this protocol, which is a plus. How it works is video is chopped up into 10-second segments. Latency for delivery tends to be in the 45-second range. With some settings applied, the delay can be reduced to 3-5 seconds. This protocol also includes several other built-in features. For example, HLS is an adaptive bit rate protocol. This means that the client device and server dynamically detect the internet speed of the user and adjusts video quality accordingly.","title":"HLS"},{"location":"blog/pi/stream-ffmpeg-hls-dash/#mpeg-dash","text":"As a newer standard, MPEG-DASH is an up-and-coming competitor to HLS. This protocol was created as a response to fragmentation in the video streaming market. At the time, Apple\u2019s HLS was competing with several other streaming protocols. The outcome was uncertain, which led standards organizations to develop MPEG-DASH as an alternative, unifying streaming protocol. MPEG-DASH is an open-source standard. Like the HLS streaming protocol, MPEG-DASH is an adaptive bit rate video method. It also supports advertising, and the technology for this is rapidly advancing. However, MPEG-DASH is not supported on the mobile Safari browser. HLS is simply much more widely compatible than MPEG-DASH.","title":"MPEG-DASH"},{"location":"blog/pi/stream-ffmpeg-hls-dash/#setup-web-server","text":"Because HLS and MPEG-DASH are HTTP-based protocols, there is no need to install a special web server, what is needed is just a simple web server which can serve video chunk files.","title":"Setup web server"},{"location":"blog/pi/stream-ffmpeg-hls-dash/#apache","text":"Apache is a popular web server application which can be installed on the Raspberry Pi to allow it to serve web pages. On its own, Apache can serve HTML files over HTTP, and with additional modules can serve dynamic web pages using scripting languages such as PHP. Apache\u2019s design architecture: Process Driven Approach Creates a new thread for each request. sudo apt install -y apache2 By default, Apache puts a test HTML file in the web folder /var/www/html/ . This default web page is served at http://localhost , or on the Pi itself IP address.","title":"Apache"},{"location":"blog/pi/stream-ffmpeg-hls-dash/#nginx","text":"NGINX (pronounced engine x ) is a popular lightweight web server application which can be installed on the Raspberry Pi to allow it to serve web pages. Like Apache, NGINX can serve HTML files over HTTP, and with additional modules can serve dynamic web pages using scripting languages such as PHP. NGINX\u2019s design architecture: Event-Driven approach Handles multiple requests within one thread Nginx can work very fast and wide with limited resources. sudo apt install -y nginx Similar to Apache, NGINX also serves web pages in /var/www/html/ . Go to http://localhost/etc/nginx/sites-available to see the site\u2019s links. As the article Apache Vs NGINX \u2014 Which Is The Best Web Server? mentioned, it should go with NGINX if serving static web page with a high traffic (requests).","title":"NGINX"},{"location":"blog/pi/stream-ffmpeg-hls-dash/#stream-live-video","text":"MPEG-DASH and HLS both create playlist files whose content are list of video chunks. ffmpeg can read from camera and write video chunks as well as update the playlist. To speed up and to protect SD Card, it is better to write video chunks to RAM memory. When the number of chunks go high, clear the old ones to get more space . Let\u2019s do it with HLS first!","title":"Stream live video"},{"location":"blog/pi/stream-ffmpeg-hls-dash/#create-video-chunks","text":"Create a new folder in shared memory: mkdir -p /dev/shm/hls and make a soft-link to the web folder: ln -s /dev/shm/hls /var/www/html/hls Use ffmpeg to create HLS playlist: .no-list ul { list-style-type: circle; } -input_format h264 -i /dev/video0 : input from /dev/video0 (Pi Camera) with V4L2 H264 format (see more in V4L2 H264 direct copy ) -c:v copy : directly use H264 video from V4L2 driver -f hls : output in HLS format -hls_time 1 : video chunks are saved in 1-second segments -hls_list_size 30 : playlist has 30 segments -hls_flags delete_segments : delete segments not in the playlist /dev/shm/hls/live.m3u8 : the location of playlist file and video segments ffmpeg -y \\ -input_format h264 -i /dev/video0 \\ -c:v copy \\ -f hls \\ -hls_time 1 \\ -hls_list_size 30 \\ -hls_flags delete_segments \\ /dev/shm/hls/live.m3u8","title":"Create video chunks"},{"location":"blog/pi/stream-ffmpeg-hls-dash/#use-hls-streaming","text":"A JavaScript named hls.js will be used to play HLS stream. /var/www/html/hls.html <!DOCTYPE html> < html > < head > < meta charset = \"utf-8\" /> < title > HLS Live Stream </ title > </ head > < body > < h1 > HLS Live Stream </ h1 > < script src = \"hls.js\" ></ script > < video id = \"video\" controls autoplay ></ video > < script > var video = document . getElementById ( \"video\" ); var videoSrc = \"hls/live.m3u8\" ; // First check for native browser HLS support if ( video . canPlayType ( \"application/vnd.apple.mpegurl\" )) { video . src = videoSrc ; } // If no native HLS support, check if hls.js is supported else if ( Hls . isSupported ()) { var hls = new Hls (); hls . loadSource ( videoSrc ); hls . attachMedia ( video ); } </ script > </ body > </ html > HLS Performance HLS is good to stream over HTTP but it has big delay. At the resolution 1024x768 @ 30fps, 1-second segments, it still shows a delay of ~10 seconds . HLS testing site https://hls-js.netlify.app/demo can measure the performance of a HLS playlist. If testing a local server, it needs to enable CORS in server settings or use CORS unblock extension.","title":"Use HLS streaming"},{"location":"blog/pi/stream-ffmpeg-hls-dash/#use-mpeg-dash-streaming","text":"DASH is the same as HLS, the difference is in the playlist format and the container of segments. Create a new folder in shared memory: mkdir -p /dev/shm/dash and make a soft-link to the web folder: ln -s /dev/shm/dash /var/www/html/dash Use ffmpeg to create DASH playlist: -f dash : DASH format -seg_duration 1 : segment size is 1-second -streaming 1 : streaming enabled -window_size 30 -remove_at_exit 1 : playlist has 30 chunks, delete chunks when exit /dev/shm/dash/live.mpd : playlist file ffmpeg -y \\ -input_format h264 \\ -i /dev/video0 \\ -c:v copy \\ -f dash \\ -seg_duration 1 \\ -streaming 1 \\ -window_size 30 -remove_at_exit 1 \\ /dev/shm/dash/live.mpd And finally, change to Dash.js to play DASH stream: /var/www/html/dash.html <!DOCTYPE html> < html > < head > < meta charset = \"utf-8\" /> < title > MPEG-DASH Live Stream </ title > </ head > < body > < h1 > MPEG-DASH Live Stream </ h1 > < script src = \"dash.all.min.js\" ></ script > < video id = \"videoPlayer\" controls ></ video > < script > ( function () { var url = \"dash/live.mpd\" ; var player = dashjs . MediaPlayer (). create (); player . initialize ( document . querySelector ( \"#videoPlayer\" ), url , true ); player . updateSettings ({ streaming : { lowLatencyEnabled : true , liveDelay : 2 , liveCatchup : { minDrift : 0.05 , playbackRate : 1 , latencyThreshold : 30 , }, }, }); })(); </ script > </ body > </ html > MPEG-DASH Performance MPEG-DASH can achieve ~3 seconds of delay , which is much better than HLS. However, it is still far from real-time live stream. Low latency HLS and MPEG-DASH support Low Latency streaming, but need configured in server and encoder. This topic will be covered later.","title":"Use MPEG-DASH streaming"},{"location":"blog/pi/stream-ffmpeg-hls-dash/#python-web-server","text":"Python HTTP server http.server.SimpleHTTPRequestHandler can stream HLS files too. Here listed necessary files to run HLS streaming server with Python: index.html Use hls.js to play HLS Stream. There is extra HLS configs: var config = Hls . DefaultConfig ; config . liveSyncDurationCount = 1 ; config . startFragPrefetch = true ; var hls = new Hls ( config ); hls.js HLS Stream player written in JavaScript for web server.py This implements a simple HTTP Request Handler based on SimpleHTTPRequestHandler run.sh This script creates a temporary folder in shared memory to store video segments. Then it runs ffmpeg to read camera and write video chunks. Finally, it calls server.py to serve the web. Use ffmpeg to generate both HLS and DASH segments, with some options to reduce latency. ffmpeg -y \\ -input_format h264 \\ -f video4linux2 \\ -framerate 25 \\ -use_wallclock_as_timestamps 1 \\ -i /dev/video0 \\ -c:v copy \\ -f dash \\ -ldash 1 \\ -seg_duration 1 \\ -frag_duration 1 \\ -streaming 1 \\ -window_size 30 -remove_at_exit 1 \\ -strict experimental -lhls 1 \\ -hls_playlist 1 -hls_master_name live.m3u8 \\ -utc_timing_url https://time.akamai.com/?iso \\ -write_prft 1 \\ -target_latency 1 \\ /dev/shm/hls/live.mpd & The result is not good as expected, as there is still about 3.3 seconds of delay in a LAN. Delay in HLS streaming Some lines of code to handle exception are also needed, for full source code, please download by clicking on the download button at the beginning of this post. Can NOT bind to port numbers lower than 1024 Port numbers lower than 1024 are for privileged user only . Therefore: Use a port number larger than 1024 (recommended) Or run the script as a privileged user Harder, but more secure solution if it\u2019s really necessary to accept from port numbers lower than 1024: Run the as unprivileged on a higher port, and forward that port to lower port externally.","title":"Python Web Server"},{"location":"blog/pi/stream-picamera-h264/","tags":["raspberry-pi","stream","camera","h264","python","picamera"],"text":"stream_picamera_h264 Low latency streaming using H264 format Big Buck Bunny movie , \u00a9 2008, Blender Foundation Stream video # Live-streaming requires very low latency with acceptable quality and bandwidth. MJPEG Streaming has low latency but high bandwidth. HLS/DASH Streaming is not real-time. Therefore, people have to find a method to transfer encoded video in real-time. An example of streaming real video (not frame by frame) is pistreaming which uses mpeg1video format. The video stream is sent to user\u2019s browser via a websocket , and is decoded by JSMPEG JavaScript library. This post will show a method similar to both MPEG stream and MJPEG images: send video using H264 Network Abstract Layer (NAL) units and decode those units to display video. Broadway.js \u2014 An H264 decoder # The h264-live-player is used for streaming an Android screen to a webpage. That player uses Broadway.js library to decode the video stream. It also has a streaming server for Raspberry Pi using raspivid , nodejs , and websocket . The method used in that player is quite similar to MJPEG Streaming : video stream is split into NAL units (Video Control Layer (VCL) or non-VLC packages), then transported using a Websocket, and finally decoded by the Broadway.js library. Broadway.js provides Player.js , Decoder.js , YUVCanvas.js , and avc.wasm , with very simple usage: create a new Player object; then put the player\u2019s canvas to an element to display the video; and call the decode function with the stream data. var player = new Player ({ < options > }); playerElement = document . getElementById ( playerId ) playerElement . appendChild ( player . canvas ) player . decode ( < h264 data > ); Create a webpage # The webpage firstly loads necessary libraries and requests to open a Websocket connection, then feeds Broadway decoder with a streaming data chunk by calling player.decode() method. index.html <!DOCTYPE html> < html > < head > < meta charset = 'utf-8' > < title > PiCamera H264 Streaming </ title > </ head > < body > < h1 > PiCamera H264 Streaming </ h1 > < div id = 'viewer' ></ div > < script src = 'Decoder.js' ></ script > < script src = 'YUVCanvas.js' ></ script > < script src = 'Player.js' ></ script > < script > // player window . player = new Player ({ useWorker : true , webgl : 'auto' , size : { width : 848 , height : 480 } }) var playerElement = document . getElementById ( 'viewer' ) playerElement . appendChild ( window . player . canvas ) // Websocket var wsUri = window . location . protocol . replace ( /http/ , 'ws' ) + '//' + window . location . hostname + ':9000' var ws = new WebSocket ( wsUri ) ws . binaryType = 'arraybuffer' ws . onopen = function ( e ) { console . log ( 'Client connected' ) ws . onmessage = function ( msg ) { // decode stream window . player . decode ( new Uint8Array ( msg . data )); } } ws . onclose = function ( e ) { console . log ( 'Client disconnected' ) } </ script > </ body > </ html > Create server # Here is the structure of a H264 streaming system use in the post. PiCamera will capture a H264 stream and write to FrameBuffer each NALU package which will be sent to the Broadway.js via a Websocket. The decoded video frame will be drawn on a canvas to show in the webpage. The webpage is provided via an HTTP server which will load the Broadway.js and set up the decoder and a Websocket client. H264 streaming server structure Frame buffer # The FrameBuffer is implemented as an output of PiCamera which store each H264 Network Abstraction Layer (NAL) unit from H264/AVC or HEVC video stream. There is a Condition object to synchronize between FrameBuffer and WebSocketServer . For more detail of how to construct FrameBuffer class, refer to Streaming using MJPEG import io from threading import Condition class FrameBuffer ( object ): def __init__ ( self ): self . frame = None self . buffer = io . BytesIO () self . condition = Condition () def write ( self , buf ): if buf . startswith ( b ' \\x00\\x00\\x00\\x01 ' ): with self . condition : self . buffer . seek ( 0 ) self . buffer . write ( buf ) self . buffer . truncate () self . frame = self . buffer . getvalue () self . condition . notify_all () HTTP Server # The web interface server is served by ThreadingHTTPServer with SimpleHTTPRequestHandler to serve requested files ( index.html , *.js , etc.). from http.server import SimpleHTTPRequestHandler , ThreadingHTTPServer from threading import Thread httpd = ThreadingHTTPServer (( '' , 8000 ), SimpleHTTPRequestHandler ) httpd_thread = Thread ( target = httpd . serve_forever ) Websocket Server # One of good Websocket packages for Python is ws4py which supports both Python 2 and Python 3 (while websockets requires Python \u2265 3.6.1). From the package ws4py , use module wsgiref as a Web Server Gateway Interface to make a websocket server. The function make_server() needs to know the port, and some classes to initialize a server, those can be built-in objects in ws4py such as WebSocketWSGIRequestHandler , WebSocketWSGIApplication , and base WebSocket . Finally, a client manager should be created in the websocket server, to use broadcasting function later. from wsgiref.simple_server import make_server from threading import Thread websocketd = make_server ( '' , 9000 , server_class = WSGIServer , handler_class = WebSocketWSGIRequestHandler , app = WebSocketWSGIApplication ( handler_cls = WebSocket )) websocketd . initialize_websockets_manager () websocketd_thread = Thread ( target = websocketd . serve_forever ) Main thread # The main application will start PiCamera and write output video in h264 encode. As noted in Broadway.js, it only supports H264 Baseline profile , therefore, set profile = \"baseline\" when starting video record. import picamera with picamera . PiCamera ( resolution = '640x480' , framerate = 24 ) as camera : broadcasting = True frame_buffer = FrameBuffer () camera . start_recording ( frame_buffer , format = 'h264' , profile = \"baseline\" ) The main loop should broadcast H264 NAL units to all connected clients, after it starts threads for HTTP Server and Websocket Server. try : websocketd_thread . start () httpd_thread . start () while broadcasting : with frame_buffer . condition : frame_buffer . condition . wait () websocketd . manager . broadcast ( frame_buffer . frame , binary = True ) Low latency in H264 streaming There may be some delay before the video shows up in user webpage because the Player has to wait for a IDR Frame (keyframe) to be able to start decoding. Some lines of code to handle exception are also needed, for full source code, please download by clicking on the download button at the beginning of this post.","title":"Camera live streaming using H264 format"},{"location":"blog/pi/stream-picamera-h264/#stream-video","text":"Live-streaming requires very low latency with acceptable quality and bandwidth. MJPEG Streaming has low latency but high bandwidth. HLS/DASH Streaming is not real-time. Therefore, people have to find a method to transfer encoded video in real-time. An example of streaming real video (not frame by frame) is pistreaming which uses mpeg1video format. The video stream is sent to user\u2019s browser via a websocket , and is decoded by JSMPEG JavaScript library. This post will show a method similar to both MPEG stream and MJPEG images: send video using H264 Network Abstract Layer (NAL) units and decode those units to display video.","title":"Stream video"},{"location":"blog/pi/stream-picamera-h264/#broadwayjs--an-h264-decoder","text":"The h264-live-player is used for streaming an Android screen to a webpage. That player uses Broadway.js library to decode the video stream. It also has a streaming server for Raspberry Pi using raspivid , nodejs , and websocket . The method used in that player is quite similar to MJPEG Streaming : video stream is split into NAL units (Video Control Layer (VCL) or non-VLC packages), then transported using a Websocket, and finally decoded by the Broadway.js library. Broadway.js provides Player.js , Decoder.js , YUVCanvas.js , and avc.wasm , with very simple usage: create a new Player object; then put the player\u2019s canvas to an element to display the video; and call the decode function with the stream data. var player = new Player ({ < options > }); playerElement = document . getElementById ( playerId ) playerElement . appendChild ( player . canvas ) player . decode ( < h264 data > );","title":"Broadway.js \u2014 An H264 decoder"},{"location":"blog/pi/stream-picamera-h264/#create-a-webpage","text":"The webpage firstly loads necessary libraries and requests to open a Websocket connection, then feeds Broadway decoder with a streaming data chunk by calling player.decode() method. index.html <!DOCTYPE html> < html > < head > < meta charset = 'utf-8' > < title > PiCamera H264 Streaming </ title > </ head > < body > < h1 > PiCamera H264 Streaming </ h1 > < div id = 'viewer' ></ div > < script src = 'Decoder.js' ></ script > < script src = 'YUVCanvas.js' ></ script > < script src = 'Player.js' ></ script > < script > // player window . player = new Player ({ useWorker : true , webgl : 'auto' , size : { width : 848 , height : 480 } }) var playerElement = document . getElementById ( 'viewer' ) playerElement . appendChild ( window . player . canvas ) // Websocket var wsUri = window . location . protocol . replace ( /http/ , 'ws' ) + '//' + window . location . hostname + ':9000' var ws = new WebSocket ( wsUri ) ws . binaryType = 'arraybuffer' ws . onopen = function ( e ) { console . log ( 'Client connected' ) ws . onmessage = function ( msg ) { // decode stream window . player . decode ( new Uint8Array ( msg . data )); } } ws . onclose = function ( e ) { console . log ( 'Client disconnected' ) } </ script > </ body > </ html >","title":"Create a webpage"},{"location":"blog/pi/stream-picamera-h264/#create-server","text":"Here is the structure of a H264 streaming system use in the post. PiCamera will capture a H264 stream and write to FrameBuffer each NALU package which will be sent to the Broadway.js via a Websocket. The decoded video frame will be drawn on a canvas to show in the webpage. The webpage is provided via an HTTP server which will load the Broadway.js and set up the decoder and a Websocket client. H264 streaming server structure","title":"Create server"},{"location":"blog/pi/stream-picamera-h264/#frame-buffer","text":"The FrameBuffer is implemented as an output of PiCamera which store each H264 Network Abstraction Layer (NAL) unit from H264/AVC or HEVC video stream. There is a Condition object to synchronize between FrameBuffer and WebSocketServer . For more detail of how to construct FrameBuffer class, refer to Streaming using MJPEG import io from threading import Condition class FrameBuffer ( object ): def __init__ ( self ): self . frame = None self . buffer = io . BytesIO () self . condition = Condition () def write ( self , buf ): if buf . startswith ( b ' \\x00\\x00\\x00\\x01 ' ): with self . condition : self . buffer . seek ( 0 ) self . buffer . write ( buf ) self . buffer . truncate () self . frame = self . buffer . getvalue () self . condition . notify_all ()","title":"Frame buffer"},{"location":"blog/pi/stream-picamera-h264/#http-server","text":"The web interface server is served by ThreadingHTTPServer with SimpleHTTPRequestHandler to serve requested files ( index.html , *.js , etc.). from http.server import SimpleHTTPRequestHandler , ThreadingHTTPServer from threading import Thread httpd = ThreadingHTTPServer (( '' , 8000 ), SimpleHTTPRequestHandler ) httpd_thread = Thread ( target = httpd . serve_forever )","title":"HTTP Server"},{"location":"blog/pi/stream-picamera-h264/#websocket-server","text":"One of good Websocket packages for Python is ws4py which supports both Python 2 and Python 3 (while websockets requires Python \u2265 3.6.1). From the package ws4py , use module wsgiref as a Web Server Gateway Interface to make a websocket server. The function make_server() needs to know the port, and some classes to initialize a server, those can be built-in objects in ws4py such as WebSocketWSGIRequestHandler , WebSocketWSGIApplication , and base WebSocket . Finally, a client manager should be created in the websocket server, to use broadcasting function later. from wsgiref.simple_server import make_server from threading import Thread websocketd = make_server ( '' , 9000 , server_class = WSGIServer , handler_class = WebSocketWSGIRequestHandler , app = WebSocketWSGIApplication ( handler_cls = WebSocket )) websocketd . initialize_websockets_manager () websocketd_thread = Thread ( target = websocketd . serve_forever )","title":"Websocket Server"},{"location":"blog/pi/stream-picamera-h264/#main-thread","text":"The main application will start PiCamera and write output video in h264 encode. As noted in Broadway.js, it only supports H264 Baseline profile , therefore, set profile = \"baseline\" when starting video record. import picamera with picamera . PiCamera ( resolution = '640x480' , framerate = 24 ) as camera : broadcasting = True frame_buffer = FrameBuffer () camera . start_recording ( frame_buffer , format = 'h264' , profile = \"baseline\" ) The main loop should broadcast H264 NAL units to all connected clients, after it starts threads for HTTP Server and Websocket Server. try : websocketd_thread . start () httpd_thread . start () while broadcasting : with frame_buffer . condition : frame_buffer . condition . wait () websocketd . manager . broadcast ( frame_buffer . frame , binary = True ) Low latency in H264 streaming There may be some delay before the video shows up in user webpage because the Player has to wait for a IDR Frame (keyframe) to be able to start decoding. Some lines of code to handle exception are also needed, for full source code, please download by clicking on the download button at the beginning of this post.","title":"Main thread"},{"location":"blog/pi/stream-picamera-mjpeg/","tags":["raspberry-pi","stream","camera","mjpeg","picamera","python"],"text":"stream_picamera_mjpeg Low latency streaming using MJPEG format Big Buck Bunny movie , \u00a9 2008, Blender Foundation There are many methods to implement a streaming server using MJPEG (MJPG) format. The basic principle is to send a series of JPEG (JPG) image to the user\u2019s webpage and display it in an image <img> tag. An example is the mjpg-streamer . This post shows a method to develop a streaming system, starting with a Python package named PiCamera and a simple Python HTTP server. To setup picamera package, please read more in the Setup Camera post. PiCamera also has an example to stream MJPEG at Web streaming section. The basic structure of this MJPEG streaming server is as below. PiCamera will capture JPEG images to a buffer that will be sent to user\u2019s web browser via an endless multipart/x-mixed-replace content when the webpage requests to show an image in a <img> element. A structure of an MJPEG streaming server Record video to a stream # This is a basic step to write a video stream to a buffered memory. Python has the io package which expects bytes-like objects and produces bytes objects. No encoding, decoding, or newline translation is performed, because PiCamera requests to V4L2 driver to handle the encoding in hardware. from io import BytesIO from picamera import PiCamera # create in-memory stream stream = BytesIO () # create camera object (instance) camera = PiCamera () # config camera camera . resolution = ( 640 , 480 ) # start recording to stream camera . start_recording ( stream , format = 'mjpeg' ) # wait camera . wait_recording ( 15 ) # stop recording camera . stop_recording () Frame buffer # Next step is to create a custom output to used in PiCamera.start_recording() method. Refer to Custom outputs . A file-like object (as far as PiCamera is concerned) is simply an object with: A write() method which must accept a single parameter consisting of a byte-string, and which can optionally return the number of bytes written. A flush() method with no parameters, which will be called at the end of output. In write() method, it can implement code that reacts to each and every frame. The write() method is called frequently, so its implementation must be sufficiently rapid that it doesn\u2019t stall the encoding flow. Let\u2019s write a class FrameBuffer() which checks the JPEG Magic Number 0xFF 0xD8 at the beginning of an JPEG image: import io class FrameBuffer ( object ): def __init__ ( self ): # store each frame self . frame = None # buffer to hold incoming frame self . buffer = io . BytesIO () def write ( self , buf ): # if it's a JPEG image if buf . startswith ( b ' \\xff\\xd8 ' ): # write to buffer self . buffer . seek ( 0 ) self . buffer . write ( buf ) # extract frame self . buffer . truncate () self . frame = self . buffer . getvalue () Note that FrameBuffer.frame will be used to send the frame to user\u2019s webpage. Then, use the FrameBuffer instead of the buffered memory: # create buffer frame_buffer = FrameBuffer () # write to framebuffer camera . start_recording ( frame_buffer , format = 'mjpeg' ) Streaming Web server # Python has a built-in simple HTTP Server, which is ready to run by providing a server address and a request handler class. from http.server import HTTPServer , BaseHTTPRequestHandler def run ( server_class = HTTPServer , handler_class = BaseHTTPRequestHandler ): server_address = ( '' , 8000 ) httpd = server_class ( server_address , handler_class ) httpd . serve_forever () Now, look at some pre-defined Request Handler classes: class http . server . BaseHTTPRequestHandler This class is used to handle the HTTP requests that arrive at the server. By itself, it cannot respond to any actual HTTP requests; BaseHTTPRequestHandler just provides a number of class and instance variables, and methods for use by subclasses. It must be sub-classed to handle each request method (e.g. GET or POST). The handler will parse the request and the headers, then call a method specific to the request type. The method name is constructed from the request. For example, for the request method SPAM , the do_SPAM() method will be called with no arguments. All the relevant information is stored in instance variables of the handler. Subclasses should not need to override or extend the __init__() method. class http . server . SimpleHTTPRequestHandler This class serves files from the current directory and below, directly mapping the directory structure to HTTP requests. A lot of the work, such as parsing the request, is done by the base class BaseHTTPRequestHandler . This class implements the do_GET() and do_HEAD() functions. class http . server . CGIHTTPRequestHandler This class is used to serve either files or output of CGI scripts from the current directory and below. Note that mapping HTTP hierarchic structure to local directory structure is exactly as in SimpleHTTPRequestHandler . The class will however, run the CGI script, instead of serving it as a file, if it guesses it to be a CGI script. Only directory-based CGI are used \u2014 the other common server configuration is to treat special extensions as denoting CGI scripts. The do_GET() and do_HEAD() functions are modified to run CGI scripts and serve the output, instead of serving files, if the request leads to somewhere below the cgi_directories path. Let\u2019s start with SimpleHTTPRequestHandler which has some implemented features. Request Handler # Based on SimpleHTTPRequestHandler , create a new class StreamingHandler and only override do_GET() method to just print requested path and then call the base method as it is already implemented. from http.server import SimpleHTTPRequestHandler class StreamingHandler ( SimpleHTTPRequestHandler ): def do_GET ( self ): print ( self . path ) # call to the base method implemented in SimpleHTTPRequestHandler super () . do_GET () The SimpleHTTPRequestHandler will serve files in GET requests, and it will look for index.html for the homepage. To display image, create an image <img> tag which will request a file named stream.mjpg . < html > < head > < title > Picamea MJPEG Live Stream </ title > </ head > < body > <!-- Request MJPEG stream --> < img src = \"stream.mjpg\" /> </ body > </ html > There is no actual stream.mjpg file! . When the web page request stream.mjpg , web server should return a stream, not a single file, therefore a special sequence is needed to handle this special request of stream.mjpg file in the do_GET() method: Send response with HTTP Status Code 200 (Successful responses) Send header with information to notify web client about type of responded content, which is multipart/x-mixed-replace Send the content in a stream format (loop forever!): send the boundary FRAME , send content type of each frame image/jpeg , send the length of the content, and then send the actual image data from http.server import SimpleHTTPRequestHandler class StreamingHandler ( SimpleHTTPRequestHandler ): def do_GET ( self ): if self . path == '/stream.mjpg' : # response self . send_response ( 200 ) # header self . send_header ( 'Age' , 0 ) self . send_header ( 'Cache-Control' , 'no-cache, private' ) self . send_header ( 'Pragma' , 'no-cache' ) self . send_header ( 'Content-Type' , 'multipart/x-mixed-replace; boundary=FRAME' ) self . end_headers () try : while True : frame = frame_buffer . frame # need frame_buffer as global self . wfile . write ( b '--FRAME \\r\\n ' ) self . send_header ( 'Content-Type' , 'image/jpeg' ) self . send_header ( 'Content-Length' , len ( frame )) self . end_headers () self . wfile . write ( frame ) self . wfile . write ( b ' \\r\\n ' ) except Exception as e : print ( str ( e )) else : super () . do_GET () Finally, wrap them up by creating an instance of FrameBuffer , PiCamera , HTTPServer to start streaming: frame_buffer = FrameBuffer () camera = PiCamera ( resolution = '640x480' , framerate = 24 ) camera . start_recording ( frame_buffer , format = 'mjpeg' ) server_address = ( '' , 8000 ) handler_class = StreamingHandler # alias try : httpd = HTTPServer ( server_address , handler_class ) httpd . serve_forever () finally : camera . stop_recording () Bug: Hangup stream When run the above code, the web page shows up but with only one frame displayed, CPU is locked up at 100%, because the block while True : loop causes the problem. Need to find a way to synchronize between camera thread and web server thread: send a frame only when it is available. Synchronize between threads # Python has implemented a lock mechanism between threads: class threading . Condition ( lock = None ) This class implements condition variable objects. A condition variable allows one or more threads to wait until they are notified by another thread. If the lock argument is given and not None , it must be a Lock or RLock object, and it is used as the underlying lock. Otherwise, a new RLock object is created and used as the underlying lock. wait ( timeout = None ) Wait until notified or until a timeout occurs. If the calling thread has not acquired the lock when this method is called, a RuntimeError is raised. This method releases the underlying lock , and then blocks until it is awakened by a notify() or notify_all() call for the same condition variable in another thread, or until the optional timeout occurs. Once awakened or timed out, it re-acquires the lock and returns. notify_all () Wake up all threads waiting on this condition. This method acts like notify() , but wakes up all waiting threads instead of one. If the calling thread has not acquired the lock when this method is called, a RuntimeError is raised. Then add a Condition object in FrameBuffer , and use it in StreamingHandler : from threading import Condition class FrameBuffer ( object ): def __init__ ( self ): self . frame = None self . buffer = io . BytesIO () # synchronize between threads self . condition = Condition () def write ( self , buf ): if buf . startswith ( b ' \\xff\\xd8 ' ): with self . condition : self . buffer . seek ( 0 ) self . buffer . write ( buf ) self . buffer . truncate () self . frame = self . buffer . getvalue () # notify other threads self . condition . notify_all () class StreamingHandler ( SimpleHTTPRequestHandler ): def do_GET ( self ): if self . path == '/stream.mjpg' : ... try : while True : with frame_buffer . condition : # wait for a new frame frame_buffer . condition . wait () frame = frame_buffer . frame # access global variable, need to change later Wow, it works!!! the latency is just about 200ms which is unachievable with HLS/ MPEG-DASH streaming. However, the CPU usage is quite high, Pi Zero W only can handle 6 clients at the same time with video quality at 640x480 @25fps. A low latency in MJPEG streaming Hint Above sections are enough to create a simple MJPEG streaming server. Below sections are for an advanced implementation which need some advanced Python programming to create multiple buffers in an application, which can be used to merge or manipulate the image before sending to user\u2019s browsers. Some updates in the script # The instance frame_buffer is used as a global variable in the StreamingHandler , it is not good if there is another FrameBuffer used for another stream in a same script. Here is an advanced method to have multiple frame buffers by passing an instance of FrameBuffer into an instance of StreamingHandler . It can be done by adding an Instance variable that holds reference to an instance of FrameBuffer , but can not be done using Class variable . Let\u2019s check how they work. Class variable # Class variable is shared by all instance, therefore it acts like a global static attribute of the class. class StreamingHandler ( SimpleHTTPRequestHandler ): # class variable refers to an instance of FrameBuffer my_frame_buffer = None def do_GET ( self ): ... frame = self . my_frame_buffer . frame # create an instance of FrameBuffer frame_buffer = FrameBuffer () handler_class = StreamingHandler # alias # assign class variable handler_class . my_frame_buffer = frame_buffer # all instance will share class variables first_handler = StreamingHandler () second_handler = StreamingHandler () # first_handler.my_frame_buffer will be the same as second_handler.my_frame_buffer Instance variable # Instance variables are for the data unique to each instance, they are created in the __init()__ constructor of that class: class StreamingHandler ( SimpleHTTPRequestHandler ): def __init__ ( self , frame_buffer , request , client_address , server , directory = None ): self . my_frame_buffer = frame_buffer super () . __init__ ( request , client_address , server , directory ) def do_GET (): ... However, with this modification, script cannot use StreamingHandler to initialize ThreadingHTTPServer anymore, because it expects to call a request handler with only required positional arguments (request, client_address, server) , without a new argument frame_buffer . Therefore, write a function that convert expected parameters list to new parameters list: frame_buffer = FrameBuffer () def getStreamingHandler ( request , client_address , server ): return StreamingHandler ( frame_buffer , request , client_address , server ) httpd = ThreadingHTTPServer ( address , getStreamingHandler ) Well, it works, but the convert function actually drop the parameter directory which is an optional parameter in original constructor of SimpleHTTPRequestHandler . To solve this problem, let\u2019s use special *args and **kwargs parameters. *args and **kwargs # The special *args and **kwargs parameters allow passing multiple arguments or keyword arguments to a function. Read about them in here . So, change the parameter list (request, client_address, server, ...) to *args in code, then it looks better: class StreamingHandler ( SimpleHTTPRequestHandler ): def __init__ ( self , frame_buffer , * args ): self . my_frame_buffer = frame_buffer super () . __init__ ( * args ) frame_buffer = FrameBuffer () def getStreamingHandler ( * args ): return StreamingHandler ( frame_buffer , * args ) httpd = ThreadingHTTPServer ( address , getStreamingHandler ) Lambda function # Python and other languages like Java, C#, and even C++ have had lambda functions added to their syntax, whereas languages like LISP or the ML family of languages, Haskell, OCaml, and F#, use lambdas as a core concept. Read more in here So, reduce the function getStreamingHandler to a lambda function which can be declared in-line when creating ThreadingHTTPServer instance: frame_buffer = FrameBuffer () httpd = ThreadingHTTPServer ( address , lambda * args : StreamingHandler ( frame_buffer , * args )) Measure FPS # In the while loop of sending frames, use frame_count variable to count the number of processed frames. With time package, it is easy to calculate FPS over a defined period, for example, 5 seconds in below code: try : # tracking serving time start_time = time . time () frame_count = 0 # endless stream while True : with self . frames_buffer . condition : # wait for a new frame self . frames_buffer . condition . wait () # it's available, pick it up frame = self . frames_buffer . frame # send it ... # count frames frame_count += 1 # calculate FPS every 5s if ( time . time () - start_time ) > 5 : print ( \"FPS: \" , frame_count / ( time . time () - start_time )) frame_count = 0 start_time = time . time () ... Some lines of code to handle exception are also needed, for full source code, please download by clicking on the download button at the beginning of this post.","title":"Camera live streaming using MJPEG format"},{"location":"blog/pi/stream-picamera-mjpeg/#record-video-to-a-stream","text":"This is a basic step to write a video stream to a buffered memory. Python has the io package which expects bytes-like objects and produces bytes objects. No encoding, decoding, or newline translation is performed, because PiCamera requests to V4L2 driver to handle the encoding in hardware. from io import BytesIO from picamera import PiCamera # create in-memory stream stream = BytesIO () # create camera object (instance) camera = PiCamera () # config camera camera . resolution = ( 640 , 480 ) # start recording to stream camera . start_recording ( stream , format = 'mjpeg' ) # wait camera . wait_recording ( 15 ) # stop recording camera . stop_recording ()","title":"Record video to a stream"},{"location":"blog/pi/stream-picamera-mjpeg/#frame-buffer","text":"Next step is to create a custom output to used in PiCamera.start_recording() method. Refer to Custom outputs . A file-like object (as far as PiCamera is concerned) is simply an object with: A write() method which must accept a single parameter consisting of a byte-string, and which can optionally return the number of bytes written. A flush() method with no parameters, which will be called at the end of output. In write() method, it can implement code that reacts to each and every frame. The write() method is called frequently, so its implementation must be sufficiently rapid that it doesn\u2019t stall the encoding flow. Let\u2019s write a class FrameBuffer() which checks the JPEG Magic Number 0xFF 0xD8 at the beginning of an JPEG image: import io class FrameBuffer ( object ): def __init__ ( self ): # store each frame self . frame = None # buffer to hold incoming frame self . buffer = io . BytesIO () def write ( self , buf ): # if it's a JPEG image if buf . startswith ( b ' \\xff\\xd8 ' ): # write to buffer self . buffer . seek ( 0 ) self . buffer . write ( buf ) # extract frame self . buffer . truncate () self . frame = self . buffer . getvalue () Note that FrameBuffer.frame will be used to send the frame to user\u2019s webpage. Then, use the FrameBuffer instead of the buffered memory: # create buffer frame_buffer = FrameBuffer () # write to framebuffer camera . start_recording ( frame_buffer , format = 'mjpeg' )","title":"Frame buffer"},{"location":"blog/pi/stream-picamera-mjpeg/#streaming-web-server","text":"Python has a built-in simple HTTP Server, which is ready to run by providing a server address and a request handler class. from http.server import HTTPServer , BaseHTTPRequestHandler def run ( server_class = HTTPServer , handler_class = BaseHTTPRequestHandler ): server_address = ( '' , 8000 ) httpd = server_class ( server_address , handler_class ) httpd . serve_forever () Now, look at some pre-defined Request Handler classes: class http . server . BaseHTTPRequestHandler This class is used to handle the HTTP requests that arrive at the server. By itself, it cannot respond to any actual HTTP requests; BaseHTTPRequestHandler just provides a number of class and instance variables, and methods for use by subclasses. It must be sub-classed to handle each request method (e.g. GET or POST). The handler will parse the request and the headers, then call a method specific to the request type. The method name is constructed from the request. For example, for the request method SPAM , the do_SPAM() method will be called with no arguments. All the relevant information is stored in instance variables of the handler. Subclasses should not need to override or extend the __init__() method. class http . server . SimpleHTTPRequestHandler This class serves files from the current directory and below, directly mapping the directory structure to HTTP requests. A lot of the work, such as parsing the request, is done by the base class BaseHTTPRequestHandler . This class implements the do_GET() and do_HEAD() functions. class http . server . CGIHTTPRequestHandler This class is used to serve either files or output of CGI scripts from the current directory and below. Note that mapping HTTP hierarchic structure to local directory structure is exactly as in SimpleHTTPRequestHandler . The class will however, run the CGI script, instead of serving it as a file, if it guesses it to be a CGI script. Only directory-based CGI are used \u2014 the other common server configuration is to treat special extensions as denoting CGI scripts. The do_GET() and do_HEAD() functions are modified to run CGI scripts and serve the output, instead of serving files, if the request leads to somewhere below the cgi_directories path. Let\u2019s start with SimpleHTTPRequestHandler which has some implemented features.","title":"Streaming Web server"},{"location":"blog/pi/stream-picamera-mjpeg/#request-handler","text":"Based on SimpleHTTPRequestHandler , create a new class StreamingHandler and only override do_GET() method to just print requested path and then call the base method as it is already implemented. from http.server import SimpleHTTPRequestHandler class StreamingHandler ( SimpleHTTPRequestHandler ): def do_GET ( self ): print ( self . path ) # call to the base method implemented in SimpleHTTPRequestHandler super () . do_GET () The SimpleHTTPRequestHandler will serve files in GET requests, and it will look for index.html for the homepage. To display image, create an image <img> tag which will request a file named stream.mjpg . < html > < head > < title > Picamea MJPEG Live Stream </ title > </ head > < body > <!-- Request MJPEG stream --> < img src = \"stream.mjpg\" /> </ body > </ html > There is no actual stream.mjpg file! . When the web page request stream.mjpg , web server should return a stream, not a single file, therefore a special sequence is needed to handle this special request of stream.mjpg file in the do_GET() method: Send response with HTTP Status Code 200 (Successful responses) Send header with information to notify web client about type of responded content, which is multipart/x-mixed-replace Send the content in a stream format (loop forever!): send the boundary FRAME , send content type of each frame image/jpeg , send the length of the content, and then send the actual image data from http.server import SimpleHTTPRequestHandler class StreamingHandler ( SimpleHTTPRequestHandler ): def do_GET ( self ): if self . path == '/stream.mjpg' : # response self . send_response ( 200 ) # header self . send_header ( 'Age' , 0 ) self . send_header ( 'Cache-Control' , 'no-cache, private' ) self . send_header ( 'Pragma' , 'no-cache' ) self . send_header ( 'Content-Type' , 'multipart/x-mixed-replace; boundary=FRAME' ) self . end_headers () try : while True : frame = frame_buffer . frame # need frame_buffer as global self . wfile . write ( b '--FRAME \\r\\n ' ) self . send_header ( 'Content-Type' , 'image/jpeg' ) self . send_header ( 'Content-Length' , len ( frame )) self . end_headers () self . wfile . write ( frame ) self . wfile . write ( b ' \\r\\n ' ) except Exception as e : print ( str ( e )) else : super () . do_GET () Finally, wrap them up by creating an instance of FrameBuffer , PiCamera , HTTPServer to start streaming: frame_buffer = FrameBuffer () camera = PiCamera ( resolution = '640x480' , framerate = 24 ) camera . start_recording ( frame_buffer , format = 'mjpeg' ) server_address = ( '' , 8000 ) handler_class = StreamingHandler # alias try : httpd = HTTPServer ( server_address , handler_class ) httpd . serve_forever () finally : camera . stop_recording () Bug: Hangup stream When run the above code, the web page shows up but with only one frame displayed, CPU is locked up at 100%, because the block while True : loop causes the problem. Need to find a way to synchronize between camera thread and web server thread: send a frame only when it is available.","title":"Request Handler"},{"location":"blog/pi/stream-picamera-mjpeg/#synchronize-between-threads","text":"Python has implemented a lock mechanism between threads: class threading . Condition ( lock = None ) This class implements condition variable objects. A condition variable allows one or more threads to wait until they are notified by another thread. If the lock argument is given and not None , it must be a Lock or RLock object, and it is used as the underlying lock. Otherwise, a new RLock object is created and used as the underlying lock. wait ( timeout = None ) Wait until notified or until a timeout occurs. If the calling thread has not acquired the lock when this method is called, a RuntimeError is raised. This method releases the underlying lock , and then blocks until it is awakened by a notify() or notify_all() call for the same condition variable in another thread, or until the optional timeout occurs. Once awakened or timed out, it re-acquires the lock and returns. notify_all () Wake up all threads waiting on this condition. This method acts like notify() , but wakes up all waiting threads instead of one. If the calling thread has not acquired the lock when this method is called, a RuntimeError is raised. Then add a Condition object in FrameBuffer , and use it in StreamingHandler : from threading import Condition class FrameBuffer ( object ): def __init__ ( self ): self . frame = None self . buffer = io . BytesIO () # synchronize between threads self . condition = Condition () def write ( self , buf ): if buf . startswith ( b ' \\xff\\xd8 ' ): with self . condition : self . buffer . seek ( 0 ) self . buffer . write ( buf ) self . buffer . truncate () self . frame = self . buffer . getvalue () # notify other threads self . condition . notify_all () class StreamingHandler ( SimpleHTTPRequestHandler ): def do_GET ( self ): if self . path == '/stream.mjpg' : ... try : while True : with frame_buffer . condition : # wait for a new frame frame_buffer . condition . wait () frame = frame_buffer . frame # access global variable, need to change later Wow, it works!!! the latency is just about 200ms which is unachievable with HLS/ MPEG-DASH streaming. However, the CPU usage is quite high, Pi Zero W only can handle 6 clients at the same time with video quality at 640x480 @25fps. A low latency in MJPEG streaming Hint Above sections are enough to create a simple MJPEG streaming server. Below sections are for an advanced implementation which need some advanced Python programming to create multiple buffers in an application, which can be used to merge or manipulate the image before sending to user\u2019s browsers.","title":"Synchronize between threads"},{"location":"blog/pi/stream-picamera-mjpeg/#some-updates-in-the-script","text":"The instance frame_buffer is used as a global variable in the StreamingHandler , it is not good if there is another FrameBuffer used for another stream in a same script. Here is an advanced method to have multiple frame buffers by passing an instance of FrameBuffer into an instance of StreamingHandler . It can be done by adding an Instance variable that holds reference to an instance of FrameBuffer , but can not be done using Class variable . Let\u2019s check how they work.","title":"Some updates in the script"},{"location":"blog/pi/stream-picamera-mjpeg/#class-variable","text":"Class variable is shared by all instance, therefore it acts like a global static attribute of the class. class StreamingHandler ( SimpleHTTPRequestHandler ): # class variable refers to an instance of FrameBuffer my_frame_buffer = None def do_GET ( self ): ... frame = self . my_frame_buffer . frame # create an instance of FrameBuffer frame_buffer = FrameBuffer () handler_class = StreamingHandler # alias # assign class variable handler_class . my_frame_buffer = frame_buffer # all instance will share class variables first_handler = StreamingHandler () second_handler = StreamingHandler () # first_handler.my_frame_buffer will be the same as second_handler.my_frame_buffer","title":"Class variable"},{"location":"blog/pi/stream-picamera-mjpeg/#instance-variable","text":"Instance variables are for the data unique to each instance, they are created in the __init()__ constructor of that class: class StreamingHandler ( SimpleHTTPRequestHandler ): def __init__ ( self , frame_buffer , request , client_address , server , directory = None ): self . my_frame_buffer = frame_buffer super () . __init__ ( request , client_address , server , directory ) def do_GET (): ... However, with this modification, script cannot use StreamingHandler to initialize ThreadingHTTPServer anymore, because it expects to call a request handler with only required positional arguments (request, client_address, server) , without a new argument frame_buffer . Therefore, write a function that convert expected parameters list to new parameters list: frame_buffer = FrameBuffer () def getStreamingHandler ( request , client_address , server ): return StreamingHandler ( frame_buffer , request , client_address , server ) httpd = ThreadingHTTPServer ( address , getStreamingHandler ) Well, it works, but the convert function actually drop the parameter directory which is an optional parameter in original constructor of SimpleHTTPRequestHandler . To solve this problem, let\u2019s use special *args and **kwargs parameters.","title":"Instance variable"},{"location":"blog/pi/stream-picamera-mjpeg/#args-and-kwargs","text":"The special *args and **kwargs parameters allow passing multiple arguments or keyword arguments to a function. Read about them in here . So, change the parameter list (request, client_address, server, ...) to *args in code, then it looks better: class StreamingHandler ( SimpleHTTPRequestHandler ): def __init__ ( self , frame_buffer , * args ): self . my_frame_buffer = frame_buffer super () . __init__ ( * args ) frame_buffer = FrameBuffer () def getStreamingHandler ( * args ): return StreamingHandler ( frame_buffer , * args ) httpd = ThreadingHTTPServer ( address , getStreamingHandler )","title":"*args and **kwargs"},{"location":"blog/pi/stream-picamera-mjpeg/#lambda-function","text":"Python and other languages like Java, C#, and even C++ have had lambda functions added to their syntax, whereas languages like LISP or the ML family of languages, Haskell, OCaml, and F#, use lambdas as a core concept. Read more in here So, reduce the function getStreamingHandler to a lambda function which can be declared in-line when creating ThreadingHTTPServer instance: frame_buffer = FrameBuffer () httpd = ThreadingHTTPServer ( address , lambda * args : StreamingHandler ( frame_buffer , * args ))","title":"Lambda function"},{"location":"blog/pi/stream-picamera-mjpeg/#measure-fps","text":"In the while loop of sending frames, use frame_count variable to count the number of processed frames. With time package, it is easy to calculate FPS over a defined period, for example, 5 seconds in below code: try : # tracking serving time start_time = time . time () frame_count = 0 # endless stream while True : with self . frames_buffer . condition : # wait for a new frame self . frames_buffer . condition . wait () # it's available, pick it up frame = self . frames_buffer . frame # send it ... # count frames frame_count += 1 # calculate FPS every 5s if ( time . time () - start_time ) > 5 : print ( \"FPS: \" , frame_count / ( time . time () - start_time )) frame_count = 0 start_time = time . time () ... Some lines of code to handle exception are also needed, for full source code, please download by clicking on the download button at the beginning of this post.","title":"Measure FPS"},{"location":"blog/pi/ubuntu/","tags":["raspberry-pi"],"text":"Ubuntu # Ubuntu Desktop comes with a rich desktop environment which consumes a bit high system resource and performance. Therefore, other lightweight version of Ubuntu will be chosen. In December 2019, Canonical published a support roadmap for the latest Raspberry Pi 4 single-board computer on their Ubuntu Server operating system and pledged to fully support Ubuntu on all Raspberry Pi boards. Ubuntu for Pi currently supports Raspberry Pi 2, Raspberry Pi 3, and Raspberry Pi 4 models, and images are available for the latest version of Ubuntu LTS. Old-releases archived images Visit https://old-releases.ubuntu.com/releases/ to see the full list of prebuilt images for older versions. Supported boards # Ubuntu supports : Raspberry Pi 2 Raspberry Pi 3 Raspberry Pi 4 Raspberry Pi 400 Raspberry Pi CM4 All boards have 2 version: 64-bit and 32-bit , except Raspberry Pi 2 which has only 32-bit version. 64-bit version This version is built for 64-bit mode of the CPU used in Raspberry Pi boards. It has arm64 tag in the image name. 32-bit version This version is built for 32-bit mode of the CPU used in Raspberry Pi boards. It has armhf tag in the image name. Choose an OS version Flash image to a microSD Card # Follow the instruction of using Etcher to flash the image. Launch Etcher and select the image file and the target SD card. The process will take a few minutes, so be patient. When Etcher is done, follow the headless mode setup if needed as the installed Ubuntu version is for server. SSH Create an empty file ssh at the root folder of the boot partition of the SD Card. UART Console By default, Ubuntu image enables the primary mini UART port, and also enables the Linux system console on that port. Connect a USB to TTL serial converter to GPIO 14 ( PIN8 ) and GPIO 15 ( PIN 10 ) to access the UART port. UART pins From https://pinout.xyz/pinout/uart : Primary UART pins Boot up Login with the default user: Login: ubuntu Password: ubuntu Right after the first time logging in, default password have to be changed. Wi-Fi setup # Starting from Ubuntu 18.04 LTS, Ubuntu uses Netplan to configure network interfaces by default. Netplan is a utility for configuring network interfaces on Linux. Netplan uses YAML files for configuring network interfaces. YAML configuration file format is really simple. It has clear and easy to understand syntax. Edit the Netplan YAML configuration file /etc/netplan/50-cloud-init.yaml with the following command: sudo nano /etc/netplan/50-cloud-init.yaml Add the Wi-Fi access information. Make sure not to use tab for space, use the spaces to create the blank. /etc/netplan/50-cloud-init.yaml # This file is generated from information provided by # the datasource. Changes to it will not persist across an instance. # To disable cloud-init's network configuration capabilities, write a file # /etc/cloud/cloud.cfg.d/99-disable-network-config.cfg with the following: # network: {config: disabled} network : version : 2 ethernets : eth0 : optional : true dhcp4 : true # add wifi setup information here ... wifis : wlan0 : optional : true access-points : \"YOUR-SSID-NAME\" : password : \"NETWORK-PASSWORD\" dhcp4 : true Change the SSID-NAME and the NETWORK-PASSWORD with the Wi-Fi AP information. Close and save the file using Ctrl + X and press yes. Now, check whether there\u2019s any error in the configuration file with the following command: sudo netplan --debug try If any error encounters then check with this command for detailed error information: sudo netplan --debug generate Apply the configuration file with the following command: sudo netplan --debug apply Setup priority # By default, Ethernet has higher priority to route network packets through it. Run: route -n This will show the metric value for eth0 is 100 and that value of wlan0 is 600. Lower value has higher priority. Destination Gateway Genmask Flags Metric Ref Use Iface 0.0.0.0 192.168.0.1 0.0.0.0 UG 100 0 0 eth0 0.0.0.0 192.168.1.1 0.0.0.0 UG 600 0 0 wlan0 192.168.0.0 0.0.0.0 255.255.255.0 U 0 0 0 eth0 192.168.0.1 0.0.0.0 255.255.255.255 UH 100 0 0 eth0 192.168.1.0 0.0.0.0 255.255.255.0 U 0 0 0 wlan0 192.168.1.1 0.0.0.0 255.255.255.255 UH 600 0 0 wlan0 To make Wi-Fi has higher priority, add a config line in Netplan configuration file: sudo nano /etc/netplan/50-cloud-init.yaml /etc/netplan/50-cloud-init.yaml wifis : wlan0 : access-points : \"SSID\" : password : \"pasword\" dhcp4 : true dhcp4-overrides : route-metric : 50 optional : true Then regenerate network configs and apply them: sudo netplan --debug generate && \\ sudo netplan --debug apply Run again: route -n to see the metric for wlan0 is now set to 50: Kernel IP routing table Destination Gateway Genmask Flags Metric Ref Use Iface 0.0.0.0 192.168.1.1 0.0.0.0 UG 50 0 0 wlan0 0.0.0.0 192.168.0.1 0.0.0.0 UG 100 0 0 eth0 192.168.0.0 0.0.0.0 255.255.255.0 U 0 0 0 eth0 192.168.0.1 0.0.0.0 255.255.255.255 UH 100 0 0 eth0 192.168.1.0 0.0.0.0 255.255.255.0 U 0 0 0 wlan0 192.168.1.1 0.0.0.0 255.255.255.255 UH 50 0 0 wlan0 Refer to https://netplan.io/reference/ for Netplan configuration. Install Desktop Environment # The installed Ubuntu version is for server which is designed to use minimal resources. To install a very lightweight desktop environment run bellow command: Update packages: sudo apt update && \\ sudo apt upgrade -y Install Unity desktop environment without addons: sudo apt install ubuntu-desktop --no-install-recommends Or install the lightweight Xubuntu desktop without addons: sudo apt install xubuntu-desktop --no-install-recommends Missing packages in a minimal installation The option --no-install-recommends will not install many bloat packages (offices, mail, etc.,) that helps to reduce download and install size. However, it may cause GUI does not show up. The most happened issue is missing fbdev which shown in the log: ~/.local/share/xorg/Xorg.0.log ... (WW) Warning, couldn't open module fbdev (EE) Failed to load module \"fbdev\" (module does not exist, 0) ... Fatal server error: (EE) no screens found(EE) ... To install fbdev , run: sudo apt install xserver-xorg-video-fbdev Lubuntu vs Xubuntu If you are looking for the most lightweight, Lubuntu is the choice to go. It uses the least system resources and comes with the fewest installed applications, unlike Xubuntu which packs some punch in polish and features meaning a lot more resource use. Xubuntu is relatively lightweight, as in, it\u2019s lighter than Ubuntu and Kubuntu but Lubuntu is extremely lightweight. Ubuntu Mate Ubuntu Mate is an alternative Ubuntu version using MATE desktop environment. The latest version is available at https://ubuntu-mate.org/download/ , while old releases are listed in https://releases.ubuntu-mate.org/archived .","title":"Run Ubuntu distro"},{"location":"blog/pi/ubuntu/#ubuntu","text":"Ubuntu Desktop comes with a rich desktop environment which consumes a bit high system resource and performance. Therefore, other lightweight version of Ubuntu will be chosen. In December 2019, Canonical published a support roadmap for the latest Raspberry Pi 4 single-board computer on their Ubuntu Server operating system and pledged to fully support Ubuntu on all Raspberry Pi boards. Ubuntu for Pi currently supports Raspberry Pi 2, Raspberry Pi 3, and Raspberry Pi 4 models, and images are available for the latest version of Ubuntu LTS. Old-releases archived images Visit https://old-releases.ubuntu.com/releases/ to see the full list of prebuilt images for older versions.","title":"Ubuntu"},{"location":"blog/pi/ubuntu/#supported-boards","text":"Ubuntu supports : Raspberry Pi 2 Raspberry Pi 3 Raspberry Pi 4 Raspberry Pi 400 Raspberry Pi CM4 All boards have 2 version: 64-bit and 32-bit , except Raspberry Pi 2 which has only 32-bit version. 64-bit version This version is built for 64-bit mode of the CPU used in Raspberry Pi boards. It has arm64 tag in the image name. 32-bit version This version is built for 32-bit mode of the CPU used in Raspberry Pi boards. It has armhf tag in the image name. Choose an OS version","title":"Supported boards"},{"location":"blog/pi/ubuntu/#flash-image-to-a-microsd-card","text":"Follow the instruction of using Etcher to flash the image. Launch Etcher and select the image file and the target SD card. The process will take a few minutes, so be patient. When Etcher is done, follow the headless mode setup if needed as the installed Ubuntu version is for server. SSH Create an empty file ssh at the root folder of the boot partition of the SD Card. UART Console By default, Ubuntu image enables the primary mini UART port, and also enables the Linux system console on that port. Connect a USB to TTL serial converter to GPIO 14 ( PIN8 ) and GPIO 15 ( PIN 10 ) to access the UART port. UART pins From https://pinout.xyz/pinout/uart : Primary UART pins Boot up Login with the default user: Login: ubuntu Password: ubuntu Right after the first time logging in, default password have to be changed.","title":"Flash image to a microSD Card"},{"location":"blog/pi/ubuntu/#wi-fi-setup","text":"Starting from Ubuntu 18.04 LTS, Ubuntu uses Netplan to configure network interfaces by default. Netplan is a utility for configuring network interfaces on Linux. Netplan uses YAML files for configuring network interfaces. YAML configuration file format is really simple. It has clear and easy to understand syntax. Edit the Netplan YAML configuration file /etc/netplan/50-cloud-init.yaml with the following command: sudo nano /etc/netplan/50-cloud-init.yaml Add the Wi-Fi access information. Make sure not to use tab for space, use the spaces to create the blank. /etc/netplan/50-cloud-init.yaml # This file is generated from information provided by # the datasource. Changes to it will not persist across an instance. # To disable cloud-init's network configuration capabilities, write a file # /etc/cloud/cloud.cfg.d/99-disable-network-config.cfg with the following: # network: {config: disabled} network : version : 2 ethernets : eth0 : optional : true dhcp4 : true # add wifi setup information here ... wifis : wlan0 : optional : true access-points : \"YOUR-SSID-NAME\" : password : \"NETWORK-PASSWORD\" dhcp4 : true Change the SSID-NAME and the NETWORK-PASSWORD with the Wi-Fi AP information. Close and save the file using Ctrl + X and press yes. Now, check whether there\u2019s any error in the configuration file with the following command: sudo netplan --debug try If any error encounters then check with this command for detailed error information: sudo netplan --debug generate Apply the configuration file with the following command: sudo netplan --debug apply","title":"Wi-Fi setup"},{"location":"blog/pi/ubuntu/#setup-priority","text":"By default, Ethernet has higher priority to route network packets through it. Run: route -n This will show the metric value for eth0 is 100 and that value of wlan0 is 600. Lower value has higher priority. Destination Gateway Genmask Flags Metric Ref Use Iface 0.0.0.0 192.168.0.1 0.0.0.0 UG 100 0 0 eth0 0.0.0.0 192.168.1.1 0.0.0.0 UG 600 0 0 wlan0 192.168.0.0 0.0.0.0 255.255.255.0 U 0 0 0 eth0 192.168.0.1 0.0.0.0 255.255.255.255 UH 100 0 0 eth0 192.168.1.0 0.0.0.0 255.255.255.0 U 0 0 0 wlan0 192.168.1.1 0.0.0.0 255.255.255.255 UH 600 0 0 wlan0 To make Wi-Fi has higher priority, add a config line in Netplan configuration file: sudo nano /etc/netplan/50-cloud-init.yaml /etc/netplan/50-cloud-init.yaml wifis : wlan0 : access-points : \"SSID\" : password : \"pasword\" dhcp4 : true dhcp4-overrides : route-metric : 50 optional : true Then regenerate network configs and apply them: sudo netplan --debug generate && \\ sudo netplan --debug apply Run again: route -n to see the metric for wlan0 is now set to 50: Kernel IP routing table Destination Gateway Genmask Flags Metric Ref Use Iface 0.0.0.0 192.168.1.1 0.0.0.0 UG 50 0 0 wlan0 0.0.0.0 192.168.0.1 0.0.0.0 UG 100 0 0 eth0 192.168.0.0 0.0.0.0 255.255.255.0 U 0 0 0 eth0 192.168.0.1 0.0.0.0 255.255.255.255 UH 100 0 0 eth0 192.168.1.0 0.0.0.0 255.255.255.0 U 0 0 0 wlan0 192.168.1.1 0.0.0.0 255.255.255.255 UH 50 0 0 wlan0 Refer to https://netplan.io/reference/ for Netplan configuration.","title":"Setup priority"},{"location":"blog/pi/ubuntu/#install-desktop-environment","text":"The installed Ubuntu version is for server which is designed to use minimal resources. To install a very lightweight desktop environment run bellow command: Update packages: sudo apt update && \\ sudo apt upgrade -y Install Unity desktop environment without addons: sudo apt install ubuntu-desktop --no-install-recommends Or install the lightweight Xubuntu desktop without addons: sudo apt install xubuntu-desktop --no-install-recommends Missing packages in a minimal installation The option --no-install-recommends will not install many bloat packages (offices, mail, etc.,) that helps to reduce download and install size. However, it may cause GUI does not show up. The most happened issue is missing fbdev which shown in the log: ~/.local/share/xorg/Xorg.0.log ... (WW) Warning, couldn't open module fbdev (EE) Failed to load module \"fbdev\" (module does not exist, 0) ... Fatal server error: (EE) no screens found(EE) ... To install fbdev , run: sudo apt install xserver-xorg-video-fbdev Lubuntu vs Xubuntu If you are looking for the most lightweight, Lubuntu is the choice to go. It uses the least system resources and comes with the fewest installed applications, unlike Xubuntu which packs some punch in polish and features meaning a lot more resource use. Xubuntu is relatively lightweight, as in, it\u2019s lighter than Ubuntu and Kubuntu but Lubuntu is extremely lightweight. Ubuntu Mate Ubuntu Mate is an alternative Ubuntu version using MATE desktop environment. The latest version is available at https://ubuntu-mate.org/download/ , while old releases are listed in https://releases.ubuntu-mate.org/archived .","title":"Install Desktop Environment"},{"location":"blog/ros/","text":"","title":"Robot Operating System (ROS)"},{"location":"blog/ros/beginner-guide-1/","tags":["ros"],"text":"This guide was created by using ROS Melodic on Ubuntu 18.04 LTS . The official guide is at https://wiki.ros.org/ROS/Tutorials . An ebook for further reference: A Gentle Introduction to ROS by Jason M. O\u2019Kane . Install ROS # There is more than one ROS distribution supported at a time. Some are older releases with long term support, making them more stable, while others are newer with shorter support life times, but with binaries for more recent platforms and more recent versions of the ROS packages that make them up. Recommend ones of the versions below: ROS Melodic Morenia Released May, 2018 LTS until May, 2023 Recommended for Ubuntu 18.04 ROS Noetic Ninjemys Released May, 2020 LTS until May, 2025 Recommended for Ubuntu 20.04 What is the difference between ROS Melodic model and Noetic model? There aren\u2019t many differences at the base level. The ROS Noetic is recommended for Ubuntu 20.04 whereas ROS Melodic for Ubuntu 18.04: Feature ROS Noetic ROS Melodic Python 3.8 2.7 Gazebo 11.x 9.0 OpenCV 4.2 3.2 Detailed comparison is at repositories.ros.org . Choose the ROS version based on the installed OS. Here, Melodic is used on Ubuntu 18.04 . Configure repositories # Configure the Ubuntu repositories to allow \u201crestricted,\u201d \u201cuniverse,\u201d and \u201cmultiverse\u201d by following the Ubuntu guide . Setup source list to get ROS packages: sudo sh -c 'echo \"deb http://packages.ros.org/ros/ubuntu $(lsb_release -sc) main\" > /etc/apt/sources.list.d/ros-latest.list' Add keys: sudo apt install -y curl && \\ curl -s https://raw.githubusercontent.com/ros/rosdistro/master/ros.asc | sudo apt-key add - Then pull the package list: sudo apt update Finally, install a desktop-full package as recommended to start learning: sudo apt install -y ros-melodic-desktop-full && \\ sudo apt install -y ros-melodic-rqt && \\ sudo apt install -y ros-melodic-rqt-common-plugins It\u2019s convenient if the ROS environment variables are automatically added to a bash session every time a new shell is launched: echo \"source /opt/ros/melodic/setup.bash\" >> ~/.bashrc && \\ source ~/.bashrc A good way to check the installation is to ensure that environment variables like ROS_ROOT and ROS_PACKAGE_PATH are set: printenv | grep ROS ROS_ETC_DIR = /opt/ros/melodic/etc/ros ROS_ROOT = /opt/ros/melodic/share/ros ROS_MASTER_URI = http://localhost:11311 ROS_VERSION = 1 ROS_PYTHON_VERSION = 2 ROS_PACKAGE_PATH = /opt/ros/melodic/share ROSLISP_PACKAGE_DIRECTORIES = ROS_DISTRO = melodic Build packages # Build packages are needed for code compilation. sudo apt install -y python-rosdep python-rosinstall python-rosinstall-generator python-wstool build-essential Initialize the package rosdep to track package dependency: sudo rosdep init && \\ rosdep update ROS Workspace # A catkin workspace is a folder where to modify, build, and install catkin packages. The catkin_make command is a convenience tool for working with catkin workspaces. Running it the first time in a workspace, it will create a CMakeLists.txt link in the \u2018src\u2019 folder. mkdir -p catkin_ws/src && \\ cd catkin_ws && \\ catkin_make In the current directory, it should now have a build and devel folder. Inside the devel folder, there are now several setup.*sh files. Sourcing any of these files will overlay this workspace on top of current environment. source devel/setup.bash To make sure workspace is properly overlaid by the setup script, make sure ROS_PACKAGE_PATH environment variable includes the current workspace directory. echo $ROS_PACKAGE_PATH /home/vqtrong/Work/catkin_ws/src:/opt/ros/melodic/share This also helps ROS to find new packages. The ROS File system # For this tutorial, to inspect a package in ros-tutorials , please install a prebuilt package using: sudo apt install -y ros-melodic-ros-tutorials Two main concepts of the File Systems: Packages are the software organization unit of ROS code. Each package can contain libraries, executables, scripts, or other artifacts. Manifests (package.xml) is a description of a package. It serves to define dependencies between packages and to capture meta information about the package like version, maintainer, license, etc\u2026 Code is spread across many ROS packages. Navigating with command-line tools such as ls and cd can be very tedious which is why ROS provides tools to help. File system Tools # rospack allows getting information about packages. rospack find roscpp roscd allows changing directory ( cd ) directly to a package, and also is able to move to a subdirectory of a package roscd roscpp # go to cpp package roscd roscpp/cmake # go to cmake folder inside the cpp package roscd log # go to the log folder, available after run roscore Create a ROS Package # Firstly, use the catkin_create_pkg script to create a new package called beginner_tutorials which depends on std_msgs , roscpp , and rospy : catkin_ws/ cd src && \\ catkin_create_pkg beginner_tutorials std_msgs rospy roscpp This will create a beginner_tutorials folder which contains a package.xml and a CMakeLists.txt , which have been partially filled out with the information given in the catkin_create_pkg command. Build that new workspace again to see beginner_tutorials is added into build folder: catkin_ws/src/ cd .. && \\ catkin_make Add the workspace to the ROS environment: source devel/setup.bash To check the direct dependencies of a package: rospack depends1 beginner_tutorials To check the indirect dependencies of a package: rospack depends beginner_tutorials ROS Nodes # Quick overview of Graph Concepts: Nodes : A node is an executable that uses ROS to communicate with other nodes. Messages : ROS data type used when subscribing or publishing to a topic. Topics : Nodes can publish messages to a topic as well as subscribe to a topic to receive messages. Master : Name service for ROS (i.e. helps nodes find each other) Rosout : ROS equivalent of stdout/stderr Roscore : Master + Rosout + Ros parameter server (parameter server will be introduced later) Roscore # roscore will start up a ROS Master, a ROS Parameter Server and a Rosout logging node Options: -h, --help # show this help message and exit -p, --port = # master port. Only valid if master is launched -v # verbose printing -w, --numworkers = # override number of worker threads -t, --timeout = # override the socket connection timeout (in seconds). --master-logger-level = # set logger level # ('debug', 'info', 'warn', 'error', 'fatal') See more in http://wiki.ros.org/roscore . Rosnode # rosnode is a command-line tool for printing information about ROS Nodes. Commands: rosnode ping # test connectivity to node rosnode list # list active nodes rosnode info # print information about node rosnode machine # list nodes running on a particular machine rosnode kill # kill a running node rosnode cleanup # purge registration information of unreachable nodes Type rosnode <command> -h for more detailed usage. Rosrun # The syntax for rosrun is: rosrun [ --prefix cmd ] [ --debug ] PACKAGE EXECUTABLE [ ARGS ] The tool rosrun will locate PACKAGE and try to find an executable named EXECUTABLE in the PACKAGE tree. If it finds it, it will run it with ARGS . Start with this guide, run the turtlesim_node in the turtlesim package: rosrun turtlesim turtlesim_node Turtle sim ROS Topics # Run turtle keyboard turtle_teleop_key node in a new terminal: rosrun turtlesim turtle_teleop_key After that, the turtle can be moved by using keyboard arrow keys. The turtlesim_node and the turtle_teleop_key node are communicating with each other over a ROS Topic. turtle_teleop_key is publishing the keystrokes on a topic, while turtlesim subscribes to the same topic to receive the keystrokes. Rqt_graph # The rqt_graph tool creates a dynamic graph of what\u2019s going on in the system. rqt_graph is part of the rqt package. sudo apt install -y ros-melodic-rqt && \\ sudo apt install -y ros-melodic-rqt-common-plugins Run rqt_graph in a new terminal: rosrun rqt_graph rqt_graph The turtlesim_node and the turtle_teleop_key nodes are communicating on the topic named /turtle1/command_vel . RosGraph Rostopic # The rostopic tool allows getting information about ROS topics. rostopic bw # display bandwidth used by topic rostopic echo # print messages to screen rostopic hz # display publishing rate of topic rostopic list # print information about active topics rostopic pub # publish data to topic rostopic type # print topic type ROS Messages # Communication on topics happens by sending ROS messages between nodes. For the publisher ( turtle_teleop_key ) and subscriber ( turtlesim_node ) to communicate, the publisher and subscriber must send and receive the same type of message. This means that a topic type is defined by the message type published on it. The type of the message sent on a topic can be determined using rostopic type. rostopic type /turtle1/cmd_vel geometry_msgs/Twist The command rosmsg show prints out the details of the message: rosmsg show geometry_msgs/Twist geometry_msgs/Vector3 linear float64 x float64 y float64 z geometry_msgs/Vector3 angular float64 x float64 y float64 z Publish a message # A message can be published through command line: rostopic pub [ topic ] [ msg_type ] [ args ] For example, to send one message on the topic /turtle1/cmd_vel using message type geometry_msgs/Twist and its required -- parameters '[2.0, 0.0, 0.0]' '[0.0, 0.0, 1.8]' , enter the below command: rostopic pub -1 \\ /turtle1/cmd_vel \\ geometry_msgs/Twist \\ -- '[2.0, 0.0, 0.0]' '[0.0, 0.0, 1.8]' To continuously send message at the rate of 1Hz, use -r 1 options: rostopic pub -r 1 \\ /turtle1/cmd_vel \\ geometry_msgs/Twist \\ -- '[2.0, 0.0, 0.0]' '[0.0, 0.0, -1.8]' The rate of message can be inspected by using the command rostopic hz : rostopic hz /turtle1/pose Rqt_plot # The rqt_plot tool displays a scrolling time plot of the data published on topics: rosrun rqt_plot rqt_plot In the new window that should pop up, a text box in the upper left corner gives the ability to add any topic to the plot. Typing /turtle1/pose/x will highlight the plus button, previously disabled. Press it and repeat the same procedure with the topic /turtle1/pose/y . Now the turtle\u2019s x-y location is plotted in the graph. RosPlot ROS Services # Services are another way that nodes can communicate with each other. Services allow nodes to send a request and receive a response . A rosservice can easily be attached to ROS\u2019s client/service framework with services. Commands that can be used on services are: rosservice list # print information about active services rosservice call # call the service with the provided args rosservice type # print service type rosservice find # find services by service type rosservice uri # print service ROSRPC uri Let\u2019s see current services: rosservice list /clear /kill /reset /rosout/get_loggers /rosout/set_logger_level /spawn /turtle1/set_pen /turtle1/teleport_absolute /turtle1/teleport_relative /turtlesim/get_loggers /turtlesim/set_logger_level Check the parameter of a service: rosservice type /clear std_srvs/Empty The /clear service shows an Empty parameter, but the /spawn has 4 parameter and returns string: rosservice type /spawn turtlesim/Spawn rosservice type /spawn | rossrv show float32 x float32 y float32 theta string name --- string name The input parameter are x , y , theta and name , and the output is name . Ok, let\u2019s clear the background and spawn a new turtle: rosservice call /clear && \\ rosservice call /spawn 2 2 0 .2 \"\" Rosparam # The rosparam tool allows storing and manipulate data on the ROS Parameter Server. The Parameter Server can store integers, floats, boolean, dictionaries, and lists. rosparam uses the YAML markup language for syntax. In simple cases, YAML looks very natural: 1 is an integer, 1.0 is a float, one is a string, true is a boolean, [1, 2, 3] is a list of integers, and {a: b, c: d} is a dictionary. rosparam has many commands that can be used on parameters, as shown below: rosparam set # set parameter rosparam get # get parameter rosparam load # load parameters from file rosparam dump # dump parameters to file rosparam delete # delete parameter rosparam list # list parameter names See the list of parameters: rosparam list /rosdistro /roslaunch/uris/host_ubuntu18__43509 /rosversion /run_id /turtlesim/background_b /turtlesim/background_g /turtlesim/background_r Here will change the red channel of the background color: rosparam set /turtlesim/background_r 150 Use get command to see the parameters: rosparam get / && \\ rosparam get /turtlesim/background_g dump and load option are also available: rosparam dump [ file_name ] [ namespace ] rosparam load [ file_name ] [ namespace ] For example: rosparam dump params.yaml will create a file params.yaml with the content similar to: rosdistro : \"melodic \" roslaunch : uris : { host_ubuntu18__43509 : \"http://ubuntu18:43509/\" } rosversion : \"1.14.11 \" run_id : 409b84fc-e2ff-11eb-be5c-080027b61567 turtlesim : { background_b : 255 , background_g : 86 , background_r : 150 } ROS Console # The command rqt_console attaches to ROS\u2019s logging framework to display output from nodes. rqt_logger_level allows to change the verbosity level ( DEBUG , WARN , INFO , and ERROR ) of nodes as they run. rosrun rqt_console rqt_console && \\ rosrun rqt_logger_level rqt_logger_level ROS Console and Logger Level Logging levels are prioritized in the following order: Fatal Error Warn Info Debug The Fatal level has the highest priority and Debug level has the lowest. By setting the logger level, logger will show all messages of that priority level or higher. For example, by setting the level to Warn , it will get all Warn , Error , and Fatal logging messages. ROS Launch # The roslaunch command starts nodes as defined in a launch file. roslaunch [ package ] [ filename.launch ] Starting with the beginner_tutorials package: cd catkin_ws && \\ source devel/setup.bash && \\ roscd beginner_tutorials vqtrong@ubuntu18:~/Work/catkin_ws/src/beginner_tutorials$ Then let\u2019s make a launch directory: mkdir launch && \\ cd launch Now let\u2019s create a launch file called turtlemimic.launch and paste the following: <launch> <group ns= \"turtlesim1\" > <node pkg= \"turtlesim\" name= \"sim\" type= \"turtlesim_node\" /> </group> <group ns= \"turtlesim2\" > <node pkg= \"turtlesim\" name= \"sim\" type= \"turtlesim_node\" /> </group> <node pkg= \"turtlesim\" name= \"mimic\" type= \"mimic\" > <remap from= \"input\" to= \"turtlesim1/turtle1\" /> <remap from= \"output\" to= \"turtlesim2/turtle1\" /> </node> </launch> Notes: Two groups with a namespace tag of turtlesim1 and turtlesim2 are created from a turtlesim node with a name of sim . This allows to start two simulators without having name conflicts. The mimic node with the topics input and output remapped to turtlesim1 and turtlesim2 . This renaming will cause turtlesim2 to mimic turtlesim1 . Roslaunch # Start the launch file: roslaunch beginner_tutorials turtlemimic.launch And post messages to the first turtle: rostopic pub /turtlesim1/turtle1/cmd_vel geometry_msgs/Twist -r 1 -- '[2.0, 0.0, 0.0]' '[0.0, 0.0, -1.8]' Run the rqt_graph to see what is going on: rqt_graph Turtle mimic nodes graph Playback data # This tutorial will teach how to record data from a running ROS system into a .bag file, and then to play back the data to produce similar behavior in a running system. Record data # First, execute the following commands in separate terminals: Terminal 1: roscore Terminal 2: rosrun turtlesim turtlesim_node Terminal 3: rosrun turtlesim turtle_teleop_key This will start two nodes \u2014 the turtlesim visualizer and a node that allows for the keyboard control of turtlesim using the arrows keys on the keyboard. Let\u2019s examine the full list of topics that are currently being published in the running system. To do this, open a new terminal and execute the command: rostopic list -v Published topics: * /turtle1/color_sensor [ turtlesim/Color ] 1 publisher * /turtle1/cmd_vel [ geometry_msgs/Twist ] 1 publisher * /rosout [ rosgraph_msgs/Log ] 2 publishers * /rosout_agg [ rosgraph_msgs/Log ] 1 publisher * /turtle1/pose [ turtlesim/Pose ] 1 publisher Subscribed topics: * /turtle1/cmd_vel [ geometry_msgs/Twist ] 1 subscriber * /rosout [ rosgraph_msgs/Log ] 1 subscriber The list of published topics is the only message types that could potentially be recorded in the data log file, as only published messages are recorded: The topic /turtle1/cmd_vel is the command message published by the teleop_turtle node that is taken as input by the turtlesim process. The messages /turtle1/color_sensor and /turtle1/pose are output messages published by turtlesim . Open a new terminal window. In this window run the following commands. Running rosbag record with the option -a indicates that all published topics should be accumulated in a bag file. roscd beginner_tutorials && \\ mkdir bagfiles && \\ cd bagfiles && \\ rosbag record -a [ INFO ] [ 1626862434 .586239631 ] : Recording to '2021-07-21-17-13-54.bag' . [ INFO ] [ 1626862434 .587320465 ] : Subscribing to /turtle1/color_sensor [ INFO ] [ 1626862434 .589356574 ] : Subscribing to /turtle1/cmd_vel [ INFO ] [ 1626862434 .591447646 ] : Subscribing to /rosout [ INFO ] [ 1626862434 .593544025 ] : Subscribing to /rosout_agg [ INFO ] [ 1626862434 .595557444 ] : Subscribing to /turtle1/pose Move back to the terminal window with turtle_teleop and move the turtle around for 10 or so seconds. Rosbag info # Run the command rosbag info to see the info of a rosbag file: rosbag info <bagfile> path: xxx.bag version: 2 .0 duration: 2 :21s ( 141s ) start: xxx end: xxx size: 1 .3 MB messages: 18150 compression: none [ 2 /2 chunks ] types: geometry_msgs/Twist [ 9f195f881246fdfa2798d1d3eebca84a ] rosgraph_msgs/Log [ acffd30cd6b6de30f120938c17c593fb ] turtlesim/Color [ 353891e354491c51aabe32df673fb446 ] turtlesim/Pose [ 863b248d5016ca62ea2e895ae5265cf9 ] topics: /rosout 217 msgs : rosgraph_msgs/Log ( 2 connections ) /rosout_agg 214 msgs : rosgraph_msgs/Log /turtle1/cmd_vel 286 msgs : geometry_msgs/Twist /turtle1/color_sensor 8716 msgs : turtlesim/Color /turtle1/pose 8717 msgs : turtlesim/Pose Rosbag play # The next step in this tutorial is to replay the bag file to reproduce behavior in the running system. First kill the tele-operator program that may be still running from the previous section. Leave turtlesim running. In a terminal window run the following command: rosbag play <bagfile> In its default mode rosbag play will wait for a certain period (.2 seconds) after advertising each message before it actually begins publishing the contents of the bag file. Waiting for some duration allows any subscriber of a message to be alerted that the message has been advertised and that messages may follow. If rosbag play publishes messages immediately upon advertising, subscribers may not receive the first several published messages. The waiting period can be specified with the -d option. Recording a subset # When running a complicated system, such as the pr2 software suite, there may be hundreds of topics being published, with some topics, like camera image streams, potentially publishing huge amounts of data. In such a system it is often impractical to write log files consisting of all topics to disk in a single bag file. The rosbag record command supports logging only particular topics to a bag file, allowing users to only record the topics of interest to them. rosbag record -O subset /turtle1/cmd_vel /turtle1/pose The -O argument tells rosbag record to log to a file named subset.bag , and the topic arguments cause rosbag record to only subscribe to these two topics. The limitations of rosbag record/play Different start condition can cause different results even the events are the same. The rate of recorded events is not guaranteed to be the same as the real actions. Read Rosbag message # The script ros_readbagfile will read rosbag file and extract all messages of selected topics: ros_readbagfile <mybagfile.bag> [ info ] [ N ] [ topic1 ] [ topic2 ] [ ... ] Download and install ros_readbag.py using below command: cd ~ && \\ wget https://raw.githubusercontent.com/vuquangtrong/ \\ ros_readbagfile/main/ros_readbagfile Edit the shebang to use python 2 if needed. Change #!/usr/bin/python3 to #!/usr/bin/python . Make it executable: chmod +x ros_readbagfile The ~/bin directory for personal binaries: mkdir -p ~/bin Add this folder to the PATH : echo \"PATH=\\\" $PATH :~/bin\\\"\" >> ~/.bashrc Move this executable script into that directory as ros_readbagfile , so that it will be available as that command: mv ros_readbagfile ~/bin/ros_readbagfile Usage See the information of the input bag file: ros_readbagfile mybagfile.bag info Print all messages of all topics in the bag file to the screen: ros_readbagfile mybagfile.bag Print all messages of the topic /test in the bag file to the screen: ros_readbagfile mybagfile.bag /test Print at most N first messages of all topics in the bag file to the screen: ros_readbagfile mybagfile.bag N Print at most N first messages of the topic /test in the bag file to the screen: ros_readbagfile mybagfile.bag N /test To save the output to a file, use redirection syntax: ros_readbagfile mybagfile.bag N /test > output.txt Determine the exact topic names you\u2019d like to read from the bag file, by using rosbag info as mentioned above, or use ros_readbagfile info command: Use ros_readbagfile from terminal as below: rosbag info 2021 -07-21-17-13-54.bag path: 2021 -07-21-17-13-54.bag version: 2 .0 duration: 30 .8s start: Jul 21 2021 17 :13:54.60 ( 1626862434 .60 ) end: Jul 21 2021 17 :14:25.40 ( 1626862465 .40 ) size: 280 .8 KB messages: 3895 compression: none [ 1 /1 chunks ] types: geometry_msgs/Twist [ 9f195f881246fdfa2798d1d3eebca84a ] rosgraph_msgs/Log [ acffd30cd6b6de30f120938c17c593fb ] turtlesim/Color [ 353891e354491c51aabe32df673fb446 ] turtlesim/Pose [ 863b248d5016ca62ea2e895ae5265cf9 ] topics: /rosout 4 msgs : rosgraph_msgs/Log ( 2 connections ) /turtle1/cmd_vel 93 msgs : geometry_msgs/Twist /turtle1/color_sensor 1899 msgs : turtlesim/Color /turtle1/pose 1899 msgs : turtlesim/Pose Now, get all messages of the topic /turtle1/pose and save to the file: ros_readbagfile 2021 -07-21-17-13-54.bag /turtle1/pose > turtle1_pose.yaml # ======================================= # topic: /turtle1/pose # msg_count: 1899 # timestamp (sec): 1626862465.397807837 # - - - x: 10 .0430784225 y: 6 .37491464615 theta: -2.62400007248 linear_velocity: 0 .0 angular_velocity: 0 .0 # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ # Total messages found: 1899 # # /turtle1/pose: 1899 # # DONE. # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~","title":"Beginner Guide 1 - Definitions"},{"location":"blog/ros/beginner-guide-1/#install-ros","text":"There is more than one ROS distribution supported at a time. Some are older releases with long term support, making them more stable, while others are newer with shorter support life times, but with binaries for more recent platforms and more recent versions of the ROS packages that make them up. Recommend ones of the versions below: ROS Melodic Morenia Released May, 2018 LTS until May, 2023 Recommended for Ubuntu 18.04 ROS Noetic Ninjemys Released May, 2020 LTS until May, 2025 Recommended for Ubuntu 20.04 What is the difference between ROS Melodic model and Noetic model? There aren\u2019t many differences at the base level. The ROS Noetic is recommended for Ubuntu 20.04 whereas ROS Melodic for Ubuntu 18.04: Feature ROS Noetic ROS Melodic Python 3.8 2.7 Gazebo 11.x 9.0 OpenCV 4.2 3.2 Detailed comparison is at repositories.ros.org . Choose the ROS version based on the installed OS. Here, Melodic is used on Ubuntu 18.04 .","title":"Install ROS"},{"location":"blog/ros/beginner-guide-1/#configure-repositories","text":"Configure the Ubuntu repositories to allow \u201crestricted,\u201d \u201cuniverse,\u201d and \u201cmultiverse\u201d by following the Ubuntu guide . Setup source list to get ROS packages: sudo sh -c 'echo \"deb http://packages.ros.org/ros/ubuntu $(lsb_release -sc) main\" > /etc/apt/sources.list.d/ros-latest.list' Add keys: sudo apt install -y curl && \\ curl -s https://raw.githubusercontent.com/ros/rosdistro/master/ros.asc | sudo apt-key add - Then pull the package list: sudo apt update Finally, install a desktop-full package as recommended to start learning: sudo apt install -y ros-melodic-desktop-full && \\ sudo apt install -y ros-melodic-rqt && \\ sudo apt install -y ros-melodic-rqt-common-plugins It\u2019s convenient if the ROS environment variables are automatically added to a bash session every time a new shell is launched: echo \"source /opt/ros/melodic/setup.bash\" >> ~/.bashrc && \\ source ~/.bashrc A good way to check the installation is to ensure that environment variables like ROS_ROOT and ROS_PACKAGE_PATH are set: printenv | grep ROS ROS_ETC_DIR = /opt/ros/melodic/etc/ros ROS_ROOT = /opt/ros/melodic/share/ros ROS_MASTER_URI = http://localhost:11311 ROS_VERSION = 1 ROS_PYTHON_VERSION = 2 ROS_PACKAGE_PATH = /opt/ros/melodic/share ROSLISP_PACKAGE_DIRECTORIES = ROS_DISTRO = melodic","title":"Configure repositories"},{"location":"blog/ros/beginner-guide-1/#build-packages","text":"Build packages are needed for code compilation. sudo apt install -y python-rosdep python-rosinstall python-rosinstall-generator python-wstool build-essential Initialize the package rosdep to track package dependency: sudo rosdep init && \\ rosdep update","title":"Build packages"},{"location":"blog/ros/beginner-guide-1/#ros-workspace","text":"A catkin workspace is a folder where to modify, build, and install catkin packages. The catkin_make command is a convenience tool for working with catkin workspaces. Running it the first time in a workspace, it will create a CMakeLists.txt link in the \u2018src\u2019 folder. mkdir -p catkin_ws/src && \\ cd catkin_ws && \\ catkin_make In the current directory, it should now have a build and devel folder. Inside the devel folder, there are now several setup.*sh files. Sourcing any of these files will overlay this workspace on top of current environment. source devel/setup.bash To make sure workspace is properly overlaid by the setup script, make sure ROS_PACKAGE_PATH environment variable includes the current workspace directory. echo $ROS_PACKAGE_PATH /home/vqtrong/Work/catkin_ws/src:/opt/ros/melodic/share This also helps ROS to find new packages.","title":"ROS Workspace"},{"location":"blog/ros/beginner-guide-1/#the-ros-file-system","text":"For this tutorial, to inspect a package in ros-tutorials , please install a prebuilt package using: sudo apt install -y ros-melodic-ros-tutorials Two main concepts of the File Systems: Packages are the software organization unit of ROS code. Each package can contain libraries, executables, scripts, or other artifacts. Manifests (package.xml) is a description of a package. It serves to define dependencies between packages and to capture meta information about the package like version, maintainer, license, etc\u2026 Code is spread across many ROS packages. Navigating with command-line tools such as ls and cd can be very tedious which is why ROS provides tools to help.","title":"The ROS File system"},{"location":"blog/ros/beginner-guide-1/#file-system-tools","text":"rospack allows getting information about packages. rospack find roscpp roscd allows changing directory ( cd ) directly to a package, and also is able to move to a subdirectory of a package roscd roscpp # go to cpp package roscd roscpp/cmake # go to cmake folder inside the cpp package roscd log # go to the log folder, available after run roscore","title":"File system Tools"},{"location":"blog/ros/beginner-guide-1/#create-a-ros-package","text":"Firstly, use the catkin_create_pkg script to create a new package called beginner_tutorials which depends on std_msgs , roscpp , and rospy : catkin_ws/ cd src && \\ catkin_create_pkg beginner_tutorials std_msgs rospy roscpp This will create a beginner_tutorials folder which contains a package.xml and a CMakeLists.txt , which have been partially filled out with the information given in the catkin_create_pkg command. Build that new workspace again to see beginner_tutorials is added into build folder: catkin_ws/src/ cd .. && \\ catkin_make Add the workspace to the ROS environment: source devel/setup.bash To check the direct dependencies of a package: rospack depends1 beginner_tutorials To check the indirect dependencies of a package: rospack depends beginner_tutorials","title":"Create a ROS Package"},{"location":"blog/ros/beginner-guide-1/#ros-nodes","text":"Quick overview of Graph Concepts: Nodes : A node is an executable that uses ROS to communicate with other nodes. Messages : ROS data type used when subscribing or publishing to a topic. Topics : Nodes can publish messages to a topic as well as subscribe to a topic to receive messages. Master : Name service for ROS (i.e. helps nodes find each other) Rosout : ROS equivalent of stdout/stderr Roscore : Master + Rosout + Ros parameter server (parameter server will be introduced later)","title":"ROS Nodes"},{"location":"blog/ros/beginner-guide-1/#roscore","text":"roscore will start up a ROS Master, a ROS Parameter Server and a Rosout logging node Options: -h, --help # show this help message and exit -p, --port = # master port. Only valid if master is launched -v # verbose printing -w, --numworkers = # override number of worker threads -t, --timeout = # override the socket connection timeout (in seconds). --master-logger-level = # set logger level # ('debug', 'info', 'warn', 'error', 'fatal') See more in http://wiki.ros.org/roscore .","title":"Roscore"},{"location":"blog/ros/beginner-guide-1/#rosnode","text":"rosnode is a command-line tool for printing information about ROS Nodes. Commands: rosnode ping # test connectivity to node rosnode list # list active nodes rosnode info # print information about node rosnode machine # list nodes running on a particular machine rosnode kill # kill a running node rosnode cleanup # purge registration information of unreachable nodes Type rosnode <command> -h for more detailed usage.","title":"Rosnode"},{"location":"blog/ros/beginner-guide-1/#rosrun","text":"The syntax for rosrun is: rosrun [ --prefix cmd ] [ --debug ] PACKAGE EXECUTABLE [ ARGS ] The tool rosrun will locate PACKAGE and try to find an executable named EXECUTABLE in the PACKAGE tree. If it finds it, it will run it with ARGS . Start with this guide, run the turtlesim_node in the turtlesim package: rosrun turtlesim turtlesim_node Turtle sim","title":"Rosrun"},{"location":"blog/ros/beginner-guide-1/#ros-topics","text":"Run turtle keyboard turtle_teleop_key node in a new terminal: rosrun turtlesim turtle_teleop_key After that, the turtle can be moved by using keyboard arrow keys. The turtlesim_node and the turtle_teleop_key node are communicating with each other over a ROS Topic. turtle_teleop_key is publishing the keystrokes on a topic, while turtlesim subscribes to the same topic to receive the keystrokes.","title":"ROS Topics"},{"location":"blog/ros/beginner-guide-1/#rqt_graph","text":"The rqt_graph tool creates a dynamic graph of what\u2019s going on in the system. rqt_graph is part of the rqt package. sudo apt install -y ros-melodic-rqt && \\ sudo apt install -y ros-melodic-rqt-common-plugins Run rqt_graph in a new terminal: rosrun rqt_graph rqt_graph The turtlesim_node and the turtle_teleop_key nodes are communicating on the topic named /turtle1/command_vel . RosGraph","title":"Rqt_graph"},{"location":"blog/ros/beginner-guide-1/#rostopic","text":"The rostopic tool allows getting information about ROS topics. rostopic bw # display bandwidth used by topic rostopic echo # print messages to screen rostopic hz # display publishing rate of topic rostopic list # print information about active topics rostopic pub # publish data to topic rostopic type # print topic type","title":"Rostopic"},{"location":"blog/ros/beginner-guide-1/#ros-messages","text":"Communication on topics happens by sending ROS messages between nodes. For the publisher ( turtle_teleop_key ) and subscriber ( turtlesim_node ) to communicate, the publisher and subscriber must send and receive the same type of message. This means that a topic type is defined by the message type published on it. The type of the message sent on a topic can be determined using rostopic type. rostopic type /turtle1/cmd_vel geometry_msgs/Twist The command rosmsg show prints out the details of the message: rosmsg show geometry_msgs/Twist geometry_msgs/Vector3 linear float64 x float64 y float64 z geometry_msgs/Vector3 angular float64 x float64 y float64 z","title":"ROS Messages"},{"location":"blog/ros/beginner-guide-1/#publish-a-message","text":"A message can be published through command line: rostopic pub [ topic ] [ msg_type ] [ args ] For example, to send one message on the topic /turtle1/cmd_vel using message type geometry_msgs/Twist and its required -- parameters '[2.0, 0.0, 0.0]' '[0.0, 0.0, 1.8]' , enter the below command: rostopic pub -1 \\ /turtle1/cmd_vel \\ geometry_msgs/Twist \\ -- '[2.0, 0.0, 0.0]' '[0.0, 0.0, 1.8]' To continuously send message at the rate of 1Hz, use -r 1 options: rostopic pub -r 1 \\ /turtle1/cmd_vel \\ geometry_msgs/Twist \\ -- '[2.0, 0.0, 0.0]' '[0.0, 0.0, -1.8]' The rate of message can be inspected by using the command rostopic hz : rostopic hz /turtle1/pose","title":"Publish a message"},{"location":"blog/ros/beginner-guide-1/#rqt_plot","text":"The rqt_plot tool displays a scrolling time plot of the data published on topics: rosrun rqt_plot rqt_plot In the new window that should pop up, a text box in the upper left corner gives the ability to add any topic to the plot. Typing /turtle1/pose/x will highlight the plus button, previously disabled. Press it and repeat the same procedure with the topic /turtle1/pose/y . Now the turtle\u2019s x-y location is plotted in the graph. RosPlot","title":"Rqt_plot"},{"location":"blog/ros/beginner-guide-1/#ros-services","text":"Services are another way that nodes can communicate with each other. Services allow nodes to send a request and receive a response . A rosservice can easily be attached to ROS\u2019s client/service framework with services. Commands that can be used on services are: rosservice list # print information about active services rosservice call # call the service with the provided args rosservice type # print service type rosservice find # find services by service type rosservice uri # print service ROSRPC uri Let\u2019s see current services: rosservice list /clear /kill /reset /rosout/get_loggers /rosout/set_logger_level /spawn /turtle1/set_pen /turtle1/teleport_absolute /turtle1/teleport_relative /turtlesim/get_loggers /turtlesim/set_logger_level Check the parameter of a service: rosservice type /clear std_srvs/Empty The /clear service shows an Empty parameter, but the /spawn has 4 parameter and returns string: rosservice type /spawn turtlesim/Spawn rosservice type /spawn | rossrv show float32 x float32 y float32 theta string name --- string name The input parameter are x , y , theta and name , and the output is name . Ok, let\u2019s clear the background and spawn a new turtle: rosservice call /clear && \\ rosservice call /spawn 2 2 0 .2 \"\"","title":"ROS Services"},{"location":"blog/ros/beginner-guide-1/#rosparam","text":"The rosparam tool allows storing and manipulate data on the ROS Parameter Server. The Parameter Server can store integers, floats, boolean, dictionaries, and lists. rosparam uses the YAML markup language for syntax. In simple cases, YAML looks very natural: 1 is an integer, 1.0 is a float, one is a string, true is a boolean, [1, 2, 3] is a list of integers, and {a: b, c: d} is a dictionary. rosparam has many commands that can be used on parameters, as shown below: rosparam set # set parameter rosparam get # get parameter rosparam load # load parameters from file rosparam dump # dump parameters to file rosparam delete # delete parameter rosparam list # list parameter names See the list of parameters: rosparam list /rosdistro /roslaunch/uris/host_ubuntu18__43509 /rosversion /run_id /turtlesim/background_b /turtlesim/background_g /turtlesim/background_r Here will change the red channel of the background color: rosparam set /turtlesim/background_r 150 Use get command to see the parameters: rosparam get / && \\ rosparam get /turtlesim/background_g dump and load option are also available: rosparam dump [ file_name ] [ namespace ] rosparam load [ file_name ] [ namespace ] For example: rosparam dump params.yaml will create a file params.yaml with the content similar to: rosdistro : \"melodic \" roslaunch : uris : { host_ubuntu18__43509 : \"http://ubuntu18:43509/\" } rosversion : \"1.14.11 \" run_id : 409b84fc-e2ff-11eb-be5c-080027b61567 turtlesim : { background_b : 255 , background_g : 86 , background_r : 150 }","title":"Rosparam"},{"location":"blog/ros/beginner-guide-1/#ros-console","text":"The command rqt_console attaches to ROS\u2019s logging framework to display output from nodes. rqt_logger_level allows to change the verbosity level ( DEBUG , WARN , INFO , and ERROR ) of nodes as they run. rosrun rqt_console rqt_console && \\ rosrun rqt_logger_level rqt_logger_level ROS Console and Logger Level Logging levels are prioritized in the following order: Fatal Error Warn Info Debug The Fatal level has the highest priority and Debug level has the lowest. By setting the logger level, logger will show all messages of that priority level or higher. For example, by setting the level to Warn , it will get all Warn , Error , and Fatal logging messages.","title":"ROS Console"},{"location":"blog/ros/beginner-guide-1/#ros-launch","text":"The roslaunch command starts nodes as defined in a launch file. roslaunch [ package ] [ filename.launch ] Starting with the beginner_tutorials package: cd catkin_ws && \\ source devel/setup.bash && \\ roscd beginner_tutorials vqtrong@ubuntu18:~/Work/catkin_ws/src/beginner_tutorials$ Then let\u2019s make a launch directory: mkdir launch && \\ cd launch Now let\u2019s create a launch file called turtlemimic.launch and paste the following: <launch> <group ns= \"turtlesim1\" > <node pkg= \"turtlesim\" name= \"sim\" type= \"turtlesim_node\" /> </group> <group ns= \"turtlesim2\" > <node pkg= \"turtlesim\" name= \"sim\" type= \"turtlesim_node\" /> </group> <node pkg= \"turtlesim\" name= \"mimic\" type= \"mimic\" > <remap from= \"input\" to= \"turtlesim1/turtle1\" /> <remap from= \"output\" to= \"turtlesim2/turtle1\" /> </node> </launch> Notes: Two groups with a namespace tag of turtlesim1 and turtlesim2 are created from a turtlesim node with a name of sim . This allows to start two simulators without having name conflicts. The mimic node with the topics input and output remapped to turtlesim1 and turtlesim2 . This renaming will cause turtlesim2 to mimic turtlesim1 .","title":"ROS Launch"},{"location":"blog/ros/beginner-guide-1/#roslaunch","text":"Start the launch file: roslaunch beginner_tutorials turtlemimic.launch And post messages to the first turtle: rostopic pub /turtlesim1/turtle1/cmd_vel geometry_msgs/Twist -r 1 -- '[2.0, 0.0, 0.0]' '[0.0, 0.0, -1.8]' Run the rqt_graph to see what is going on: rqt_graph Turtle mimic nodes graph","title":"Roslaunch"},{"location":"blog/ros/beginner-guide-1/#playback-data","text":"This tutorial will teach how to record data from a running ROS system into a .bag file, and then to play back the data to produce similar behavior in a running system.","title":"Playback data"},{"location":"blog/ros/beginner-guide-1/#record-data","text":"First, execute the following commands in separate terminals: Terminal 1: roscore Terminal 2: rosrun turtlesim turtlesim_node Terminal 3: rosrun turtlesim turtle_teleop_key This will start two nodes \u2014 the turtlesim visualizer and a node that allows for the keyboard control of turtlesim using the arrows keys on the keyboard. Let\u2019s examine the full list of topics that are currently being published in the running system. To do this, open a new terminal and execute the command: rostopic list -v Published topics: * /turtle1/color_sensor [ turtlesim/Color ] 1 publisher * /turtle1/cmd_vel [ geometry_msgs/Twist ] 1 publisher * /rosout [ rosgraph_msgs/Log ] 2 publishers * /rosout_agg [ rosgraph_msgs/Log ] 1 publisher * /turtle1/pose [ turtlesim/Pose ] 1 publisher Subscribed topics: * /turtle1/cmd_vel [ geometry_msgs/Twist ] 1 subscriber * /rosout [ rosgraph_msgs/Log ] 1 subscriber The list of published topics is the only message types that could potentially be recorded in the data log file, as only published messages are recorded: The topic /turtle1/cmd_vel is the command message published by the teleop_turtle node that is taken as input by the turtlesim process. The messages /turtle1/color_sensor and /turtle1/pose are output messages published by turtlesim . Open a new terminal window. In this window run the following commands. Running rosbag record with the option -a indicates that all published topics should be accumulated in a bag file. roscd beginner_tutorials && \\ mkdir bagfiles && \\ cd bagfiles && \\ rosbag record -a [ INFO ] [ 1626862434 .586239631 ] : Recording to '2021-07-21-17-13-54.bag' . [ INFO ] [ 1626862434 .587320465 ] : Subscribing to /turtle1/color_sensor [ INFO ] [ 1626862434 .589356574 ] : Subscribing to /turtle1/cmd_vel [ INFO ] [ 1626862434 .591447646 ] : Subscribing to /rosout [ INFO ] [ 1626862434 .593544025 ] : Subscribing to /rosout_agg [ INFO ] [ 1626862434 .595557444 ] : Subscribing to /turtle1/pose Move back to the terminal window with turtle_teleop and move the turtle around for 10 or so seconds.","title":"Record data"},{"location":"blog/ros/beginner-guide-1/#rosbag-info","text":"Run the command rosbag info to see the info of a rosbag file: rosbag info <bagfile> path: xxx.bag version: 2 .0 duration: 2 :21s ( 141s ) start: xxx end: xxx size: 1 .3 MB messages: 18150 compression: none [ 2 /2 chunks ] types: geometry_msgs/Twist [ 9f195f881246fdfa2798d1d3eebca84a ] rosgraph_msgs/Log [ acffd30cd6b6de30f120938c17c593fb ] turtlesim/Color [ 353891e354491c51aabe32df673fb446 ] turtlesim/Pose [ 863b248d5016ca62ea2e895ae5265cf9 ] topics: /rosout 217 msgs : rosgraph_msgs/Log ( 2 connections ) /rosout_agg 214 msgs : rosgraph_msgs/Log /turtle1/cmd_vel 286 msgs : geometry_msgs/Twist /turtle1/color_sensor 8716 msgs : turtlesim/Color /turtle1/pose 8717 msgs : turtlesim/Pose","title":"Rosbag info"},{"location":"blog/ros/beginner-guide-1/#rosbag-play","text":"The next step in this tutorial is to replay the bag file to reproduce behavior in the running system. First kill the tele-operator program that may be still running from the previous section. Leave turtlesim running. In a terminal window run the following command: rosbag play <bagfile> In its default mode rosbag play will wait for a certain period (.2 seconds) after advertising each message before it actually begins publishing the contents of the bag file. Waiting for some duration allows any subscriber of a message to be alerted that the message has been advertised and that messages may follow. If rosbag play publishes messages immediately upon advertising, subscribers may not receive the first several published messages. The waiting period can be specified with the -d option.","title":"Rosbag play"},{"location":"blog/ros/beginner-guide-1/#recording-a-subset","text":"When running a complicated system, such as the pr2 software suite, there may be hundreds of topics being published, with some topics, like camera image streams, potentially publishing huge amounts of data. In such a system it is often impractical to write log files consisting of all topics to disk in a single bag file. The rosbag record command supports logging only particular topics to a bag file, allowing users to only record the topics of interest to them. rosbag record -O subset /turtle1/cmd_vel /turtle1/pose The -O argument tells rosbag record to log to a file named subset.bag , and the topic arguments cause rosbag record to only subscribe to these two topics. The limitations of rosbag record/play Different start condition can cause different results even the events are the same. The rate of recorded events is not guaranteed to be the same as the real actions.","title":"Recording a subset"},{"location":"blog/ros/beginner-guide-1/#read-rosbag-message","text":"The script ros_readbagfile will read rosbag file and extract all messages of selected topics: ros_readbagfile <mybagfile.bag> [ info ] [ N ] [ topic1 ] [ topic2 ] [ ... ] Download and install ros_readbag.py using below command: cd ~ && \\ wget https://raw.githubusercontent.com/vuquangtrong/ \\ ros_readbagfile/main/ros_readbagfile Edit the shebang to use python 2 if needed. Change #!/usr/bin/python3 to #!/usr/bin/python . Make it executable: chmod +x ros_readbagfile The ~/bin directory for personal binaries: mkdir -p ~/bin Add this folder to the PATH : echo \"PATH=\\\" $PATH :~/bin\\\"\" >> ~/.bashrc Move this executable script into that directory as ros_readbagfile , so that it will be available as that command: mv ros_readbagfile ~/bin/ros_readbagfile Usage See the information of the input bag file: ros_readbagfile mybagfile.bag info Print all messages of all topics in the bag file to the screen: ros_readbagfile mybagfile.bag Print all messages of the topic /test in the bag file to the screen: ros_readbagfile mybagfile.bag /test Print at most N first messages of all topics in the bag file to the screen: ros_readbagfile mybagfile.bag N Print at most N first messages of the topic /test in the bag file to the screen: ros_readbagfile mybagfile.bag N /test To save the output to a file, use redirection syntax: ros_readbagfile mybagfile.bag N /test > output.txt Determine the exact topic names you\u2019d like to read from the bag file, by using rosbag info as mentioned above, or use ros_readbagfile info command: Use ros_readbagfile from terminal as below: rosbag info 2021 -07-21-17-13-54.bag path: 2021 -07-21-17-13-54.bag version: 2 .0 duration: 30 .8s start: Jul 21 2021 17 :13:54.60 ( 1626862434 .60 ) end: Jul 21 2021 17 :14:25.40 ( 1626862465 .40 ) size: 280 .8 KB messages: 3895 compression: none [ 1 /1 chunks ] types: geometry_msgs/Twist [ 9f195f881246fdfa2798d1d3eebca84a ] rosgraph_msgs/Log [ acffd30cd6b6de30f120938c17c593fb ] turtlesim/Color [ 353891e354491c51aabe32df673fb446 ] turtlesim/Pose [ 863b248d5016ca62ea2e895ae5265cf9 ] topics: /rosout 4 msgs : rosgraph_msgs/Log ( 2 connections ) /turtle1/cmd_vel 93 msgs : geometry_msgs/Twist /turtle1/color_sensor 1899 msgs : turtlesim/Color /turtle1/pose 1899 msgs : turtlesim/Pose Now, get all messages of the topic /turtle1/pose and save to the file: ros_readbagfile 2021 -07-21-17-13-54.bag /turtle1/pose > turtle1_pose.yaml # ======================================= # topic: /turtle1/pose # msg_count: 1899 # timestamp (sec): 1626862465.397807837 # - - - x: 10 .0430784225 y: 6 .37491464615 theta: -2.62400007248 linear_velocity: 0 .0 angular_velocity: 0 .0 # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ # Total messages found: 1899 # # /turtle1/pose: 1899 # # DONE. # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~","title":"Read Rosbag message"},{"location":"blog/ros/beginner-guide-2/","tags":["ros"],"text":"This guide was created by using ROS Melodic on Ubuntu 18.04 LTS . The official guide is at https://wiki.ros.org/ROS/Tutorials . An ebook for further reference: A Gentle Introduction to ROS by Jason M. O\u2019Kane . Create ROS msg and srv # The msg files are simple text files that describe the fields of a ROS message. They are used to generating source code for messages in different languages. The msg files are stored in the msg directory of a package The field types include: int8 , int16 , int32 , int64 float32 , float64 string time , duration other msg files variable-length array[] and fixed-length array[x] There is also a special type in ROS: Header , the header contains a timestamp and coordinate frame information that are commonly used in ROS. Here is an example of a msg that uses a Header , a string primitive, and two other messages : Header header string child_frame_id geometry_msgs/PoseWithCovariance pose geometry_msgs/TwistWithCovariance twist The srv file describes a service. It is composed of two parts: a request and a response, and srv files are stored in the srv directory. The two parts are separated by a \u2018\u2014\u2018 line. Here is an example of a srv file: int64 A int64 B --- int64 Sum In the above example, A and B are the request, and Sum is the response. Create a msg # Let\u2019s define a new msg in the beginner_tutorials package: roscd beginner_tutorials && \\ mkdir msg && \\ echo \"int64 num\" > msg/Num.msg Using rosmsg to see a message definition: rosmsg show beginner_tutorials/Num Creating a srv # Let\u2019s define a new msg in the beginner_tutorials package: roscd beginner_tutorials && \\ mkdir srv && \\ touch srv/AddTwoInts.srv The file content: int64 a int64 b --- int64 sum Using rossrv to see a service definition: rossrv show beginner_tutorials/AddTwoInts Generate msg and srv # To make sure that the msg files are turned into source code for C++, Python, and other languages, open package.xml , and make sure these two lines are in it: <build_depend> message_generation </build_depend> <exec_depend> message_runtime </exec_depend> and then add these packages into the CMakeLists.txt file: find_package ( catkin REQUIRED COMPONENTS roscpp rospy std_msgs message_generation ) ## Generate messages in the 'msg' folder add_message_files ( FILES Num.msg ) ## Generate services in the 'srv' folder add_service_files ( FILES AddTwoInts.srv ) ## Generate added messages and services with any dependencies listed here generate_messages ( DEPENDENCIES std_msgs ) make the package again: roscd beginner_tutorials && \\ cd ../.. && \\ catkin_make && \\ cd - Any .msg file in the msg directory will generate code for use in all supported languages: The C++ message header file will be generated in catkin_ws/devel/include/beginner_tutorials/ . The Python script will be created in catkin_ws/devel/lib/python2.7/dist-packages/beginner_tutorials/msg . The lisp file appears in catkin_ws/devel/share/common-lisp/ros/beginner_tutorials/msg/ . Similarly, any .srv files in the srv directory will have generated code in supported languages. For C++, this will generate header files in the same directory as the messages. For Python and Lisp, there will be a srv folder beside the msg folders. Here are the generated files: devel/include/beginner_tutorials/Num.h devel/include/beginner_tutorials/AddTwoInts.h Let\u2019s see what was generated! In the Num.h header file: Create a namespace based on the package name namespace beginner_tutorials {} Use a template of an Allocator to create a new Num type: template < class ContainerAllocator > struct Num_ { typedef Num_ < ContainerAllocator > Type ; // constructor Num_ () : num ( 0 ) { } Num_ ( const ContainerAllocator & _alloc ) : num ( 0 ) { ( void ) _alloc ; } // members typedef int64_t _num_type ; _num_type num ; // define new type of pointer typedef boost :: shared_ptr < :: beginner_tutorials :: Num_ < ContainerAllocator > > Ptr ; typedef boost :: shared_ptr < :: beginner_tutorials :: Num_ < ContainerAllocator > const > ConstPtr ; }; // struct Num_ Create new pointer types of this new Num type typedef :: beginner_tutorials :: Num_ < std :: allocator < void > > Num ; typedef boost :: shared_ptr < :: beginner_tutorials :: Num > NumPtr ; typedef boost :: shared_ptr < :: beginner_tutorials :: Num const > NumConstPtr ; Noted that ROS uses shared_ptr to manage the memory, that will prevent any memory leak issue. Create friendly operations template < class ContainerAllocator > struct Printer < :: beginner_tutorials :: Num_ < ContainerAllocator > > { template < typename Stream > static void stream ( Stream & s , const std :: string & indent , const :: beginner_tutorials :: Num_ < ContainerAllocator >& v ) { s << indent << \"num: \" ; Printer < int64_t >:: stream ( s , indent + \" \" , v . num ); } }; template < typename ContainerAllocator > std :: ostream & operator << ( std :: ostream & s , const :: beginner_tutorials :: Num_ < ContainerAllocator > & v ) { ros :: message_operations :: Printer < :: beginner_tutorials :: Num_ < ContainerAllocator > > :: stream ( s , \"\" , v ); return s ; } template < typename ContainerAllocator1 , typename ContainerAllocator2 > bool operator == ( const :: beginner_tutorials :: Num_ < ContainerAllocator1 > & lhs , const :: beginner_tutorials :: Num_ < ContainerAllocator2 > & rhs ) { return lhs . num == rhs . num ; } template < typename ContainerAllocator1 , typename ContainerAllocator2 > bool operator != ( const :: beginner_tutorials :: Num_ < ContainerAllocator1 > & lhs , const :: beginner_tutorials :: Num_ < ContainerAllocator2 > & rhs ) { return ! ( lhs == rhs ); } Metadata which will be used by ROS to show object\u2019s information template < class ContainerAllocator > struct IsFixedSize < :: beginner_tutorials :: Num_ < ContainerAllocator > > : TrueType { }; template < class ContainerAllocator > struct IsFixedSize < :: beginner_tutorials :: Num_ < ContainerAllocator > const > : TrueType { }; template < class ContainerAllocator > struct IsMessage < :: beginner_tutorials :: Num_ < ContainerAllocator > > : TrueType { }; template < class ContainerAllocator > struct IsMessage < :: beginner_tutorials :: Num_ < ContainerAllocator > const > : TrueType { }; template < class ContainerAllocator > struct HasHeader < :: beginner_tutorials :: Num_ < ContainerAllocator > > : FalseType { }; template < class ContainerAllocator > struct HasHeader < :: beginner_tutorials :: Num_ < ContainerAllocator > const > : FalseType { }; template < class ContainerAllocator > struct MD5Sum < :: beginner_tutorials :: Num_ < ContainerAllocator > > { static const char * value () { return \"57d3c40ec3ac3754af76a83e6e73127a\" ; } static const char * value ( const :: beginner_tutorials :: Num_ < ContainerAllocator >& ) { return value (); } static const uint64_t static_value1 = 0x57d3c40ec3ac3754ULL ; static const uint64_t static_value2 = 0xaf76a83e6e73127aULL ; }; template < class ContainerAllocator > struct DataType < :: beginner_tutorials :: Num_ < ContainerAllocator > > { static const char * value () { return \"beginner_tutorials/Num\" ; } static const char * value ( const :: beginner_tutorials :: Num_ < ContainerAllocator >& ) { return value (); } }; template < class ContainerAllocator > struct Definition < :: beginner_tutorials :: Num_ < ContainerAllocator > > { static const char * value () { return \"int64 num \\n \" ; } static const char * value ( const :: beginner_tutorials :: Num_ < ContainerAllocator >& ) { return value (); } }; Publisher and Subscriber (C++) # Go to the source code folder of the beginner_tutorials package: roscd beginner_tutorials && \\ mkdir src && \\ cd src A Publisher Node # This tutorial demonstrates simple sending of messages over the ROS system. nano talker.cpp #include \"ros/ros.h\" #include \"std_msgs/String.h\" #include <sstream> int main ( int argc , char ** argv ) { // init with a name ros :: init ( argc , argv , \"talker\" ); // create a node ros :: NodeHandle n ; // publish on a the `chatter` topic, queue = 1000 ros :: Publisher chatter_pub = n . advertise < std_msgs :: String > ( \"chatter\" , 1000 ); // publishing rate 1 Hz ros :: Rate loop_rate ( 1 ); // main loop int count = 0 ; while ( ros :: ok ()) { // message std_msgs :: String msg ; // content std :: stringstream ss ; ss << \"hello world \" << count ++ ; msg . data = ss . str (); ROS_INFO ( \"%s\" , msg . data . c_str ()); // publish chatter_pub . publish ( msg ); // check status ros :: spinOnce (); // sleep loop_rate . sleep (); } return 0 ; } A Subscriber Node # This tutorial demonstrates simple receipt of messages over the ROS system. nano listener.cpp #include \"ros/ros.h\" #include \"std_msgs/String.h\" void chatterCallback ( const std_msgs :: String :: ConstPtr & msg ) { ROS_INFO ( \"I heard: [%s]\" , msg -> data . c_str ()); } int main ( int argc , char ** argv ) { // init with a name ros :: init ( argc , argv , \"listener\" ); // create a node ros :: NodeHandle n ; // subscribe on a the `chatter` topic, queue = 1000 // execute chatterCallback on receive ros :: Subscriber sub = n . subscribe ( \"chatter\" , 1000 , chatterCallback ); // main loop ros :: spin (); return 0 ; } Building new nodes # Add the source code files which need to be compiled into the CMakeLists.txt . With all dependency packages listed above, add below lines also: cd .. && \\ nano CMakeLists.txt ## Declare a C++ executable add_executable ( talker src/talker.cpp ) target_link_libraries ( talker ${ catkin_LIBRARIES } ) add_dependencies ( talker beginner_tutorials_generate_messages_cpp ) add_executable ( listener src/listener.cpp ) target_link_libraries ( listener ${ catkin_LIBRARIES } ) add_dependencies ( listener beginner_tutorials_generate_messages_cpp ) This will create two executables, talker and listener, which by default will go into package directory in devel space, located by default at catkin_ws/devel/lib/<package name> . Finally, make the package again: roscd beginner_tutorials && \\ cd ../.. && \\ catkin_make && \\ cd - Run new nodes # Run roscore first if it is not running. Then run 2 new nodes in two terminals: rosrun beginner_tutorials talker rosrun beginner_tutorials listener Talker and Listener Publisher and Subscriber (Python) # Go to the scripts\u2019 folder of the beginner_tutorials package: roscd beginner_tutorials && \\ mkdir scripts && \\ cd scripts A Publisher Node # This tutorial demonstrates simple sending of messages over the ROS system. Note that a node is created from a publisher, in contrast to C++ implementation, a publisher is created from a node. In ROS, nodes are uniquely named. If two nodes with the same name are launched, the previous one is kicked off. The anonymous=True flag means that rospy will choose a unique name for a new listener node so that multiple listeners can run simultaneously. nano talker.py #!/usr/bin/env python import rospy from std_msgs.msg import String def talker (): # create a publisher, on topic `chatter` pub = rospy . Publisher ( 'chatter' , String , queue_size = 10 ) # create a node rospy . init_node ( 'talker' , anonymous = True ) # set the rate of publishing rate = rospy . Rate ( 1 ) # 1hz # main loop while not rospy . is_shutdown (): # make content hello_str = \"hello world %s \" % rospy . get_time () rospy . loginfo ( hello_str ) # publish a message pub . publish ( hello_str ) rate . sleep () if __name__ == '__main__' : try : talker () except rospy . ROSInterruptException : pass A Subscriber Node # This tutorial demonstrates simple receipt of messages over the ROS system. nano listener.py #!/usr/bin/env python import rospy from std_msgs.msg import String def callback ( data ): rospy . loginfo ( rospy . get_caller_id () + \"I heard %s \" , data . data ) def listener (): # create a node rospy . init_node ( 'listener' , anonymous = True ) # create a subcriber rospy . Subscriber ( \"chatter\" , String , callback ) # spin() simply keeps python from exiting until this node is stopped rospy . spin () if __name__ == '__main__' : listener () The function rospy.spin() simply keeps the node from exiting until the node has been shutdown. Unlike roscpp, rospy.spin() does not affect the subscriber callback functions, as those have their own threads. Make script executable # Scripts need to get execution permission before they can run: chmod +x * Building new nodes # Add the source code files which need to be compiled into the CMakeLists.txt . With all dependency packages listed above, add below lines also: cd .. && \\ nano CMakeLists.txt catkin_install_python ( PROGRAMS scripts/talker.py scripts/listener.py DESTINATION ${ CATKIN_PACKAGE_BIN_DESTINATION } ) Finally, make the package again: roscd beginner_tutorials && \\ cd ../.. && \\ catkin_make && \\ cd - Run new nodes # Run roscore first if it is not running. Then run 2 new nodes in two terminals: rosrun beginner_tutorials talker.py rosrun beginner_tutorials listener.py Python script execution If the error /usr/bin/env: \u2018python \\r \u2019: No such file or directory shows up, it is because of the ending line characters. Unix use LF only while Windows use CRLF . Save python scripts in Unix ending character only. Service and Client (C++) # Go to the source code folder of the beginner_tutorials package: roscd beginner_tutorials && \\ mkdir src && \\ cd src A Service Node # This guide will create the service add_two_ints_server node which will receive two numbers and return the sum. This service uses the beginner_tutorials/AddTwoInts.h header file generated from the srv file that is created earlier. nano add_two_ints_server.cpp #include \"ros/ros.h\" #include \"beginner_tutorials/AddTwoInts.h\" // service fuction bool add ( beginner_tutorials :: AddTwoInts :: Request & req , beginner_tutorials :: AddTwoInts :: Response & res ) { res . sum = req . a + req . b ; ROS_INFO ( \"request: x=%ld, y=%ld\" , ( long int ) req . a , ( long int ) req . b ); ROS_INFO ( \"sending back response: [%ld]\" , ( long int ) res . sum ); return true ; } int main ( int argc , char ** argv ) { ros :: init ( argc , argv , \"add_two_ints_server\" ); // create a node ros :: NodeHandle n ; // node will have a service ros :: ServiceServer service = n . advertiseService ( \"add_two_ints\" , add ); ROS_INFO ( \"Ready to add two ints.\" ); // main loop ros :: spin (); return 0 ; } A Client Node # This guide will create the service add_two_ints_client node which will receive two ints and return the sum. nano add_two_ints_client.cpp #include \"ros/ros.h\" #include \"beginner_tutorials/AddTwoInts.h\" #include <cstdlib> int main ( int argc , char ** argv ) { // check args ros :: init ( argc , argv , \"add_two_ints_client\" ); if ( argc != 3 ) { ROS_INFO ( \"usage: add_two_ints_client X Y\" ); return 1 ; } // create a node ros :: NodeHandle n ; // node will have a client ros :: ServiceClient client = n . serviceClient < beginner_tutorials :: AddTwoInts > ( \"add_two_ints\" ); // create a service target beginner_tutorials :: AddTwoInts srv ; // add params srv . request . a = atoll ( argv [ 1 ]); srv . request . b = atoll ( argv [ 2 ]); // call to service if ( client . call ( srv )) { ROS_INFO ( \"Sum: %ld\" , ( long int ) srv . response . sum ); } else { ROS_ERROR ( \"Failed to call service add_two_ints\" ); return 1 ; } return 0 ; } Building new nodes # Add the source code files which need to be compiled into the CMakeLists.txt . With all dependency packages listed above, add below lines also: cd .. && \\ nano CMakeLists.txt ## Declare a C++ executable add_executable ( add_two_ints_server src/add_two_ints_server.cpp ) target_link_libraries ( add_two_ints_server ${ catkin_LIBRARIES } ) add_dependencies ( add_two_ints_server beginner_tutorials_gencpp ) add_executable ( add_two_ints_client src/add_two_ints_client.cpp ) target_link_libraries ( add_two_ints_client ${ catkin_LIBRARIES } ) add_dependencies ( add_two_ints_client beginner_tutorials_gencpp ) This will create two executables, add_two_ints_server and add_two_ints_client, which by default will go into package directory in devel space, located by default at catkin_ws/devel/lib/<package name> . Finally, make the package again: roscd beginner_tutorials && \\ cd ../.. && \\ catkin_make && \\ cd - Run new nodes # Run roscore first if it is not running. Then run 2 new nodes in two terminals: rosrun beginner_tutorials add_two_ints_server rosrun beginner_tutorials add_two_ints_client 1 2 Service and Client Service and Client (Python) # Go to the source code folder of the beginner_tutorials package: roscd beginner_tutorials && \\ mkdir scripts && \\ cd scripts && \\ A Service Node # This guide will create the service add_two_ints_server node which will receive two ints and return the sum. This service uses the beginner_tutorials/AddTwoInts.h header file generated from the srv file that is created earlier. nano add_two_ints_server.py #!/usr/bin/env python from __future__ import print_function from beginner_tutorials.srv import AddTwoInts , AddTwoIntsResponse import rospy def handle_add_two_ints ( req ): print ( \"Returning [ %s + %s = %s ]\" % ( req . a , req . b , ( req . a + req . b ))) return AddTwoIntsResponse ( req . a + req . b ) def add_two_ints_server (): rospy . init_node ( 'add_two_ints_server' ) s = rospy . Service ( 'add_two_ints' , AddTwoInts , handle_add_two_ints ) print ( \"Ready to add two ints.\" ) rospy . spin () if __name__ == \"__main__\" : add_two_ints_server () A Client Node # This guide will create the service add_two_ints_client node which will receive two ints and return the sum. nano add_two_ints_client.py #!/usr/bin/env python from __future__ import print_function import sys import rospy from beginner_tutorials.srv import * def add_two_ints_client ( x , y ): rospy . wait_for_service ( 'add_two_ints' ) try : add_two_ints = rospy . ServiceProxy ( 'add_two_ints' , AddTwoInts ) resp1 = add_two_ints ( x , y ) return resp1 . sum except rospy . ServiceException as e : print ( \"Service call failed: %s \" % e ) def usage (): return \" %s [x y]\" % sys . argv [ 0 ] if __name__ == \"__main__\" : if len ( sys . argv ) == 3 : x = int ( sys . argv [ 1 ]) y = int ( sys . argv [ 2 ]) else : print ( usage ()) sys . exit ( 1 ) print ( \"Requesting %s + %s \" % ( x , y )) print ( \" %s + %s = %s \" % ( x , y , add_two_ints_client ( x , y ))) Make scripts executable # Scripts need to get execution permission before they can run: chmod +x * Building new nodes # Add the source code files which need to be compiled into the CMakeLists.txt . With all dependency packages listed above, add below lines also: cd .. && \\ nano CMakeLists.txt catkin_install_python ( PROGRAMS scripts/add_two_ints_server.py scripts/add_two_ints_client.py DESTINATION ${ CATKIN_PACKAGE_BIN_DESTINATION } ) This will create two executables, add_two_ints_server and add_two_ints_client, which by default will go into package directory in devel space, located by default at catkin_ws/devel/lib/<package name> . Finally, make the package again: roscd beginner_tutorials && \\ cd ../.. && \\ catkin_make && \\ cd - Run new nodes # Run roscore first if it is not running. Then run 2 new nodes in two terminals: rosrun beginner_tutorials add_two_ints_server.py rosrun beginner_tutorials add_two_ints_client.py 1 3 Reference # There is an interesting book named A Gentle Introduction to ROS by Jason M. O\u2019Kane published on https://cse.sc.edu/~jokane/agitr/ . This book supplements ROS\u2019s own documentation, explaining how to interact with existing ROS systems and how to create new ROS programs using C++, with special attention to common mistakes and misunderstandings. An excerpt from the book: Giving ROS control The final complication is that ROS will only execute our callback function when we give it explicit permission to do so. There are actually two slightly different ways to accomplish this. One version looks like this: ros :: spinOnce (); This code asks ROS to execute all of the pending callbacks from all of the node\u2019s subscriptions, and then return control back to us. The other option looks like this: ros :: spin (); This alternative to ros::spinOnce() asks ROS to wait for and execute callbacks until the node shuts down. In other words, ros::spin() is roughly equivalent to this loop: while ( ros :: ok ()) { ros :: spinOnce (); } The question of whether to use ros::spinOnce() or ros::spin() comes down to this: Does your program have any repetitive work to do, other than responding to callbacks? If the answer is No , then use ros::spin() . If the answer is Yes , then a reasonable option is to write a loop that does that other work and calls ros::spinOnce() periodically to process callbacks. A common error in subscriber programs is to mistakenly omit both ros::spinOnce() and ros::spin() . In this case, ROS never has an opportunity to execute your callback function. Omitting ros::spin() will likely cause your program to exit shortly after it starts. Omitting ros::spinOnce() might make it appear as though no messages are being received.","title":"Beginner Guide 2 - Create a package"},{"location":"blog/ros/beginner-guide-2/#create-ros-msg-and-srv","text":"The msg files are simple text files that describe the fields of a ROS message. They are used to generating source code for messages in different languages. The msg files are stored in the msg directory of a package The field types include: int8 , int16 , int32 , int64 float32 , float64 string time , duration other msg files variable-length array[] and fixed-length array[x] There is also a special type in ROS: Header , the header contains a timestamp and coordinate frame information that are commonly used in ROS. Here is an example of a msg that uses a Header , a string primitive, and two other messages : Header header string child_frame_id geometry_msgs/PoseWithCovariance pose geometry_msgs/TwistWithCovariance twist The srv file describes a service. It is composed of two parts: a request and a response, and srv files are stored in the srv directory. The two parts are separated by a \u2018\u2014\u2018 line. Here is an example of a srv file: int64 A int64 B --- int64 Sum In the above example, A and B are the request, and Sum is the response.","title":"Create ROS msg and srv"},{"location":"blog/ros/beginner-guide-2/#create-a-msg","text":"Let\u2019s define a new msg in the beginner_tutorials package: roscd beginner_tutorials && \\ mkdir msg && \\ echo \"int64 num\" > msg/Num.msg Using rosmsg to see a message definition: rosmsg show beginner_tutorials/Num","title":"Create a msg"},{"location":"blog/ros/beginner-guide-2/#creating-a-srv","text":"Let\u2019s define a new msg in the beginner_tutorials package: roscd beginner_tutorials && \\ mkdir srv && \\ touch srv/AddTwoInts.srv The file content: int64 a int64 b --- int64 sum Using rossrv to see a service definition: rossrv show beginner_tutorials/AddTwoInts","title":"Creating a srv"},{"location":"blog/ros/beginner-guide-2/#generate-msg-and-srv","text":"To make sure that the msg files are turned into source code for C++, Python, and other languages, open package.xml , and make sure these two lines are in it: <build_depend> message_generation </build_depend> <exec_depend> message_runtime </exec_depend> and then add these packages into the CMakeLists.txt file: find_package ( catkin REQUIRED COMPONENTS roscpp rospy std_msgs message_generation ) ## Generate messages in the 'msg' folder add_message_files ( FILES Num.msg ) ## Generate services in the 'srv' folder add_service_files ( FILES AddTwoInts.srv ) ## Generate added messages and services with any dependencies listed here generate_messages ( DEPENDENCIES std_msgs ) make the package again: roscd beginner_tutorials && \\ cd ../.. && \\ catkin_make && \\ cd - Any .msg file in the msg directory will generate code for use in all supported languages: The C++ message header file will be generated in catkin_ws/devel/include/beginner_tutorials/ . The Python script will be created in catkin_ws/devel/lib/python2.7/dist-packages/beginner_tutorials/msg . The lisp file appears in catkin_ws/devel/share/common-lisp/ros/beginner_tutorials/msg/ . Similarly, any .srv files in the srv directory will have generated code in supported languages. For C++, this will generate header files in the same directory as the messages. For Python and Lisp, there will be a srv folder beside the msg folders. Here are the generated files: devel/include/beginner_tutorials/Num.h devel/include/beginner_tutorials/AddTwoInts.h Let\u2019s see what was generated! In the Num.h header file: Create a namespace based on the package name namespace beginner_tutorials {} Use a template of an Allocator to create a new Num type: template < class ContainerAllocator > struct Num_ { typedef Num_ < ContainerAllocator > Type ; // constructor Num_ () : num ( 0 ) { } Num_ ( const ContainerAllocator & _alloc ) : num ( 0 ) { ( void ) _alloc ; } // members typedef int64_t _num_type ; _num_type num ; // define new type of pointer typedef boost :: shared_ptr < :: beginner_tutorials :: Num_ < ContainerAllocator > > Ptr ; typedef boost :: shared_ptr < :: beginner_tutorials :: Num_ < ContainerAllocator > const > ConstPtr ; }; // struct Num_ Create new pointer types of this new Num type typedef :: beginner_tutorials :: Num_ < std :: allocator < void > > Num ; typedef boost :: shared_ptr < :: beginner_tutorials :: Num > NumPtr ; typedef boost :: shared_ptr < :: beginner_tutorials :: Num const > NumConstPtr ; Noted that ROS uses shared_ptr to manage the memory, that will prevent any memory leak issue. Create friendly operations template < class ContainerAllocator > struct Printer < :: beginner_tutorials :: Num_ < ContainerAllocator > > { template < typename Stream > static void stream ( Stream & s , const std :: string & indent , const :: beginner_tutorials :: Num_ < ContainerAllocator >& v ) { s << indent << \"num: \" ; Printer < int64_t >:: stream ( s , indent + \" \" , v . num ); } }; template < typename ContainerAllocator > std :: ostream & operator << ( std :: ostream & s , const :: beginner_tutorials :: Num_ < ContainerAllocator > & v ) { ros :: message_operations :: Printer < :: beginner_tutorials :: Num_ < ContainerAllocator > > :: stream ( s , \"\" , v ); return s ; } template < typename ContainerAllocator1 , typename ContainerAllocator2 > bool operator == ( const :: beginner_tutorials :: Num_ < ContainerAllocator1 > & lhs , const :: beginner_tutorials :: Num_ < ContainerAllocator2 > & rhs ) { return lhs . num == rhs . num ; } template < typename ContainerAllocator1 , typename ContainerAllocator2 > bool operator != ( const :: beginner_tutorials :: Num_ < ContainerAllocator1 > & lhs , const :: beginner_tutorials :: Num_ < ContainerAllocator2 > & rhs ) { return ! ( lhs == rhs ); } Metadata which will be used by ROS to show object\u2019s information template < class ContainerAllocator > struct IsFixedSize < :: beginner_tutorials :: Num_ < ContainerAllocator > > : TrueType { }; template < class ContainerAllocator > struct IsFixedSize < :: beginner_tutorials :: Num_ < ContainerAllocator > const > : TrueType { }; template < class ContainerAllocator > struct IsMessage < :: beginner_tutorials :: Num_ < ContainerAllocator > > : TrueType { }; template < class ContainerAllocator > struct IsMessage < :: beginner_tutorials :: Num_ < ContainerAllocator > const > : TrueType { }; template < class ContainerAllocator > struct HasHeader < :: beginner_tutorials :: Num_ < ContainerAllocator > > : FalseType { }; template < class ContainerAllocator > struct HasHeader < :: beginner_tutorials :: Num_ < ContainerAllocator > const > : FalseType { }; template < class ContainerAllocator > struct MD5Sum < :: beginner_tutorials :: Num_ < ContainerAllocator > > { static const char * value () { return \"57d3c40ec3ac3754af76a83e6e73127a\" ; } static const char * value ( const :: beginner_tutorials :: Num_ < ContainerAllocator >& ) { return value (); } static const uint64_t static_value1 = 0x57d3c40ec3ac3754ULL ; static const uint64_t static_value2 = 0xaf76a83e6e73127aULL ; }; template < class ContainerAllocator > struct DataType < :: beginner_tutorials :: Num_ < ContainerAllocator > > { static const char * value () { return \"beginner_tutorials/Num\" ; } static const char * value ( const :: beginner_tutorials :: Num_ < ContainerAllocator >& ) { return value (); } }; template < class ContainerAllocator > struct Definition < :: beginner_tutorials :: Num_ < ContainerAllocator > > { static const char * value () { return \"int64 num \\n \" ; } static const char * value ( const :: beginner_tutorials :: Num_ < ContainerAllocator >& ) { return value (); } };","title":"Generate msg and srv"},{"location":"blog/ros/beginner-guide-2/#publisher-and-subscriber-c","text":"Go to the source code folder of the beginner_tutorials package: roscd beginner_tutorials && \\ mkdir src && \\ cd src","title":"Publisher and Subscriber (C++)"},{"location":"blog/ros/beginner-guide-2/#a-publisher-node","text":"This tutorial demonstrates simple sending of messages over the ROS system. nano talker.cpp #include \"ros/ros.h\" #include \"std_msgs/String.h\" #include <sstream> int main ( int argc , char ** argv ) { // init with a name ros :: init ( argc , argv , \"talker\" ); // create a node ros :: NodeHandle n ; // publish on a the `chatter` topic, queue = 1000 ros :: Publisher chatter_pub = n . advertise < std_msgs :: String > ( \"chatter\" , 1000 ); // publishing rate 1 Hz ros :: Rate loop_rate ( 1 ); // main loop int count = 0 ; while ( ros :: ok ()) { // message std_msgs :: String msg ; // content std :: stringstream ss ; ss << \"hello world \" << count ++ ; msg . data = ss . str (); ROS_INFO ( \"%s\" , msg . data . c_str ()); // publish chatter_pub . publish ( msg ); // check status ros :: spinOnce (); // sleep loop_rate . sleep (); } return 0 ; }","title":"A Publisher Node"},{"location":"blog/ros/beginner-guide-2/#a-subscriber-node","text":"This tutorial demonstrates simple receipt of messages over the ROS system. nano listener.cpp #include \"ros/ros.h\" #include \"std_msgs/String.h\" void chatterCallback ( const std_msgs :: String :: ConstPtr & msg ) { ROS_INFO ( \"I heard: [%s]\" , msg -> data . c_str ()); } int main ( int argc , char ** argv ) { // init with a name ros :: init ( argc , argv , \"listener\" ); // create a node ros :: NodeHandle n ; // subscribe on a the `chatter` topic, queue = 1000 // execute chatterCallback on receive ros :: Subscriber sub = n . subscribe ( \"chatter\" , 1000 , chatterCallback ); // main loop ros :: spin (); return 0 ; }","title":"A Subscriber Node"},{"location":"blog/ros/beginner-guide-2/#building-new-nodes","text":"Add the source code files which need to be compiled into the CMakeLists.txt . With all dependency packages listed above, add below lines also: cd .. && \\ nano CMakeLists.txt ## Declare a C++ executable add_executable ( talker src/talker.cpp ) target_link_libraries ( talker ${ catkin_LIBRARIES } ) add_dependencies ( talker beginner_tutorials_generate_messages_cpp ) add_executable ( listener src/listener.cpp ) target_link_libraries ( listener ${ catkin_LIBRARIES } ) add_dependencies ( listener beginner_tutorials_generate_messages_cpp ) This will create two executables, talker and listener, which by default will go into package directory in devel space, located by default at catkin_ws/devel/lib/<package name> . Finally, make the package again: roscd beginner_tutorials && \\ cd ../.. && \\ catkin_make && \\ cd -","title":"Building new nodes"},{"location":"blog/ros/beginner-guide-2/#run-new-nodes","text":"Run roscore first if it is not running. Then run 2 new nodes in two terminals: rosrun beginner_tutorials talker rosrun beginner_tutorials listener Talker and Listener","title":"Run new nodes"},{"location":"blog/ros/beginner-guide-2/#publisher-and-subscriber-python","text":"Go to the scripts\u2019 folder of the beginner_tutorials package: roscd beginner_tutorials && \\ mkdir scripts && \\ cd scripts","title":"Publisher and Subscriber (Python)"},{"location":"blog/ros/beginner-guide-2/#a-publisher-node_1","text":"This tutorial demonstrates simple sending of messages over the ROS system. Note that a node is created from a publisher, in contrast to C++ implementation, a publisher is created from a node. In ROS, nodes are uniquely named. If two nodes with the same name are launched, the previous one is kicked off. The anonymous=True flag means that rospy will choose a unique name for a new listener node so that multiple listeners can run simultaneously. nano talker.py #!/usr/bin/env python import rospy from std_msgs.msg import String def talker (): # create a publisher, on topic `chatter` pub = rospy . Publisher ( 'chatter' , String , queue_size = 10 ) # create a node rospy . init_node ( 'talker' , anonymous = True ) # set the rate of publishing rate = rospy . Rate ( 1 ) # 1hz # main loop while not rospy . is_shutdown (): # make content hello_str = \"hello world %s \" % rospy . get_time () rospy . loginfo ( hello_str ) # publish a message pub . publish ( hello_str ) rate . sleep () if __name__ == '__main__' : try : talker () except rospy . ROSInterruptException : pass","title":"A Publisher Node"},{"location":"blog/ros/beginner-guide-2/#a-subscriber-node_1","text":"This tutorial demonstrates simple receipt of messages over the ROS system. nano listener.py #!/usr/bin/env python import rospy from std_msgs.msg import String def callback ( data ): rospy . loginfo ( rospy . get_caller_id () + \"I heard %s \" , data . data ) def listener (): # create a node rospy . init_node ( 'listener' , anonymous = True ) # create a subcriber rospy . Subscriber ( \"chatter\" , String , callback ) # spin() simply keeps python from exiting until this node is stopped rospy . spin () if __name__ == '__main__' : listener () The function rospy.spin() simply keeps the node from exiting until the node has been shutdown. Unlike roscpp, rospy.spin() does not affect the subscriber callback functions, as those have their own threads.","title":"A Subscriber Node"},{"location":"blog/ros/beginner-guide-2/#make-script-executable","text":"Scripts need to get execution permission before they can run: chmod +x *","title":"Make script executable"},{"location":"blog/ros/beginner-guide-2/#building-new-nodes_1","text":"Add the source code files which need to be compiled into the CMakeLists.txt . With all dependency packages listed above, add below lines also: cd .. && \\ nano CMakeLists.txt catkin_install_python ( PROGRAMS scripts/talker.py scripts/listener.py DESTINATION ${ CATKIN_PACKAGE_BIN_DESTINATION } ) Finally, make the package again: roscd beginner_tutorials && \\ cd ../.. && \\ catkin_make && \\ cd -","title":"Building new nodes"},{"location":"blog/ros/beginner-guide-2/#run-new-nodes_1","text":"Run roscore first if it is not running. Then run 2 new nodes in two terminals: rosrun beginner_tutorials talker.py rosrun beginner_tutorials listener.py Python script execution If the error /usr/bin/env: \u2018python \\r \u2019: No such file or directory shows up, it is because of the ending line characters. Unix use LF only while Windows use CRLF . Save python scripts in Unix ending character only.","title":"Run new nodes"},{"location":"blog/ros/beginner-guide-2/#service-and-client-c","text":"Go to the source code folder of the beginner_tutorials package: roscd beginner_tutorials && \\ mkdir src && \\ cd src","title":"Service and Client (C++)"},{"location":"blog/ros/beginner-guide-2/#a-service-node","text":"This guide will create the service add_two_ints_server node which will receive two numbers and return the sum. This service uses the beginner_tutorials/AddTwoInts.h header file generated from the srv file that is created earlier. nano add_two_ints_server.cpp #include \"ros/ros.h\" #include \"beginner_tutorials/AddTwoInts.h\" // service fuction bool add ( beginner_tutorials :: AddTwoInts :: Request & req , beginner_tutorials :: AddTwoInts :: Response & res ) { res . sum = req . a + req . b ; ROS_INFO ( \"request: x=%ld, y=%ld\" , ( long int ) req . a , ( long int ) req . b ); ROS_INFO ( \"sending back response: [%ld]\" , ( long int ) res . sum ); return true ; } int main ( int argc , char ** argv ) { ros :: init ( argc , argv , \"add_two_ints_server\" ); // create a node ros :: NodeHandle n ; // node will have a service ros :: ServiceServer service = n . advertiseService ( \"add_two_ints\" , add ); ROS_INFO ( \"Ready to add two ints.\" ); // main loop ros :: spin (); return 0 ; }","title":"A Service Node"},{"location":"blog/ros/beginner-guide-2/#a-client-node","text":"This guide will create the service add_two_ints_client node which will receive two ints and return the sum. nano add_two_ints_client.cpp #include \"ros/ros.h\" #include \"beginner_tutorials/AddTwoInts.h\" #include <cstdlib> int main ( int argc , char ** argv ) { // check args ros :: init ( argc , argv , \"add_two_ints_client\" ); if ( argc != 3 ) { ROS_INFO ( \"usage: add_two_ints_client X Y\" ); return 1 ; } // create a node ros :: NodeHandle n ; // node will have a client ros :: ServiceClient client = n . serviceClient < beginner_tutorials :: AddTwoInts > ( \"add_two_ints\" ); // create a service target beginner_tutorials :: AddTwoInts srv ; // add params srv . request . a = atoll ( argv [ 1 ]); srv . request . b = atoll ( argv [ 2 ]); // call to service if ( client . call ( srv )) { ROS_INFO ( \"Sum: %ld\" , ( long int ) srv . response . sum ); } else { ROS_ERROR ( \"Failed to call service add_two_ints\" ); return 1 ; } return 0 ; }","title":"A Client Node"},{"location":"blog/ros/beginner-guide-2/#building-new-nodes_2","text":"Add the source code files which need to be compiled into the CMakeLists.txt . With all dependency packages listed above, add below lines also: cd .. && \\ nano CMakeLists.txt ## Declare a C++ executable add_executable ( add_two_ints_server src/add_two_ints_server.cpp ) target_link_libraries ( add_two_ints_server ${ catkin_LIBRARIES } ) add_dependencies ( add_two_ints_server beginner_tutorials_gencpp ) add_executable ( add_two_ints_client src/add_two_ints_client.cpp ) target_link_libraries ( add_two_ints_client ${ catkin_LIBRARIES } ) add_dependencies ( add_two_ints_client beginner_tutorials_gencpp ) This will create two executables, add_two_ints_server and add_two_ints_client, which by default will go into package directory in devel space, located by default at catkin_ws/devel/lib/<package name> . Finally, make the package again: roscd beginner_tutorials && \\ cd ../.. && \\ catkin_make && \\ cd -","title":"Building new nodes"},{"location":"blog/ros/beginner-guide-2/#run-new-nodes_2","text":"Run roscore first if it is not running. Then run 2 new nodes in two terminals: rosrun beginner_tutorials add_two_ints_server rosrun beginner_tutorials add_two_ints_client 1 2 Service and Client","title":"Run new nodes"},{"location":"blog/ros/beginner-guide-2/#service-and-client-python","text":"Go to the source code folder of the beginner_tutorials package: roscd beginner_tutorials && \\ mkdir scripts && \\ cd scripts && \\","title":"Service and Client (Python)"},{"location":"blog/ros/beginner-guide-2/#a-service-node_1","text":"This guide will create the service add_two_ints_server node which will receive two ints and return the sum. This service uses the beginner_tutorials/AddTwoInts.h header file generated from the srv file that is created earlier. nano add_two_ints_server.py #!/usr/bin/env python from __future__ import print_function from beginner_tutorials.srv import AddTwoInts , AddTwoIntsResponse import rospy def handle_add_two_ints ( req ): print ( \"Returning [ %s + %s = %s ]\" % ( req . a , req . b , ( req . a + req . b ))) return AddTwoIntsResponse ( req . a + req . b ) def add_two_ints_server (): rospy . init_node ( 'add_two_ints_server' ) s = rospy . Service ( 'add_two_ints' , AddTwoInts , handle_add_two_ints ) print ( \"Ready to add two ints.\" ) rospy . spin () if __name__ == \"__main__\" : add_two_ints_server ()","title":"A Service Node"},{"location":"blog/ros/beginner-guide-2/#a-client-node_1","text":"This guide will create the service add_two_ints_client node which will receive two ints and return the sum. nano add_two_ints_client.py #!/usr/bin/env python from __future__ import print_function import sys import rospy from beginner_tutorials.srv import * def add_two_ints_client ( x , y ): rospy . wait_for_service ( 'add_two_ints' ) try : add_two_ints = rospy . ServiceProxy ( 'add_two_ints' , AddTwoInts ) resp1 = add_two_ints ( x , y ) return resp1 . sum except rospy . ServiceException as e : print ( \"Service call failed: %s \" % e ) def usage (): return \" %s [x y]\" % sys . argv [ 0 ] if __name__ == \"__main__\" : if len ( sys . argv ) == 3 : x = int ( sys . argv [ 1 ]) y = int ( sys . argv [ 2 ]) else : print ( usage ()) sys . exit ( 1 ) print ( \"Requesting %s + %s \" % ( x , y )) print ( \" %s + %s = %s \" % ( x , y , add_two_ints_client ( x , y )))","title":"A Client Node"},{"location":"blog/ros/beginner-guide-2/#make-scripts-executable","text":"Scripts need to get execution permission before they can run: chmod +x *","title":"Make scripts executable"},{"location":"blog/ros/beginner-guide-2/#building-new-nodes_3","text":"Add the source code files which need to be compiled into the CMakeLists.txt . With all dependency packages listed above, add below lines also: cd .. && \\ nano CMakeLists.txt catkin_install_python ( PROGRAMS scripts/add_two_ints_server.py scripts/add_two_ints_client.py DESTINATION ${ CATKIN_PACKAGE_BIN_DESTINATION } ) This will create two executables, add_two_ints_server and add_two_ints_client, which by default will go into package directory in devel space, located by default at catkin_ws/devel/lib/<package name> . Finally, make the package again: roscd beginner_tutorials && \\ cd ../.. && \\ catkin_make && \\ cd -","title":"Building new nodes"},{"location":"blog/ros/beginner-guide-2/#run-new-nodes_3","text":"Run roscore first if it is not running. Then run 2 new nodes in two terminals: rosrun beginner_tutorials add_two_ints_server.py rosrun beginner_tutorials add_two_ints_client.py 1 3","title":"Run new nodes"},{"location":"blog/ros/beginner-guide-2/#reference","text":"There is an interesting book named A Gentle Introduction to ROS by Jason M. O\u2019Kane published on https://cse.sc.edu/~jokane/agitr/ . This book supplements ROS\u2019s own documentation, explaining how to interact with existing ROS systems and how to create new ROS programs using C++, with special attention to common mistakes and misunderstandings. An excerpt from the book: Giving ROS control The final complication is that ROS will only execute our callback function when we give it explicit permission to do so. There are actually two slightly different ways to accomplish this. One version looks like this: ros :: spinOnce (); This code asks ROS to execute all of the pending callbacks from all of the node\u2019s subscriptions, and then return control back to us. The other option looks like this: ros :: spin (); This alternative to ros::spinOnce() asks ROS to wait for and execute callbacks until the node shuts down. In other words, ros::spin() is roughly equivalent to this loop: while ( ros :: ok ()) { ros :: spinOnce (); } The question of whether to use ros::spinOnce() or ros::spin() comes down to this: Does your program have any repetitive work to do, other than responding to callbacks? If the answer is No , then use ros::spin() . If the answer is Yes , then a reasonable option is to write a loop that does that other work and calls ros::spinOnce() periodically to process callbacks. A common error in subscriber programs is to mistakenly omit both ros::spinOnce() and ros::spin() . In this case, ROS never has an opportunity to execute your callback function. Omitting ros::spin() will likely cause your program to exit shortly after it starts. Omitting ros::spinOnce() might make it appear as though no messages are being received.","title":"Reference"},{"location":"blog/site-setup/","text":"","title":"How to set up your site"},{"location":"blog/site-setup/add-new-features/","tags":["jinja","javascript"],"text":"Tags page # The tag page is the place to list all tags, and list all pages that have a common tag. A new page will be created at docs\\tags\\index.md . There is a method to use MkDocs Macros in Markdown template, but it is quite complicated. Visit the Tags page to see the result. I use Jinja syntax to create the content of the Tags page, therefore, create a new file at overrides\\tags.html and use it as the template for the Tags page: docs\\tags\\index.md --- title : Tags description : Tags and list of pages template : tags.html disqus : \"\" hide : - navigation - toc --- The tags.html template to include 2 parts: tag-cloud.html : make a tag cloud to see how many pages are associated with a tag tag-list-pages.html : for each tag, list all pages having that tag to show similar articles together overrides\\tags.html {% extends \"main.html\" %} {% block site_nav %} {% endblock %} {% block content %} <style> .md-typeset .tags { max-width: 35rem; margin: 0 auto; } .md-typeset .tags details { background-color: aliceblue !important; padding: 0.5em 1em; } </style> <div class=\"tags\"> {% include \"partials/tag-cloud.html\" %} <hr> {% include \"partials/tag-page-list.html\" %} </div> {% endblock %} Tags will have random colors, to easily disguise them to each other. A helper random_color() macro that returns a random color looks like: overrides\\partials\\random-colors.html {% - macro random_color () - %} {{ - [ \"DarkRed\" , \"DarkGoldenrod\" , \"DarkGreen\" , \"DarkOliveGreen\" , \"DarkCyan\" , \"DarkTurquoise\" , \"DarkBlue\" , \"DarkMagenta\" , \"DarkViolet\" , \"DarkSlateBlue\" , \"DarkOrchid\" , \"DarkSlateGray\" ] | random - }} {% - endmacro - %} Then it can be imported and used: {% from \"partials/random-colors.html\" import random_color %} <span style=\"color: {{ random_color () }} ;\">tag</span> Tag cloud # The tag cloud shows all tags in different size and color. The bigger a tag is, the more pages mention that tag. Steps to make a tag cloud: Scan all pages and create a list of pairs (tag, pages[]) . Count the number of pages for each tag then show each tag with different text size and color using font-size and color attributes. overrides\\partials\\tag-cloud.html {% from \"partials/colors.html\" import color %} {% set tags =[] %} {# scan all pages #} {% for p in pages %} {% if p.page.meta.tags %} {# extract tags if available #} {% for tag in p.page.meta.tags %} {% if tags | length %} {% set ns = namespace ( found = False ) %} {# read more about scope at https://jinja.palletsprojects.com/en/2.11.x/templates/#assignments #} {# check if tag exists, append to its page list #} {% for item in tags %} {% set t , ps = item %} {% if tag == t %} {% set ns.found = True %} {# use \"\" to not add spaces in content #} {{ ps.append ( p.page ) or \"\" }} {% endif %} {% endfor %} {# if tag doesn't exist, create new page list#} {% if not ns.found %} {{ tags.append (( tag , [ p.page ])) or \"\" }} {% endif %} {% else %} {{ tags.append (( tag , [ p.page ])) or \"\" }} {% endif %} {% endfor %} {% endif %} {% endfor %} <style> .tag-cloud { margin-top:0; margin-bottom: 0.5em; } .tag-cloud-content { padding: 0 0.6rem; {% if page.url == 'tags/' %} text-align: center; {% endif %} } </style> <p class=\"md-nav tag-cloud\"> <label class=\"md-nav__title\">Tag cloud</label> </p> <div class=\"tag-cloud-content\"> {% if tags | count %} {% for item in tags %} {% set tag , ps = item %} {# create a link with tag name #} {# font size is based on the page count #} <a class=\"tag\" href=\" {{ config.site_url }} tags/# {{ tag }} \"> <span class=\"tag-name\" style=\" {% set sz = ps | count %} {% if sz > 10 %} {% set sz = 10 %} {% endif %} {% if page.url == 'tags/' %} font-size: {{ 1 + sz * 0.05 }} rem; {% else %} font-size: {{ 0.5 + sz * 0.05 }} rem; {% endif %} color: {{ color ( loop .index % 12 ) }} ; \"> {{ - tag - }} &nbsp; </span> <!--<sup class=\"tag-count\"> {{ - ps | count - }} </sup>--> </a> {% endfor %} {% else %} <p> No tag found! </p> {% endif %} </div> Page list # This section is simple as it just needs to loop through the list of pairs (tag, pages[]) and create a link to each page. Steps to take that: Scan all pages and create a list of pairs (tag, pages[]) . Show each tag with the list of pages in a collapsible <details> block. Only one tag block is open at a time to easily follow the selected tag. To do this, I added a callback of the toggle event on all tag blocks. Whenever a block is opened, this script will close all others. A tag block can be opened via URL with hash being the selected tag. overrides\\partials\\tag-page-list.html {% set tags =[] %} {# scan all pages #} {% for p in pages %} {% set pg = p.page %} {% set hidden = true if ( pg.meta and pg.meta.hide and ( 'in_recent_list' in pg.meta.hide )) %} {% if pg.meta.tags and not hidden %} {# extract tags if available #} {% for tag in pg.meta.tags %} {% if tags | length %} {% set ns = namespace ( found = False ) %} {# read more about scope at https://jinja.palletsprojects.com/en/2.11.x/templates/#assignments #} {# check if tag exists, append to its page list #} {% for item in tags %} {% set t , ps = item %} {% if tag == t %} {% set ns.found = True %} {# use \"\" to not add spaces in content #} {{ ps.append ( pg ) or \"\" }} {% endif %} {% endfor %} {# if tag doesn't exist, create new page list#} {% if not ns.found %} {{ tags.append (( tag , [ pg ])) or \"\" }} {% endif %} {% else %} {{ tags.append (( tag , [ pg ])) or \"\" }} {% endif %} {% endfor %} {% endif %} {% endfor %} <style> .md-typeset .tag summary::before { height: 1rem; width: 1rem; margin-top: 0.25em; } </style> <div class=\"tag-page-list\"> {% for item in tags %} {% set tag , ps = item %} <details class=\"tag\" id= {{ tag }} > <summary> {{ - tag }} ( {{ - ps | count - }} ) <a class=\"headerlink\" href=\"# {{ tag }} \">\u2693\ufe0e</a> </summary> <ol> {% for p in ps %} <li> <a href=\" {{ p.canonical_url }} \"> {% - if p.meta and p.meta.title - %} {{ - p.meta.title - }} {% - else - %} {{ - p.title - }} {% - endif - %} </a> </li> {% endfor %} </ol> </details> {% endfor %} </div> <!-- expand page list for only selected tag --> <script> [...document.getElementsByTagName(\"details\")].forEach((D, _, A) => { D.open = false D.addEventListener(\"toggle\", E => D.open && A.forEach(d => d != E.target && (d.open = false) ) ) } ) var hash = window.location.hash.substr(1); if (hash) { document.getElementById(hash).open = true; } </script> Main template # The main.html file, extending the base.html template, will be used for all markdown pages, and it is the starting point to add custom template. To override it, add the main.html file in the overrides folder. Here are things I\u2019m going to do to add more content into a blog post: Extract metadata to get title , description , tags , and other information. Add block to use the Open Graph protocol to show the page\u2019s information when a user shares a page on a social network. Include modified Navigation section to show Tag cloud in either left or right panel. Include modified Page Content which renders the content with additional sections (cover, table of content, main content, comments.). overrides\\main.html {# page info #} {% set page_title = '' %} {% if page and page.meta and page.meta.title %} {% set page_title = page.meta.title %} {% elif page and page.title and not page.is_homepage %} {% set page_title = page.title %} {% endif %} {% if page.markdown == '' and page.parent.children %} {% if page and page.meta and page.meta.title %} {% set page_title = page.meta.title %} {% else %} {% set page_title = page.parent.title %} {% endif %} {% endif %} {% set page_description = '' %} {% if page and page.meta and page.meta.description %} {% set page_description = page.meta.description %} {% elif page and page.description and not page.is_homepage %} {% set page_description = page.description %} {% endif %} {% set page_url = page.canonical_url %} {% set page_image = config.site_url ~ \"assets/banner.jpg\" %} {% if page and page.meta and page.meta.banner %} {% set page_image = page.canonical_url ~ page.meta.banner %} {% endif %} {% if page and page.meta and page.meta.tags %} {% set page_tags = page.meta.tags %} {% endif %} {# template #} {% extends \"base.html\" %} {# title #} {% block htmltitle %} <title> {{ page_title }} - {{ config.site_name }} </title> {% endblock %} {# sharing #} {% block extrahead %} {% include \"partials/ads.html\" %} <!-- Open Graph --> <meta property=\"og:type\" content=\"website\" /> <meta property=\"og:title\" content=\" {{ page_title }} - {{ config.site_name }} \" /> <meta property=\"og:description\" content=\" {{ page_description }} - {{ config.site_description }} \" /> <meta property=\"og:url\" content=\" {{ page_url }} \" /> <meta property=\"og:image\" content=\" {{ page_image }} \" /> <meta property=\"og:image:type\" content=\"image/png\" /> <meta property=\"og:image:width\" content=\"1200\" /> <meta property=\"og:image:height\" content=\"630\" /> <!-- Twitter Cards --> <meta name=\"twitter:card\" content=\"summary_large_image\" /> <meta name=\"twitter:title\" content=\" {{ page_title }} - {{ config.site_name }} \" /> <meta name=\"twitter:description\" content=\" {{ page_description }} - {{ config.site_description }} \" /> <meta name=\"twitter:image\" content=\" {{ page_image }} \" /> {% endblock %} {# navigation #} {% block site_nav %} {% include \"partials/navigation.html\" %} {% endblock %} {# content #} {% block content %} {% include \"partials/post-content.html\" %} {% include \"partials/ads-end-of-content.html\" %} {% endblock %} Navigation # The sidebar will display the tag cloud based in the page\u2019s table of content. overrides\\partials\\navigation.html {% if nav %} {% if page.meta and page.meta.hide %} {% set hidden = \"hidden\" if \"navigation\" in page.meta.hide %} {% endif %} <div class=\"md-sidebar md-sidebar--primary\" data-md-component=\"sidebar\" data-md-type=\"navigation\" {{ hidden }} > <div class=\"md-sidebar__scrollwrap\"> <div class=\"md-sidebar__inner\"> {% include \"partials/nav.html\" %} {# show tags on the left side if the right side has toc #} {% if page.toc %} <br> <br> <div class=\"tag-cloud-nav\"> {% include \"partials/tag-cloud.html\" %} </div> {% endif %} {% include \"partials/ads-sidebar.html\" %} </div> </div> </div> {% endif %} {% if not \"toc.integrate\" in features %} {% if page.meta and page.meta.hide %} {% set hidden = \"hidden\" if \"toc\" in page.meta.hide %} {% endif %} <div class=\"md-sidebar md-sidebar--secondary\" data-md-component=\"sidebar\" data-md-type=\"toc\" {{ hidden }} > <div class=\"md-sidebar__scrollwrap\"> <div class=\"md-sidebar__inner\"> {% if not page.is_homepage %} {% include \"partials/toc.html\" %} {% endif %} {# show tags on the right side if there is no toc there #} {% if page.is_homepage or not page.toc %} <div class=\"tag-cloud-toc\"> {% include \"partials/tag-cloud.html\" %} </div> {% endif %} {% include \"partials/ads-sidebar.html\" %} </div> </div> </div> {% endif %} Page content # The page content will be placed in the main block. If there is no content, a list of children posts will be shown. overrides\\partials\\post-content.html {# edit button #} {% if page.edit_url %} <a href=\" {{ page.edit_url }} \" title=\" {{ lang.t ( 'edit.link.title' ) }} \" class=\"md-content__button md-icon\"> {% include \".icons/material/pencil.svg\" %} </a> {% endif %} {% include \"partials/post-cover.html\" %} <hr class=\"screen-only\"> {% include \"partials/post-toc.html\" %} {% if not page.is_homepage %} {% include \"partials/ads-search.html\" %} {% endif %} {# show the children pages if no content #} {% if page.markdown == '' and page.parent.children %} <h2>Posts in this section:</h2> <ol> {% for obj in page.parent.children %} {% if obj.is_section %} {% set p = obj.children [ 0 ] %} <li> <a href=\" {{ p.canonical_url }} \"> {% - if p.meta and p.meta.title - %} {{ - p.meta.title - }} {% - else - %} {{ - p.title - }} {% - endif - %} </a> </li> {% endif %} {% endfor %} </ol> {% else %} {# content #} {{ page.content }} {% endif %} {% if page.markdown == '' and page.parent.children %} {% else %} {# comment #} {% include \"partials/disqus.html\" %} {% endif %} When printing to a PDF file, the first page should show the post title and its short description. This page is called the cover page which will be created only in printing mode. Create an element with class cover in the post-cover.html template to wrap the cover section. In print mode, this element should cover the full height (100%) of the first paper and align its content vertically. After the line of tags, the updated date will be shown to easily check the latest version of the document: overrides\\partials\\post-cover.html {# the cover page #} <style> .md-typeset .cover { margin-bottom: 1em; } .md-typeset .page-category { color: gray; font-size: large; } .md-typeset .page-title { margin-left: -0.0625em; } .md-typeset .page-extra { color: gray; font-size: small; } .md-typeset .page-tags { margin: 0; } .md-typeset .page-date { margin: 0; text-align: end; } @media print { .md-typeset .cover { height: 100vh; display: flex; flex-direction: column; justify-content: center; } .md-typeset .cover + * { margin-top: 0; } } </style> <div class=\"cover\"> {# category #} {% if page.meta and page.meta.category %} <span class=\"page-category\"> {{ page.meta.category }} \u00bb </span> <br> {% endif %} {# title #} <h1 class=\"page-title\"> {{ page_title | d ( config.site_name , true ) }} </h1> {# description #} {% if page.meta and page.meta.description %} <p class=\"page-description\"> {{ page.meta.description }} </p> {% endif %} {% if page.markdown == '' and page.parent.children %} {% else %} <div class=\"page-extra row\"> <div class=\"col\"> {% if page.meta and page.meta.tags %} <p class=\"page-tags\"> {% for tag in page.meta.tags %} <a class=\"tag\" href=\" {{ config.site_url }} tags/# {{ tag }} \"> <span class=\"tag-name\"> # {{ tag }} &nbsp; </span> </a> {% endfor %} </p> {% endif %} </div> <div class=\"col\"> <p class=\"page-date\"> <span> {% if page.meta.git_revision_date_localized_raw_iso_date %} {{ lang.t ( \"source.file.date.updated\" ) }} : {{ page.meta.git_revision_date_localized_raw_iso_date }} {% endif %} </span> </p> </div> </div> {% endif %} </div> When displaying on a screen, the Table of Content is displayed in the right sidebar. In printed pages, there should be a page to display the table of content too. This page is also only visible in printing. The base Material for MkDocs theme has a partial block for Table of Content section, so I just need to declare it in post-toc.html and include it in the main.html template, between the cover page and the main content. overrides\\partials\\post-toc.html {# the table of content page #} <style> .md-typeset .toc { display: none; } .md-typeset .toc label { display: none; } .md-typeset .toc .md-nav { font-size: unset; line-height: 1.6; } .md-typeset .toc .md-nav--secondary { margin-left: -2em; } .md-typeset .toc .md-nav__list { margin: 0; } .md-typeset .toc ul { list-style: none; } @media print { .md-typeset .toc { display: block; page-break-after: always; } .md-typeset .toc .md-nav__link { color: var(--md-typeset-a-color); } .md-typeset .toc .md-nav__link.md-nav__link--active { font-weight: unset; } .md-typeset .toc + * { margin-top: 0; } } </style> <div class=\"toc\"> <h2>Table of Content</h2> {% include \"partials/toc.html\" %} </div> Jinja object It is easy to display an object in Jinja template as Jinja is based on Python. To show all attributes: {{ page.__dict__ }} To show a specific attribute: {{ page.parent.children }} The recent blog posts # There should be a page showing the recent posts to help users see what is new and updated. With the Revision Date plugin, it is able to use two new meta-data fields: git_revision_date_localized , and git_creation_date_localized if the option enable_creation_date is true . Create new index.md file inside the blog folder. When using the Section Index plugin, this index file will be merged to the Blog section, therefore, when user selects the Blog label, there is a list of recent posts will be shown. docs\\blog\\index.md --- title : Recent posts description : The lastest activities show in the list of recently updated post. Please read the post title and description and choose any post which seems interesting to you. I hope you always can find something new here. template : blog.html disqus : \"\" --- This page will use the blog.html template in which it scans all posts and check the creation date to make a list of posts. Each post should be displayed in a container and be formatted to show the title, the description (at most 250 character using the truncate filter), the creation date, and its tags. Here is the code to sort all pages in order of creation date, and then filter all blog posts to save into the array blog_pages which will be used to generate content. {% set blog_pages =[] %} {% for p in pages | sort ( attribute = 'page.meta.git_revision_date_localized' , reverse = True ) %} {% set pg = p.page %} {# do not list homepage, empty pages, hidden pages #} {% set hidden = true if ( pg.meta and pg.meta.hide and ( 'in_recent_list' in pg.meta.hide )) %} {% if ( not pg.is_homepage ) and ( not pg.markdown == '' ) and ( not hidden ) %} {{ blog_pages.append ( pg ) or \"\" }} {# use \"\" to not add spaces in content #} {% endif %} {% endfor %} Groups of pages # When the number of posts goes bigger, the recent post list becomes longer. It\u2019s time to brake the long list into pages \u2014 the user can click on the page number to see its children posts. This is called \u201cPagination\u201d. How to implement it? Jinja template has the slice filter to divide a list into sub-lists. Here, I\u2019d like to have maximum of 10 posts on each page. {# count the number of pages #} {% set page_num = (blog_pages|count / 10)|round(method='ceil')|int %} < div id = \"page_num\" data-value = \"{{page_num}}\" ></ div > < div class = \"pages\" > {% for pg_group in blog_pages|slice(page_num) %} < div class = \"page\" id = \"page{{ loop.index }}\" > {% for pg in pg_group %} < div class = \"post\" > ... create post layout and content ... </ div > {% endfor %} </ div > {% endfor %} </ div > Post-entry # Each post is wrapped inside a < div class = \"post\" > and its elements are marked with different classes, such as post-title , post-description , etc. for applying styles later. < div class = \"post\" > < h4 class = \"post-title\" > < a href = \"{{ pg.canonical_url }}\" > {{ pg.title }} </ a > </ h4 > < div class = \"post-info\" > < div > < p class = \"post-description\" > {% if pg.meta and pg.meta.description %} {{ pg.meta.description | truncate(200) }} {% endif %} </ p > < div class = \"post-extra row\" > < div class = \"col\" > {% if pg.meta and pg.meta.git_revision_date_localized %} < p class = \"post-date\" > < span > {{ pg.meta.git_revision_date_localized }} </ span > </ p > {% endif %} </ div > < div class = \"col\" > {% if pg.meta and pg.meta.tags %} < p class = \"post-tags\" > {% for tag in pg.meta.tags %} < a class = \"tag\" href = \"{{ config.site_url }}tags/#{{tag}}\" > < span class = \"tag-name\" style = \"color:{{ random_color() }};\" > #{{ tag }} </ span > </ a > {% endfor %} </ p > {% endif %} </ div > </ div > </ div > {% if pg_image %} < img class = \"post-banner \" src = '{{ pg_image }}' /> {% endif %} </ div > </ div > Here is a simple style to make each post display necessary basic information: . md-typeset . post { margin-bottom : 1 rem ; } . md-typeset . post . post-title { margin : 0.25 rem 0 ; text-decoration : none ; font-size : 1.3 em ; } . md-typeset . post . post-info { display : flex ; } . md-typeset . post . post-banner { margin-top : -1 rem ; max-height : 6 rem ; border : 1 px solid lightgray ; } . md-typeset . post . post-description { margin : 0 1 rem 0 0 ; } . md-typeset . post . post-extra { margin : 0.5 rem 1 rem 0 0 ; color : darkgray ; } . md-typeset . post . post-tags { margin : 0 ; text-align : end ; } . md-typeset . post . post-date { margin : 0 ; } Pagination bar # To show the current active page, I use pure CSS and JavaScript. The idea is to use the URL hash to detect which page is activated, such as #page1 . {# pagination #} < div class = \"pages\" > {% for pg_group in blog_pages|slice(page_num) %} < div class = \"page\" id = \"page{{ loop.index }}\" > {% for pg in pg_group %} {% set pg_image = \"\" %} {% if pg.meta and pg.meta.banner %} {% set pg_image = pg.canonical_url ~ pg.meta.banner %} {% endif %} < div class = \"post\" > ... </ div > {% endfor %} </ div > {% endfor %} </ div > < hr > < div class = \"center\" > < div class = \"pagination\" id = \"pagination-bottom\" > <!-- <a href=\"#\">&laquo;</a> --> {% for pg_group in blog_pages|slice(page_num) %} < a class = \"page-number {% if loop.index==1 %}active{% endif%}\" href = \"#page{{ loop.index }}\" > {{ loop.index }} </ a > {% endfor %} <!-- <a href=\"#\">&raquo;</a> --> </ div > </ div > < hr > < p class = \"center\" > Total < b > {{ blog_pages|count }} </ b > posts in {{ page_num }} pages. </ p > Then add some styles to the pagination block and its children links: CSS Styles : Use target keyword to select the selected page ID , then show only the target element. . md-typeset . pages > . page : target ~ . page : last-child , . md-typeset . pages > . page { display : none ; } . md-typeset . pages > : last-child , . md-typeset . pages > . page : target { display : block ; } JavaScript When the page is loaded, a script will run to get all pagination\u2019s links, and then add a callback function for click event, that remove active class from last activated element and then assign active class to the event\u2019s source element. Note that the first page is activated by default when the page is loaded. After a page is selected, function scrollToTop() will navigate to the top view. overrides\\partials\\post-list.html < script > function scrollToTop () { // delay a little for css to calculate windows size setTimeout ( function () { window . scrollTo ( 0 , 0 ); }, 100 ); } function activatePaginationLinks ( name ) { var pagination = document . getElementById ( \"pagination-\" + name ); if ( pagination ) { var links = pagination . getElementsByClassName ( \"page-number\" ); if ( links . length ) { for ( var i = 0 ; i < links . length ; i ++ ) { if ( links [ i ]. getAttribute ( \"href\" ) == window . location . hash ) { links [ i ]. classList . add ( \"active\" ); } else { links [ i ]. classList . remove ( \"active\" ) } } } } } // show page 1 as default window . location . hash = \"#page1\" ; // listen to hash change window . onhashchange = function () { var hash = window . location . hash ; const regexp = /^#page[0-9]+$/ ; if ( regexp . test ( hash )) { var num = parseInt ( hash . substr ( 5 )); var max = parseInt ( document . getElementById ( 'page_num' ). dataset . value ); if ( num >= 1 && num <= max ) { activatePaginationLinks ( \"top\" ); activatePaginationLinks ( \"bottom\" ); scrollToTop (); return ; } } window . location . hash = \"#page1\" ; } < /script> Zoom-in Images # As mentioned in the Images section, view-bigimg library helps to zoom and pan images. It\u2019s useful when the image is in high resolution and resized to fit site\u2019s width. Download view-bigimg.css and view-bigimg.js files from the view-bigimg repo, then add them into the addition assets configs in mkdocs.yml : extra_css : - assets/view-bigimg.css extra_javascript : - assets/view-bigimg.js When click on the image, this library will create a new layer and show the image in a bigger size. However, it must be clicked on the close button to go back to the page\u2019s content. I want to simplify this step by just click on the image. Panning still is activated by press and hold. Therefore, I write a function to detect mousedown and mousemove event, then only close the image if it is a simple click: assets\\extra.js var dragged = false ; document . addEventListener ( \"mousedown\" , () => ( dragged = false )); document . addEventListener ( \"mousemove\" , () => ( dragged = true )); var viewer = new ViewBigimg (); var figures = document . querySelectorAll ( \"img\" ); for ( var i = 0 ; i < figures . length ; i ++ ) { figures [ i ]. onclick = ( e ) => { if ( e . target . nodeName === \"IMG\" ) { viewer . show ( e . target . src ); } }; } var containers = document . querySelectorAll ( \"#iv-container .iv-image-view\" ); for ( var i = 0 ; i < containers . length ; i ++ ) { containers [ i ]. onclick = () => { if ( ! dragged ) { viewer . hide (); } }; } Open external links # When following links, to remain the blog page opened, external links should be shown in new tabs without any tracking information. To do that, I write some lines of code to get all external links in the page, then set target = \"_blank\" and add attribute rel = \"noopener noreferrer\" to them. assets\\extra.js /* open external links in new tab */ var links = document . links ; for ( var i = 0 , linksLength = links . length ; i < linksLength ; i ++ ) { if ( links [ i ]. hostname != window . location . hostname ) { links [ i ]. target = \"_blank\" ; links [ i ]. setAttribute ( \"rel\" , \"noopener noreferrer\" ); links [ i ]. className += \" externalLink\" ; } else { links [ i ]. className += \" localLink\" ; } }","title":"Add Tags, Recent Post and new Features to my Blog site"},{"location":"blog/site-setup/add-new-features/#tags-page","text":"The tag page is the place to list all tags, and list all pages that have a common tag. A new page will be created at docs\\tags\\index.md . There is a method to use MkDocs Macros in Markdown template, but it is quite complicated. Visit the Tags page to see the result. I use Jinja syntax to create the content of the Tags page, therefore, create a new file at overrides\\tags.html and use it as the template for the Tags page: docs\\tags\\index.md --- title : Tags description : Tags and list of pages template : tags.html disqus : \"\" hide : - navigation - toc --- The tags.html template to include 2 parts: tag-cloud.html : make a tag cloud to see how many pages are associated with a tag tag-list-pages.html : for each tag, list all pages having that tag to show similar articles together overrides\\tags.html {% extends \"main.html\" %} {% block site_nav %} {% endblock %} {% block content %} <style> .md-typeset .tags { max-width: 35rem; margin: 0 auto; } .md-typeset .tags details { background-color: aliceblue !important; padding: 0.5em 1em; } </style> <div class=\"tags\"> {% include \"partials/tag-cloud.html\" %} <hr> {% include \"partials/tag-page-list.html\" %} </div> {% endblock %} Tags will have random colors, to easily disguise them to each other. A helper random_color() macro that returns a random color looks like: overrides\\partials\\random-colors.html {% - macro random_color () - %} {{ - [ \"DarkRed\" , \"DarkGoldenrod\" , \"DarkGreen\" , \"DarkOliveGreen\" , \"DarkCyan\" , \"DarkTurquoise\" , \"DarkBlue\" , \"DarkMagenta\" , \"DarkViolet\" , \"DarkSlateBlue\" , \"DarkOrchid\" , \"DarkSlateGray\" ] | random - }} {% - endmacro - %} Then it can be imported and used: {% from \"partials/random-colors.html\" import random_color %} <span style=\"color: {{ random_color () }} ;\">tag</span>","title":"Tags page"},{"location":"blog/site-setup/add-new-features/#tag-cloud","text":"The tag cloud shows all tags in different size and color. The bigger a tag is, the more pages mention that tag. Steps to make a tag cloud: Scan all pages and create a list of pairs (tag, pages[]) . Count the number of pages for each tag then show each tag with different text size and color using font-size and color attributes. overrides\\partials\\tag-cloud.html {% from \"partials/colors.html\" import color %} {% set tags =[] %} {# scan all pages #} {% for p in pages %} {% if p.page.meta.tags %} {# extract tags if available #} {% for tag in p.page.meta.tags %} {% if tags | length %} {% set ns = namespace ( found = False ) %} {# read more about scope at https://jinja.palletsprojects.com/en/2.11.x/templates/#assignments #} {# check if tag exists, append to its page list #} {% for item in tags %} {% set t , ps = item %} {% if tag == t %} {% set ns.found = True %} {# use \"\" to not add spaces in content #} {{ ps.append ( p.page ) or \"\" }} {% endif %} {% endfor %} {# if tag doesn't exist, create new page list#} {% if not ns.found %} {{ tags.append (( tag , [ p.page ])) or \"\" }} {% endif %} {% else %} {{ tags.append (( tag , [ p.page ])) or \"\" }} {% endif %} {% endfor %} {% endif %} {% endfor %} <style> .tag-cloud { margin-top:0; margin-bottom: 0.5em; } .tag-cloud-content { padding: 0 0.6rem; {% if page.url == 'tags/' %} text-align: center; {% endif %} } </style> <p class=\"md-nav tag-cloud\"> <label class=\"md-nav__title\">Tag cloud</label> </p> <div class=\"tag-cloud-content\"> {% if tags | count %} {% for item in tags %} {% set tag , ps = item %} {# create a link with tag name #} {# font size is based on the page count #} <a class=\"tag\" href=\" {{ config.site_url }} tags/# {{ tag }} \"> <span class=\"tag-name\" style=\" {% set sz = ps | count %} {% if sz > 10 %} {% set sz = 10 %} {% endif %} {% if page.url == 'tags/' %} font-size: {{ 1 + sz * 0.05 }} rem; {% else %} font-size: {{ 0.5 + sz * 0.05 }} rem; {% endif %} color: {{ color ( loop .index % 12 ) }} ; \"> {{ - tag - }} &nbsp; </span> <!--<sup class=\"tag-count\"> {{ - ps | count - }} </sup>--> </a> {% endfor %} {% else %} <p> No tag found! </p> {% endif %} </div>","title":"Tag cloud"},{"location":"blog/site-setup/add-new-features/#page-list","text":"This section is simple as it just needs to loop through the list of pairs (tag, pages[]) and create a link to each page. Steps to take that: Scan all pages and create a list of pairs (tag, pages[]) . Show each tag with the list of pages in a collapsible <details> block. Only one tag block is open at a time to easily follow the selected tag. To do this, I added a callback of the toggle event on all tag blocks. Whenever a block is opened, this script will close all others. A tag block can be opened via URL with hash being the selected tag. overrides\\partials\\tag-page-list.html {% set tags =[] %} {# scan all pages #} {% for p in pages %} {% set pg = p.page %} {% set hidden = true if ( pg.meta and pg.meta.hide and ( 'in_recent_list' in pg.meta.hide )) %} {% if pg.meta.tags and not hidden %} {# extract tags if available #} {% for tag in pg.meta.tags %} {% if tags | length %} {% set ns = namespace ( found = False ) %} {# read more about scope at https://jinja.palletsprojects.com/en/2.11.x/templates/#assignments #} {# check if tag exists, append to its page list #} {% for item in tags %} {% set t , ps = item %} {% if tag == t %} {% set ns.found = True %} {# use \"\" to not add spaces in content #} {{ ps.append ( pg ) or \"\" }} {% endif %} {% endfor %} {# if tag doesn't exist, create new page list#} {% if not ns.found %} {{ tags.append (( tag , [ pg ])) or \"\" }} {% endif %} {% else %} {{ tags.append (( tag , [ pg ])) or \"\" }} {% endif %} {% endfor %} {% endif %} {% endfor %} <style> .md-typeset .tag summary::before { height: 1rem; width: 1rem; margin-top: 0.25em; } </style> <div class=\"tag-page-list\"> {% for item in tags %} {% set tag , ps = item %} <details class=\"tag\" id= {{ tag }} > <summary> {{ - tag }} ( {{ - ps | count - }} ) <a class=\"headerlink\" href=\"# {{ tag }} \">\u2693\ufe0e</a> </summary> <ol> {% for p in ps %} <li> <a href=\" {{ p.canonical_url }} \"> {% - if p.meta and p.meta.title - %} {{ - p.meta.title - }} {% - else - %} {{ - p.title - }} {% - endif - %} </a> </li> {% endfor %} </ol> </details> {% endfor %} </div> <!-- expand page list for only selected tag --> <script> [...document.getElementsByTagName(\"details\")].forEach((D, _, A) => { D.open = false D.addEventListener(\"toggle\", E => D.open && A.forEach(d => d != E.target && (d.open = false) ) ) } ) var hash = window.location.hash.substr(1); if (hash) { document.getElementById(hash).open = true; } </script>","title":"Page list"},{"location":"blog/site-setup/add-new-features/#main-template","text":"The main.html file, extending the base.html template, will be used for all markdown pages, and it is the starting point to add custom template. To override it, add the main.html file in the overrides folder. Here are things I\u2019m going to do to add more content into a blog post: Extract metadata to get title , description , tags , and other information. Add block to use the Open Graph protocol to show the page\u2019s information when a user shares a page on a social network. Include modified Navigation section to show Tag cloud in either left or right panel. Include modified Page Content which renders the content with additional sections (cover, table of content, main content, comments.). overrides\\main.html {# page info #} {% set page_title = '' %} {% if page and page.meta and page.meta.title %} {% set page_title = page.meta.title %} {% elif page and page.title and not page.is_homepage %} {% set page_title = page.title %} {% endif %} {% if page.markdown == '' and page.parent.children %} {% if page and page.meta and page.meta.title %} {% set page_title = page.meta.title %} {% else %} {% set page_title = page.parent.title %} {% endif %} {% endif %} {% set page_description = '' %} {% if page and page.meta and page.meta.description %} {% set page_description = page.meta.description %} {% elif page and page.description and not page.is_homepage %} {% set page_description = page.description %} {% endif %} {% set page_url = page.canonical_url %} {% set page_image = config.site_url ~ \"assets/banner.jpg\" %} {% if page and page.meta and page.meta.banner %} {% set page_image = page.canonical_url ~ page.meta.banner %} {% endif %} {% if page and page.meta and page.meta.tags %} {% set page_tags = page.meta.tags %} {% endif %} {# template #} {% extends \"base.html\" %} {# title #} {% block htmltitle %} <title> {{ page_title }} - {{ config.site_name }} </title> {% endblock %} {# sharing #} {% block extrahead %} {% include \"partials/ads.html\" %} <!-- Open Graph --> <meta property=\"og:type\" content=\"website\" /> <meta property=\"og:title\" content=\" {{ page_title }} - {{ config.site_name }} \" /> <meta property=\"og:description\" content=\" {{ page_description }} - {{ config.site_description }} \" /> <meta property=\"og:url\" content=\" {{ page_url }} \" /> <meta property=\"og:image\" content=\" {{ page_image }} \" /> <meta property=\"og:image:type\" content=\"image/png\" /> <meta property=\"og:image:width\" content=\"1200\" /> <meta property=\"og:image:height\" content=\"630\" /> <!-- Twitter Cards --> <meta name=\"twitter:card\" content=\"summary_large_image\" /> <meta name=\"twitter:title\" content=\" {{ page_title }} - {{ config.site_name }} \" /> <meta name=\"twitter:description\" content=\" {{ page_description }} - {{ config.site_description }} \" /> <meta name=\"twitter:image\" content=\" {{ page_image }} \" /> {% endblock %} {# navigation #} {% block site_nav %} {% include \"partials/navigation.html\" %} {% endblock %} {# content #} {% block content %} {% include \"partials/post-content.html\" %} {% include \"partials/ads-end-of-content.html\" %} {% endblock %}","title":"Main template"},{"location":"blog/site-setup/add-new-features/#navigation","text":"The sidebar will display the tag cloud based in the page\u2019s table of content. overrides\\partials\\navigation.html {% if nav %} {% if page.meta and page.meta.hide %} {% set hidden = \"hidden\" if \"navigation\" in page.meta.hide %} {% endif %} <div class=\"md-sidebar md-sidebar--primary\" data-md-component=\"sidebar\" data-md-type=\"navigation\" {{ hidden }} > <div class=\"md-sidebar__scrollwrap\"> <div class=\"md-sidebar__inner\"> {% include \"partials/nav.html\" %} {# show tags on the left side if the right side has toc #} {% if page.toc %} <br> <br> <div class=\"tag-cloud-nav\"> {% include \"partials/tag-cloud.html\" %} </div> {% endif %} {% include \"partials/ads-sidebar.html\" %} </div> </div> </div> {% endif %} {% if not \"toc.integrate\" in features %} {% if page.meta and page.meta.hide %} {% set hidden = \"hidden\" if \"toc\" in page.meta.hide %} {% endif %} <div class=\"md-sidebar md-sidebar--secondary\" data-md-component=\"sidebar\" data-md-type=\"toc\" {{ hidden }} > <div class=\"md-sidebar__scrollwrap\"> <div class=\"md-sidebar__inner\"> {% if not page.is_homepage %} {% include \"partials/toc.html\" %} {% endif %} {# show tags on the right side if there is no toc there #} {% if page.is_homepage or not page.toc %} <div class=\"tag-cloud-toc\"> {% include \"partials/tag-cloud.html\" %} </div> {% endif %} {% include \"partials/ads-sidebar.html\" %} </div> </div> </div> {% endif %}","title":"Navigation"},{"location":"blog/site-setup/add-new-features/#page-content","text":"The page content will be placed in the main block. If there is no content, a list of children posts will be shown. overrides\\partials\\post-content.html {# edit button #} {% if page.edit_url %} <a href=\" {{ page.edit_url }} \" title=\" {{ lang.t ( 'edit.link.title' ) }} \" class=\"md-content__button md-icon\"> {% include \".icons/material/pencil.svg\" %} </a> {% endif %} {% include \"partials/post-cover.html\" %} <hr class=\"screen-only\"> {% include \"partials/post-toc.html\" %} {% if not page.is_homepage %} {% include \"partials/ads-search.html\" %} {% endif %} {# show the children pages if no content #} {% if page.markdown == '' and page.parent.children %} <h2>Posts in this section:</h2> <ol> {% for obj in page.parent.children %} {% if obj.is_section %} {% set p = obj.children [ 0 ] %} <li> <a href=\" {{ p.canonical_url }} \"> {% - if p.meta and p.meta.title - %} {{ - p.meta.title - }} {% - else - %} {{ - p.title - }} {% - endif - %} </a> </li> {% endif %} {% endfor %} </ol> {% else %} {# content #} {{ page.content }} {% endif %} {% if page.markdown == '' and page.parent.children %} {% else %} {# comment #} {% include \"partials/disqus.html\" %} {% endif %} When printing to a PDF file, the first page should show the post title and its short description. This page is called the cover page which will be created only in printing mode. Create an element with class cover in the post-cover.html template to wrap the cover section. In print mode, this element should cover the full height (100%) of the first paper and align its content vertically. After the line of tags, the updated date will be shown to easily check the latest version of the document: overrides\\partials\\post-cover.html {# the cover page #} <style> .md-typeset .cover { margin-bottom: 1em; } .md-typeset .page-category { color: gray; font-size: large; } .md-typeset .page-title { margin-left: -0.0625em; } .md-typeset .page-extra { color: gray; font-size: small; } .md-typeset .page-tags { margin: 0; } .md-typeset .page-date { margin: 0; text-align: end; } @media print { .md-typeset .cover { height: 100vh; display: flex; flex-direction: column; justify-content: center; } .md-typeset .cover + * { margin-top: 0; } } </style> <div class=\"cover\"> {# category #} {% if page.meta and page.meta.category %} <span class=\"page-category\"> {{ page.meta.category }} \u00bb </span> <br> {% endif %} {# title #} <h1 class=\"page-title\"> {{ page_title | d ( config.site_name , true ) }} </h1> {# description #} {% if page.meta and page.meta.description %} <p class=\"page-description\"> {{ page.meta.description }} </p> {% endif %} {% if page.markdown == '' and page.parent.children %} {% else %} <div class=\"page-extra row\"> <div class=\"col\"> {% if page.meta and page.meta.tags %} <p class=\"page-tags\"> {% for tag in page.meta.tags %} <a class=\"tag\" href=\" {{ config.site_url }} tags/# {{ tag }} \"> <span class=\"tag-name\"> # {{ tag }} &nbsp; </span> </a> {% endfor %} </p> {% endif %} </div> <div class=\"col\"> <p class=\"page-date\"> <span> {% if page.meta.git_revision_date_localized_raw_iso_date %} {{ lang.t ( \"source.file.date.updated\" ) }} : {{ page.meta.git_revision_date_localized_raw_iso_date }} {% endif %} </span> </p> </div> </div> {% endif %} </div> When displaying on a screen, the Table of Content is displayed in the right sidebar. In printed pages, there should be a page to display the table of content too. This page is also only visible in printing. The base Material for MkDocs theme has a partial block for Table of Content section, so I just need to declare it in post-toc.html and include it in the main.html template, between the cover page and the main content. overrides\\partials\\post-toc.html {# the table of content page #} <style> .md-typeset .toc { display: none; } .md-typeset .toc label { display: none; } .md-typeset .toc .md-nav { font-size: unset; line-height: 1.6; } .md-typeset .toc .md-nav--secondary { margin-left: -2em; } .md-typeset .toc .md-nav__list { margin: 0; } .md-typeset .toc ul { list-style: none; } @media print { .md-typeset .toc { display: block; page-break-after: always; } .md-typeset .toc .md-nav__link { color: var(--md-typeset-a-color); } .md-typeset .toc .md-nav__link.md-nav__link--active { font-weight: unset; } .md-typeset .toc + * { margin-top: 0; } } </style> <div class=\"toc\"> <h2>Table of Content</h2> {% include \"partials/toc.html\" %} </div> Jinja object It is easy to display an object in Jinja template as Jinja is based on Python. To show all attributes: {{ page.__dict__ }} To show a specific attribute: {{ page.parent.children }}","title":"Page content"},{"location":"blog/site-setup/add-new-features/#the-recent-blog-posts","text":"There should be a page showing the recent posts to help users see what is new and updated. With the Revision Date plugin, it is able to use two new meta-data fields: git_revision_date_localized , and git_creation_date_localized if the option enable_creation_date is true . Create new index.md file inside the blog folder. When using the Section Index plugin, this index file will be merged to the Blog section, therefore, when user selects the Blog label, there is a list of recent posts will be shown. docs\\blog\\index.md --- title : Recent posts description : The lastest activities show in the list of recently updated post. Please read the post title and description and choose any post which seems interesting to you. I hope you always can find something new here. template : blog.html disqus : \"\" --- This page will use the blog.html template in which it scans all posts and check the creation date to make a list of posts. Each post should be displayed in a container and be formatted to show the title, the description (at most 250 character using the truncate filter), the creation date, and its tags. Here is the code to sort all pages in order of creation date, and then filter all blog posts to save into the array blog_pages which will be used to generate content. {% set blog_pages =[] %} {% for p in pages | sort ( attribute = 'page.meta.git_revision_date_localized' , reverse = True ) %} {% set pg = p.page %} {# do not list homepage, empty pages, hidden pages #} {% set hidden = true if ( pg.meta and pg.meta.hide and ( 'in_recent_list' in pg.meta.hide )) %} {% if ( not pg.is_homepage ) and ( not pg.markdown == '' ) and ( not hidden ) %} {{ blog_pages.append ( pg ) or \"\" }} {# use \"\" to not add spaces in content #} {% endif %} {% endfor %}","title":"The recent blog posts"},{"location":"blog/site-setup/add-new-features/#groups-of-pages","text":"When the number of posts goes bigger, the recent post list becomes longer. It\u2019s time to brake the long list into pages \u2014 the user can click on the page number to see its children posts. This is called \u201cPagination\u201d. How to implement it? Jinja template has the slice filter to divide a list into sub-lists. Here, I\u2019d like to have maximum of 10 posts on each page. {# count the number of pages #} {% set page_num = (blog_pages|count / 10)|round(method='ceil')|int %} < div id = \"page_num\" data-value = \"{{page_num}}\" ></ div > < div class = \"pages\" > {% for pg_group in blog_pages|slice(page_num) %} < div class = \"page\" id = \"page{{ loop.index }}\" > {% for pg in pg_group %} < div class = \"post\" > ... create post layout and content ... </ div > {% endfor %} </ div > {% endfor %} </ div >","title":"Groups of pages"},{"location":"blog/site-setup/add-new-features/#post-entry","text":"Each post is wrapped inside a < div class = \"post\" > and its elements are marked with different classes, such as post-title , post-description , etc. for applying styles later. < div class = \"post\" > < h4 class = \"post-title\" > < a href = \"{{ pg.canonical_url }}\" > {{ pg.title }} </ a > </ h4 > < div class = \"post-info\" > < div > < p class = \"post-description\" > {% if pg.meta and pg.meta.description %} {{ pg.meta.description | truncate(200) }} {% endif %} </ p > < div class = \"post-extra row\" > < div class = \"col\" > {% if pg.meta and pg.meta.git_revision_date_localized %} < p class = \"post-date\" > < span > {{ pg.meta.git_revision_date_localized }} </ span > </ p > {% endif %} </ div > < div class = \"col\" > {% if pg.meta and pg.meta.tags %} < p class = \"post-tags\" > {% for tag in pg.meta.tags %} < a class = \"tag\" href = \"{{ config.site_url }}tags/#{{tag}}\" > < span class = \"tag-name\" style = \"color:{{ random_color() }};\" > #{{ tag }} </ span > </ a > {% endfor %} </ p > {% endif %} </ div > </ div > </ div > {% if pg_image %} < img class = \"post-banner \" src = '{{ pg_image }}' /> {% endif %} </ div > </ div > Here is a simple style to make each post display necessary basic information: . md-typeset . post { margin-bottom : 1 rem ; } . md-typeset . post . post-title { margin : 0.25 rem 0 ; text-decoration : none ; font-size : 1.3 em ; } . md-typeset . post . post-info { display : flex ; } . md-typeset . post . post-banner { margin-top : -1 rem ; max-height : 6 rem ; border : 1 px solid lightgray ; } . md-typeset . post . post-description { margin : 0 1 rem 0 0 ; } . md-typeset . post . post-extra { margin : 0.5 rem 1 rem 0 0 ; color : darkgray ; } . md-typeset . post . post-tags { margin : 0 ; text-align : end ; } . md-typeset . post . post-date { margin : 0 ; }","title":"Post-entry"},{"location":"blog/site-setup/add-new-features/#pagination-bar","text":"To show the current active page, I use pure CSS and JavaScript. The idea is to use the URL hash to detect which page is activated, such as #page1 . {# pagination #} < div class = \"pages\" > {% for pg_group in blog_pages|slice(page_num) %} < div class = \"page\" id = \"page{{ loop.index }}\" > {% for pg in pg_group %} {% set pg_image = \"\" %} {% if pg.meta and pg.meta.banner %} {% set pg_image = pg.canonical_url ~ pg.meta.banner %} {% endif %} < div class = \"post\" > ... </ div > {% endfor %} </ div > {% endfor %} </ div > < hr > < div class = \"center\" > < div class = \"pagination\" id = \"pagination-bottom\" > <!-- <a href=\"#\">&laquo;</a> --> {% for pg_group in blog_pages|slice(page_num) %} < a class = \"page-number {% if loop.index==1 %}active{% endif%}\" href = \"#page{{ loop.index }}\" > {{ loop.index }} </ a > {% endfor %} <!-- <a href=\"#\">&raquo;</a> --> </ div > </ div > < hr > < p class = \"center\" > Total < b > {{ blog_pages|count }} </ b > posts in {{ page_num }} pages. </ p > Then add some styles to the pagination block and its children links: CSS Styles : Use target keyword to select the selected page ID , then show only the target element. . md-typeset . pages > . page : target ~ . page : last-child , . md-typeset . pages > . page { display : none ; } . md-typeset . pages > : last-child , . md-typeset . pages > . page : target { display : block ; } JavaScript When the page is loaded, a script will run to get all pagination\u2019s links, and then add a callback function for click event, that remove active class from last activated element and then assign active class to the event\u2019s source element. Note that the first page is activated by default when the page is loaded. After a page is selected, function scrollToTop() will navigate to the top view. overrides\\partials\\post-list.html < script > function scrollToTop () { // delay a little for css to calculate windows size setTimeout ( function () { window . scrollTo ( 0 , 0 ); }, 100 ); } function activatePaginationLinks ( name ) { var pagination = document . getElementById ( \"pagination-\" + name ); if ( pagination ) { var links = pagination . getElementsByClassName ( \"page-number\" ); if ( links . length ) { for ( var i = 0 ; i < links . length ; i ++ ) { if ( links [ i ]. getAttribute ( \"href\" ) == window . location . hash ) { links [ i ]. classList . add ( \"active\" ); } else { links [ i ]. classList . remove ( \"active\" ) } } } } } // show page 1 as default window . location . hash = \"#page1\" ; // listen to hash change window . onhashchange = function () { var hash = window . location . hash ; const regexp = /^#page[0-9]+$/ ; if ( regexp . test ( hash )) { var num = parseInt ( hash . substr ( 5 )); var max = parseInt ( document . getElementById ( 'page_num' ). dataset . value ); if ( num >= 1 && num <= max ) { activatePaginationLinks ( \"top\" ); activatePaginationLinks ( \"bottom\" ); scrollToTop (); return ; } } window . location . hash = \"#page1\" ; } < /script>","title":"Pagination bar"},{"location":"blog/site-setup/add-new-features/#zoom-in-images","text":"As mentioned in the Images section, view-bigimg library helps to zoom and pan images. It\u2019s useful when the image is in high resolution and resized to fit site\u2019s width. Download view-bigimg.css and view-bigimg.js files from the view-bigimg repo, then add them into the addition assets configs in mkdocs.yml : extra_css : - assets/view-bigimg.css extra_javascript : - assets/view-bigimg.js When click on the image, this library will create a new layer and show the image in a bigger size. However, it must be clicked on the close button to go back to the page\u2019s content. I want to simplify this step by just click on the image. Panning still is activated by press and hold. Therefore, I write a function to detect mousedown and mousemove event, then only close the image if it is a simple click: assets\\extra.js var dragged = false ; document . addEventListener ( \"mousedown\" , () => ( dragged = false )); document . addEventListener ( \"mousemove\" , () => ( dragged = true )); var viewer = new ViewBigimg (); var figures = document . querySelectorAll ( \"img\" ); for ( var i = 0 ; i < figures . length ; i ++ ) { figures [ i ]. onclick = ( e ) => { if ( e . target . nodeName === \"IMG\" ) { viewer . show ( e . target . src ); } }; } var containers = document . querySelectorAll ( \"#iv-container .iv-image-view\" ); for ( var i = 0 ; i < containers . length ; i ++ ) { containers [ i ]. onclick = () => { if ( ! dragged ) { viewer . hide (); } }; }","title":"Zoom-in Images"},{"location":"blog/site-setup/add-new-features/#open-external-links","text":"When following links, to remain the blog page opened, external links should be shown in new tabs without any tracking information. To do that, I write some lines of code to get all external links in the page, then set target = \"_blank\" and add attribute rel = \"noopener noreferrer\" to them. assets\\extra.js /* open external links in new tab */ var links = document . links ; for ( var i = 0 , linksLength = links . length ; i < linksLength ; i ++ ) { if ( links [ i ]. hostname != window . location . hostname ) { links [ i ]. target = \"_blank\" ; links [ i ]. setAttribute ( \"rel\" , \"noopener noreferrer\" ); links [ i ]. className += \" externalLink\" ; } else { links [ i ]. className += \" localLink\" ; } }","title":"Open external links"},{"location":"blog/site-setup/create-site-project/","tags":["mkdocs"],"text":"Material for MkDocs # A personal site is usually a static site which has pre-built contents. A static site generator is a tool that generates a full static HTML website based on raw data and a set of templates. Visit the list of Site Generators to see available tools. MkDocs is a fast and simple engine to build a site for project documentation. Content source files are written in Markdown format, and the site is configured with a single YAML config file. Material for MkDocs is a popular theme for MkDocs. It has a simple and clear layout with a bunch of useful features, such as better navigation behaviors, strongly integrated Markdown extensions, and some additional tweaks. This project has a paid version called Insiders , but the free version is perfectly enough for a personal use. Installation # Steps to install and create a new site: Download and install Python 3 . Create a new folder to store the project: mkdir CodeInsideOut cd CodeInsideOut It\u2019s recommended to use a virtual environment to isolate this project with others from a possible package conflict. python -m venv .venv Then activate the virtual environment: Windows Linux .venv\\Scripts\\activate.bat .venv/Scripts/activate Remember to run this command every time you come back to work in this project. Install Material for MkDocs package. Read more at getting started : pip install mkdocs-material Start a new site: mkdocs new . This will create the following file structure: . \u251c\u2500 mkdocs.yml # The configuration file \u2514\u2500 docs/ # Other markdown pages \u251c\u2500 index.md # The documentation homepage \u2514\u2500 ... # Other files Enable Material for MkDocs theme by adding a config into mkdocs.yml : theme : name : material Run a local server, and preview the site at http://localhost:8000 to see the default homepage: mkdocs serve To publish the site, build it first: mkdocs build Then copy all the content in the site folder to the website\u2019s root folder. Working folder # Each Markdown file inside the folder docs will be rendered as a page of the site. The index page is located at docs\\index.md . Sub-folders are used as the path to a group of related posts. If a post is named other than index.md , the filename will be used as the directory path of the generated page. Here is how MkDocs generates URLs for Markdown posts: folder docs becomes the root of the site www.site.com/ file docs\\blog\\post.md becomes the link www.site.com/blog/post/ file docs\\blog\\post\\index.md also becomes the link www.site.com/blog/post/ Use hyphen ( - ) in folder name and file name to create good URLs. Some tips here . Visual Studio Code # Visual Studio Code is a lightweight but powerful source code editor. It well supports users to write code, documents, notes. This editor also have some extensions to turn it into a full-feature IDE. Useful extensions for writing in Markdown format and editing HTML template: Markdown All in One : add keyboard shortcuts, auto-completion, edit and format list and table. Markdown Paste : paste images, links from the clipboard. Prettier \u2014 Code formatter : a formatter which supports a lot of languages. Draw.io Integration : edit diagrams and SVG images. LTeX : Grammar/spell checker using LanguageTool with support for LaTeX, Markdown, and others. Additional extensions: Jinja : highlight Jinja syntax in HTML templates. Sublime Text Key map and Settings Importer : import keybindings and settings. Writing a post using Visual Studio Code Basic Configuration # All configurations are declared in the config file mkdocs.yml at the root of the project folder. Here are some main settings to quickly customize your site: Site Information # Site information consists of the name, the URL, the title, a description and some keywords that are used to get brief information about the content of the site. The copyright word should include a link to the original theme when you use the free version. site_name : Code Inside Out site_url : https://www.codeinsideout.com/ # must have the trailing slash site_author : V\u0169 Quang Tr\u1ecdng (vuquangtrong@gmail.com) site_description : Guides, notes and useful stuff for learning embedded systems. copyright : > # should remain a link to the original theme &copy; 2021 Code Inside Out<br> <a href=\"https://github.com/vuquangtrong/mkdocs-material-blog\">Blog Theme</a> / <a href=\"https://squidfunk.github.io/mkdocs-material/\">Material for MkDocs</a> The social links in the footer can be added in the extra section. extra : social : - icon : fontawesome/brands/github-alt link : https://github.com/vuquangtrong name : vuquangtrong - icon : fontawesome/brands/facebook-f link : https://facebook.com/trongvq name : trongvq - icon : fontawesome/brands/linkedin-in link : https://www.linkedin.com/in/vqtrong name : vqtrong generator : false # hide the line \"Made with Material for MkDocs\" Appearance # The theme can be customized by changing below options: Colors # Changing color is to select colors for 2 main groups: The primary color which is used for the header, the sidebar, text links and several other components. The accent color which is used to denote elements that can be interacted with, e.g. hovered links, buttons and scroll-bars. theme : palette : primary : white accent : deep orange Fonts # Serif fonts 1 are widely used for body text because they are considered to be easier to read than Sans-Serif fonts in print. For better reading, distinguishing the digit zero 0 from the Latin script letter Oh o or O is a way to avoid mistake, especially while reading technical notes. Fonts for source code do have slashed/ dotted/ open zero 2 , but fonts for reading don\u2019t have those styles. It\u2019s also needed to clearly distinguish the digit one 1 with lowercase i , the uppercase I , and the lowercase l . Luckily, they usually do not stand close to each other. To replace the defaults fonts , this site uses Noto Serif for the body text, and Roboto Mono for the code block. theme : font : text : Noto Serif code : Roboto Mono Can you easily read below pairs of characters? Body text: 0o 0O oO 1i 1I 1l 1L iI il iL Il IL lL Code block: 0o 0O oO 1i 1I 1l 1L iI il iL Il IL lL Icons # Icons can be selected in built-in icon packs, such as . It can be an image also. theme : icon : logo : fontawesome/solid/code favicon : favicon.png Navigation # A clear and concise navigation structure is an important aspect of good site. The layout will be 3 columns: Site Navigation, Main Content, Table of Content. Some navigation features are applied as below: theme : name : material features : # - navigation.instant # some features may not work properly with XHR - navigation.tracking # the URL changes with the active anchor - navigation.tabs # first top-level sections are shown as tabs # - navigation.tabs.sticky # tabs always show # - navigation.sections # sections are rendered as groups in the sidebar # - navigation.expand # all sections are expanded - navigation.indexes # link an index.md page to a section - navigation.top # show back-to-top button # - toc.integrate # show table of contents to navigation panel # - header.autohide Search # The MkDocs-based sites come with a built-in search engine , which also provides some additional features as below: theme : name : material features : - search.suggest # display the likeliest completion for the last word - search.highlight # highlight all occurrences - search.share # show a share button Content # Some extra features are enabled to render interactive elements. theme : name : material features : - content.code.annotate When Metadata is enabled, the navigation and/or table of contents sidebars can be hidden for a document with custom front matter. --- hide : - navigation - toc - feedback --- Site analytics # Material for MkDocs integrates with both, Google Analytics 4 and the now phasing out Universal Analytics. extra : analytics : provider : google property : G-XXXXXXXXXX or UA-XXXXXXXX-X Customization # Below are ways to customize the theme in terms of adding some extra lines of code. However, this method is quite easy even for beginners who have known some of CSS and JS. Extra assets # Additional assets can be used to add user\u2019s stylesheets and JavaScript files. Those file should be added to the docs directory as below structure: . \u251c\u2500 docs/ \u2502 \u251c\u2500 assets/ \u2502 | \u2514\u2500 extra.css \u2502 | \u2514\u2500 extra.js | \u2514\u2500 blog/ \u2514\u2500 mkdocs.yml Then, add the following line to mkdocs.yml : extra_css : - assets/extra.css extra_javascript : - assets/extra.js Use the Developer mode in your browser to inspect elements and changes their styles as your taste in extra.css . Add extra scripts to extra.js to interact with elements also. Extend the theme # Extending the theme is a way to alter the HTML structure and layout. Create a new folder name overrides beside the docs folder and add below config into mkdocs.yml : theme : name : material custom_dir : overrides The structure in the overrides directory must mirror the directory structure of the original theme, as any file in the overrides directory will replace the file with the same name which is part of the original theme. Besides, further assets may also be put in the overrides directory: . \u251c\u2500 .icons/ # Bundled icon sets \u251c\u2500 assets/ \u2502 \u251c\u2500 images/ # Images and icons \u2502 \u251c\u2500 javascripts/ # JavaScript files \u2502 \u2514\u2500 stylesheets/ # Style sheets \u251c\u2500 partials/ \u2502 \u251c\u2500 integrations/ # Third-party integrations \u2502 \u2502 \u251c\u2500 analytics/ # Analytics integrations \u2502 \u2502 \u2514\u2500 analytics.html # Analytics setup \u2502 \u251c\u2500 languages/ # Translation languages \u2502 \u251c\u2500 content.html # Page content \u2502 \u251c\u2500 copyright.html # Copyright and theme information \u2502 \u251c\u2500 footer.html # Footer bar \u2502 \u251c\u2500 header.html # Header bar \u2502 \u251c\u2500 language.html # Translation setup \u2502 \u251c\u2500 logo.html # Logo in header and sidebar \u2502 \u251c\u2500 nav.html # Main navigation \u2502 \u251c\u2500 nav-item.html # Main navigation item \u2502 \u251c\u2500 palette.html # Color palette \u2502 \u251c\u2500 search.html # Search interface \u2502 \u251c\u2500 social.html # Social links \u2502 \u251c\u2500 source.html # Repository information \u2502 \u251c\u2500 source-file.html # Source file information \u2502 \u251c\u2500 tabs.html # Tabs navigation \u2502 \u251c\u2500 tabs-item.html # Tabs navigation item \u2502 \u251c\u2500 toc.html # Table of contents \u2502 \u2514\u2500 toc-item.html # Table of contents item \u251c\u2500 404 .html # 404 error page \u251c\u2500 base.html # Base template \u2514\u2500 main.html # Default page Overriding partials In order to override a partial, we can replace it with a file of the same name and location in the overrides directory. For example, to replace the original footer.html partial, create a new footer.html partial in the overrides directory: . \u251c\u2500 overrides/ \u2502 \u2514\u2500 partials/ \u2502 \u2514\u2500 footer.html \u2514\u2500 mkdocs.yml MkDocs will now use the new partial when rendering the theme. This can be done with any file. Overriding blocks (recommended) Besides overriding partials, it\u2019s also possible to override (and extend) template blocks, which are defined inside the templates and wrap specific features. In order to set up block overrides, create a main.html file inside the overrides directory: . \u251c\u2500 overrides/ \u2502 \u2514\u2500 main.html \u2514\u2500 mkdocs.yml Then, e.g. to override the site title, add the following lines to main.html: {% extends \"base.html\" %} {% block htmltitle %} <title>Lorem ipsum dolor sit amet</title> {% endblock %} The following template blocks are provided by the theme: analytics # Wraps the Google Analytics integration announce # Wraps the announcement bar config # Wraps the JavaScript application config content # Wraps the main content disqus # Wraps the Disqus integration extrahead # Empty block to add custom meta tags fonts # Wraps the font definitions footer # Wraps the footer with navigation and copyright header # Wraps the fixed header bar hero # Wraps the hero teaser (if available) htmltitle # Wraps the <title> tag libs # Wraps the JavaScript libraries (header) outdated # Wraps the version warning scripts # Wraps the JavaScript application (footer) site_meta # Wraps the meta tags in the document head site_nav # Wraps the site navigation and table of contents styles # Wraps the style sheets (also extra sources) tabs # Wraps the tabs navigation (if available) Comment system # Disqus can be easily integrated into theme by overriding the file post-content.html , and adding disqus section. See full guide here . mkdocs.yml extra : disqus : \"vuquangtrong-github-io\" overrides\\partials\\post-content.html {# edit button #} {% if page.edit_url %} < a href = \"{{ page.edit_url }}\" title = \"{{ lang.t('edit.link.title') }}\" class = \"md-content__button md-icon\" > {% include \".icons/material/pencil.svg\" %} </ a > {% endif %} {% include \"partials/post-cover.html\" %} < hr class = \"screen-only\" > {% include \"partials/post-toc.html\" %} {% if not page.is_homepage %} {% include \"partials/ads-search.html\" %} {% endif %} {# show the children pages if no content #} {% if page.markdown == '' and page.parent.children %} < h2 > Posts in this section: </ h2 > < ol > {% for obj in page.parent.children %} {% if obj.is_section %} {% set p = obj.children[0] %} < li > < a href = \"{{ p.canonical_url }}\" > {%- if p.meta and p.meta.title -%} {{- p.meta.title -}} {%- else -%} {{- p.title -}} {%- endif -%} </ a > </ li > {% endif %} {% endfor %} </ ol > {% else %} {# content #} {{ page.content }} {% endif %} {% if page.markdown == '' and page.parent.children %} {% else %} {# comment #} {% include \"partials/disqus.html\" %} {% endif %} overrides\\partials\\disqus.html <!-- Get setting from mkdocs.yml, but allow page-level overrides --> {% set disqus = config.extra.disqus %} {% if page.meta and page.meta.disqus is string %} {% set disqus = page.meta.disqus %} {% endif %} <!-- Inject Disqus into current page --> {% if not page.is_homepage and disqus %} < h2 id = \"__comments\" > {{ lang.t(\"meta.comments\") }} </ h2 > < div id = \"disqus_thread\" ></ div > < script > var disqus_config = function () { this . page . url = \"{{ page.canonical_url }}\" this . page . identifier = \"{{ page.canonical_url | replace(config.site_url, '') }}\" } /* Set up for the first time */ if ( typeof DISQUS === \"undefined\" ) { var script = document . createElement ( \"script\" ) script . async = true script . src = \"https://{{ disqus }}.disqus.com/embed.js\" script . setAttribute ( \"data-timestamp\" , Date . now ()) /* Inject script tag */ document . body . appendChild ( script ) /* Set up on navigation (instant loading) */ } else { DISQUS . reset ({ reload : true , config : disqus_config }) } </ script > {% endif %} https://en.wikipedia.org/wiki/Serif \u21a9 https://en.wikipedia.org/wiki/Slashed_zero \u21a9","title":"A Guide to Create a Personal Site"},{"location":"blog/site-setup/create-site-project/#material-for-mkdocs","text":"A personal site is usually a static site which has pre-built contents. A static site generator is a tool that generates a full static HTML website based on raw data and a set of templates. Visit the list of Site Generators to see available tools. MkDocs is a fast and simple engine to build a site for project documentation. Content source files are written in Markdown format, and the site is configured with a single YAML config file. Material for MkDocs is a popular theme for MkDocs. It has a simple and clear layout with a bunch of useful features, such as better navigation behaviors, strongly integrated Markdown extensions, and some additional tweaks. This project has a paid version called Insiders , but the free version is perfectly enough for a personal use.","title":"Material for MkDocs"},{"location":"blog/site-setup/create-site-project/#installation","text":"Steps to install and create a new site: Download and install Python 3 . Create a new folder to store the project: mkdir CodeInsideOut cd CodeInsideOut It\u2019s recommended to use a virtual environment to isolate this project with others from a possible package conflict. python -m venv .venv Then activate the virtual environment: Windows Linux .venv\\Scripts\\activate.bat .venv/Scripts/activate Remember to run this command every time you come back to work in this project. Install Material for MkDocs package. Read more at getting started : pip install mkdocs-material Start a new site: mkdocs new . This will create the following file structure: . \u251c\u2500 mkdocs.yml # The configuration file \u2514\u2500 docs/ # Other markdown pages \u251c\u2500 index.md # The documentation homepage \u2514\u2500 ... # Other files Enable Material for MkDocs theme by adding a config into mkdocs.yml : theme : name : material Run a local server, and preview the site at http://localhost:8000 to see the default homepage: mkdocs serve To publish the site, build it first: mkdocs build Then copy all the content in the site folder to the website\u2019s root folder.","title":"Installation"},{"location":"blog/site-setup/create-site-project/#working-folder","text":"Each Markdown file inside the folder docs will be rendered as a page of the site. The index page is located at docs\\index.md . Sub-folders are used as the path to a group of related posts. If a post is named other than index.md , the filename will be used as the directory path of the generated page. Here is how MkDocs generates URLs for Markdown posts: folder docs becomes the root of the site www.site.com/ file docs\\blog\\post.md becomes the link www.site.com/blog/post/ file docs\\blog\\post\\index.md also becomes the link www.site.com/blog/post/ Use hyphen ( - ) in folder name and file name to create good URLs. Some tips here .","title":"Working folder"},{"location":"blog/site-setup/create-site-project/#visual-studio-code","text":"Visual Studio Code is a lightweight but powerful source code editor. It well supports users to write code, documents, notes. This editor also have some extensions to turn it into a full-feature IDE. Useful extensions for writing in Markdown format and editing HTML template: Markdown All in One : add keyboard shortcuts, auto-completion, edit and format list and table. Markdown Paste : paste images, links from the clipboard. Prettier \u2014 Code formatter : a formatter which supports a lot of languages. Draw.io Integration : edit diagrams and SVG images. LTeX : Grammar/spell checker using LanguageTool with support for LaTeX, Markdown, and others. Additional extensions: Jinja : highlight Jinja syntax in HTML templates. Sublime Text Key map and Settings Importer : import keybindings and settings. Writing a post using Visual Studio Code","title":"Visual Studio Code"},{"location":"blog/site-setup/create-site-project/#basic-configuration","text":"All configurations are declared in the config file mkdocs.yml at the root of the project folder. Here are some main settings to quickly customize your site:","title":"Basic Configuration"},{"location":"blog/site-setup/create-site-project/#site-information","text":"Site information consists of the name, the URL, the title, a description and some keywords that are used to get brief information about the content of the site. The copyright word should include a link to the original theme when you use the free version. site_name : Code Inside Out site_url : https://www.codeinsideout.com/ # must have the trailing slash site_author : V\u0169 Quang Tr\u1ecdng (vuquangtrong@gmail.com) site_description : Guides, notes and useful stuff for learning embedded systems. copyright : > # should remain a link to the original theme &copy; 2021 Code Inside Out<br> <a href=\"https://github.com/vuquangtrong/mkdocs-material-blog\">Blog Theme</a> / <a href=\"https://squidfunk.github.io/mkdocs-material/\">Material for MkDocs</a> The social links in the footer can be added in the extra section. extra : social : - icon : fontawesome/brands/github-alt link : https://github.com/vuquangtrong name : vuquangtrong - icon : fontawesome/brands/facebook-f link : https://facebook.com/trongvq name : trongvq - icon : fontawesome/brands/linkedin-in link : https://www.linkedin.com/in/vqtrong name : vqtrong generator : false # hide the line \"Made with Material for MkDocs\"","title":"Site Information"},{"location":"blog/site-setup/create-site-project/#appearance","text":"The theme can be customized by changing below options:","title":"Appearance"},{"location":"blog/site-setup/create-site-project/#colors","text":"Changing color is to select colors for 2 main groups: The primary color which is used for the header, the sidebar, text links and several other components. The accent color which is used to denote elements that can be interacted with, e.g. hovered links, buttons and scroll-bars. theme : palette : primary : white accent : deep orange","title":"Colors"},{"location":"blog/site-setup/create-site-project/#fonts","text":"Serif fonts 1 are widely used for body text because they are considered to be easier to read than Sans-Serif fonts in print. For better reading, distinguishing the digit zero 0 from the Latin script letter Oh o or O is a way to avoid mistake, especially while reading technical notes. Fonts for source code do have slashed/ dotted/ open zero 2 , but fonts for reading don\u2019t have those styles. It\u2019s also needed to clearly distinguish the digit one 1 with lowercase i , the uppercase I , and the lowercase l . Luckily, they usually do not stand close to each other. To replace the defaults fonts , this site uses Noto Serif for the body text, and Roboto Mono for the code block. theme : font : text : Noto Serif code : Roboto Mono Can you easily read below pairs of characters? Body text: 0o 0O oO 1i 1I 1l 1L iI il iL Il IL lL Code block: 0o 0O oO 1i 1I 1l 1L iI il iL Il IL lL","title":"Fonts"},{"location":"blog/site-setup/create-site-project/#icons","text":"Icons can be selected in built-in icon packs, such as . It can be an image also. theme : icon : logo : fontawesome/solid/code favicon : favicon.png","title":"Icons"},{"location":"blog/site-setup/create-site-project/#navigation","text":"A clear and concise navigation structure is an important aspect of good site. The layout will be 3 columns: Site Navigation, Main Content, Table of Content. Some navigation features are applied as below: theme : name : material features : # - navigation.instant # some features may not work properly with XHR - navigation.tracking # the URL changes with the active anchor - navigation.tabs # first top-level sections are shown as tabs # - navigation.tabs.sticky # tabs always show # - navigation.sections # sections are rendered as groups in the sidebar # - navigation.expand # all sections are expanded - navigation.indexes # link an index.md page to a section - navigation.top # show back-to-top button # - toc.integrate # show table of contents to navigation panel # - header.autohide","title":"Navigation"},{"location":"blog/site-setup/create-site-project/#search","text":"The MkDocs-based sites come with a built-in search engine , which also provides some additional features as below: theme : name : material features : - search.suggest # display the likeliest completion for the last word - search.highlight # highlight all occurrences - search.share # show a share button","title":"Search"},{"location":"blog/site-setup/create-site-project/#content","text":"Some extra features are enabled to render interactive elements. theme : name : material features : - content.code.annotate When Metadata is enabled, the navigation and/or table of contents sidebars can be hidden for a document with custom front matter. --- hide : - navigation - toc - feedback ---","title":"Content"},{"location":"blog/site-setup/create-site-project/#site-analytics","text":"Material for MkDocs integrates with both, Google Analytics 4 and the now phasing out Universal Analytics. extra : analytics : provider : google property : G-XXXXXXXXXX or UA-XXXXXXXX-X","title":"Site analytics"},{"location":"blog/site-setup/create-site-project/#customization","text":"Below are ways to customize the theme in terms of adding some extra lines of code. However, this method is quite easy even for beginners who have known some of CSS and JS.","title":"Customization"},{"location":"blog/site-setup/create-site-project/#extra-assets","text":"Additional assets can be used to add user\u2019s stylesheets and JavaScript files. Those file should be added to the docs directory as below structure: . \u251c\u2500 docs/ \u2502 \u251c\u2500 assets/ \u2502 | \u2514\u2500 extra.css \u2502 | \u2514\u2500 extra.js | \u2514\u2500 blog/ \u2514\u2500 mkdocs.yml Then, add the following line to mkdocs.yml : extra_css : - assets/extra.css extra_javascript : - assets/extra.js Use the Developer mode in your browser to inspect elements and changes their styles as your taste in extra.css . Add extra scripts to extra.js to interact with elements also.","title":"Extra assets"},{"location":"blog/site-setup/create-site-project/#extend-the-theme","text":"Extending the theme is a way to alter the HTML structure and layout. Create a new folder name overrides beside the docs folder and add below config into mkdocs.yml : theme : name : material custom_dir : overrides The structure in the overrides directory must mirror the directory structure of the original theme, as any file in the overrides directory will replace the file with the same name which is part of the original theme. Besides, further assets may also be put in the overrides directory: . \u251c\u2500 .icons/ # Bundled icon sets \u251c\u2500 assets/ \u2502 \u251c\u2500 images/ # Images and icons \u2502 \u251c\u2500 javascripts/ # JavaScript files \u2502 \u2514\u2500 stylesheets/ # Style sheets \u251c\u2500 partials/ \u2502 \u251c\u2500 integrations/ # Third-party integrations \u2502 \u2502 \u251c\u2500 analytics/ # Analytics integrations \u2502 \u2502 \u2514\u2500 analytics.html # Analytics setup \u2502 \u251c\u2500 languages/ # Translation languages \u2502 \u251c\u2500 content.html # Page content \u2502 \u251c\u2500 copyright.html # Copyright and theme information \u2502 \u251c\u2500 footer.html # Footer bar \u2502 \u251c\u2500 header.html # Header bar \u2502 \u251c\u2500 language.html # Translation setup \u2502 \u251c\u2500 logo.html # Logo in header and sidebar \u2502 \u251c\u2500 nav.html # Main navigation \u2502 \u251c\u2500 nav-item.html # Main navigation item \u2502 \u251c\u2500 palette.html # Color palette \u2502 \u251c\u2500 search.html # Search interface \u2502 \u251c\u2500 social.html # Social links \u2502 \u251c\u2500 source.html # Repository information \u2502 \u251c\u2500 source-file.html # Source file information \u2502 \u251c\u2500 tabs.html # Tabs navigation \u2502 \u251c\u2500 tabs-item.html # Tabs navigation item \u2502 \u251c\u2500 toc.html # Table of contents \u2502 \u2514\u2500 toc-item.html # Table of contents item \u251c\u2500 404 .html # 404 error page \u251c\u2500 base.html # Base template \u2514\u2500 main.html # Default page Overriding partials In order to override a partial, we can replace it with a file of the same name and location in the overrides directory. For example, to replace the original footer.html partial, create a new footer.html partial in the overrides directory: . \u251c\u2500 overrides/ \u2502 \u2514\u2500 partials/ \u2502 \u2514\u2500 footer.html \u2514\u2500 mkdocs.yml MkDocs will now use the new partial when rendering the theme. This can be done with any file. Overriding blocks (recommended) Besides overriding partials, it\u2019s also possible to override (and extend) template blocks, which are defined inside the templates and wrap specific features. In order to set up block overrides, create a main.html file inside the overrides directory: . \u251c\u2500 overrides/ \u2502 \u2514\u2500 main.html \u2514\u2500 mkdocs.yml Then, e.g. to override the site title, add the following lines to main.html: {% extends \"base.html\" %} {% block htmltitle %} <title>Lorem ipsum dolor sit amet</title> {% endblock %} The following template blocks are provided by the theme: analytics # Wraps the Google Analytics integration announce # Wraps the announcement bar config # Wraps the JavaScript application config content # Wraps the main content disqus # Wraps the Disqus integration extrahead # Empty block to add custom meta tags fonts # Wraps the font definitions footer # Wraps the footer with navigation and copyright header # Wraps the fixed header bar hero # Wraps the hero teaser (if available) htmltitle # Wraps the <title> tag libs # Wraps the JavaScript libraries (header) outdated # Wraps the version warning scripts # Wraps the JavaScript application (footer) site_meta # Wraps the meta tags in the document head site_nav # Wraps the site navigation and table of contents styles # Wraps the style sheets (also extra sources) tabs # Wraps the tabs navigation (if available)","title":"Extend the theme"},{"location":"blog/site-setup/create-site-project/#comment-system","text":"Disqus can be easily integrated into theme by overriding the file post-content.html , and adding disqus section. See full guide here . mkdocs.yml extra : disqus : \"vuquangtrong-github-io\" overrides\\partials\\post-content.html {# edit button #} {% if page.edit_url %} < a href = \"{{ page.edit_url }}\" title = \"{{ lang.t('edit.link.title') }}\" class = \"md-content__button md-icon\" > {% include \".icons/material/pencil.svg\" %} </ a > {% endif %} {% include \"partials/post-cover.html\" %} < hr class = \"screen-only\" > {% include \"partials/post-toc.html\" %} {% if not page.is_homepage %} {% include \"partials/ads-search.html\" %} {% endif %} {# show the children pages if no content #} {% if page.markdown == '' and page.parent.children %} < h2 > Posts in this section: </ h2 > < ol > {% for obj in page.parent.children %} {% if obj.is_section %} {% set p = obj.children[0] %} < li > < a href = \"{{ p.canonical_url }}\" > {%- if p.meta and p.meta.title -%} {{- p.meta.title -}} {%- else -%} {{- p.title -}} {%- endif -%} </ a > </ li > {% endif %} {% endfor %} </ ol > {% else %} {# content #} {{ page.content }} {% endif %} {% if page.markdown == '' and page.parent.children %} {% else %} {# comment #} {% include \"partials/disqus.html\" %} {% endif %} overrides\\partials\\disqus.html <!-- Get setting from mkdocs.yml, but allow page-level overrides --> {% set disqus = config.extra.disqus %} {% if page.meta and page.meta.disqus is string %} {% set disqus = page.meta.disqus %} {% endif %} <!-- Inject Disqus into current page --> {% if not page.is_homepage and disqus %} < h2 id = \"__comments\" > {{ lang.t(\"meta.comments\") }} </ h2 > < div id = \"disqus_thread\" ></ div > < script > var disqus_config = function () { this . page . url = \"{{ page.canonical_url }}\" this . page . identifier = \"{{ page.canonical_url | replace(config.site_url, '') }}\" } /* Set up for the first time */ if ( typeof DISQUS === \"undefined\" ) { var script = document . createElement ( \"script\" ) script . async = true script . src = \"https://{{ disqus }}.disqus.com/embed.js\" script . setAttribute ( \"data-timestamp\" , Date . now ()) /* Inject script tag */ document . body . appendChild ( script ) /* Set up on navigation (instant loading) */ } else { DISQUS . reset ({ reload : true , config : disqus_config }) } </ script > {% endif %} https://en.wikipedia.org/wiki/Serif \u21a9 https://en.wikipedia.org/wiki/Slashed_zero \u21a9","title":"Comment system"},{"location":"blog/site-setup/handle-missing-page/","tags":["javascript"],"text":"The 404 page # Whenever a page is not found in a website, the error 404 is return to the requested users. I need to create this special page to display a short message and guide user to search in this blog. The 404 page should be created in the overrides folder as it will replace the default 404 pages of Material theme. TRY THIS 404 Page Layout and content # Its layout is based on the main.html , and the content is a message displayed in the center of the page. The disqus comment section is removed. The sidebar should not be visible to display message clearly. Search suggestion # I assume that the path of URL contains keywords of what users are looking for. Therefore, after getting the requested URL from window.location.pathname , I will try to open a search form filled with those keywords. JavaScript is helpful here. The sequence of handling is as below: Show 404 message and wait for 5 seconds Open search form Get URL path name, and spit it into keywords For each keyword, fill it into input form Fire events (value changed, element focused) to trigger search engine Delay using Asynchronous function Looking up result may take some time to return, therefore, async function is used to wait for the data. Source code # overrides\\404.html {% extends \"main.html\" %} {% block site_nav %} {% endblock %} {% block content %} {# styles #} < style > . md-typeset . caution * { text-align : center ; } . md-typeset . caution h3 { border-bottom : none ; } </ style > < div class = \"caution\" > < h1 > Oops! Something went wrong! </ h1 > < h3 > Please go back to the < a href = \"{{ config.site_url }}\" > {{ config.site_name }} </ a > homepage, < br > or press < kbd > S </ kbd > to search on this site. </ h3 > < p id = \"info\" > We will open a search for your in < span id = \"counter\" > 5 </ span > second(s)! </ p > </ div > <!-- Open search --> < script > function sleep ( ms ) { return new Promise ( resolve => setTimeout ( resolve , ms )); } function countdown () { var i = 4 ; var x = setInterval ( function () { document . getElementById ( \"counter\" ). textContent = i ; i -- ; if ( i < 0 ) { clearInterval ( x ); document . getElementById ( \"info\" ). style . display = \"none\" ; searchForUserRequest (); } }, 1000 ); } async function searchForUserRequest () { document . querySelector ( \"label.md-search__icon.md-icon\" ). click (); pathname = window . location . pathname ; requests = pathname . split ( \"/\" ); for ( var i = requests . length - 1 ; i > 0 ; i -- ) { if ( await haveSearchResult ( requests [ i ])) { break ; } } } async function haveSearchResult ( request ) { console . log ( request ); document . forms . search . query . value = request ; var ev = new Event ( 'change' ); document . forms . search . query . dispatchEvent ( ev ); var ev2 = new Event ( 'focus' ); document . forms . search . query . dispatchEvent ( ev2 ); await sleep ( 1000 ); result = document . querySelector ( \"div.md-search-result__meta\" ). textContent ; if ( result == 'No matching documents' ) { return false ; } return true ; } window . onload = countdown ; </ script > {% endblock %} {% block disqus %} {% endblock %}","title":"Hanlde Page Not Found (404) error"},{"location":"blog/site-setup/handle-missing-page/#the-404-page","text":"Whenever a page is not found in a website, the error 404 is return to the requested users. I need to create this special page to display a short message and guide user to search in this blog. The 404 page should be created in the overrides folder as it will replace the default 404 pages of Material theme. TRY THIS 404 Page","title":"The 404 page"},{"location":"blog/site-setup/handle-missing-page/#layout-and-content","text":"Its layout is based on the main.html , and the content is a message displayed in the center of the page. The disqus comment section is removed. The sidebar should not be visible to display message clearly.","title":"Layout and content"},{"location":"blog/site-setup/handle-missing-page/#search-suggestion","text":"I assume that the path of URL contains keywords of what users are looking for. Therefore, after getting the requested URL from window.location.pathname , I will try to open a search form filled with those keywords. JavaScript is helpful here. The sequence of handling is as below: Show 404 message and wait for 5 seconds Open search form Get URL path name, and spit it into keywords For each keyword, fill it into input form Fire events (value changed, element focused) to trigger search engine Delay using Asynchronous function Looking up result may take some time to return, therefore, async function is used to wait for the data.","title":"Search suggestion"},{"location":"blog/site-setup/handle-missing-page/#source-code","text":"overrides\\404.html {% extends \"main.html\" %} {% block site_nav %} {% endblock %} {% block content %} {# styles #} < style > . md-typeset . caution * { text-align : center ; } . md-typeset . caution h3 { border-bottom : none ; } </ style > < div class = \"caution\" > < h1 > Oops! Something went wrong! </ h1 > < h3 > Please go back to the < a href = \"{{ config.site_url }}\" > {{ config.site_name }} </ a > homepage, < br > or press < kbd > S </ kbd > to search on this site. </ h3 > < p id = \"info\" > We will open a search for your in < span id = \"counter\" > 5 </ span > second(s)! </ p > </ div > <!-- Open search --> < script > function sleep ( ms ) { return new Promise ( resolve => setTimeout ( resolve , ms )); } function countdown () { var i = 4 ; var x = setInterval ( function () { document . getElementById ( \"counter\" ). textContent = i ; i -- ; if ( i < 0 ) { clearInterval ( x ); document . getElementById ( \"info\" ). style . display = \"none\" ; searchForUserRequest (); } }, 1000 ); } async function searchForUserRequest () { document . querySelector ( \"label.md-search__icon.md-icon\" ). click (); pathname = window . location . pathname ; requests = pathname . split ( \"/\" ); for ( var i = requests . length - 1 ; i > 0 ; i -- ) { if ( await haveSearchResult ( requests [ i ])) { break ; } } } async function haveSearchResult ( request ) { console . log ( request ); document . forms . search . query . value = request ; var ev = new Event ( 'change' ); document . forms . search . query . dispatchEvent ( ev ); var ev2 = new Event ( 'focus' ); document . forms . search . query . dispatchEvent ( ev2 ); await sleep ( 1000 ); result = document . querySelector ( \"div.md-search-result__meta\" ). textContent ; if ( result == 'No matching documents' ) { return false ; } return true ; } window . onload = countdown ; </ script > {% endblock %} {% block disqus %} {% endblock %}","title":"Source code"},{"location":"blog/site-setup/markdown-syntax/","tags":["markdown"],"text":"For basic markdown syntax, refer to Markdown Guide Meta-data # The Meta-Data extension adds a syntax for defining meta-data of a document. It is inspired by and follows the syntax of MultiMarkdown . Meta-data is the additional information that can be used to briefly describe the content of a post, such as the title, the short description, tags, and sometimes the banner image. I prefer YAML format : --- title : The page title description : The summary of the page content --- The meta-data can be used in the template and the page content 1 . In Jinja syntax, each page is represented as a page object, then the meta-data field {{ page.meta.title }} will be replaced by the string The page title . Code highlighting # Below extensions are extremely useful for showing code blocks by adding colors, and decoration. Inline code # The InlineHilite is an inline code highlighter inspired by CodeHilite . Borrowing from CodeHilite\u2019s existing syntax, InlineHilite utilizes the following syntax to insert inline highlighted code: `:::language my code` or `#!language my code` . This will render this line `#!python [x for x in range(1, 10) if x % 2]` to a fully colored inline Python code: [ x for x in range ( 1 , 10 ) if x % 2 ] . Code blocks # The Code blocks plugin provides a number of features including allowing the nesting of fences, and ability to specify custom fences to provide features like flowcharts, sequence diagrams, or other custom blocks. Highlighting can be further controlled via the Highlight extension . The standard format which supports to add id , class , or custom attribute key=value is as below: ``` { .language #id .class key=\"value\" } content ``` Some special attributes key=value are as below: title = \"abc\" creates a title for the block, used to show the filename or the purpose. linenums = \"n\" creates line numbers starting from n . hl_lines = \"x y-z\" highlights the x -th line and lines in the range from y -th to z -th. Line numbers are always referenced starting at 1 ignoring what the line number is started labeling at the number set by the option linenums = \"n\" . Example: ``` cpp title=\"main.c\" linenums=\"2\" hl_lines=\"1 4-5\" #include <stdio.h> int main(void) { printf(\"Hello world!\\n\"); return 0; } ``` Result: main.c #include <stdio.h> int main ( void ) { printf ( \"Hello world! \\n \" ); return 0 ; } Code annotations # Code annotation is a unique feature of Material theme which offers a comfortable and friendly way to attach arbitrary content to specific sections of code blocks by adding numeric markers in block and inline comments in the language of the code block. Code annotations can be placed anywhere in a code block where a comment for the language of the block can be placed, e.g. for JavaScript in // ... and /* ... */ , for YAML in # ... , etc. Example: ``` cpp int main(void) { printf(\"Hello world!\\n\"); return 0; } ``` 1. Need including\\ `#!cpp #include <stdio.h>` Result: Click on to show the annotation. int main ( void ) { printf ( \"Hello world! \\n \" ); // (1) return 0 ; } Need including #include <stdio.h> Admonitions # Admonitions , also known as call-outs, are an excellent choice for including side content without significantly interrupting the document flow. Marked blocks # These types of blocks show an icon to help readers notice the kind of content, such as additional information , caution , or error . Example: !!! info \"The title of the block\" The content can contain formatted text. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nullam sagittis ante blandit diam accumsan scelerisque. - Lorem ipsum dolor sit amet - Lorem ipsum dolor sit amet ``` cpp int main(void) { return 0; } ``` Result: The title of the block The content can contain formatted text. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nullam sagittis ante blandit diam accumsan scelerisque. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet int main ( void ) { return 0 ; } To remove the title but keep the icon, use a space: !!! hint \" \" Need some CSS styles to adjust content block of admonitions. Result: Need some CSS styles to adjust content block of admonitions. Supported types # abstract, summary, tldr info, todo tip, hint, important success, check, done question, help, faq tag warning, caution, attention failure, fail, missing danger, error bug example quote, cite Collapsible blocks # When Details is enabled and an admonition block is started with ??? instead of !!!, the admonition is rendered as a collapsible block with a small toggle on the right side. Use plus ( + ) sign to make it expanded by default. Example: ???+ quote \"Expandable\" Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result: Expandable Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. MathJax # MathJax is a beautiful and accessible way to display mathematical content in the browser, adds support for mathematical typesetting in different notations (e.g. LaTeX , MathML , AsciiMath ). Block syntax # Blocks must be enclosed in $$...$$ or \\[...\\] on separate lines: Example: $$ \\operatorname {ker} f = \\{ g \\in G:f ( g )= e_{H} \\} { \\mbox {.}} $$ Result: \\[ \\operatorname{ker} f=\\{g\\in G:f(g)=e_{H}\\}{\\mbox{.}} \\] Inline syntax # Inline blocks must be enclosed in $...$ or \\(...\\) : Example: The homomorphism $ f $ is injective if and only if its kernel is only the singleton set $ e_G $ , because otherwise $ \\exists a,b \\in G $ with $ a \\neq b $ such that $ f ( a )= f ( b ) $ . Result: The homomorphism \\(f\\) is injective if and only if its kernel is only the singleton set \\(e_G\\) , because otherwise \\(\\exists a,b \\in G\\) with \\(a \\neq b\\) such that \\(f(a)=f(b)\\) . Formatting # Beside Italic , Bold , Italic and Bold , here are some more syntax to format texts. Caret # Caret optionally adds two different features which are syntactically built around the ^ character. The double carets ^^ inserts <ins></ins> tags, and the single caret ^ inserts <sup></sup> tags. Example: The ^^mass-energy^^ equivalence: E=m*c^2^. Result: The mass-energy equivalence: E=m*c 2 . Mark # Mark adds the ability to insert <mark></mark> tags. The syntax requires the text to be surrounded by double equal signs == . Example: ==mark me== and ==mark==me==all==. Result: mark me and mark==me==all . Tildes # Tildes optionally adds two different features which are syntactically built around the ~ character. Add Deletion by using double tildes ~~ which inserts <del></del> tags and Add Subscript by using single tilde ~ which inserts <sub></sub> tags. Example: ~~Remove~~ the existence of CH~3~CH~2~OH. Result: Remove the existence of CH 3 CH 2 OH. Critic # Critic is an extension that adds handling and support of Critic Markup which uses a special syntax to represent edits to a Markdown document. This extension runs before all other extensions to parse the critic edits. Critic Markup uses special markup to insert, delete, substitute, highlight, and comment. Example: To insert or remove text, use {\u200b++insert me++} and {\u200b--remove me--}.\\ Denote a substitution with {\u200b~~that ~> this one~~}. Highlight specific text with {\u200b==highlight me==}.\\ Or even add {\u200b>>a comment<<}. Result: To insert or remove text, use insert me and remove me . Denote a substitution with that this one . Highlight specific text with highlight me . Or even add a comment . Lists # This element allows to group a set of related items in lists. Children items can be numbered in ordered list, or even can have inline checkbox. Ordered list # 1. Ordered item 1 1. Child 1 2. Child 2 2. Ordered item 2 Ordered item 1 Child 1 Child 2 Ordered item 2 Unordered list # - Unordered item 1 - Child 1 - Child 2 - Unordered item 2 Unordered item 1 Child 1 Child 2 Unordered item 2 Task list # - [x] item 1 - [x] item a - [ ] item b - [ ] item 2 item 1 item a item b item 2 Definition # Roses : are red Violets : are blue Roses are red Violets are blue Images # There are some extensions to add a caption to an image. After testing, markdown-captions is a good one that uses the alternate text to make caption, accepts markdown in the alternate text. ![ A photo from <https://picsum.photos> ]( https://picsum.photos/320/240 ) A photo from https://picsum.photos Some images have big size that does not show the detail, therefore, it\u2019s better to zoom in by clicking on them, and pan the image on the screen. The view-bigimg library can do that requirement well. Tabs # Tabbed extension provides a syntax to easily add tabbed Markdown content. Tabs start with === to signify a tab followed by a quoted title. Consecutive tabs are grouped into a tab set. Example: === \"Tab 1\" Some texts === \"Tab A\" Text A === \"Tab B\" Text B === \"Tab 2\" Some other texts Result: Tab 1 Tab 2 Some texts Tab A Tab B Text A Text B Some other texts Tables # Markdown Tables are written in pipe-line format: row is on one line, cell is inline text only. The 1 st line contains the column headers. The 2 nd line is to control text alignment in a column: :--- , :---: and ---: are left, center, and right alignment. Styles for table need to change a little to show cell border. Example: | Syntax | Description | Test Text | | :--------- | :----------: | ----------: | | Left align | Center align | Right align | | A text | Another text | More texts | Result: Syntax Description Test Text Left align Center align Right align A text Another text More texts Icons & Emojis # The Emoji extension adds support for inserting emoji via simple short names enclosed within colons :short_name: . This is accomplished by using a short name index to map easy-to-remember names to the corresponding emoji characters. Emojis # Emojis can be written by putting the short-code of the emoji between two colons. Look up the short-codes at Emojipedia . :smile: , and :heart: Icons # Icons can be used similarly to emojis, by referencing a valid path to any icon bundled with the theme, which are located in the .icons directory, and replacing / with - . E.g. The short-code :material-account-circle: will be converted to an SVG image element with the path .icons/material/account-circle.svg which eventually shows the icon on the webpage. Using include function of Jinja to add an icon wrapped in a twemoji class, e.g. to show : < span class = \"twemoji\" > {% include \".icons/fontawesome/brands/twitter.svg\" %} </ span > Escape All # The Escape All extension makes the backslash \\ character escape everything after it, except things in code blocks of any kind. There are two special escapes among all of these escapes though: escaping space characters and escaping newline characters: Enable nbsp to convert an escaped space into a non-breaking space: &nbsp; . Enable hardbreak to convert an escaped newline to a hard break <br> . The advantage of hard break is that the backslash is visually seen in the document, opposed to the Markdown\u2019s default method of two spaces at the end of a line. Special characters # The Smarty Pants extension converts ASCII dashes, quotes and ellipses to their HTML entity equivalents. Syntax Render 'single quote' \u2018single quote\u2019 \"double quote\" \u201cdouble quote\u201d <<angle quote>> \u00abangle quote\u00bb ellipses ... ellipses \u2026 N-dash -- N-dash \u2013 M-dash --- M-dash \u2013 The Smart Symbols adds syntax for creating special characters such as trademarks, arrows, fractions, etc. Syntax Render trademark (tm) trademark \u2122 copyright (c) copyright \u00a9 registered (r) registered \u00ae in care of c/o in care of \u2105 plus or minus +/- plus or minus \u00b1 arrows --> <-- <--> arrows \u2192 \u2190 \u2194 not equal =/= not equal \u2260 fractions 1/4 2/3 fractions \u00bc \u2154 ordinal numbers 1st 2nd 3rd 4th 5th ordinal numbers 1 st 2 nd 3 rd 4 th 5 th Not all fractions can be displayed. To render fractions in a better format, use MathJax with inline format. Such as $1 \\over 4$ \u2192 \\(1 \\over 4\\) , or $2 \\over 3$ \u2192 \\(2 \\over 3\\) . Footnotes # The Footnotes extension adds syntax for defining footnotes in Markdown documents. Example: Footnotes[^fn] have a label[^lb] and the footnote's content. [ ^fn ]: This is a footnote content. [ ^lb ]: A footnote on the label `lb`. Result: Footnotes 2 have a label 3 and the footnote\u2019s content. Use mkdocs-macros plugin to use Jinja template directly in the Markdown content. \u21a9 This is a footnote content. \u21a9 A footnote on the label lb . \u21a9","title":"Syntaxes for Writing Markdown Documents"},{"location":"blog/site-setup/markdown-syntax/#meta-data","text":"The Meta-Data extension adds a syntax for defining meta-data of a document. It is inspired by and follows the syntax of MultiMarkdown . Meta-data is the additional information that can be used to briefly describe the content of a post, such as the title, the short description, tags, and sometimes the banner image. I prefer YAML format : --- title : The page title description : The summary of the page content --- The meta-data can be used in the template and the page content 1 . In Jinja syntax, each page is represented as a page object, then the meta-data field {{ page.meta.title }} will be replaced by the string The page title .","title":"Meta-data"},{"location":"blog/site-setup/markdown-syntax/#code-highlighting","text":"Below extensions are extremely useful for showing code blocks by adding colors, and decoration.","title":"Code highlighting"},{"location":"blog/site-setup/markdown-syntax/#inline-code","text":"The InlineHilite is an inline code highlighter inspired by CodeHilite . Borrowing from CodeHilite\u2019s existing syntax, InlineHilite utilizes the following syntax to insert inline highlighted code: `:::language my code` or `#!language my code` . This will render this line `#!python [x for x in range(1, 10) if x % 2]` to a fully colored inline Python code: [ x for x in range ( 1 , 10 ) if x % 2 ] .","title":"Inline code"},{"location":"blog/site-setup/markdown-syntax/#code-blocks","text":"The Code blocks plugin provides a number of features including allowing the nesting of fences, and ability to specify custom fences to provide features like flowcharts, sequence diagrams, or other custom blocks. Highlighting can be further controlled via the Highlight extension . The standard format which supports to add id , class , or custom attribute key=value is as below: ``` { .language #id .class key=\"value\" } content ``` Some special attributes key=value are as below: title = \"abc\" creates a title for the block, used to show the filename or the purpose. linenums = \"n\" creates line numbers starting from n . hl_lines = \"x y-z\" highlights the x -th line and lines in the range from y -th to z -th. Line numbers are always referenced starting at 1 ignoring what the line number is started labeling at the number set by the option linenums = \"n\" . Example: ``` cpp title=\"main.c\" linenums=\"2\" hl_lines=\"1 4-5\" #include <stdio.h> int main(void) { printf(\"Hello world!\\n\"); return 0; } ``` Result: main.c #include <stdio.h> int main ( void ) { printf ( \"Hello world! \\n \" ); return 0 ; }","title":"Code blocks"},{"location":"blog/site-setup/markdown-syntax/#code-annotations","text":"Code annotation is a unique feature of Material theme which offers a comfortable and friendly way to attach arbitrary content to specific sections of code blocks by adding numeric markers in block and inline comments in the language of the code block. Code annotations can be placed anywhere in a code block where a comment for the language of the block can be placed, e.g. for JavaScript in // ... and /* ... */ , for YAML in # ... , etc. Example: ``` cpp int main(void) { printf(\"Hello world!\\n\"); return 0; } ``` 1. Need including\\ `#!cpp #include <stdio.h>` Result: Click on to show the annotation. int main ( void ) { printf ( \"Hello world! \\n \" ); // (1) return 0 ; } Need including #include <stdio.h>","title":"Code annotations"},{"location":"blog/site-setup/markdown-syntax/#admonitions","text":"Admonitions , also known as call-outs, are an excellent choice for including side content without significantly interrupting the document flow.","title":"Admonitions"},{"location":"blog/site-setup/markdown-syntax/#marked-blocks","text":"These types of blocks show an icon to help readers notice the kind of content, such as additional information , caution , or error . Example: !!! info \"The title of the block\" The content can contain formatted text. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nullam sagittis ante blandit diam accumsan scelerisque. - Lorem ipsum dolor sit amet - Lorem ipsum dolor sit amet ``` cpp int main(void) { return 0; } ``` Result: The title of the block The content can contain formatted text. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nullam sagittis ante blandit diam accumsan scelerisque. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet int main ( void ) { return 0 ; } To remove the title but keep the icon, use a space: !!! hint \" \" Need some CSS styles to adjust content block of admonitions. Result: Need some CSS styles to adjust content block of admonitions.","title":"Marked blocks"},{"location":"blog/site-setup/markdown-syntax/#supported-types","text":"abstract, summary, tldr info, todo tip, hint, important success, check, done question, help, faq tag warning, caution, attention failure, fail, missing danger, error bug example quote, cite","title":"Supported types"},{"location":"blog/site-setup/markdown-syntax/#collapsible-blocks","text":"When Details is enabled and an admonition block is started with ??? instead of !!!, the admonition is rendered as a collapsible block with a small toggle on the right side. Use plus ( + ) sign to make it expanded by default. Example: ???+ quote \"Expandable\" Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result: Expandable Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.","title":"Collapsible blocks"},{"location":"blog/site-setup/markdown-syntax/#mathjax","text":"MathJax is a beautiful and accessible way to display mathematical content in the browser, adds support for mathematical typesetting in different notations (e.g. LaTeX , MathML , AsciiMath ).","title":"MathJax"},{"location":"blog/site-setup/markdown-syntax/#block-syntax","text":"Blocks must be enclosed in $$...$$ or \\[...\\] on separate lines: Example: $$ \\operatorname {ker} f = \\{ g \\in G:f ( g )= e_{H} \\} { \\mbox {.}} $$ Result: \\[ \\operatorname{ker} f=\\{g\\in G:f(g)=e_{H}\\}{\\mbox{.}} \\]","title":"Block syntax"},{"location":"blog/site-setup/markdown-syntax/#inline-syntax","text":"Inline blocks must be enclosed in $...$ or \\(...\\) : Example: The homomorphism $ f $ is injective if and only if its kernel is only the singleton set $ e_G $ , because otherwise $ \\exists a,b \\in G $ with $ a \\neq b $ such that $ f ( a )= f ( b ) $ . Result: The homomorphism \\(f\\) is injective if and only if its kernel is only the singleton set \\(e_G\\) , because otherwise \\(\\exists a,b \\in G\\) with \\(a \\neq b\\) such that \\(f(a)=f(b)\\) .","title":"Inline syntax"},{"location":"blog/site-setup/markdown-syntax/#formatting","text":"Beside Italic , Bold , Italic and Bold , here are some more syntax to format texts.","title":"Formatting"},{"location":"blog/site-setup/markdown-syntax/#caret","text":"Caret optionally adds two different features which are syntactically built around the ^ character. The double carets ^^ inserts <ins></ins> tags, and the single caret ^ inserts <sup></sup> tags. Example: The ^^mass-energy^^ equivalence: E=m*c^2^. Result: The mass-energy equivalence: E=m*c 2 .","title":"Caret"},{"location":"blog/site-setup/markdown-syntax/#mark","text":"Mark adds the ability to insert <mark></mark> tags. The syntax requires the text to be surrounded by double equal signs == . Example: ==mark me== and ==mark==me==all==. Result: mark me and mark==me==all .","title":"Mark"},{"location":"blog/site-setup/markdown-syntax/#tildes","text":"Tildes optionally adds two different features which are syntactically built around the ~ character. Add Deletion by using double tildes ~~ which inserts <del></del> tags and Add Subscript by using single tilde ~ which inserts <sub></sub> tags. Example: ~~Remove~~ the existence of CH~3~CH~2~OH. Result: Remove the existence of CH 3 CH 2 OH.","title":"Tildes"},{"location":"blog/site-setup/markdown-syntax/#critic","text":"Critic is an extension that adds handling and support of Critic Markup which uses a special syntax to represent edits to a Markdown document. This extension runs before all other extensions to parse the critic edits. Critic Markup uses special markup to insert, delete, substitute, highlight, and comment. Example: To insert or remove text, use {\u200b++insert me++} and {\u200b--remove me--}.\\ Denote a substitution with {\u200b~~that ~> this one~~}. Highlight specific text with {\u200b==highlight me==}.\\ Or even add {\u200b>>a comment<<}. Result: To insert or remove text, use insert me and remove me . Denote a substitution with that this one . Highlight specific text with highlight me . Or even add a comment .","title":"Critic"},{"location":"blog/site-setup/markdown-syntax/#lists","text":"This element allows to group a set of related items in lists. Children items can be numbered in ordered list, or even can have inline checkbox.","title":"Lists"},{"location":"blog/site-setup/markdown-syntax/#ordered-list","text":"1. Ordered item 1 1. Child 1 2. Child 2 2. Ordered item 2 Ordered item 1 Child 1 Child 2 Ordered item 2","title":"Ordered list"},{"location":"blog/site-setup/markdown-syntax/#unordered-list","text":"- Unordered item 1 - Child 1 - Child 2 - Unordered item 2 Unordered item 1 Child 1 Child 2 Unordered item 2","title":"Unordered list"},{"location":"blog/site-setup/markdown-syntax/#task-list","text":"- [x] item 1 - [x] item a - [ ] item b - [ ] item 2 item 1 item a item b item 2","title":"Task list"},{"location":"blog/site-setup/markdown-syntax/#definition","text":"Roses : are red Violets : are blue Roses are red Violets are blue","title":"Definition"},{"location":"blog/site-setup/markdown-syntax/#images","text":"There are some extensions to add a caption to an image. After testing, markdown-captions is a good one that uses the alternate text to make caption, accepts markdown in the alternate text. ![ A photo from <https://picsum.photos> ]( https://picsum.photos/320/240 ) A photo from https://picsum.photos Some images have big size that does not show the detail, therefore, it\u2019s better to zoom in by clicking on them, and pan the image on the screen. The view-bigimg library can do that requirement well.","title":"Images"},{"location":"blog/site-setup/markdown-syntax/#tabs","text":"Tabbed extension provides a syntax to easily add tabbed Markdown content. Tabs start with === to signify a tab followed by a quoted title. Consecutive tabs are grouped into a tab set. Example: === \"Tab 1\" Some texts === \"Tab A\" Text A === \"Tab B\" Text B === \"Tab 2\" Some other texts Result: Tab 1 Tab 2 Some texts Tab A Tab B Text A Text B Some other texts","title":"Tabs"},{"location":"blog/site-setup/markdown-syntax/#tables","text":"Markdown Tables are written in pipe-line format: row is on one line, cell is inline text only. The 1 st line contains the column headers. The 2 nd line is to control text alignment in a column: :--- , :---: and ---: are left, center, and right alignment. Styles for table need to change a little to show cell border. Example: | Syntax | Description | Test Text | | :--------- | :----------: | ----------: | | Left align | Center align | Right align | | A text | Another text | More texts | Result: Syntax Description Test Text Left align Center align Right align A text Another text More texts","title":"Tables"},{"location":"blog/site-setup/markdown-syntax/#icons--emojis","text":"The Emoji extension adds support for inserting emoji via simple short names enclosed within colons :short_name: . This is accomplished by using a short name index to map easy-to-remember names to the corresponding emoji characters.","title":"Icons &amp; Emojis"},{"location":"blog/site-setup/markdown-syntax/#emojis","text":"Emojis can be written by putting the short-code of the emoji between two colons. Look up the short-codes at Emojipedia . :smile: , and :heart:","title":"Emojis"},{"location":"blog/site-setup/markdown-syntax/#icons","text":"Icons can be used similarly to emojis, by referencing a valid path to any icon bundled with the theme, which are located in the .icons directory, and replacing / with - . E.g. The short-code :material-account-circle: will be converted to an SVG image element with the path .icons/material/account-circle.svg which eventually shows the icon on the webpage. Using include function of Jinja to add an icon wrapped in a twemoji class, e.g. to show : < span class = \"twemoji\" > {% include \".icons/fontawesome/brands/twitter.svg\" %} </ span >","title":"Icons"},{"location":"blog/site-setup/markdown-syntax/#escape-all","text":"The Escape All extension makes the backslash \\ character escape everything after it, except things in code blocks of any kind. There are two special escapes among all of these escapes though: escaping space characters and escaping newline characters: Enable nbsp to convert an escaped space into a non-breaking space: &nbsp; . Enable hardbreak to convert an escaped newline to a hard break <br> . The advantage of hard break is that the backslash is visually seen in the document, opposed to the Markdown\u2019s default method of two spaces at the end of a line.","title":"Escape All"},{"location":"blog/site-setup/markdown-syntax/#special-characters","text":"The Smarty Pants extension converts ASCII dashes, quotes and ellipses to their HTML entity equivalents. Syntax Render 'single quote' \u2018single quote\u2019 \"double quote\" \u201cdouble quote\u201d <<angle quote>> \u00abangle quote\u00bb ellipses ... ellipses \u2026 N-dash -- N-dash \u2013 M-dash --- M-dash \u2013 The Smart Symbols adds syntax for creating special characters such as trademarks, arrows, fractions, etc. Syntax Render trademark (tm) trademark \u2122 copyright (c) copyright \u00a9 registered (r) registered \u00ae in care of c/o in care of \u2105 plus or minus +/- plus or minus \u00b1 arrows --> <-- <--> arrows \u2192 \u2190 \u2194 not equal =/= not equal \u2260 fractions 1/4 2/3 fractions \u00bc \u2154 ordinal numbers 1st 2nd 3rd 4th 5th ordinal numbers 1 st 2 nd 3 rd 4 th 5 th Not all fractions can be displayed. To render fractions in a better format, use MathJax with inline format. Such as $1 \\over 4$ \u2192 \\(1 \\over 4\\) , or $2 \\over 3$ \u2192 \\(2 \\over 3\\) .","title":"Special characters"},{"location":"blog/site-setup/markdown-syntax/#footnotes","text":"The Footnotes extension adds syntax for defining footnotes in Markdown documents. Example: Footnotes[^fn] have a label[^lb] and the footnote's content. [ ^fn ]: This is a footnote content. [ ^lb ]: A footnote on the label `lb`. Result: Footnotes 2 have a label 3 and the footnote\u2019s content. Use mkdocs-macros plugin to use Jinja template directly in the Markdown content. \u21a9 This is a footnote content. \u21a9 A footnote on the label lb . \u21a9","title":"Footnotes"},{"location":"blog/site-setup/mkdocs-plugins/","tags":["mkdocs"],"text":"Places to get MkDocs Plugins: Official List , Wheelodex , and GitHub . Awesome Pages # MkDocs Awesome Pages plugin simplifies configuring page titles and their entries order. Install the plugin: pip install -U mkdocs-awesome-pages-plugin Enable it in the config file mkdocs.yml : plugins : - search # built-in search must be always activated - awesome-pages Create a YAML file named .pages in a directory and use a local nav attribute to customize the navigation in each folder with some more extra configurations: A 3-dots ... entry is used to specify where all remaining items should be inserted. It can filter the remaining items using glob patterns or regular expressions. For example: The pattern is checked against the basename of remaining items - not their whole path, so it can be used to filter files in sub-folders. Hide directory by setting the hide attribute to true . Optionally set the directory title using the title attribute. Optionally specify a title for the navigation entry before its document path. For example: Collapse single nested pages by setting collapse_single_pages attribute to true . Example: .pages title : New section nav : - ... | introduction-*.md - ... - summary.md - First page : page1.md - Link Title : https://example.com hide : false collapse_single_pages : false Using Awesome Pages plugin with collapse_single_pages enabled, before and after applying Section index # This plugin is no longer used in this site! The feature navigation.indexes comes with Material theme already does the work of this plugin. In MkDocs, each directory will become a section, and by default, section only contains its children pages. There is no page associated to a section. MkDocs Section Index is a plugin that attaches the first child page, usually an index page, to the section link. Install the plugin: pip install -U mkdocs-section-index Enable it in the config file mkdocs.yml : plugins : - search # built-in search must be always activated - awesome-pages - section-index # must be after awesome-pages # (1) Note that the feature navigation.indexes comes with Material theme already to the work of this plugin. The merged section page shows the section\u2019s title from the directory name , not the attached page\u2019s title. Using the Section Index plugin, before and after applying Revision date # To keep tracking the last modified date of a post, git-revision-date plugin can be used. A better alternative plugin is git-revision-date-localized which provides more types of date format (e.g. in time-ago format), and the creation date. Install the plugin: pip install -U mkdocs-git-revision-date-localized-plugin Enable it in the config file: plugins : - search # built-in search must be always activated - git-revision-date-localized : enable_creation_date : true type : iso_date This plugin creates new field in the post\u2019s meta-data which content the creation and update date. This information is used to sort the posts by revision date to get recently updated items, as shown in the Recent blog posts page. Print to PDF # Enabling this plugin causes very long build time when you have lot of posts! To export the posts on this blog, there are some plugins which can do it. However, most of them depend on Weasy Print which in turn depends on many other packages. There is one plugin that prints in an easy and simple way: use browser to print page by sending print command (like press Ctrl + S ). More detail of installation and configuration the MkDocs PDF with JS plugin for printing to PDF can be read in Print to PDF . Macros # This plugin is no longer used in this site! MkDocs Macros is a plugin/ framework that makes it easy to produce richer and more beautiful pages. It can do two things: Transform the markdown pages into a Jinja2 templates that can use variables, macros and filters. Replace MkDocs plugins for a wide range of tasks: e.g. manipulating the navigation, adding files after the HTML pages have already been generated etc. Install the plugin: pip install -U mkdocs-macros-plugin Enable it in the config file: plugins : - search # built-in search must be always activated - macros Incomplete data in macro The macro {{ navigation.pages }} contains a list of all pages, but the data of each page maybe not complete, such as title or meta-data . This issue happens when rendering a the content of the first page, but it needs to know the content of the second page which has not been parsed already as it is waiting for the first page getting done. DrawIO Exporter # This plugin is no longer used in this site! DrawIO Exporter is a great plugin that exports the .drawio diagrams to images at build time and insert them to the document. This plugin can replace the Mermaid plugin, and it is faster thanks to no JavaScript needed at runtime. It also helps to enable instant navigation mode of the Material theme. Install the plugin: pip install -U mkdocs-drawio-exporter Enable it in the config file: plugins : - search # built-in search must be always activated - drawio-exporter To create end edit .drawio diagram, download and install the diagrams.net application. To import a diagram, just use the syntax for inserting an image: ![ My alt text ]( my-diagram.drawio ) The plugin will generate an SVG image to a cache folder (default in docs\\drawio-exporter ), and then modify the image\u2019s source to point to the generated image. If the diagram is a multipage document, append the index of the page as an anchor in the image\u2019s URL to select the target page: ![ Page 1 ]( my-diagram.drawio#0 ) A draw.io diagram Alternative method Using Draw.io Integration extension in Visual Studio Code, I can save a DrawIO diagram as a .drawio.svg file, then use that file directly in the page as an usual image. However this method will not support multiple pages in the drawing: ![ My alt text ]( my-diagram.drawio.svg ) // work ![ My alt text ]( my-diagram.drawio.svg#1 ) // does not work Mermaid # This plugin is no longer used in this site! MkDocs Mermaid2 is a plugin to render textual graph description into Mermaid graphs (flow charts, sequence diagrams, pie charts, etc.). Install the plugin: pip install -U mkdocs-mermaid2-plugin Enable it in the config file: plugins : - search # built-in search must be always activated - mermaid2 And configure the code block parser for mermaid2 blocks: markdown_extensions : - pymdownx.superfences : custom_fences : - name : mermaid class : mermaid format : !!python/name:mermaid2.fence_mermaid Example: ``` mermaid graph LR A[Start] --> B{Error?}; B -->|Yes| C[Hmm...]; C --> D[Debug]; D --> B; B ---->|No| E[Yay!]; ``` will render as: A diagram generated by Mermaid","title":"Additional Features using MkDocs Plugins"},{"location":"blog/site-setup/mkdocs-plugins/#awesome-pages","text":"MkDocs Awesome Pages plugin simplifies configuring page titles and their entries order. Install the plugin: pip install -U mkdocs-awesome-pages-plugin Enable it in the config file mkdocs.yml : plugins : - search # built-in search must be always activated - awesome-pages Create a YAML file named .pages in a directory and use a local nav attribute to customize the navigation in each folder with some more extra configurations: A 3-dots ... entry is used to specify where all remaining items should be inserted. It can filter the remaining items using glob patterns or regular expressions. For example: The pattern is checked against the basename of remaining items - not their whole path, so it can be used to filter files in sub-folders. Hide directory by setting the hide attribute to true . Optionally set the directory title using the title attribute. Optionally specify a title for the navigation entry before its document path. For example: Collapse single nested pages by setting collapse_single_pages attribute to true . Example: .pages title : New section nav : - ... | introduction-*.md - ... - summary.md - First page : page1.md - Link Title : https://example.com hide : false collapse_single_pages : false Using Awesome Pages plugin with collapse_single_pages enabled, before and after applying","title":"Awesome Pages"},{"location":"blog/site-setup/mkdocs-plugins/#section-index","text":"This plugin is no longer used in this site! The feature navigation.indexes comes with Material theme already does the work of this plugin. In MkDocs, each directory will become a section, and by default, section only contains its children pages. There is no page associated to a section. MkDocs Section Index is a plugin that attaches the first child page, usually an index page, to the section link. Install the plugin: pip install -U mkdocs-section-index Enable it in the config file mkdocs.yml : plugins : - search # built-in search must be always activated - awesome-pages - section-index # must be after awesome-pages # (1) Note that the feature navigation.indexes comes with Material theme already to the work of this plugin. The merged section page shows the section\u2019s title from the directory name , not the attached page\u2019s title. Using the Section Index plugin, before and after applying","title":"Section index"},{"location":"blog/site-setup/mkdocs-plugins/#revision-date","text":"To keep tracking the last modified date of a post, git-revision-date plugin can be used. A better alternative plugin is git-revision-date-localized which provides more types of date format (e.g. in time-ago format), and the creation date. Install the plugin: pip install -U mkdocs-git-revision-date-localized-plugin Enable it in the config file: plugins : - search # built-in search must be always activated - git-revision-date-localized : enable_creation_date : true type : iso_date This plugin creates new field in the post\u2019s meta-data which content the creation and update date. This information is used to sort the posts by revision date to get recently updated items, as shown in the Recent blog posts page.","title":"Revision date"},{"location":"blog/site-setup/mkdocs-plugins/#print-to-pdf","text":"Enabling this plugin causes very long build time when you have lot of posts! To export the posts on this blog, there are some plugins which can do it. However, most of them depend on Weasy Print which in turn depends on many other packages. There is one plugin that prints in an easy and simple way: use browser to print page by sending print command (like press Ctrl + S ). More detail of installation and configuration the MkDocs PDF with JS plugin for printing to PDF can be read in Print to PDF .","title":"Print to PDF"},{"location":"blog/site-setup/mkdocs-plugins/#macros","text":"This plugin is no longer used in this site! MkDocs Macros is a plugin/ framework that makes it easy to produce richer and more beautiful pages. It can do two things: Transform the markdown pages into a Jinja2 templates that can use variables, macros and filters. Replace MkDocs plugins for a wide range of tasks: e.g. manipulating the navigation, adding files after the HTML pages have already been generated etc. Install the plugin: pip install -U mkdocs-macros-plugin Enable it in the config file: plugins : - search # built-in search must be always activated - macros Incomplete data in macro The macro {{ navigation.pages }} contains a list of all pages, but the data of each page maybe not complete, such as title or meta-data . This issue happens when rendering a the content of the first page, but it needs to know the content of the second page which has not been parsed already as it is waiting for the first page getting done.","title":"Macros"},{"location":"blog/site-setup/mkdocs-plugins/#drawio-exporter","text":"This plugin is no longer used in this site! DrawIO Exporter is a great plugin that exports the .drawio diagrams to images at build time and insert them to the document. This plugin can replace the Mermaid plugin, and it is faster thanks to no JavaScript needed at runtime. It also helps to enable instant navigation mode of the Material theme. Install the plugin: pip install -U mkdocs-drawio-exporter Enable it in the config file: plugins : - search # built-in search must be always activated - drawio-exporter To create end edit .drawio diagram, download and install the diagrams.net application. To import a diagram, just use the syntax for inserting an image: ![ My alt text ]( my-diagram.drawio ) The plugin will generate an SVG image to a cache folder (default in docs\\drawio-exporter ), and then modify the image\u2019s source to point to the generated image. If the diagram is a multipage document, append the index of the page as an anchor in the image\u2019s URL to select the target page: ![ Page 1 ]( my-diagram.drawio#0 ) A draw.io diagram Alternative method Using Draw.io Integration extension in Visual Studio Code, I can save a DrawIO diagram as a .drawio.svg file, then use that file directly in the page as an usual image. However this method will not support multiple pages in the drawing: ![ My alt text ]( my-diagram.drawio.svg ) // work ![ My alt text ]( my-diagram.drawio.svg#1 ) // does not work","title":"DrawIO Exporter"},{"location":"blog/site-setup/mkdocs-plugins/#mermaid","text":"This plugin is no longer used in this site! MkDocs Mermaid2 is a plugin to render textual graph description into Mermaid graphs (flow charts, sequence diagrams, pie charts, etc.). Install the plugin: pip install -U mkdocs-mermaid2-plugin Enable it in the config file: plugins : - search # built-in search must be always activated - mermaid2 And configure the code block parser for mermaid2 blocks: markdown_extensions : - pymdownx.superfences : custom_fences : - name : mermaid class : mermaid format : !!python/name:mermaid2.fence_mermaid Example: ``` mermaid graph LR A[Start] --> B{Error?}; B -->|Yes| C[Hmm...]; C --> D[Debug]; D --> B; B ---->|No| E[Yay!]; ``` will render as: A diagram generated by Mermaid","title":"Mermaid"},{"location":"blog/site-setup/print-to-pdf/","tags":["python"],"text":"The cover page # When printing to a PDF file, the first page should show the post title and its short description. This page is called the cover page which will be created only in printing mode. Create an element with class cover in the post-cover.html template to wrap the cover section. In print mode, this element should cover the full height (100%) of the first paper and align its content vertically. After the line of tags, the updated date will be shown to easily check the latest version of the document: overrides\\partials\\post-cover.html {# the cover page #} < style > . md-typeset . cover { margin-bottom : 1 em ; } . md-typeset . page-category { color : gray ; font-size : large ; } . md-typeset . page-title { margin-left : -0.0625 em ; } . md-typeset . page-extra { color : gray ; font-size : small ; } . md-typeset . page-tags { margin : 0 ; } . md-typeset . page-date { margin : 0 ; text-align : end ; } @ media print { . md-typeset . cover { height : 100 vh ; display : flex ; flex-direction : column ; justify-content : center ; } . md-typeset . cover + * { margin-top : 0 ; } } </ style > < div class = \"cover\" > {# category #} {% if page.meta and page.meta.category %} < span class = \"page-category\" > {{ page.meta.category }} \u00bb </ span > < br > {% endif %} {# title #} < h1 class = \"page-title\" > {{ page_title | d(config.site_name, true) }} </ h1 > {# description #} {% if page.meta and page.meta.description %} < p class = \"page-description\" > {{ page.meta.description }} </ p > {% endif %} {% if page.markdown == '' and page.parent.children %} {% else %} < div class = \"page-extra row\" > < div class = \"col\" > {% if page.meta and page.meta.tags %} < p class = \"page-tags\" > {% for tag in page.meta.tags %} < a class = \"tag\" href = \"{{ config.site_url }}tags/#{{tag}}\" > < span class = \"tag-name\" > #{{ tag }} &nbsp; </ span > </ a > {% endfor %} </ p > {% endif %} </ div > < div class = \"col\" > < p class = \"page-date\" > < span > {% if page.meta.git_revision_date_localized_raw_iso_date %} {{ lang.t(\"source.file.date.updated\") }}: {{ page.meta.git_revision_date_localized_raw_iso_date }} {% endif %} </ span > </ p > </ div > </ div > {% endif %} </ div > The Table of Content page # When displaying on a screen, the Table of Content is displayed in the right sidebar. In printed pages, there should be a page to display the table of content too. This page is also only visible in printing. The base Material for MkDocs theme has a partial block for Table of Content section, so I just need to declare it in post-toc.html and include it in the main.html template, between the cover page and the main content. overrides\\partials\\post-toc.html {# the table of content page #} < style > . md-typeset . toc { display : none ; } . md-typeset . toc label { display : none ; } . md-typeset . toc . md-nav { font-size : unset ; line-height : 1.6 ; } . md-typeset . toc . md-nav--secondary { margin-left : -2 em ; } . md-typeset . toc . md-nav__list { margin : 0 ; } . md-typeset . toc ul { list-style : none ; } @ media print { . md-typeset . toc { display : block ; page-break-after : always ; } . md-typeset . toc . md-nav__link { color : var ( --md-typeset-a-color ); } . md-typeset . toc . md-nav__link . md-nav__link--active { font-weight : unset ; } . md-typeset . toc + * { margin-top : 0 ; } } </ style > < div class = \"toc\" > < h2 > Table of Content </ h2 > {% include \"partials/toc.html\" %} </ div > There are some styles applied for this section: Hide the default label and add a new <h2> header Remove list-style to make a clear list When printing, remove color effect on link items Preview of the printing document Printing styles # There are some more additional styles need to be applied on the page when printing. I preview the printed version using Save to PDF option in the Chrome browser. Set the paper size and printing margins: @ page { size : a4 portrait ; margin : 25mm 15mm 25mm 20mm ; } Some elements only show in printing version, add media query type to display them: . md-typeset . print-only { display : none ; } @ media print { . md-typeset . print-only { display : block ; } . md-typeset . screen-only { display : none ; } } Tabs labels should be marked in printing as they are selected: . md-typeset . tabbed-set > label { border-color : var ( --md-accent-fg-color ); color : var ( --md-accent-fg-color ); } The Disqus section also needs to be hidden in printing: @ media print { . md-typeset # __comments , . md-typeset # disqus_recommendations , . md-typeset # disqus_thread { display : none ; } } Image and its caption should be displayed in the same page: @ media print { . md-typeset figure { page-break-inside : avoid ; } } Admonition can be printed on multiple pages: @ media print { . md-typeset . admonition , . md-typeset details { page-break-inside : auto ; } } Print to PDF plugin # This feature is disabled by default !!! The plugin depends on Chrome and Chrome Driver, and it also consumes quite long time to finish rederning. It is recommended to manually print pages that you need. The MkDocs PDF with JS Plugin 1 exports documentation in PDF format with rendered JavaScript content. This is very useful if documents have mermaid diagrams. A download button will be added to the top of the page, and it is hidden in the PDF files. For executing the JavaScript code, ChromeDriver is used, so it is necessary to: Install Chrome , find the Chrome version in About section. Download ChromeDriver , note to choose correct version of driver based on your installed Chrome version. Add the ChromeDriver to OS user\u2019s PATH environment. After that, install the plugin: pip install -U git+https://github.com/vuquangtrong/mkdocs-pdf-with-js-plugin.git Install the original plugin with pip install mkdocs-pdf-with-js-plugin if don\u2019t need a customized version. The following features are not implemented in the original version. Enable the plugin: plugins : - search # built-in search must be always activated - pdf-with-js While building mkdocs build or serving mkdocs serve the documentation, the PDF files will be generated. They are stored in the site\\pdfs folder. Add header and footer # The command sent to ChromeDriver to print a page is Page.printToPDF , read more at Chrome DevTools Protocol \u2014 printToPDF . This command needs some parameters to control the printing, which include: landscape : boolean Paper orientation. Defaults to false. displayHeaderFooter : boolean Display header and footer. Defaults to false. headerTemplate : string HTML template for the print header. Should be valid HTML markup with following classes used to inject printing values into them: date : formatted print date title : document title url : document location pageNumber : current page number totalPages : total pages in the document For example, < span class = title ></ span > would generate a span containing the title . footerTemplate : string HTML template for the print footer. Should use the same format as the headerTemplate . Those parameters are initialized in the __init__ function: def __init__ ( self ): self . displayHeaderFooter = True self . headerTemplate = \\ '<div style=\"font-size:8px; margin:auto;\">' \\ '<span class=title></span>' \\ '</div>' self . footerTemplate = \\ '<div style=\"font-size:8px; margin:auto;\">' \\ 'Page <span class=\"pageNumber\"></span> of ' \\ '<span class=\"totalPages\"></span>' \\ '</div>' and they are used to creating print options in a dictionary variable: def _get_print_options ( self ): return { 'landscape' : False , 'displayHeaderFooter' : self . displayHeaderFooter , 'footerTemplate' : self . footerTemplate , 'headerTemplate' : self . headerTemplate , 'printBackground' : True , 'preferCSSPageSize' : True , } Finally, the print options are used in the print command: def print_to_pdf ( self , driver , page ): driver . get ( page [ \"url\" ]) result = self . _send_devtools_command ( driver , \"Page.printToPDF\" , self . _get_print_options () ) self . _write_file ( result [ 'data' ], page [ \"pdf_file\" ]) Add plugin config options # To allow user to change the print options in the project config file mkdocs.yml , add the config fields into the plugin.py file. class PdfWithJS ( BasePlugin ): config_scheme = ( ( 'enable' , config_options . Type ( bool , default = True )), ( 'display_header_footer' , config_options . Type ( bool , default = False )), ( 'header_template' , config_options . Type ( str , default = '' )), ( 'footer_template' , config_options . Type ( str , default = '' )), ) When the MkDocs engine calls to on_config() function in this plugin, save the user\u2019s configs as below: def on_config ( self , config , ** kwargs ): self . enabled = self . config [ 'enable' ] self . printer . set_config ( self . config [ 'display_header_footer' ], self . config [ 'header_template' ], self . config [ 'footer_template' ] ) return config By doing this, users can add their parameters to the pdf-with-js entry under the plugins field in the config file mkdocs.yml : plugins : - search # built-in search must be always activated - pdf-with-js : enable : false # should enable only when need PDF files add_download_button : false display_header_footer : true header_template : >- <div style=\"font-size:8px; margin:auto; color:lightgray;\"> <span class=\"title\"></span> </div> footer_template : >- <div style=\"font-size:8px; margin:auto; color:lightgray;\"> Page <span class=\"pageNumber\"></span> of <span class=\"totalPages\"></span> </div> Add a download button # Create an element to contain the download button at the beginning of the document content in the base.html template. This element should be hidden in printing mode. The plugin will find the < div class = \"btn-actions\" > element to insert a button. If there is no such existing element, the plugin will create a new element and insert to the page content. def _add_link ( self , soup , page_paths ): icon = BeautifulSoup ( '' '<span class=\"twemoji\">' '<svg viewBox=\"0 0 24 24\" xmlns=\"http://www.w3.org/2000/svg\">' '<path d=\"M5 20h14v-2H5m14-9h-4V3H9v6H5l7 7 7-7z\"></path>' '</svg>' '</span>' , 'html.parser' ) text = \"PDF\" btn = soup . new_tag ( \"a\" , href = page_paths [ \"relpath\" ]) btn . append ( icon ) btn . append ( text ) btn [ 'class' ] = 'md-button' bar = soup . find ( \"div\" , { \"class\" : \"btn-actions\" }) if bar : bar . p . insert ( 0 , btn ) else : toc = soup . find ( \"div\" , { \"class\" : \"toc\" }) if toc : div = BeautifulSoup ( '' '<div class=\"btn-actions screen-only\">' '<p></p>' '</div>' , 'html.parser' ) div . p . insert ( 0 , btn ) toc . insert_after ( div ) return soup That\u2019s it. All blog posts now have a download button for users to get the PDF version. originally developed by smaxtec \u21a9","title":"Print Pages to PDF files"},{"location":"blog/site-setup/print-to-pdf/#the-cover-page","text":"When printing to a PDF file, the first page should show the post title and its short description. This page is called the cover page which will be created only in printing mode. Create an element with class cover in the post-cover.html template to wrap the cover section. In print mode, this element should cover the full height (100%) of the first paper and align its content vertically. After the line of tags, the updated date will be shown to easily check the latest version of the document: overrides\\partials\\post-cover.html {# the cover page #} < style > . md-typeset . cover { margin-bottom : 1 em ; } . md-typeset . page-category { color : gray ; font-size : large ; } . md-typeset . page-title { margin-left : -0.0625 em ; } . md-typeset . page-extra { color : gray ; font-size : small ; } . md-typeset . page-tags { margin : 0 ; } . md-typeset . page-date { margin : 0 ; text-align : end ; } @ media print { . md-typeset . cover { height : 100 vh ; display : flex ; flex-direction : column ; justify-content : center ; } . md-typeset . cover + * { margin-top : 0 ; } } </ style > < div class = \"cover\" > {# category #} {% if page.meta and page.meta.category %} < span class = \"page-category\" > {{ page.meta.category }} \u00bb </ span > < br > {% endif %} {# title #} < h1 class = \"page-title\" > {{ page_title | d(config.site_name, true) }} </ h1 > {# description #} {% if page.meta and page.meta.description %} < p class = \"page-description\" > {{ page.meta.description }} </ p > {% endif %} {% if page.markdown == '' and page.parent.children %} {% else %} < div class = \"page-extra row\" > < div class = \"col\" > {% if page.meta and page.meta.tags %} < p class = \"page-tags\" > {% for tag in page.meta.tags %} < a class = \"tag\" href = \"{{ config.site_url }}tags/#{{tag}}\" > < span class = \"tag-name\" > #{{ tag }} &nbsp; </ span > </ a > {% endfor %} </ p > {% endif %} </ div > < div class = \"col\" > < p class = \"page-date\" > < span > {% if page.meta.git_revision_date_localized_raw_iso_date %} {{ lang.t(\"source.file.date.updated\") }}: {{ page.meta.git_revision_date_localized_raw_iso_date }} {% endif %} </ span > </ p > </ div > </ div > {% endif %} </ div >","title":"The cover page"},{"location":"blog/site-setup/print-to-pdf/#the-table-of-content-page","text":"When displaying on a screen, the Table of Content is displayed in the right sidebar. In printed pages, there should be a page to display the table of content too. This page is also only visible in printing. The base Material for MkDocs theme has a partial block for Table of Content section, so I just need to declare it in post-toc.html and include it in the main.html template, between the cover page and the main content. overrides\\partials\\post-toc.html {# the table of content page #} < style > . md-typeset . toc { display : none ; } . md-typeset . toc label { display : none ; } . md-typeset . toc . md-nav { font-size : unset ; line-height : 1.6 ; } . md-typeset . toc . md-nav--secondary { margin-left : -2 em ; } . md-typeset . toc . md-nav__list { margin : 0 ; } . md-typeset . toc ul { list-style : none ; } @ media print { . md-typeset . toc { display : block ; page-break-after : always ; } . md-typeset . toc . md-nav__link { color : var ( --md-typeset-a-color ); } . md-typeset . toc . md-nav__link . md-nav__link--active { font-weight : unset ; } . md-typeset . toc + * { margin-top : 0 ; } } </ style > < div class = \"toc\" > < h2 > Table of Content </ h2 > {% include \"partials/toc.html\" %} </ div > There are some styles applied for this section: Hide the default label and add a new <h2> header Remove list-style to make a clear list When printing, remove color effect on link items Preview of the printing document","title":"The Table of Content page"},{"location":"blog/site-setup/print-to-pdf/#printing-styles","text":"There are some more additional styles need to be applied on the page when printing. I preview the printed version using Save to PDF option in the Chrome browser. Set the paper size and printing margins: @ page { size : a4 portrait ; margin : 25mm 15mm 25mm 20mm ; } Some elements only show in printing version, add media query type to display them: . md-typeset . print-only { display : none ; } @ media print { . md-typeset . print-only { display : block ; } . md-typeset . screen-only { display : none ; } } Tabs labels should be marked in printing as they are selected: . md-typeset . tabbed-set > label { border-color : var ( --md-accent-fg-color ); color : var ( --md-accent-fg-color ); } The Disqus section also needs to be hidden in printing: @ media print { . md-typeset # __comments , . md-typeset # disqus_recommendations , . md-typeset # disqus_thread { display : none ; } } Image and its caption should be displayed in the same page: @ media print { . md-typeset figure { page-break-inside : avoid ; } } Admonition can be printed on multiple pages: @ media print { . md-typeset . admonition , . md-typeset details { page-break-inside : auto ; } }","title":"Printing styles"},{"location":"blog/site-setup/print-to-pdf/#print-to-pdf-plugin","text":"This feature is disabled by default !!! The plugin depends on Chrome and Chrome Driver, and it also consumes quite long time to finish rederning. It is recommended to manually print pages that you need. The MkDocs PDF with JS Plugin 1 exports documentation in PDF format with rendered JavaScript content. This is very useful if documents have mermaid diagrams. A download button will be added to the top of the page, and it is hidden in the PDF files. For executing the JavaScript code, ChromeDriver is used, so it is necessary to: Install Chrome , find the Chrome version in About section. Download ChromeDriver , note to choose correct version of driver based on your installed Chrome version. Add the ChromeDriver to OS user\u2019s PATH environment. After that, install the plugin: pip install -U git+https://github.com/vuquangtrong/mkdocs-pdf-with-js-plugin.git Install the original plugin with pip install mkdocs-pdf-with-js-plugin if don\u2019t need a customized version. The following features are not implemented in the original version. Enable the plugin: plugins : - search # built-in search must be always activated - pdf-with-js While building mkdocs build or serving mkdocs serve the documentation, the PDF files will be generated. They are stored in the site\\pdfs folder.","title":"Print to PDF plugin"},{"location":"blog/site-setup/print-to-pdf/#add-header-and-footer","text":"The command sent to ChromeDriver to print a page is Page.printToPDF , read more at Chrome DevTools Protocol \u2014 printToPDF . This command needs some parameters to control the printing, which include: landscape : boolean Paper orientation. Defaults to false. displayHeaderFooter : boolean Display header and footer. Defaults to false. headerTemplate : string HTML template for the print header. Should be valid HTML markup with following classes used to inject printing values into them: date : formatted print date title : document title url : document location pageNumber : current page number totalPages : total pages in the document For example, < span class = title ></ span > would generate a span containing the title . footerTemplate : string HTML template for the print footer. Should use the same format as the headerTemplate . Those parameters are initialized in the __init__ function: def __init__ ( self ): self . displayHeaderFooter = True self . headerTemplate = \\ '<div style=\"font-size:8px; margin:auto;\">' \\ '<span class=title></span>' \\ '</div>' self . footerTemplate = \\ '<div style=\"font-size:8px; margin:auto;\">' \\ 'Page <span class=\"pageNumber\"></span> of ' \\ '<span class=\"totalPages\"></span>' \\ '</div>' and they are used to creating print options in a dictionary variable: def _get_print_options ( self ): return { 'landscape' : False , 'displayHeaderFooter' : self . displayHeaderFooter , 'footerTemplate' : self . footerTemplate , 'headerTemplate' : self . headerTemplate , 'printBackground' : True , 'preferCSSPageSize' : True , } Finally, the print options are used in the print command: def print_to_pdf ( self , driver , page ): driver . get ( page [ \"url\" ]) result = self . _send_devtools_command ( driver , \"Page.printToPDF\" , self . _get_print_options () ) self . _write_file ( result [ 'data' ], page [ \"pdf_file\" ])","title":"Add header and footer"},{"location":"blog/site-setup/print-to-pdf/#add-plugin-config-options","text":"To allow user to change the print options in the project config file mkdocs.yml , add the config fields into the plugin.py file. class PdfWithJS ( BasePlugin ): config_scheme = ( ( 'enable' , config_options . Type ( bool , default = True )), ( 'display_header_footer' , config_options . Type ( bool , default = False )), ( 'header_template' , config_options . Type ( str , default = '' )), ( 'footer_template' , config_options . Type ( str , default = '' )), ) When the MkDocs engine calls to on_config() function in this plugin, save the user\u2019s configs as below: def on_config ( self , config , ** kwargs ): self . enabled = self . config [ 'enable' ] self . printer . set_config ( self . config [ 'display_header_footer' ], self . config [ 'header_template' ], self . config [ 'footer_template' ] ) return config By doing this, users can add their parameters to the pdf-with-js entry under the plugins field in the config file mkdocs.yml : plugins : - search # built-in search must be always activated - pdf-with-js : enable : false # should enable only when need PDF files add_download_button : false display_header_footer : true header_template : >- <div style=\"font-size:8px; margin:auto; color:lightgray;\"> <span class=\"title\"></span> </div> footer_template : >- <div style=\"font-size:8px; margin:auto; color:lightgray;\"> Page <span class=\"pageNumber\"></span> of <span class=\"totalPages\"></span> </div>","title":"Add plugin config options"},{"location":"blog/site-setup/print-to-pdf/#add-a-download-button","text":"Create an element to contain the download button at the beginning of the document content in the base.html template. This element should be hidden in printing mode. The plugin will find the < div class = \"btn-actions\" > element to insert a button. If there is no such existing element, the plugin will create a new element and insert to the page content. def _add_link ( self , soup , page_paths ): icon = BeautifulSoup ( '' '<span class=\"twemoji\">' '<svg viewBox=\"0 0 24 24\" xmlns=\"http://www.w3.org/2000/svg\">' '<path d=\"M5 20h14v-2H5m14-9h-4V3H9v6H5l7 7 7-7z\"></path>' '</svg>' '</span>' , 'html.parser' ) text = \"PDF\" btn = soup . new_tag ( \"a\" , href = page_paths [ \"relpath\" ]) btn . append ( icon ) btn . append ( text ) btn [ 'class' ] = 'md-button' bar = soup . find ( \"div\" , { \"class\" : \"btn-actions\" }) if bar : bar . p . insert ( 0 , btn ) else : toc = soup . find ( \"div\" , { \"class\" : \"toc\" }) if toc : div = BeautifulSoup ( '' '<div class=\"btn-actions screen-only\">' '<p></p>' '</div>' , 'html.parser' ) div . p . insert ( 0 , btn ) toc . insert_after ( div ) return soup That\u2019s it. All blog posts now have a download button for users to get the PDF version. originally developed by smaxtec \u21a9","title":"Add a download button"},{"location":"blog/site-setup/protected-page/","tags":["encryption"],"text":"+/nYCQbKOLWb9VBJ+x/wEw==;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;^","title":"[Protected] A Password-proteted private page!"},{"location":"blog/site-setup/protected-page/#encryption","text":"CSmFyNpiOtAj6yzgizHymQ==;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;^","title":"Encryption"},{"location":"blog/site-setup/protected-page/#decrypted-content","text":"VC6BUPNGBUlfn9mxbyX+PA==;cx1V+W9pj9Cn2IxufAUBOI7vaqRHNTCC58a3eKFhrNmOKA/TYVWM76Bz+C+vSUqAUoMZ6K4jmNc7qLC5jC64CU88F9vPfbGfhVl18hu1y++81vodzwv/SMCfqdF34lL6gYq3oGaiioL5YmdZBEVEKf4qgVAXt8W3NyMYp8ZnpnqhNhmn56FImc7r5jgglTPN7sghtMBUrPivJYfH8p3IOvkKtKDWtFwz+hQTB3t6sfIUu/T3/0hq5ZgbAdAHw5I2OVgMIsagwWbvTSPVXrd3S+PPB5DRZD+1nZWiX450pfTr8T1uMpDMZaGTMqbtz4Np1lNVWbbZOI/QW3KdVs/FBemeM2JLn78hDCOVFXhnSqUyAN0/LMkS+G1N6VOZjjeJZtXBonqq9aWG6glfH51o/cnnT6K/S0YTy58SkyifhsroKe/Hc+ulLOlx7E08HHic151R02C8UT/YM457BNtQyNScKoO1kIBaWEHX+8Jex/FeFjRCxGTGg+INPj62+waPxepHjebrEH1IWb9qcIE0C2dD/67BOuB0x7XRwPa3Ij/qMw4bn/d1i7+8adg+Jxge8t1F7uI29bRVm83OBcuNwGFxug69Fm9h/rfSlvnOcnoyavMT4LZPzClDbDFyzsOhAz64jCmFlqFtvDLG/chKiufAvXFhonA3xaFPA58UgK09PECvqgUmUKT4UkH0/JP4UjsNO5zAH0IdxYEbR6bttaFyow689E5APVBHl0fTbYgYI3hipWa2EwJgLkOpYXfoySHpkevcqLufVLOLeOiRABPq0bkylr8uYU01/11d3nEOKY3aPFhM/rY1XSSLMFDdKKavTVBySOqg9O63YBboNnPU/H22bp7ykL7MOkTxKv7zwywEKJ76qRR/oq8ljoPm00L5VdUJTeVUYbaoU+8CJJttxf4635OjzWBa4yFwrF+UVwwzFShiLqh6M5G8+Nbc337J6mZEQDrfGuKNrNzhuHxec77Rf1ooSawU2J47qNnjvEh7nQ9N3sRycZh02BW6;^","title":"Decrypted Content"},{"location":"blog/site-setup/protected-page/#meta-data","text":"vv1pm204kjlb6McvnQkEuA==;R90TYJShRkueBsdvif7kdOCEXOO6JqdnoRi+RrqmdAjYjD6cOI726OKBNyP1v3Xqk118QJ34RMXVJSwM8Y25pEEJhJk5TFEiyzKUg0to0riFPk/y3/UruOarwIgYDBymXiqywguE11KbBa+bmJzIFYG+ny86zLfmty8XFCAEuUmL26zJ9gJHrK6KstBKNDgj2h17lnDgS5jSFMYNzH39wonAI2ySt3aMGq+iC/ISU6iorSNNRXzX+0uRcgd0hPrbHSfhjVRsriQO6Gfn6hBIOIOU4HrDVcqxiPUMXdpoKwlZ7bZ/Moqx0bKzdJzuiUu94eXSP4oqxGxNcQeI6Lek0t1vfypSfhn02tOe51ZZpsyI6urc6LdBShNlzoARRNZz6/axm1wVbigzSDPbu+NDQeY3OZJ+bcuII1Q8nEqnMS+XRnBJ/NEVF1q/gpcy3lU3Ut5mlZK06dGrmn/BPAjCjJrmzzvPcwt6tNRcVM9ixwgnN2JNaAvdugH07RHMfuA2qdRF14Vb97RSXGO4tzR5pihgZ9JBH2iVTgpme21UVzZEeSRv2DlakAoCfhA3EH2Vvr/xqkzFUfVtjHjI26GLxGXLZfChZMbo9NBVx5YN9P56nU5l0cIiew2FCabRljxPwflqr706QKao/y6Uu2xzYN0V1kYTPoyGs4ayygUCjA77qhwr4J+MJlgcV2fcdfmAaoG3gSqGrU1MeHiP4aFyhUBNmFyCy2MWiN6mH/fVlzXrLM9a6v3Ci8fFP10Slmr6WbF/ythQIG7RBMlfJKAupdGF/jSFXkLEn01A26t12a5jgmltGgl81M9VcBYmjnHpU6t2M1vfH0ZfDkjM5qPZgA0eIIi/dffwoM6N8+zMORSRiXRZ+0hDN+iveyX7tDM4;^","title":"Meta-data"},{"location":"blog/site-setup/protected-page/#code-highlighting","text":"jyyad6SDTPZ/3aX+djLd5w==;hQZd0i32RSHjRfVpmnH6MvKlD4NY/i17A85Rxx1/j5F80XWRHWxrE/y0HKzLFE6lMpLyRZpNlkBeNGuAOc6jIraEHX4ctAQQaFAWfNGxHpWS2rjeNqeYLTQE9XKeQL5mQq3G4ksXCY8WmVbBlUeQdHE8mbsq3QrTFPMVjF2+iQE=;^","title":"Code highlighting"},{"location":"blog/site-setup/protected-page/#inline-code","text":"V/age6CSE/hniDZg7SD3Yw==;v/ZQbVqaadj8oLQsLhvYaBPzHa4YUUY+DxgNToHLdLJBeTI9eTjfvlxxkUFp+I8dPWRHyVvzIhloLvgv426cmfVkNlisU0yB2uuRRhm+SJ5ijGje52ir/GgCs1UaHbwnjppkJuUnWUmnAuChG3C5NBQqDYw3jqMiJVk7ERmaG5zTq+YcLJaalyc8qh934v/dwBPKPECaPQ3qqDUHbr7IYw6QiWjSQLmHRBMg7KKjPHuo+dFF6xXrCJhcnhJpfYvmSI2AgRr/3qJ+gCLl8FKNyt+QjYewu+KfiZkmmnH0jBQSFg5QpybHqxen601ZqHLusyxOpurdbMjVISc/Vos4HAy+GXVaelr8da+aYS/JAW0r1GLfsHUw1/VzEPu2UqfQJj4JwCIfKIkq8SqPwnqxRm5Gli04Gxdo3i+5HvPBhdZf+rWnD6nIbwVstRWp/eoWJl4ndHd7zt+SB/VK4zyC9QSOaC865+2xVWUHZeHSi3O0XcIXTBRJ/0ZHzaUGMhr0Abu/PoBFH/9HuA6AvrsLkvDWYTHHzItEc8ry/KqF8Fpyf0RDY82fbC4iHAjeJNhUJ04mqkH5dy5OGfIfR/gisw==;^","title":"Inline code"},{"location":"blog/site-setup/protected-page/#code-blocks","text":"BeHinkmjPeeyQBar9bA3Sw==;NrRh6h7DsKbxKM+e/ERLuRkEHIBdmKrbcV82QtAs+/4cgSA5IJof4mXloMhC7NBeoOD5doWbf6kRL/gOELYETzQHK6yuqYTI9ulbhwZmjQdr0XijtRVCDqhSlmj1P6C0yGTAHUOeWkGnP5BZdWU+mkvv31z+O1VYH9OY/HTj2SRK9EIq4IHri2jqvjdQ4EvsAP/U4PLb6QHD++tltiDcbHpK7HBMqETgF+Nh+CzjPPhUqcGmr3qq2IzUeAC+ikzd5b1NJIpzGbV//t10TxgAtBIU5naFZjyYRx+KDGT1GLi090O0Sv+E4ajojflyukP9Ay0zMqNEXpM8olzq82HG15B7Urvc/1y7f/43/alRLjAiTao5xPKszWjRXLgPVHkrxKptqG1jR6ZqRHb5v7EEqSh7IFSfGUH2N5l38MNmNEn8miFoZnKAg/DLCqU8DhrUn+tohSl7gWMyhpk0qtshI372vReHiPOSPdq0BcErtzu83DOLcsVdg0tb+dccrTDcHBi1+AV6FFEn55bmuRT8+8THbsOd4LD3PxcObM4067P+TyYBMXyWyeKVkzKw1Q1wAr3Z849WFutcrrukMi1Iml3JjNeVOU62gyC7kkpEyiEW2kx/asuYGp649i+E9pHYB4YaVC+HAtqWNwmjy6MmvEMxNYRrvyCJt0R9yW9FJ8Zvjox8d9EOjKFw9GPByHVWx7HK+qltYcj87I7krSWpQuo+7R7DXM/0t2KCAlJqbaGbxx4yoObv5ijw9kBZdHv2972fdL465SYrSDy/EahxXLcjtEm8QF2clxf0E/NeqoFR1UDQ69HQaCDzrmyYoUL0vN7UK7DGOSOgTE1UuIv0pS6Z8XlB7rXp7TMQn9TEZIqZZKQEV3hI0hjCeE5WGissBAgaWb/pSE2kEMbotW+PU8Z/a8geYrxNds7f6Kv7N7mnJpFLpgySRTHULURPVa4cTdjckkSk5hpQ7y+6yuIU25x+DoGfHBkawim5Xv99HG34+uuaMHVJ3ak5y8LYjh3H+gxP3uZsuTGMGWBTEuw5QhHIqi9zjjcuaZg6jDJEIDDQPgRLHTZh6FR5oySZTGEXaC/qT7aHUnYGboAM1z4rdkYntOwqyDrxiPpj8Pctc/twXl3cTHUOEvqEY3cFXBifwpmumMTDMAURuj1gs5FGx5fX+/uerZndemPzy3niZP3HLhmPbPwGD9/E53anjtcmmtqRj4PlzqF9kiPq5/uepsBA39Ft0kaKsi56nuAWH1YaQYHtglX/sm5LR8X7rEJW7+jRGdY1F3KKUmTICuLmcTM586xqzpey54cmAmiLsPb0rBQPshQMeDn/YbBiL0VuSaibOKTkIKrTM2HamFDe0YCjJTVZg4ZM5+71TSpDVtAsLUMiA1SMz4TnnXdSanumiuyPU7WBmte8oaK/A6/iXD1paoMkExXKmdh7fjrYFaj6R50R1A/uNHNJVlWrxHCISc39br0E7DBE1pc8RWtVHij/FC3BngKF39oqusJdDobN0xSj6WpDVkW3V2l7g2kxvJ7m4H7lUmErWKB948FmfctjxyrkTcOihjhHwMxCUR0=;^","title":"Code blocks"},{"location":"blog/site-setup/protected-page/#code-annotations","text":"0C7Sft/6MB1HgbIN49NKhw==;raZovVrqgP2IvgYUCXuaQekcFxW9YFZ9Ey4zHrIBJYPRY4NKPeQ4viYsFSQqXk6AeYv1zsuQn5kS/ukiIuHhWTyostzLIxaf1nQBWOTfjnKHFPLsy7yDMbATfraYiIjt5THtPVS1RnFeJLXoGitiLTftBwB0X7qTkq4nb097yXx/o+LR/Iu/MSFZrHC9v1uFKOLOvOJ0Bw3hUCjzsFmuxiy0J78tvxBWgiW5GUlMnfX3fNICRubBPetpe0u9++3oTlhc+TJ10HJ7fl+Yyl8qPCqZ8Ob5pqpgH2Xdldxa2N/QSJLwyiJTK5rBCqvM7nBwkT2tm3KyolKLZEhslBSofX7PNHXBCz2fxXfDM6U/9cps89LalwvkHM0Zu6o2efD5ViBMmvgxEEX+GZImaDkIz3feXGNH9EE3fZngjVWOZypbnMWz1R2D/P5prqOui9/hC6smKZRDhLwGnd88OtLeXSD8lP6H9W9GSKKkttlRBxKtwxSkcpa4GCgqI1A8kdqXxBZcEwXsapz9Yh9ZeSKZdPsnQ+bsCFXI+NvJpTsZH7co+AmpiNYYzFhfZyh5ivFt9SE0BRCufxn0MLJLptx40Oyh8gGcSYdWFsXoS0iYsJmu1OwtDgtiriXVsAwHyELaz+WUS+/VqBbpMApBS1tsdIYo4ZWXEkmxw2cHpcn2qXJjYb5WGvAeurfNigJbJh2r0WNtXbLYMfngVzfvcU6UPKjD2D4ozYBw1CutXVAzc3DO0t+u7eoqrTvr7l18OhxmfE27HRbLrn9h0mg6iqfuMp7UtEG9qbC7bxL0P6/p0aH0LR0M/yZUXplmYsXy6bSucrVHpjfWVBHuyKBRqVL5JV+Ws9xc0UhOxUGYlFdO8VIrdpDHd0rP4G99n0W5kw3ToV8uggOdbNlZ9k1IDJPN9Rw1qfzrQjgk4VagDWKo+pMgRXu4mVwri1wQMbbwF17SVQoAQwjB3KzDt2CiDFWACyMsNWhMtTtczPfcxLFBl0DvoM4DFtT6yyLXq3r6ZqeN;^","title":"Code annotations"},{"location":"blog/site-setup/protected-page/#admonitions","text":"DWXI0srwUBCyaSbmdKj10A==;9/sUIVo4X/oH+CzBH++i6F3945NvsrVsNlNYPIBlTrTe4x4TJ7FivhHD3rgBi9rRwrC6dbJj4PKmiKZSsWes04PJvjWrA+O7IkHmvT2xEQaIXJkJexv6pr1uLfaYO+ghITjL0bTHBiHExHPK/f8xj8Det0C58YdjL6JUDj2qiGxRq/7+snKCB4e7n8yxND1oWwru5RLRlQQCdVilQAsxuw==;^","title":"Admonitions"},{"location":"blog/site-setup/protected-page/#marked-blocks","text":"Kq9WjYVJImewbeAA9qaSbw==;icAcE5inNQYgGwr8AabGKMJWOlzh+AzUL54V1G7jS5j6gTkyTGBRy1Pa3YNzjw2DJUvVGtmnHrJi+c2J1AEQVAKXpvpOPbVTZQmAwbnx3wmQibMQj2DyZaKFxBS8+xNqegHAikX8BNi2EPtM2O7VNcfbexPrUONMDUZglIbC6Ln+em4LZ1kG5v0MUa8xmVaLbTdZEuIl+DG+kMgM/YCSTU1u40DdZA7z4LrozM9Gzek4PxJSjYWXwekcY0Rq1S9KzUyQ684cO/jtXmkrgGm7q3q3A+9PwWHA2R3Wp0Dv4bSV2F2OjpYfOU2mit3XhAHz6Dp2E0dZBDD5314ZngXwFjK7HokGMuLBqTwk3f/zC70kNZtfA8pbH6zCKnIS5A5vWha2T3/5ubaKuusiROoF2DG3f2vEXsPgWts3CgmtHsnL2ShJ4QFaMC1Ox9iq7z+OApWGPvouc744lyPmNTpOLQT14J2T6yAiWZjOwypeDcD5skx3LOD+2Pf/R5GVQPUdJpHLFXYUUqixYQdVAk4pud+RXDTI7gqwAeXps+8HDh4R7kzfyzxMhEic3oQrScoVbmIIzhxm3c2e/CdDXK5w01WQ2pi8UUCfoPlb+YzNODMQkAEzRFpAAb0qG6iuWDIvMa5cdMSzpGUV/gCRfW/r6Am71ghsWO7r3mL9WRVBpnihS6xJ8II0RGjYzAyIHfzw8wKZ00/a65WyTAPtToWSd99j0ownKJPzHELUOf6MrhMZjw2mrkmf3OvsZqmfetLxug1fC5SJLT/Nt63a5tQVcNbAC92hJ0fH1DJR+cKoIjVZFD0lJLNfqa+9Kllqrn9l89kNaBbYXzhTICmmx69Nhn+Nz6yArQZDGhqgc0uPJqiJqOFQZwwXjUat4WVmYmJ7KCwWYm8T89t0xLaZQba2vTPMHBdsw/dDWbfO7OLSKXRvsjwU7mTACEE641YHMJ6Gh4NG2QYMh6e9QcPLOntUDKTdmljAbLFVSUjqAllvxnRMD6E+tnvdVrCRsWfp4HVzHgj54QqwqNydyCfMMyhXXQVdD14qqri2JvqY6ADXEjsHgq9csF/5Ha1j0bxPULt20SlhV6XdhdlwlL9hja8ipPW2xFtjEmRt6sjPyQwsvGWDNfn2VREtFpJEZ4q8t9NbIzPrOe/YB8WgewRTcBwpBcqCMTOk5nwHrCmnhjYwyfxl9uV/WetF5CcCK3SA4wimA0K0jYR3JTULgGdcW3xsDfUWt8yXxZTx7IwtF50akD/9HwryWNi4ZZVeaAxrahpXHIZFX61aZLGe+HT1JO8tArB6BdF6O40df6FNrU/OE+w=;^","title":"Marked blocks"},{"location":"blog/site-setup/protected-page/#supported-types","text":"482Y3tPaFzPykgUHK9G97w==;RsIZEbx71IwcVYseehojWAl0hJnKXgZ4TbnBjimbPzE2lb+hV2fTg/aaTUspV9d2fVzkj9gY2/7xLl+sbgYN6NZ1bcof5UjghXyLePmhJpvDxpjJoSdikZ0lGXlVTn7kA8zMtS/oWk15DLwxaTlqXLo4Y7gcLkdVYvxjs+S+D7DMnyjMiLQ0/I6sPTfSKIuuzp5L7mPdfB4y5c/WsdCr1l9WcjyktPrNtoo9GEgzLhK5YoN3ZizOjYDq2+1evx0K5kPjI5boggaS3o2KC/Sv1gky4oQbFyI+MNsELcnV4wABLerpc+U8gHqF3FytisERtvKxMA7mKDe9vEfJClmNug==;^","title":"Supported types"},{"location":"blog/site-setup/protected-page/#collapsible-blocks","text":"SiUMcEBegfJwSOaYk4HQ4w==;zbLuj/NQSF0SnIhHMWxnyhH8piAsBupMGN99gM5yAGdNEpZKSfwrOpGi9OHy0ts9TQ/auaFG/8pBkKLKJf82OwbGW+5EOHoo/42VZ8uAkNLQmzg1tb1HTSJDUc+k0CusceHknxqMlNWfhvlP5QOfsu4h442trXpiyXCKNmYviPizAgBR73MwvRdFAIH+i38XaeutWH2pMi+pxN+JGTfaWqI1vaoxaD8T7ehoJIrVS3RUPtS1+b93yXZrL0FHEDAebX34356jiL5J7xt0vTeL71MSAtbd7oWFzacqP1pXIXYPD0HopRAbKXRhtFbqCvp4XK9ep4U7fZrDTjPyzxGg1HcRu8wODG6I0Z4Vg4MvlVCay6h9gdaVWYsNNZcedTGIBeLtcSVbl4tzkkTTmRQnUYBpS5VxD5MFzCbC/KSNkmO/ZsjgjUNrZuGL23BdVYX+wSAW7Qaq9jnPArsMfaNFmnWo9DuuFLbxoalXsz6zRWe46BmW/yC13vmukvcirp6gg9m6uIAERc7FXLLJ5Clqht6kBMDjogV0jtpFUYahTWQpf8aiMFzX5sgSd8s10hOxPydciVMuV99yIxCr6Ys957NKxDGZuyIOdXUktiwvXZXKlnpVzIXErTPymoHMbEEqj3TZMzAKZSgMkjPvvBa2d73dIFD3AiSo4dYl/tarpRdsylxeiTdmjqC+3dhYuJdNCf2YowfOzC8RkhG/s9/O+OXS77XOADzW4i57zbrU6E7u0Sw98/h9jwTNcD0D8OEu1So8QWGgn1NY8mN/4IlGDKbbEOGSsnxaSMyAh7/bXhwpQAsbpQ7ZjCqkMeBbKg88rrud7bFF596w6RXxOtQegFh35Vz6wDgVrD3fNCXxJ6oJobxh/ZD373pkv/aMqK55;^","title":"Collapsible blocks"},{"location":"blog/site-setup/protected-page/#mathjax","text":"pAUhghCLEMCvAcG6rIGO9Q==;BR5UUi15+XTAXJyz+B67r+XR67xjMJGoh6ROXF9QAa+C2SrSLuaQZBoMKBFYXwhRMO2SY9PnIsaHcM6koj6jiDqDZNy/Bc9YWtEUdVzVPFeYCuL6uoLvmXs4J1IHxrDGFk2cV7LIS/Yt3qcz8bQO1XRgFksiDgMjEDMBBIInQNsy4+h0A53ALaZIMo9OFunthfXyFK4FJ96OWA+xrHnLwE3mRYnR22Tdf3etrdyf59xm/Q/1co9JYJT85A04njTLpZelY2AUCMtOrP7+PVNbpE1ykRmpcGGi+2GAIPuGS7o=;^","title":"MathJax"},{"location":"blog/site-setup/protected-page/#block-syntax","text":"/z/mFnRu06FtkixnW96BzA==;EWcsLnMZ3FC3zZ4FxHqm12KCclMWKhi25Zj02/r2Kf+Kfj2Ol61G7we0BPT2Ie1vFYAWcTbfXssHHq8fdH6pGHB7pvOjbe1XgBN0m0vHK2tyzHp3MjmFAI6pS1oB0GgPA9OkP6i7+KPK1ZoJ0EsMwFBStP04KcPUE9/BjEqFx0s3VRZhiheP7aTyFjZHhtPZmRfP5myI7zvjNmgwEv7ZDQ8uqdopLAxxF1YBqe1yYZc7ZL8yOd0RJA41HcvuCrC3gyI09vLwR46u/HMG+vVMWaDltNX2GnTUbsfRjMjt34RowCFbA3W7+6x6c/v0ZShxQgBlWs9I2FGlocdGDKznUQ==;^","title":"Block syntax"},{"location":"blog/site-setup/protected-page/#inline-syntax","text":"eZMOorXWLovP5TMNNs4Ukw==;q1l1CU3t7cKNxy10J4aOa7vxQq00a16BOpLX8L4i8ZZgWWhZAkZbHThiTQwOgdHkloViCaZcjI0mS9t0XbhuAAmU9cgRCy3rLCiFZJqGX9pe30eppBHtYTxJ9atVMiB92/SvVkUly7fSIc0Sh5p7zXj3xRJgsYhVf29lMma5QfcVabpI4b0uwp2OSRyhRq2X/IEtqDUIdFkvcLorJpBh09BlBbuaEIo99LbHL9WFDrozRdcf9jlEu8gTLsVF/cuMD89PBcuAIMpKBuPvWrxDwnSMHF805r1KXuOUVuCPtyIGSU+pkApnHg9rd8BCr6b57fBZfQ0plTEG4S+Wjr6zBH+z5u87lzSddsPDh+J1uQmlhROcTU2De2BPweFaFf7pv38oxmL3FdaeiZDIB4N8KTsnJ8BVYCwDaFRxxfOf4YadfBIjD9EUi9tskaFLArm6Do9XIoYrBG3cfxSU4yEz3DC3wLSirH0T1EsB0eOAKPKpNyWyXUMfoRaoVZnYRtMDg7/7qERSkjqJRyUL2TzcZN0eblzY88CxsaqK5Ei8gDp3Xy3RwQH2fZrpjP0dTTcwDq1KnngU2ftA01uiZkBSsdVyfQzTNg7vw7i18s6eWB6bVV0pBLzcpuADeELrp9j3;^","title":"Inline syntax"},{"location":"blog/site-setup/protected-page/#formatting","text":"NvY1lA3Bv5c1WveaiKae2Q==;Sqw8faQfgRbMMIGY5Ew9j4oj7uio41VXEAncn764qwO6GmV2wOCwht6T3dx7MnMdjDf4dGTxOscg/h2r1eI5k1rngufScgVrQ1FWc8KAai8CB01sEHAMTcjJqH94kFpG;^","title":"Formatting"},{"location":"blog/site-setup/protected-page/#caret","text":"LWthR3opDyjuDWh3Kgy1PA==;FlgZiLI+Y1Hzk5kcccXN4iEHzU7H755kBG16j2nbaKD+XIm+nHv5q7PbKy7UAZDThEYowsnCN4XVhwL6L1FIwG9DvkADnlOlwCTUmxheBshyW3lmUlcUtxqiTMPSOwUmG5L/l1CJcpAQ4PmYup/9FiVzXXRe58iQ4WocVDAoCkrf4HGzyjFozPk8K6Lo6beLVnNHTeJF9FdCPzftArzMNGcMe0hhd8jK8nzRoHErE0Nu0xp4PHFAx1hjEkPQN9cO7MpgObFLJgWHFGzFo+8JRf7mCm90czeWSMTFV6hGMIMC/CKp3L9EzMWo4LtGEqNfUapMP4ALBBxPcjyDckwlnrRdkJmzpSQYnjjcBR2gMdYcvkbbTT9w7Wxq0OmNSMm77DmWB9stoe+BQbHWkRGYZNPxO/0v2u2la3hdnO5G/XY=;^","title":"Caret"},{"location":"blog/site-setup/protected-page/#mark","text":"CzuZhcAHcmiLG1V60Zeqzg==;9GVW7t/QlP+As5KvJtB1vJZoWdUNJchKgs8fkskfCWvbB1P+Z0T4LSvmDolwF693xT9xXcVjGqFRe/wn7FvM4b28h+bnOHLuPAvINPFwMG3t/t5vudkH3fWqtsXv65ZalrQ9u7l2xDQk6g4t3try7plIv7ky3Ccjs4KJD3SaKLMmMu6Y2KNXJ3dGSGVuL10eCBVe0XUhaYe1sFIa8G4jJuHI5/ulwJHpbbGVEAcRHtl8qFUusIPLmYKME2QVBvCMQEG2FW3hlDKALlb9fduF8cGj4bjU8q75esD4bqL9sLo=;^","title":"Mark"},{"location":"blog/site-setup/protected-page/#tildes","text":"vdQ/g7Ht+PUq44DfFU5q9g==;jDzwTfWMpi9WR3Uj8VnEJEcktCDZUegprnufZASkew0Xh8oUz5R+4ffxbIrWqe2c6T9Yk3yXN2Dnffie9dp+vrfTbWnx0xXirX86jgL2d0nG5dcRqVCUccL9pVKdVcc/x7Fm92b0ouxiuaaKrOqhJWmS4ejnQfC0oJoJqfZSVxtwW0eYVm2nsvPzyQRfl19/KYXZqUMRHONNIHTTFLrOmagQumdhuAHeE6oo8Nmki6dLv5vgforNv0YPqbBBEZGSy6nz7ibqaa2JmQMGWF35t54tGQOljhiF5v3y776EP9ve/GN1IVe2zmiMBp58DzL4oGJwo84Dkd1rNekbYEHcutBH6gIQXk8J5bfV4J0CpCMkD+cvo88faI5qjwTM1ic5ZgacZV4sJilC3pFeqY6HWlBVSeOM0JMN3hnRzEqIoX9CceeTNZgZ60KIopJSlHFHLdOvg6uaJG1z4ZNaOn/zmyuS6EXHMCpO6496yrq4ee3P3WPmnnv6+q+UXNA3QAih;^","title":"Tildes"},{"location":"blog/site-setup/protected-page/#critic","text":"sXC52KUjFF7e9u127Sg/rw==;74sJWsLnpVZu+dBSMTFfNd9MzT5l0ku4g4mK7O9pKgpoA0wMALPMoZR1RvXOpf2Jt1wvCE7Im+Orlq2OO7MuoZzNYrC+RX2SYWOK1I/uGMA/Cxh5zTLL1qp0LUzi8nnkNUGlhtJy44Pn818n5EzzagQEk4W1T+PeDeOklNGm8rfdMqpup4ogD8oAcKOLxMzFe2lcy4ZNswPMLnbvW5keuajsmVP3T8gPUGkBrTD//ENIOLfWMjH3IIhAPD84X2hRKlAytvPJl1ABgzB/AMMUSgk8awzu0yBpceTk/XAromw9aI/1TVp5Hi3wm+W43Wv28X9i4CdyTWTVi7rVNftxHgHlU8ZYQOORYdKcvJxY3WcKGek5syDIp8mHtbzngzBOu08Y8xImbrbJrafWXkMNxAG8rDdrgrHQIsqD8KItN2aOu+T9TJ8JjwcRXWaYuShcPLJefJWmygh1j86CjjP7H693gbLrRoShs+qYSTWbk2fYbsPNqJAKMjmxX9Jr5C9snps4GOIAdCGwS54ixmzgAYlEJyP7hq5tqipVJdvBPe+HXUmrc0V8TVxVtcm6ScQnJyZEJl2joPYfHdlkSbdf7ASGiZNg431YctJlxfRGSUjtxr/BdFjvfXH2HUIPO4DHcWbsewRHelxPVeFErhkij5wFMqKBLaoQ3LKbosdpXp3cvclRkaACbkIeV6EMyW3OnMRiev6X2zygA7jupDhNkhueZ6+vxHbSweqIu1BD9WPJYKKRMSfJRjVgm09hzEJnk9vCw/uM1AARNTCVXsysp1yh6bGrTZriI9eWY1QncAG1y0XjPrYxd/7YyJDqIDshJy6JQpBBYh9juGYICnwi9wy0LWl4GkRBvULdO2r09a8G/GBd+pMFh+nKj66blDcptRfg1sb9BS1iLEBrt2+TdFjwrTCdktigUxAYoh+4IJYZqfb12QFDGe3te868vG3TH7AfKNqRXZhVFddqeHppFA==;^","title":"Critic"},{"location":"blog/site-setup/protected-page/#lists","text":"5ePT7tvu7H+sRAyiqLcRrw==;jurcS0yuBxeJvmUothackKRnlTrSMZv4TrE2nNSW80d7zfHdGmiDY4q5DVrBZ1rnwg2nF37UCNXfCaMjWeFyVxKHcg2fBjXmUiaPq61cFOeKGYdEGSRi0emwi1ouQsJo9ZUzEtY9pnJXYWwllFu/kYO/126pE6i3HK4nGJgjMEO0Ateg3G50kG9FxkUg2Afypfvw5nQ8HdpyZnX4qMN05g==;^","title":"Lists"},{"location":"blog/site-setup/protected-page/#ordered-list","text":"lkOCsmlvrWfio9J6tlVfBA==;nH6i0MmDhnbxONN8gzSv0IHKx0xLBU3HBbCu3j+NvRQiwCIiKuHQckD9Yg5E86dsHiUf2+bsXIFVnq3QsRfTMP40ZdqhYMS8S/uDPuqODRJzEWitkY3F48CdFQnQkAGXFwymVQfMRL7sC8V4kmHXHelH8BcFNTC5IIDcl6JFxgQYJ58j0B6cBPVri2IqzM2OQDfyyX2m1JvaGNOmNPR25A==;^","title":"Ordered list"},{"location":"blog/site-setup/protected-page/#unordered-list","text":"ZXukZlv1C4Adro6xo7Hegw==;Hlph4K1wzvV/tKaHGfS3U2h5xWlEOM18ERKT01QgPx5pT/1QXo2fn7bZJ5yFzhVr4PkRKmbEmndfkEkxSVyaG4GQ8vnECQWC7WrY9bmwitBl+4i/WHx9UXXQrtshQgFX2sbFNCBTXStROEQtkctsvd7Z0v8aCt9qbXieZ2RyB+MY3WlTqK1j9Z6ZPG9tJV/xzQ/piCXxo+D7l57AY2aG/w==;^","title":"Unordered list"},{"location":"blog/site-setup/protected-page/#task-list","text":"f6rVxHJ5fL9gV0mDNIwygg==;a7UQhy0aRllbcKHW2trIfkV5xxoGueks2i+WTNAL0fF2JipH7AuMDFg3iWnzMhH9wjlYDQ1Rfcj9zHvkLweA4Pme6rI4qbtPLYQ+blqmgiub/k+6CHJMHheYhqdVe9gEv1B6HKUb+D2f4FW9kcOQ07NyAlKVi24sHIKJtdyFM2U=;^","title":"Task list"},{"location":"blog/site-setup/protected-page/#definition","text":"soH3P9EzPkJ2a+xvnac+CQ==;utd67j/mu9zISL/7TCfBuel9ABuruXR4r2pz2CYm02s6RsSa7TPatfhsdKSejW3M/ZayRC2pYNzTCKZWTfpAUAVgnuBBhRMBKMzvBpRT1QLFAX8zYV+JNZmL5xqx5iKH;^","title":"Definition"},{"location":"blog/site-setup/protected-page/#images","text":"Fk41ZCOr93LSB5jlFfR7ow==;WPADYZCk+cfOye41uJ6di8jE6mv793gJAKjkJA3moH2MXC9SJFySs4pT0RM4RaVtjLHhQXno0KImK4rL/MAC4qhi9oAlyaQ+VE9NAJ9QoUGVMuVqxlKSvLKKKIRNI5HpiLfVqYGy/dYwWEqhtySK/WGLODRstm/4o3oEZ/k3Aa3yZvl3+wW/mkQr48HiuNPWPjZ8D/W3zlmpV5nccWkOpd1pbR3HGqZYbuGMRpjpVqHuVIX5u310OkUmHZEDHHC5O+a5pIr0LDJCUbRi0uls5ki6EBO4ej1bX0SfQtPZka9Kl03jND4oS71vhIyXFVwgHyQQzJpuSZiz4B9XVL+WnS8Vs7AjIESx9jT55ika1ZpQjrLr+hpJ8Zo/zpYuvowd7sDswod4m6ub9vIIuy4IaT+A8oBiWxqJQql8hw3zxEVCADkkx10Jor0zSb3DET23teoX1TAPhYXGmS3Citxhxh3FYGr8UeHonD1vmdnR/odYFrIje+88MXhS7fevWBPqUCzU7so3x/FD5W41wz0+Vorny0+GWJUm1fh7Dtw+rTc19HUZO+vt7xprF5/qZPJis75mozk7h6sahDSNArMO1zVO0VsLxAJ43piTA0bylStEPCmYdUM0BCB3Gf4N9hPCW6SqDTpYTN4E/m8CSiYXpXrUthsdu4+/iRiLAEssDX+9Vdre4x60KykSyYomSVEoAGtAarSTw2yx98QUnW1QAQ==;^","title":"Images"},{"location":"blog/site-setup/protected-page/#tabs","text":"+Luc5aX/ozQftkTRrO6QOw==;TGnomRLKDiYlH74O2hp2VS1sKQaq+bVOr8b5NBA/Lu+frA0u9oFawIQoX2ZYvy20PrvCqEV8VFSEnNLQLpzYW3XGaRNpkzDcpHJqK5j9pOm8O3Sp232mUotZkecIyKPblFdX52aiMOWFMDqyonjYTdTSel9uWs+XElhXPRNPRywMlwUWnABPh9vdeTMQWQ99kMdPPrq0w1dx5UHfKW8nA9lNK5bO15zhfhpI70E+HugtMqLt8SEIdiMKk9oIM1PFHic612I6YBvoP4yaOhM4CumFL0NbV0RvKngs4E3ZatDEA8whAHKDUHJ+NAiVEYiMqaxUvG+ga8KYK0VHcjPb2MbMPhfV5i/GtdMFmj5N0b5XsHIsxUZ0a3KrGru7tWg0oAU7K9UfDbPwm8ocbFNggtXQJ5JY64emc1gXrMXH4djlLHaD4SnQxvzdSxdg7NdV603eCBxWpzDgtLsoKTb9MXhHK3gmdHtYvVNu1loienbxFTM5zRe4CzR+TqLK0MzX+ySJyeRDuCN7dmeeUAHqqBPjIB018L/0DkuYGe0/W/QgOCDj/4oyyp8EXMlBaarHtQzvYkgH6eNeV5KX5tekEw==;^","title":"Tabs"},{"location":"blog/site-setup/protected-page/#tables","text":"CpWQMLBYy0+uHgBMUzblUA==;VVvbLck/kjz542cp4QExAG/w6MRtd67qpyTiJa25SX+sKtccezj/j5f3y/sIUuw0N1sXxcnuCLWQ+Hh/l1BctPvqWA/P9+S2+hdO9EsTtaJuMJd0EJclvpylLo1St4Ydg1MdYXFHhmEc+tr8909dcIcjMyDzBh5lafkbwiw4wgCz9PRuf9vFOrtGl0hBs0nEuchtv+PkX7NRuMMeUHwbxi6xWmLee1eS1FuBDMfs9Tos4sTw0Nucw0b4sd387TZXdUKCG8VyKuq+HnVRuOeRDpB4LsGNTRCaGfgM4fwWzbGdZlhiGOxfM907NmPvlZ+5fv2+THYpvMCdn4uHjmpicwoiJuZmb96koQ1dPRgHHVyuKAh9ME3+/qlxEHG8S9ONz/muDjIz50jjTP0ADd03IPs6ghib/MXdcyHEbeT5wN+52Sy43XmUwDrRTWhoBoH/hvAC+on/sdE5VqCc8cZmgR7V0iGZKiA3yCjHfyaQM82+uPeOBcKOTg68ztACn+TPKSSrunnUgW6rasnT0gcmr1EsIiyAH7r72ENG8B2B8aQlZAS7+2N22boOl3R9Heo8yw2wJUJuh/vta+wVI5+4UfQrbxJueFlN/QlJrPenoD839lpLgN4fZLGKWL7IQmjPLlT9QjP88rjC5Rrc7q/9FIyfzKIleEWgNF2aEfn7AG4m5ezfqz1MIzikSTB9VqUTZ+6gGX74aENpAWT0D/QZb5QqqBAxU8CpuFpvMk2/tCLb2YxDi+Uwzp2Ne6YqVh44wi+bpAoz3BIEu/LUW8IeDs3jpTw9q+tppKHE4ftVyAeipeyodwELpvoW9oGNa163DQi6YsEf0UF4vYXXTHGZgQ==;^","title":"Tables"},{"location":"blog/site-setup/protected-page/#icons--emojis","text":"yqfFGi0cuLnSlO0UL200Zw==;9pycbEC0v7ywomgJHX9YkhKGAzAZ5uhG5tZOvtoZOleTDjrnTkIH82saQdSKNU4ATsmrCzS3tglkoANgDx9/pRc1PGa46I3PLkut3d/0t38P+YtVxtfcfFt1XVIdWec7EFCZUv+ldtc58RREoL8ahKPAwKamkqpFD3uCiykXPlnRc32vPDBQuX/1iX2a8YpOn50SG+7lB2ckuK417idLsWPolRcBOlOzw4zfxbCr8SST86WYLwevzu2cevg71SU4+VvYi0RZc+nd2J4yHIevu6UQUq35gQLqMl25AoGbfmBzLRTq3/Hz+ZQjL7qJsYXX4OlsQAm/vsH4k/D9+SmdGQ==;^","title":"Icons &amp; Emojis"},{"location":"blog/site-setup/protected-page/#emojis","text":"8zZIcYYxJpqJxTGfmv3kRw==;/yPqZe39joaDotd6vKI90MiP5TMlqxiRnkyBaiTKstVFubDjiSXOnSbLC7JDqpDAXi5vEknAx6MhIfVFi4gS5vQCaFaKMhAdroQkS2xcpUJkmawH4JYvTskFPgVv+adIubgO0jIbPkPCXwDPKUAZIfAaGSg6sPJMDjkWUzEvn5dBogoaYLljuk4x1ra1SlH14XBBWCUT9lWdo5n9WPZ/LQ==;^","title":"Emojis"},{"location":"blog/site-setup/protected-page/#icons","text":"YTGgFab7N1uKTkKQCnd6UQ==;7erW99sEArvELoU3kt+zKi1adi42aqWFW8zXR/ZLEbcsSFPi0BNGhUuaxvxHUxvS9syUBIBPnjMP7tI8YiYb43KcEuhXq+E7tk9kJ4uqe/IE4dUcnI2aGIj7Wz7zJiudoLplcbf7rntoJ/iN0vQgAm/HEeV86X03N6yR/CslbLfCalUhVUivQl9tkUftPma6w0upE66RGlkLKHR6bQIluCe95N51hq/bgGIR4uNiPt9yluAtdQNoCzCZwN0KhfGoaVFr8+woNKKTq3HOPQDGcW/HIY7mHbGIFpxsx+4HTnT2phLRP4M78kZ3S3bxBkTYT0I1bpnL0vjIrUi+SddNcQ+U2QxU4tEAZGB0u0ohqcalvnwcmH1Ve/pk8Wr+T2VZHA4NQhZapnpPZBz/wRWe8TUCLICGD7C+eg5qQ5O74egI3Vm+qCZMpVfgDMdsMWwMZ0d9zuWAgiJFm5UX152UEi4l5ybRSs7tsHhwouAfD/1PgQuY6MXhLlrJ3wuewAZx3VFCVwyrD76Tb7wbasJfAlFSAlnZMcm3r2xUthQRCpFmGE3pd7NQiGeOoU9ESlh8VNsPQkG+cocYDrLX+aDnunmpMc9aqYJCQipVp23Gr399UueKoyUbOlR11NFnfw0MaC2hVCPRV2oMbxUbU0v/zMvXUSFyiFUY0NASJ47gWaRZpfD/LRSjrkPBG6Z+5eECyMZmHF4BxxNWymiTN8oTbTSpiNyk1igicwAFVOm4CdGUeHCjp+vl41Et5BJRSvUY;^","title":"Icons"},{"location":"blog/site-setup/protected-page/#escape-all","text":"lOxoDrHQWPoiVxDG7wVU6g==;Ov7Af5lu1vV/8Z9QIqBm0HWn2UHWyZsaffvNXT9woYN59p9A18ffsmZDQpUHfHoJKh2Tls63oVkTAYtClRJKiB+UPUz6jzhzZtT5pK1pKrd00/+MBjZxyk6Y87rJ7keYbxLWRg8Xk3u6+FP78M2MYnSyJW09/DNZ+g3eHWTrhu11Y6BRFOM+R0WduqAIFF2Jo50Y1mLj4tBGH5YjE0cgcHsF8jtA3XAPi6BHgLuL6c7ZG81vR0eOZZq8VzBrhSfao+RV17GrkUNJTJskBX0Sxq8p5cRONHIMGRby6cZAridJfsNCfc6xA+voX+hqavHQ8HC7f9xHBdsqL65ZG+ZZYlsUDJpt/UMrLoPrUUUVgZQqNk6il79MXSX9xr17S5Egsyi6Rb1Tm44lhTWOpqs1Bq8ycYOUa8FYCRqdx/SoEKBmixmynnjoPjwT4tQKwY6RnJuGZewxk8HTn6IdV4DUtnhRaT+bFkDpIFrRj2go72JafBWQiDUr0ul+AlnE1YMY0qTlbJuplzyUxy8E6SiAfR7CubGPdWv+x7XRvtZjLQ9RpG3kgfAITS5TR0CO/UDHxJVrDlg3W12wbbtux2JPwlHmxivgXBIg0jlcscYpczvQcIHyDdQ4qTsmx1dJdWL4lE+exkzWatFAH7MP7Ew31LoC00jMspHBqxztjuMtdzjAp8JLaamtijDzlPHcttE12LcB/bX7s49O7qwCG1zwB3fLAyc5R9kCuLES98h1Dz3a6hCH5eMms+qJOHsXqwFuvHgyBLZPJ/t1bwyrDbIUR/eEfVyUlVPCBGELG60HYa0=;^","title":"Escape All"},{"location":"blog/site-setup/protected-page/#special-characters","text":"TOLN7jBtSDRYEsiVjJ014g==;Xn1k+hGTKZNia8cK2yvBga5o2OiuzaryYe+XM8k129UELUZD7TsnBZjgDYLFnO3Re3kyEvXEd6c07a7ppMohVhySlfsFHKrmiyV2vbQm9SuG0d2204c/HHV5geFvofMv+PbhiiAuflDN+DNgqXF7D1IowdYl22iHGYNxYvdi8Qg4wGyQ0gIAV211tHNmV3KlEaOA2q4kDhBg5iQDYQMwQa0C2SnRPyR+iHpfhxozLedYdK6gt47is7gR1cFcBhPk50qM0wBpsNN0QrXibhQ3riWyuaZ1fe+7Knx6wm1iOk4UtfXt7LL5gZh9ZhdR//zr62+HlEKZWvTo7/Gxt4DM8/BJI+QIeIa8I7ZBHwN7+adTcWs2MZp4igHotTpesEC5pkI5gko++TAlSKminhcBxLF/fh61V7TMCh2t10TdvGZIUxw+udRjG819tPdcK+CmXUbPTHl6DNuUruWDJVYgAzGThkvfNEbw6KRcfkSxy+W7c2sIHbwWZnnwOFE3y2BEcjwPTABZEOVasSEMdEzEZeAboi7+RZKGsnRlZPPXwb4WYMA4k9fsPI6/UppGnKZuMvToYNOpjJvSh3JndXto/g0h2QcOD1ZUtPKi3azJkHzUouEQmfObD/z6NnQheRTCkXjh4asJa57bRPGCh/UX+O72RyUcV+QA4vWVWPAnS6DaaiSntpytzNXIhytI2Sqc270k5Zs3YkOByv6EW9kc/6nCus3hChQn4Ioy3NZHoR50PcanckGKj1KGMbyGy0n7GCQdRLZ87wdhIpH4mZ0DBeMJq858Z/Zv/emzS7/fwBHUouKSQgvFg+LDSkfIEstACh2o6QuX+cVcXrCcUo5JCI/RPTbr1j4d8RNw06jaZ39gkVCbmYOz18WqBC0ByUz/69Abdn5+EZinv2JeAUeBjNJqdu2JOqNhJQavAJS6nXvofPdaJ1asj0UvnNxhdm1Su/62bxHNlrlSg3zZYZWiuDJPHVahrk58mKYOPsZlIu+DOIpNa8E6AyA/saCJl9WDOOJvXhKAlGSXdwRiRESLAAox8+hm6JWK1AdJ4bY8mwcubxsMcSW4fmidDxLVCG/MkiopYv35opiIDGSN4zJJGcMnNwpeRemtmgGpqT0NCvQNG1DHVDQeTjZQvbLOxK6MnP0xve7nHvLuWbgotnZ+3jBSwfH9UpLHskLPoYF29QHUf7/xYcWQFjEQBSisb1vdCtXvX0uI7GXm55yIsSvleoHj+GZgiWV1aODryiUvqHrwsWlrVfdJ399tV+mP7RXKbcgmg30LH+j6GjghDCWnyW7LKDTBVTQo/G6ON/IHXde+m7FPeJf4+cPOha0S2TrCHr4mpibQaQu84tNG5MyyUw==;^","title":"Special characters"},{"location":"blog/site-setup/protected-page/#footnotes","text":"glJHZkgyIfehbzfbNCRkTw==;qVzBKNrngQhK6Ik7/JSnOnKuu0uCq1xfXmDKhcZ1qOtEJ0mC7Z77IjULqApgxnWB0pyZTMhr5iloi8Beu6/vqDmyzec6qid0uUPtOxDijmm6Cl92CPYTVAEwyrCi6LuCa+0SaeIkwif8VyTcHQo2IGQXn2buJxhX7OQalJLR4X1R8pGLLxFHDsCTxTgZbqU897ctnEBzqhVtSF0Ssh1+zKEKSRvGM9e4QWPUxYZLJH6rXO1C8BDJyyL4JqhdaMwyB+04+nPU3mjz23Bu3J7/IB1NxoxDTK5FsWhsKodr6FsXaVrqW+YZPTLiHHXQ3UqszRRkDcPj2xqlpbPoy/+BzpJEU0y0sIh5X3AZupM3Kl6FebOZTvemLkmA7g9dD1FKlAlqmZWSM9Ur/9tRQg75T/3k0UmZKPkvonRcG3+C5mfV6WjXSq6S2d06cJIoI5wtNCKpZN5Bta/j92DQvhSwfLpg/XkqakjSRCq3nr8qVustqKQcmGCF97hPWo/L9jWtda/7cJcYEiFswqGnOkhD1p3zVs6c9HAOP8a4yx8+ctoDA5JFbGnqipLu4xDkfh3UzwxXQDphg7i/r0OI0xKD2cp8hO9izIzjRlgHnlCChBlX4AQUMg9xoH8UZ34XMfW9VyjeGAKAAkPwquhZBUe6hmR76yUJTdl/lXGvfjrJfDY=;^","title":"Footnotes"},{"location":"blog/stm32/","text":"STM32 Nucleo boards Content # The content of each post is based on my personal experience. All posts will be arranged in an easy-to-follow order, so that beginners can understand them well. In each post, I will try cover one main topic with a clear guidance including hardware overview, software implementation in register level and using HAL libraries. I think it is a good way to understand when you learn how it works and how a library is built. Reference # Thanks to below learning sources: ST\u2019s Education center The Education Center has a lot of materials and documents arranged into groups: basics, tools, product lines, application, tips & tricks. ST\u2019s Forum As the official forum from ST, this place has many questions and answers which can help to find issue and solution more quickly. OpenSTM32 Forum Another big and old community for STM32 microcontrollers using System Workbench IDE, still having many active users. LibOpenCM3 An open-source firmware library for various ARM Cortex-M microcontrollers. Mastering STM32 by Carmine Noviello An amazing book for STM32 learners. The book will guide you in a clear and practical way to this hardware platform and the official ST CubeHAL, showing its functionalities with a lot of examples and tutorials. Copyright While learning, I\u2019ve read a lot in books and on the internet. I can not re-draw or rephrase all pieces of information, so I will directly include some pictures, paragraphs which originally come from a book or an internet page. In those cases, I will write the source link and the credit belongs to the original authors.","title":"STM32 ARM Cortex-M Microcontrollers"},{"location":"blog/stm32/#content","text":"The content of each post is based on my personal experience. All posts will be arranged in an easy-to-follow order, so that beginners can understand them well. In each post, I will try cover one main topic with a clear guidance including hardware overview, software implementation in register level and using HAL libraries. I think it is a good way to understand when you learn how it works and how a library is built.","title":"Content"},{"location":"blog/stm32/#reference","text":"Thanks to below learning sources: ST\u2019s Education center The Education Center has a lot of materials and documents arranged into groups: basics, tools, product lines, application, tips & tricks. ST\u2019s Forum As the official forum from ST, this place has many questions and answers which can help to find issue and solution more quickly. OpenSTM32 Forum Another big and old community for STM32 microcontrollers using System Workbench IDE, still having many active users. LibOpenCM3 An open-source firmware library for various ARM Cortex-M microcontrollers. Mastering STM32 by Carmine Noviello An amazing book for STM32 learners. The book will guide you in a clear and practical way to this hardware platform and the official ST CubeHAL, showing its functionalities with a lot of examples and tutorials. Copyright While learning, I\u2019ve read a lot in books and on the internet. I can not re-draw or rephrase all pieces of information, so I will directly include some pictures, paragraphs which originally come from a book or an internet page. In those cases, I will write the source link and the credit belongs to the original authors.","title":"Reference"},{"location":"blog/stm32/assembly/","tags":["arm","stm32"],"text":"STM32-Tutorials F411RE_Assembly.zip Assembly Extension # GCC defines Inline Assembly as an extension for C, read more at Using Assembly Language with C . Using Extended Assembly typically produces smaller, safer, and more efficient code, and in most cases it is a better solution than Basic Assembly. However, there are two situations where only Basic Assembly can be used: Extended Assembly statements have to be inside a C function, so to write inline assembly language at file scope (\u201ctop-level\u201d), outside C functions, you must use Basic Assembly. You can use this technique to emit assembler directives, define assembly language macros that can be invoked elsewhere in the file, or write entire functions in assembly language. Basic Assembly statements outside of functions may not use any qualifiers. Functions declared with the naked attribute also require Basic Assembly. Code optimization Do not expect a sequence of assembly statements to remain perfectly consecutive after compilation. If certain instructions need to remain consecutive in the output, put them in a single multi-instruction assembly statement. Note that GCC\u2019s optimizers can move assembly statements relative to other code, including across jumps. Under certain circumstances, GCC may duplicate (or remove duplicates of) your assembly code when optimizing. This can lead to unexpected duplicate symbol errors during compilation if your assembly code defines symbols or labels. Assembly Instruction Set documentation It\u2019s recommended to read the document for a specific Cortex-M line. This guide is written based on STM32F411RE MCU, which has a Cortex-M4 microprocessors. The document is PM0214: STM32 Cortex\u00ae-M4 MCUs and MPUs programming manual . Basic Assembly # Refer to the \u201cInstruction Set\u201d section in Programming Manual document to get details of all instructions. Take an example: MOV R0 , R1 ; Copy value in R1 to R0 ADD R0 , #12 ; Add 12 to value of R0 and save the sum to R0 Inline assembly code is used to write pure assembly code in a C/C++ program: int main () { __asm volatile ( \"MOV R0, R1\" ); __asm volatile ( \"ADD R0, R1\" ); } Use in block of instructions, note the \\n\\t at the end of each instruction: __asm volatile ( \"MOV R0, R1 \\n\\t \" \"ADD R0, R1 \\n\\t \" ); Example # We will write a simple code to: Load values from 2 addresses 0x20001000 and 0x20001004 Store the sum of those numbers to a new address 0x20001008 Inline Assembly ode: int main ( void ) { __asm volatile ( \"LDR R1, =#0x20001000 \\n\\t \" /* Load address 0x20001000 to R1 */ \"LDR R2, =#0x20001004 \\n\\t \" /* Load address 0x20001004 to R2 */ \"LDR R3, =#0x20001008 \\n\\t \" /* Load address 0x20001008 to R3 */ \"LDR R0, [R1] \\n\\t \" /* Load data at the address pointing by R1, save to R0 */ \"LDR R1, [R2] \\n\\t \" /* Load data at the address pointing by R2, save to R1 */ \"ADD R0, R1 \\n\\t \" /* Add R0 to R1, save to R0 */ \"STR R0, [R3] \\n\\t \" /* Store R0 to the address pointing by R3 */ ); } Check the list file to see that the assembler will produce below instructions: ; __asm volatile( ; \"LDR R1, =#0x20001000\\n\\t\" 800010 c: 4903 ldr r1 , [ pc , #12 ] ; (800011c <main+0x14>) ; \"LDR R2, =#0x20001004\\n\\t\" 800010 e: 4 a04 ldr r2 , [ pc , #16 ] ; (8000120 <main+0x18>) ; \"LDR R3, =#0x20001008\\n\\t\" 8000110: 4 b04 ldr r3 , [ pc , #16 ] ; (8000124 <main+0x1c>) ; \"LDR R0, [R1]\\n\\t\" 8000112: 6808 ldr r0 , [ r1 , #0 ] ; \"LDR R1, [R2]\\n\\t\" 8000114: 6811 ldr r1 , [ r2 , #0 ] ; \"ADD R0, R1\\n\\t\" 8000116: 1840 adds r0 , r0 , r1 ; \"STR R0, [R3]\\n\\t\" 8000118: 6018 str r0 , [ r3 , #0 ] ; ); ; /* Loop forever */ ; for(;;); 800011 a: e7fe b.n 800011a < main + 0x12 > 800011 c: 20001000 .word 0x20001000 8000120: 20001004 .word 0x20001004 8000124: 20001008 .word 0x20001008 You can generate list file using objdump : arm-none-eabi-objdump -h -S app.elf > app.list You will notice that, the immediate 32-bit number 0x20001000 can not be encoded into 16-bit Thumb instruction, the assembler stores the constant in the text segment close to the referencing instruction and then references the value using (usually) PC-relative addressing, i.e. some offset from PC register. The number 0x20001000 is stored at address 0x0800011c . When CPU executes the instruction at 0x800010c , it will execute: 800010 c: 4903 ldr r1 , [ pc , #12 ] ; (800011c <main+0x14>) The value of PC is the current instruction, mentioned in document PM0214, section 2.1.3 Core registers , which is 0x800010c . The offset is 12 which is 0xC You will do a calculation 0x0800010c + 0xC = 0x08000118 and found out the target address is not 0x800010c !!! Why??? Let check the LDR instruction in PM0214, section 3.4.5 LDR, PC-relative, and section 3.3.6 PC-relative expressions: PC-relative expressions A PC-relative expression or label is a symbol that represents the address of an instruction or literal data. It is represented in the instruction as the PC value plus or minus a numeric offset. The assembler calculates the required value from the label and the address of the current instruction. If the offset is too big, the assembler produces an error. For the B , BL , CBNZ , and CBZ instructions, the value of the PC is the address of the current instruction plus four bytes. (2 instructions) For all other instructions that use labels, the value of the PC is the address of the current instruction plus four bytes, with bit[1] of the result cleared to 0 to make it word aligned. Your assembler might permit other syntaxes for PC-relative expressions, such as a label plus or minus a number, or an expression of the form [PC, #number] . Our case is LDR instruction: the PC value is now 0x0800010c + 0x4 = 0x08000110 , bit[1] is already 0 , so the final PC based address is 0x08000110 the target address to be read is 0x08000110 + 0xC = 0x0800011C which is correct address storing the number 0x20001000 Actual PC value is ahead of the executing instruction! Refer to ARM processor Pipeline . The Cortex-M4 processor is built on a high-performance processor core, with a 3-stage pipeline Harvard architecture. In the execute stage, the PC always points to the address of the instruction plus 4 bytes (in Thumb state). In other words, the pc always points to the address of the instruction being executed plus two instructions ahead. This is important when the PC is used for calculating a relative offset and is an architectural characteristic across all the pipelines. Note when the processor is in ARM state the PC is the instruction address plus 8. Actual PC value in 3-stage pipeline Compile and run the example code in the Debug mode, you can see how data is loaded into registers and memory address. Open Memory Browser to see and edit data in memory space. Example of running Debug for adding values at 2 addresses Extended Assembly # The GCC Inline Assembly full syntax is: __asm volatile ( AssemblerTemplate : OutputOperands [: InputOperands [: Clobbers ]]) AssemblerTemplate : This is a literal string that is the template for the assembler code. It is a combination of fixed text and tokens that refer to the input, output, and goto parameters. OutputOperands : A comma-separated list of the C variables modified by the instructions in the AssemblerTemplate. An empty list is permitted. InputOperands : A comma-separated list of C expressions read by the instructions in the AssemblerTemplate. An empty list is permitted. Clobbers : A comma-separated list of registers or other values changed by the AssemblerTemplate, beyond those listed as outputs. An empty list is permitted. This is useful for below cases: Move the content of C variable to an ARM register Move the content of an ARM register to a C variable Access assembly instructions that are not readily available to C programs Examples # No extra operand : __asm volatile ( \"MOV R0, R1\" ); // is the same as __asm volatile ( \"MOV R0, R1\" ::: ); With input operand : int val = 50 ; __asm volatile ( \"MOV R0, %0\" : : \"r\" ( val )); // R0 = 50 __asm volatile ( \"MOV R1, %0\" : : \"i\" ( 50 )); // R1 = 50 movs r3 , #50 ; 0x32 mov r0 , r3 ; R0 = R3 = 0x32 movs r1 , #50 ; 0x32 in which: No output operand Input operand is \"r\"(val) using constraint r meaning Register operand. Input operand is \"i\"(50) using constraint i meaning Immediate value. Refer to GCC ASM Contraints %0 is the first place-holder, which will be replaced by val input With output operand : int control_reg ; __asm volatile ( \"MRS %0, CONTROL\" : \"=r\" ( control_reg )); // control_reg = CONTROL mrs r3 , CONTROL ; R3 = CONTROL str r3 , [ r7 , #0 ] ; store R3 to control_reg at R7+0 With both input and output operand : int var1 = 10 ; int var2 ; __asm volatile ( \"MOV %0, %1\" : \"=r\" ( var2 ) : \"r\" ( var1 )); // var2 = var1 ldr r3 , [ r7 , #4 ] ; load R3 from var1 at R7+4 str r3 , [ r7 , #0 ] ; store R3 to var2 at R7+0 other example: int p1 , * p2 ; p2 = ( int * ) 0x20000000 ; __asm volatile ( \"LDR %0, [%1]\" : \"=r\" ( p1 ) : \"r\" ( p2 )); // pi = *p2 ldr r3 , [ r7 , #4 ] ; load R3 from p2 at R7 + 4, its value is an address ldr r3 , [ r3 , #0 ] ; dereference R3, to get value stored at that address str r3 , [ r7 , #0 ] ; store value in R3 to p1 at R7+0 Registers for Local Variables # You can define a local register variable and associate it with a specified register like this: register int * foo __asm ( \"r12\" ); // foo is R12 register * foo = 12 ; mov r3 , ip ; copy value of R12 (IP) register to R3 movs r2 , #12 ; save 12 to R2 str r2 , [ r3 , #0 ] ; store value in R2 to the address saved in R3 (=R12) The register keyword is required, and cannot be combined with static . The register name must be a valid register name for the target platform. Do not use type qualifiers such as const and volatile , as the outcome may be contrary to expectations. In particular, using the volatile qualifier does not fully prevent the compiler from optimizing accesses to the register. Change the access level # As mentioned in Access Levels , the application runs in the Privileged level by default. However, you can change the access mode to Unprivileged level. The CONTROL register has the bit[0] nPRIV to change the access level. To change the CONTROL register, you have to use MRS and MSR assembly instructions. When application enters the Unprivileged level, application is restricted to use the MSR and MRS instructions, therefore, it can not change the CONTROL register. The application must use the SVC instruction to make a supervisor call to transfer control to privileged software. The SVC instruction has a number embedded within it, often referred to as the SVC number . On most ARM processors, this is used to indicate the service that is being requested. On microcontroller profiles, the processor saves the argument registers to the stack on the initial exception entry. The startup file startup_stm32f411retx.s has defined an SVC_Handler() function, so we can override that function to get our code run in privileged level: Example # void SVC_Handler ( void ) // reduced handler which ignores SVC number param { // Move back to Privileged level __asm volatile ( \"MRS R0, CONTROL \\n\\t \" ; Copy CONTROL to R0 \"BIC R0, R0, #1 \\n\\t \" ; Clear bit 0 in R0 \"MSR CONTROL, r0\" ; Store R0 to CONTROL ); } int main ( void ) { // Move to Unprivileged level __asm volatile ( \"MRS R0, CONTROL \\n\\t \" \"ORR R0, R0, #1 \\n\\t \" ; Set bit 0 in R0 \"MSR CONTROL, r0\" ); // Call SVC 0 to rise an interrupt __asm volatile ( \"SVC #0\" ) }","title":"GCC Inline Assembly code"},{"location":"blog/stm32/assembly/#assembly-extension","text":"GCC defines Inline Assembly as an extension for C, read more at Using Assembly Language with C . Using Extended Assembly typically produces smaller, safer, and more efficient code, and in most cases it is a better solution than Basic Assembly. However, there are two situations where only Basic Assembly can be used: Extended Assembly statements have to be inside a C function, so to write inline assembly language at file scope (\u201ctop-level\u201d), outside C functions, you must use Basic Assembly. You can use this technique to emit assembler directives, define assembly language macros that can be invoked elsewhere in the file, or write entire functions in assembly language. Basic Assembly statements outside of functions may not use any qualifiers. Functions declared with the naked attribute also require Basic Assembly. Code optimization Do not expect a sequence of assembly statements to remain perfectly consecutive after compilation. If certain instructions need to remain consecutive in the output, put them in a single multi-instruction assembly statement. Note that GCC\u2019s optimizers can move assembly statements relative to other code, including across jumps. Under certain circumstances, GCC may duplicate (or remove duplicates of) your assembly code when optimizing. This can lead to unexpected duplicate symbol errors during compilation if your assembly code defines symbols or labels. Assembly Instruction Set documentation It\u2019s recommended to read the document for a specific Cortex-M line. This guide is written based on STM32F411RE MCU, which has a Cortex-M4 microprocessors. The document is PM0214: STM32 Cortex\u00ae-M4 MCUs and MPUs programming manual .","title":"Assembly Extension"},{"location":"blog/stm32/assembly/#basic-assembly","text":"Refer to the \u201cInstruction Set\u201d section in Programming Manual document to get details of all instructions. Take an example: MOV R0 , R1 ; Copy value in R1 to R0 ADD R0 , #12 ; Add 12 to value of R0 and save the sum to R0 Inline assembly code is used to write pure assembly code in a C/C++ program: int main () { __asm volatile ( \"MOV R0, R1\" ); __asm volatile ( \"ADD R0, R1\" ); } Use in block of instructions, note the \\n\\t at the end of each instruction: __asm volatile ( \"MOV R0, R1 \\n\\t \" \"ADD R0, R1 \\n\\t \" );","title":"Basic Assembly"},{"location":"blog/stm32/assembly/#example","text":"We will write a simple code to: Load values from 2 addresses 0x20001000 and 0x20001004 Store the sum of those numbers to a new address 0x20001008 Inline Assembly ode: int main ( void ) { __asm volatile ( \"LDR R1, =#0x20001000 \\n\\t \" /* Load address 0x20001000 to R1 */ \"LDR R2, =#0x20001004 \\n\\t \" /* Load address 0x20001004 to R2 */ \"LDR R3, =#0x20001008 \\n\\t \" /* Load address 0x20001008 to R3 */ \"LDR R0, [R1] \\n\\t \" /* Load data at the address pointing by R1, save to R0 */ \"LDR R1, [R2] \\n\\t \" /* Load data at the address pointing by R2, save to R1 */ \"ADD R0, R1 \\n\\t \" /* Add R0 to R1, save to R0 */ \"STR R0, [R3] \\n\\t \" /* Store R0 to the address pointing by R3 */ ); } Check the list file to see that the assembler will produce below instructions: ; __asm volatile( ; \"LDR R1, =#0x20001000\\n\\t\" 800010 c: 4903 ldr r1 , [ pc , #12 ] ; (800011c <main+0x14>) ; \"LDR R2, =#0x20001004\\n\\t\" 800010 e: 4 a04 ldr r2 , [ pc , #16 ] ; (8000120 <main+0x18>) ; \"LDR R3, =#0x20001008\\n\\t\" 8000110: 4 b04 ldr r3 , [ pc , #16 ] ; (8000124 <main+0x1c>) ; \"LDR R0, [R1]\\n\\t\" 8000112: 6808 ldr r0 , [ r1 , #0 ] ; \"LDR R1, [R2]\\n\\t\" 8000114: 6811 ldr r1 , [ r2 , #0 ] ; \"ADD R0, R1\\n\\t\" 8000116: 1840 adds r0 , r0 , r1 ; \"STR R0, [R3]\\n\\t\" 8000118: 6018 str r0 , [ r3 , #0 ] ; ); ; /* Loop forever */ ; for(;;); 800011 a: e7fe b.n 800011a < main + 0x12 > 800011 c: 20001000 .word 0x20001000 8000120: 20001004 .word 0x20001004 8000124: 20001008 .word 0x20001008 You can generate list file using objdump : arm-none-eabi-objdump -h -S app.elf > app.list You will notice that, the immediate 32-bit number 0x20001000 can not be encoded into 16-bit Thumb instruction, the assembler stores the constant in the text segment close to the referencing instruction and then references the value using (usually) PC-relative addressing, i.e. some offset from PC register. The number 0x20001000 is stored at address 0x0800011c . When CPU executes the instruction at 0x800010c , it will execute: 800010 c: 4903 ldr r1 , [ pc , #12 ] ; (800011c <main+0x14>) The value of PC is the current instruction, mentioned in document PM0214, section 2.1.3 Core registers , which is 0x800010c . The offset is 12 which is 0xC You will do a calculation 0x0800010c + 0xC = 0x08000118 and found out the target address is not 0x800010c !!! Why??? Let check the LDR instruction in PM0214, section 3.4.5 LDR, PC-relative, and section 3.3.6 PC-relative expressions: PC-relative expressions A PC-relative expression or label is a symbol that represents the address of an instruction or literal data. It is represented in the instruction as the PC value plus or minus a numeric offset. The assembler calculates the required value from the label and the address of the current instruction. If the offset is too big, the assembler produces an error. For the B , BL , CBNZ , and CBZ instructions, the value of the PC is the address of the current instruction plus four bytes. (2 instructions) For all other instructions that use labels, the value of the PC is the address of the current instruction plus four bytes, with bit[1] of the result cleared to 0 to make it word aligned. Your assembler might permit other syntaxes for PC-relative expressions, such as a label plus or minus a number, or an expression of the form [PC, #number] . Our case is LDR instruction: the PC value is now 0x0800010c + 0x4 = 0x08000110 , bit[1] is already 0 , so the final PC based address is 0x08000110 the target address to be read is 0x08000110 + 0xC = 0x0800011C which is correct address storing the number 0x20001000 Actual PC value is ahead of the executing instruction! Refer to ARM processor Pipeline . The Cortex-M4 processor is built on a high-performance processor core, with a 3-stage pipeline Harvard architecture. In the execute stage, the PC always points to the address of the instruction plus 4 bytes (in Thumb state). In other words, the pc always points to the address of the instruction being executed plus two instructions ahead. This is important when the PC is used for calculating a relative offset and is an architectural characteristic across all the pipelines. Note when the processor is in ARM state the PC is the instruction address plus 8. Actual PC value in 3-stage pipeline Compile and run the example code in the Debug mode, you can see how data is loaded into registers and memory address. Open Memory Browser to see and edit data in memory space. Example of running Debug for adding values at 2 addresses","title":"Example"},{"location":"blog/stm32/assembly/#extended-assembly","text":"The GCC Inline Assembly full syntax is: __asm volatile ( AssemblerTemplate : OutputOperands [: InputOperands [: Clobbers ]]) AssemblerTemplate : This is a literal string that is the template for the assembler code. It is a combination of fixed text and tokens that refer to the input, output, and goto parameters. OutputOperands : A comma-separated list of the C variables modified by the instructions in the AssemblerTemplate. An empty list is permitted. InputOperands : A comma-separated list of C expressions read by the instructions in the AssemblerTemplate. An empty list is permitted. Clobbers : A comma-separated list of registers or other values changed by the AssemblerTemplate, beyond those listed as outputs. An empty list is permitted. This is useful for below cases: Move the content of C variable to an ARM register Move the content of an ARM register to a C variable Access assembly instructions that are not readily available to C programs","title":"Extended Assembly"},{"location":"blog/stm32/assembly/#examples","text":"No extra operand : __asm volatile ( \"MOV R0, R1\" ); // is the same as __asm volatile ( \"MOV R0, R1\" ::: ); With input operand : int val = 50 ; __asm volatile ( \"MOV R0, %0\" : : \"r\" ( val )); // R0 = 50 __asm volatile ( \"MOV R1, %0\" : : \"i\" ( 50 )); // R1 = 50 movs r3 , #50 ; 0x32 mov r0 , r3 ; R0 = R3 = 0x32 movs r1 , #50 ; 0x32 in which: No output operand Input operand is \"r\"(val) using constraint r meaning Register operand. Input operand is \"i\"(50) using constraint i meaning Immediate value. Refer to GCC ASM Contraints %0 is the first place-holder, which will be replaced by val input With output operand : int control_reg ; __asm volatile ( \"MRS %0, CONTROL\" : \"=r\" ( control_reg )); // control_reg = CONTROL mrs r3 , CONTROL ; R3 = CONTROL str r3 , [ r7 , #0 ] ; store R3 to control_reg at R7+0 With both input and output operand : int var1 = 10 ; int var2 ; __asm volatile ( \"MOV %0, %1\" : \"=r\" ( var2 ) : \"r\" ( var1 )); // var2 = var1 ldr r3 , [ r7 , #4 ] ; load R3 from var1 at R7+4 str r3 , [ r7 , #0 ] ; store R3 to var2 at R7+0 other example: int p1 , * p2 ; p2 = ( int * ) 0x20000000 ; __asm volatile ( \"LDR %0, [%1]\" : \"=r\" ( p1 ) : \"r\" ( p2 )); // pi = *p2 ldr r3 , [ r7 , #4 ] ; load R3 from p2 at R7 + 4, its value is an address ldr r3 , [ r3 , #0 ] ; dereference R3, to get value stored at that address str r3 , [ r7 , #0 ] ; store value in R3 to p1 at R7+0","title":"Examples"},{"location":"blog/stm32/assembly/#registers-for-local-variables","text":"You can define a local register variable and associate it with a specified register like this: register int * foo __asm ( \"r12\" ); // foo is R12 register * foo = 12 ; mov r3 , ip ; copy value of R12 (IP) register to R3 movs r2 , #12 ; save 12 to R2 str r2 , [ r3 , #0 ] ; store value in R2 to the address saved in R3 (=R12) The register keyword is required, and cannot be combined with static . The register name must be a valid register name for the target platform. Do not use type qualifiers such as const and volatile , as the outcome may be contrary to expectations. In particular, using the volatile qualifier does not fully prevent the compiler from optimizing accesses to the register.","title":"Registers for Local Variables"},{"location":"blog/stm32/assembly/#change-the-access-level","text":"As mentioned in Access Levels , the application runs in the Privileged level by default. However, you can change the access mode to Unprivileged level. The CONTROL register has the bit[0] nPRIV to change the access level. To change the CONTROL register, you have to use MRS and MSR assembly instructions. When application enters the Unprivileged level, application is restricted to use the MSR and MRS instructions, therefore, it can not change the CONTROL register. The application must use the SVC instruction to make a supervisor call to transfer control to privileged software. The SVC instruction has a number embedded within it, often referred to as the SVC number . On most ARM processors, this is used to indicate the service that is being requested. On microcontroller profiles, the processor saves the argument registers to the stack on the initial exception entry. The startup file startup_stm32f411retx.s has defined an SVC_Handler() function, so we can override that function to get our code run in privileged level:","title":"Change the access level"},{"location":"blog/stm32/assembly/#example_1","text":"void SVC_Handler ( void ) // reduced handler which ignores SVC number param { // Move back to Privileged level __asm volatile ( \"MRS R0, CONTROL \\n\\t \" ; Copy CONTROL to R0 \"BIC R0, R0, #1 \\n\\t \" ; Clear bit 0 in R0 \"MSR CONTROL, r0\" ; Store R0 to CONTROL ); } int main ( void ) { // Move to Unprivileged level __asm volatile ( \"MRS R0, CONTROL \\n\\t \" \"ORR R0, R0, #1 \\n\\t \" ; Set bit 0 in R0 \"MSR CONTROL, r0\" ); // Call SVC 0 to rise an interrupt __asm volatile ( \"SVC #0\" ) }","title":"Example"},{"location":"blog/stm32/blink/","tags":["arm","stm32"],"text":".red { color: darkred; } .blue { color: blue; } STM32-Tutorials Programming Level # High-level or Low-Level programming? There are many topics on the internet discussing how to learn MCU though generated code or through self-written bare-metal/register-based code. Here is my opinion to learn MCU which I\u2019ve followed to get better understanding: First, start with bare-metal/ register-based programming This step requires you to read document carefully, to understand every bit of the hardware configurations and how they work. At this step, you should work on small application only, on simple peripherals first. Second, work with Low-level Library (CMSIS, LL) At this step, you should use an abstraction layer to reduce your own code. This also makes your code portable, reusable, and usually more coverage rate. Low-Level Lib also uses register-based programming. You can use LL as reference for the first step. Cortex Microcontroller Software Interface Standard (CMSIS) can be used at this stage. ST also provides LL Library for this purpose. ST LL can be integrated in Code generation. Third, work with High-level Library (HAL) In more complicated projects, Hardware-Abstraction Layer (HAL) is used for a quick development. HAL is preferred to use in production as it is built and test in long time, and of course, it reduces time-to-market. However, HAL is big, and make your application slower. It\u2019s also hard to debug due to overriding or function pointers. ST provides HAL Lib, and this lib is integrated with Code generation. Another open source HAL for STM32 is libopencm3 . Quick Comparison Just to blink an LED: Programming Level Flash RAM User Code Difficulty What need to do Register-based 800 Bytes 32 Bytes 13 lines Very Hard Read Reference Manual \u2192 Define Register & Bitfields \u2192 Implement Controller CMSIS Library 800 Bytes 32 Bytes 8 lines Hard Read Reference Manual \u2192 Call Defined Register & Bitfields \u2192 Implement Controller Low-Level Library 2540 Bytes 32 Bytes 4 lines Medium Read Low-Level API \u2192 Call APIs \u2192 Implement Controller Hardware Abstract Layer Library 5300 Bytes 44 Bytes 4 lines Easy Read HAL APIs \u2192 Call APIs \u2192 Implement Callbacks Requirements # This tutorial will show both 3 levels of programming. You can use any development board you have as the steps below are general guide. The only one requirement: Blink a LED at 10 Hz Solution: Repeat forever Turn on the LED 50 ms Delay 50 ms Turn off the LED 50 ms Delay 50 ms Hardware # You can use any STM32 board because this is just a very simple project. Refer to different types listed in Development boards and choose one suit for you. I choose to use a Nucleo-64 board with STM32F411RE. ST Nucleo-64 with STM32F411RE Arduino Headers on Nucleo 64 Morpho Headers on Nucleo 64 The Green LED is connected to the pin PA5 of the MCU. Schematic of the Green LED on STM3 Nucleo-64 board Learn through example Please note that the below examples just do a very simple thing, but ther are explained in details, so it may be quite difficult to follow if you are not familiar to programming MCU at low-level. Let see what we can learn. Register-based Code Example # F411RE_Blink_RB.zip Step 1: Select the Target device # You can find the target using either MCU Selector or Board Selector . Select the target device Step 2: Select Project type # In this example, we do not use any help from the CubeMX, so let choose Empty in project type option. Select Empty project type The project will be created with minimal number of files. You will see a startup file, some source files for System Calls, Memory Management; however, at this moment, you don\u2019t need to understand them, because most of their content are dummy or default settings. No additional file is copied Step 3: Configure registers # So, this is a difficult step. You don\u2019t know where to start, do you? Go back to the Documents guide and start reading and find what we want. Read the Reference manual first!!! Check the Memory Map to know the address of Peripherals: Table 1. STM32F411xC/E register boundary addresses Boundary address Bus Peripheral 0x40023800 - 0x40023BFF AHB1 RCC (Clock) 0x40020000 - 0x400203FF AHB1 GPIOA (I/O) So, define the base addresses: #define RCC_BASE 0x40023800UL #define GPIOA_BASE 0x40020000UL Configure Clock Read the register description to know the offset and config value: 6.3.1 Clock control register (RCC_CR) Address offset: 0x00 Reset value: 0x0000XX81 \u2192 HSION is enabled by default. HSI is 16 MHz. 6.3.3 Clock configuration register (RCC_CFGR) Address offset: 0x08 Reset value: 0x00000000 \u2192 HSI oscillator is used as the system clock, no divider activated. System is clocked at 16 MHz (equal to HSI\u2019s Frequency). The GPIOA is on AHB1 bus, therefore, check the clock on AHB Bus: 6.3.9 AHB peripheral clock enable register (RCC_AHB1ENR) Address offset: 0x30 Reset value: 0x00000000 \u2192 GPIO Clock is disabled by default. Need to enable GPIOAEN bit : #define RCC_AHB1ENR RCC_BASE + 0x30 * ( uint32_t * )( RCC_AHB1ENR ) |= ( 1 << 0 ); Configure GPIO Port and Pin Read the register description to know the offset and config value: 8 General-purpose I/Os (GPIO) Each general-purpose I/O port has four 32-bit configuration registers ( GPIOx_MODER , GPIOx_OTYPER , GPIOx_OSPEEDR and GPIOx_PUPDR ), two 32-bit data registers ( GPIOx_IDR and GPIOx_ODR ) and a 32-bit set/reset register ( GPIOx_BSRR ). 8.3.5 I/O data bitwise handling The bit set reset register (GPIOx_BSRR) is a 32-bit register which allows the application to set and reset each individual bit in the output data register ( GPIOx_ODR ). When written to 1 , bit BS(i) sets the corresponding ODR(i) bit. When written to 1 , bit BR(i) resets the ODR(i) corresponding bit. Writing any bit to 0 in GPIOx_BSRR does not have any effect on the corresponding bit in GPIOx_ODR . If there is an attempt to both set and reset a bit in GPIOx_BSRR , the set action takes priority Using the GPIOx_BSRR register to change the values of individual bits in GPIOx_ODR is a \u201cone-shot\u201d effect that does not lock the GPIOx_ODR bits. Do the same reading and understanding as we do with Clock registers, here are what we have to do: Set Pin 5 on Port A to Output mode on bit [11:10] of the GPIOA_MODER register To output HIGH value, set bit 5 of the GPIOA_BSRR register To output LOW value, set bit 21 of the GPIOA_BSRR register #define GPIOA_MODER GPIOA_BASE + 0x00 #define GPIOA_BSRR GPIOA_BASE + 0x18 * ( uint32_t * )( GPIOA_MODER ) &= ~ ( 1 << 11 ); * ( uint32_t * )( GPIOA_MODER ) |= ( 1 << 10 ); * ( uint32_t * )( GPIOA_BSRR ) |= ( 1 << ( 5 )); * ( uint32_t * )( GPIOA_BSRR ) |= ( 1 << ( 5 + 16 )); Delay We know that MCU is running at 16 MHz (HSI), we can make a loop for delay as below. If each loop needs 10 instruction cycles, to delay 50 ms, the number of iterations is: \\(\\frac{0.05 \\times 16000000}{10} = 80000\\) Note that this is a blocking delay, MCU is only doing the loop. #define DELAY_MAX 80000; for ( uint32_t i = DELAY_MAX ; i -- ;); Step 4: The complete code # You can assemble all above pieces of code in the main.c file. #include <stdint.h> /* Register Addresses*/ /* Clock */ #define RCC_BASE 0x40023800UL #define RCC_AHB1ENR RCC_BASE + 0x30 /* GPIO */ #define GPIOA_BASE 0x40020000UL #define GPIOA_MODER GPIOA_BASE + 0x00 #define GPIOA_BSRR GPIOA_BASE + 0x18 /* delay counter */ #define DELAY_MAX 50000 int main ( void ) { /* turn on clock on GPIOA */ * ( uint32_t * )( RCC_AHB1ENR ) |= ( 1 << 0 ); /* set PA5 to output mode */ * ( uint32_t * )( GPIOA_MODER ) &= ~ ( 1 << 11 ); * ( uint32_t * )( GPIOA_MODER ) |= ( 1 << 10 ); while ( 1 ) { /* set HIGH value on pin PA5 */ * ( uint32_t * )( GPIOA_BSRR ) |= ( 1 << 5 ); for ( uint32_t i = DELAY_MAX ; i -- ;); /* set LOW value on pin PA5 */ * ( uint32_t * )( GPIOA_BSRR ) |= ( 1 << ( 5 + 16 )); for ( uint32_t i = DELAY_MAX ; i -- ;); } } Step 5: Check the compilation settings # There are some setting groups we need to check, right-click on the Project and select Properties : Paths and Symbols Includes are the directories to find headers, note that there is no extra included folder Symbols are extra definitions enable/disable some blocks of code. Note the symbol STM32 , STM32F4 and the target MCU STM32F411RETx are added automatically. For debug session, the symbol DEBUG is added too. Source Location are the directories containing source code which is going to be compiled Compilation Settings MCU Settings : the Floating Point Unit = FPv4-SP-D16 ; use -mfloat-abi=hard the library for C is Reduced C --specs=nano.specs GCC Assembler : Target specs, including CPU, Debug Inline assembler: -x assembler-with-cpp Target specs: -mcpu=cortex-m4 -mthumb -mfpu=fpv4-sp-d16 -mfloat-abi=hard Library specs: --specs=nano.specs Debug level: -DDEBUG -g3 GCC Compiler : C language standard: -std=gnu11 Target specs: -mcpu=cortex-m4 -mthumb -mfpu=fpv4-sp-d16 -mfloat-abi=hard Library specs: --specs=nano.specs Debug level: -DDEBUG -g3 Preprocessor: -DSTM32 -DSTM32F4 -DSTM32F411RETx Include paths: -I <paths> Optimization: No optimization -O0 , but place functions and data in separated sections for clean up dead code -ffunction-sections -fdata-sections Warning: -Wall Stack Usage analysis: -fstack-usage GCC Linker : Target specs: -mcpu=cortex-m4 -mthumb -mfpu=fpv4-sp-d16 -mfloat-abi=hard Library specs: --specs=nano.specs System call: Minimal implementation --specs=nosys.specs Generate Map file: -Wl,-Map={file} Clean up unused sections: -Wl,--gc-sections Linker file: -T\"<file>\" Library: -lc -lm , these libraries will be search in a loop to check forward declaration and cross-dependency, so they are inside the marks -Wl,--start-group and -Wl,--end-group Step 6: Check build output # Just only Blink a LED, the resource usage is about 800 B of Flash, 32 B allocated on RAM Resource report when using only Register Step 7: Run on board # Select Run and choose the target board to run. At this moment, just use default configuration for a Debug session. Hook a Logic Analyzer to check the output waveform: 10 Hz Square Wave output on PA5 Low-Level CMSIS Code Example # F411RE_Blink_CMSIS.zip Step 1: Select the Target device # Same as Register-based Code Example: Use STM32F411RETx . Step 2: Select the target Firmware Package # Same as Register-based Code Example: Use C Language in an Empty Project . Step 3: Integrate CMSIS Pack # The Common Microcontroller Software Interface Standard (CMSIS) is a vendor-independent abstraction layer for microcontrollers that are based on Arm Cortex processors. CMSIS defines generic tool interfaces and enables consistent device support. This layer is adopted by leading semiconductor companies, embedded software and tools vendors across the Arm architecture. This means you can find a CMSIS-Pack for your target MCU if the MCU\u2019s vendor is registered with ARM. Integrate the CMSIS to your project : Download CMSIS Core, the latest version is CMSIS 5 . The filename, for example, is ARM.CMSIS.5.8.0.pack , you can unzip it as a normal zip file. Copy the header files in ARM.CMSIS.5.8.0.pack/CMSIS/Core/Include to your project Download CMSIS-Pack for the target MCU: Select STMicroelectronics \u2192 STM32F4 Series \u2192 STM32F411 \u2192 STM32F41RE \u2192 STM32F411RETx Download the STM32F4 Device Support Package (DSP) . Filename is Keil.STM32F4xx_DFP.2.16.0.pack , for example. You can unzip it as a zip file. Copy the header files in Keil.STM32F4xx_DFP.2.16.0.pack/Drivers/CMSIS/Device/ST/STM32F4xx/Include to your project Add header paths to project by opening adding CMSIS/Core/Include and CMSIS/Device/ST/STM32F4xx/Include to project Paths and Symbols : Include CMSIS and STMF4xx headers Add a symbol STM32F411xE to enable target inclusion in the general header file stm32f4xx.h Add STM32F411xE symbol Add system_stm32f4xx.c to project source code, as this file implements SystemInit() and SystemCoreClockUpdate() Only add system_stm32f4xx.c and ignore all other templates Include the header file of the target device, such as: #include <stm32f4xx.h> Register-based No additional file copied CMSIS Projects with CMSIS files added Step 4: Use defined registers # Follow the same rule of reading the Reference Manual document which can be found in the Keil.STM32F4xx_DFP.2.16.0/Documentation folder, you will have to do the same steps of configuring clocks, GPIO. However, this time, you can use the definitions and macros written in the device header files. All registers name listed in the Reference Manual document are available to use. Configure Clock Use the RCC peripheral, set the bit RCC_AHB1ENR_GPIOAEN in the AHB1ENR register to enable clock for GPIOA. RCC -> AHB1ENR |= RCC_AHB1ENR_GPIOAEN ; Configure GPIOA Use the GPIOA peripheral, set the field MODER8 to 01 in the register MODER to set pin PA5 as output. GPIOA -> MODER &= ~ GPIO_MODER_MODER8_1 ; GPIOA -> MODER |= GPIO_MODER_MODER8_0 ; To set HIGH value, set the bit GPIO_BSRR_BS_5 on the BSRR register. To clear the value, set the bit GPIO_BSRR_BR_5 on the BSRR register. GPIOA -> BSRR |= GPIO_BSRR_BS_5 ; GPIOA -> BSRR |= GPIO_BSRR_BR_5 ; That\u2019s it! Very simple and easy to understand the source code. Step 5: The completed code # You can assemble all above pieces of code in the main.c file. #include <stdint.h> #include <stm32f4xx.h> /* delay counter */ #define DELAY_MAX 50000 int main ( void ) { /* turn on clock on GPIOA */ RCC -> AHB1ENR |= RCC_AHB1ENR_GPIOAEN ; /* set PA5 to output mode */ GPIOA -> MODER &= ~ GPIO_MODER_MODE5_1 ; GPIOA -> MODER |= GPIO_MODER_MODE5_0 ; while ( 1 ) { /* set HIGH value on pin PA5 */ GPIOA -> BSRR |= GPIO_BSRR_BS_5 ; for ( uint32_t i = DELAY_MAX ; i -- ;); /* set LOW value on pin PA5 */ GPIOA -> BSRR |= GPIO_BSRR_BR_5 ; for ( uint32_t i = DELAY_MAX ; i -- ;); } } Register-based /* turn on clock on GPIOA */ * ( uint32_t * )( RCC_AHB1ENR ) |= ( 1 << 0 ); Register-based CMSIS /* turn on clock on GPIOA */ RCC -> AHB1ENR |= RCC_AHB1ENR_GPIOAEN ; /* set GPIOA to output mode */ * ( uint32_t * )( GPIOA_MODER ) &= ~ ( 1 << 11 ); * ( uint32_t * )( GPIOA_MODER ) |= ( 1 << 10 ); /* set GPIOA to output mode */ GPIOA -> MODER &= ~ GPIO_MODER_MODE5_1 ; GPIOA -> MODER |= GPIO_MODER_MODE5_0 ; while ( 1 ) { /* set HIGH value on pin PA5 */ * ( uint32_t * )( GPIOA_BSRR ) |= ( 1 << 5 ); for ( uint32_t i = DELAY_MAX ; i -- ;); /* set LOW value on pin PA5 */ * ( uint32_t * )( GPIOA_BSRR ) |= ( 1 << ( 5 + 16 )); for ( uint32_t i = DELAY_MAX ; i -- ;); } while ( 1 ) { /* set HIGH value on pin PA5 */ GPIOA -> BSRR |= GPIO_BSRR_BS_5 ; for ( uint32_t i = DELAY_MAX ; i -- ;); /* set LOW value on pin PA5 */ GPIOA -> BSRR |= GPIO_BSRR_BR_5 ; for ( uint32_t i = DELAY_MAX ; i -- ;); } Step 6: Check the compilation settings # There are some setting groups we need to check, right-click on the Project and select Properties : Paths and Symbols Includes are the directories to find headers, note that there is no extra included folder Symbols are extra definitions enable/disable some block of code. Note the symbol STM32 , STM32F4 and the target MCU STM32F411RETx are added automatically. To use the header file stm32f4xx.h , you must add the definition STM32F411xE in the Project Symbols. Source Location are the directories containing source code which is going to be compiled Compilation Settings The same as the Register-based Code Example. Step 7: Check build output # Just only Blink a LED, the resource usage is the same as the Register-base Code Example, as we still access directly to register using their names. Resource report when using CMSIS Step 8: Run on board # Select Run and choose the target board to run. At this moment, just use default configuration for a Debug session. Low-Level Generated Code Example # F411RE_Blink_Cube_LL.zip Step 1: Select the Target device # Same as Register-based Code Example: Use STM32F411RETx . Step 2: Select the target Firmware Package # You have to choose a name for your project. Then select STM32Cube as the targeted type, and then use a targeted Firmware Package. Select CubeMX and Firmware Package Step 3: Assign the LED pin # In the Pinout & Configuration tab: Click on the pin PA5 and select GPIO Output Change its name to LED using the right click. Under the GPIO Configuration panel, take note the default settings for PA5 : GPIO Output Level : Low , this pin is at Low level at startup GPIO Mode : Output Push-Pull , this pin is kept connected to the driven signal, read more in GPIO Output Modes GPIO Pull-up/Pull-down : No Pull , because in Output Push-Pull mode, internal resistor does not take effect. Only in Output Open-Drain mode, Pull-Up resister can help to drive the pin at High level Max Output Speed : Low , this is crew rate meaning how fast the signal can change its level User label : LED , a name to use instead of the pin name PA5 Assign PA5 as GPIO Output with name \u201cLED\u201d Step 4: Select Clock paths # In the Clock Configuration , check the default settings for the Clock: System Clock Mux : HSI , this is high-speed internal clock at 8 MHz All prescaler : 1 , there is no modification on clock line, therefore, the core and all peripherals use the SYSCLK at 16 MHz Select Clock source and settings Step 5: Select LL firmware packages # In the Project Manager , under the Advanced Settings , make sure Driver Selector is LL for RCC (Clock Configs) and GPIO (Pin Output). Select LL as the Driver Step 6: Generate LL Code # Press Alt + K or click on menu Project \u2192 Generate Code . The STM32F4xx_HAL_Driver with LL source code and the CMSIS driver are copied to the project folder. CMSIS No additional file is copied Low-Level LL files are copied to the project The Clock Configs : CMSIS /* turn on clock on GPIOA */ RCC -> AHB1ENR |= RCC_AHB1ENR_GPIOAEN ; Low-Level void SystemClock_Config ( void ) { LL_FLASH_SetLatency ( LL_FLASH_LATENCY_0 ); while ( LL_FLASH_GetLatency () != LL_FLASH_LATENCY_0 ){} LL_PWR_SetRegulVoltageScaling ( LL_PWR_REGU_VOLTAGE_SCALE1 ); LL_RCC_HSI_SetCalibTrimming ( 16 ); LL_RCC_HSI_Enable (); /* Wait till HSI is ready */ while ( LL_RCC_HSI_IsReady () != 1 ){} LL_RCC_SetAHBPrescaler ( LL_RCC_SYSCLK_DIV_1 ); LL_RCC_SetAPB1Prescaler ( LL_RCC_APB1_DIV_1 ); LL_RCC_SetAPB2Prescaler ( LL_RCC_APB2_DIV_1 ); LL_RCC_SetSysClkSource ( LL_RCC_SYS_CLKSOURCE_HSI ); /* Wait till System clock is ready */ while ( LL_RCC_GetSysClkSource () != LL_RCC_SYS_CLKSOURCE_STATUS_HSI ){} LL_Init1msTick ( 16000000 ); LL_SetSystemCoreClock ( 16000000 ); LL_RCC_SetTIMPrescaler ( LL_RCC_TIM_PRESCALER_TWICE ); } The GPIO Configs : CMSIS /* set GPIOA to output mode */ GPIOA -> MODER &= ~ GPIO_MODER_MODE5_1 ; GPIOA -> MODER |= GPIO_MODER_MODE5_0 ; Low-Level static void MX_GPIO_Init ( void ) { LL_GPIO_InitTypeDef GPIO_InitStruct = { 0 }; /* GPIO Ports Clock Enable */ LL_AHB1_GRP1_EnableClock ( LL_AHB1_GRP1_PERIPH_GPIOA ); /**/ LL_GPIO_ResetOutputPin ( LED_GPIO_Port , LED_Pin ); /**/ GPIO_InitStruct . Pin = LED_Pin ; GPIO_InitStruct . Mode = LL_GPIO_MODE_OUTPUT ; GPIO_InitStruct . Speed = LL_GPIO_SPEED_FREQ_LOW ; GPIO_InitStruct . OutputType = LL_GPIO_OUTPUT_PUSHPULL ; GPIO_InitStruct . Pull = LL_GPIO_PULL_NO ; LL_GPIO_Init ( LED_GPIO_Port , & GPIO_InitStruct ); } Step 7: Blink LED using LL APIs # The low-layer (LL) drivers are designed to offer a fast light-weight expert-oriented layer which is closer to the hardware. For the GPIO module, you should read the document UM1725 - Description of STM32F4 HAL and low-layer drivers , you will find an instruction: To set/reset the level of a pin configured in output mode use LL_GPIO_SetOutputPin() or LL_GPIO_ResetOutputPin() Now, blink the LED in the main while loop, note that, we also have a delay function LL_mDelay() . CMSIS while ( 1 ) { /* set HIGH value on pin PA5 */ GPIOA -> BSRR |= GPIO_BSRR_BS_5 ; for ( uint32_t i = DELAY_MAX ; i -- ;); /* set LOW value on pin PA5 */ GPIOA -> BSRR |= GPIO_BSRR_BR_5 ; for ( uint32_t i = DELAY_MAX ; i -- ;); } Low-Level while ( 1 ) { LL_GPIO_SetOutputPin ( LED_GPIO_Port , LED_Pin ); LL_mDelay ( DELAY_MAX ); LL_GPIO_ResetOutputPin ( LED_GPIO_Port , LED_Pin ); LL_mDelay ( DELAY_MAX ); } Step 8: Check the compilation settings # There are some setting groups we need to check, right-click on the Project and select Properties : Paths and Symbols Includes are the directories to find headers, note the STM32F4xx_HAL_Driver and CMSIS Symbols are extra definitions enable/disable some block of code. Note the symbol USE_FULL_LL_DRIVER and the target MCU STM32F411xE There are also many other definitions such as HSI_VALUE HSE_VALUE for clock settings; DATA_CACHE_ENABLE , INSTRUCTION_CACHE_ENABLE , PREFETCH_ENABLE for pipeline settings; Source Location are the directories containing source code which is going to be compiled Compilation Settings Same as the Register-based Code Example. Step 9: Check build output # Just only Blink a LED, the resource usage more than 3 times of Registered-based example, as it uses 2.48 KB of Flash. Resource report when using LL Step 10: Run on board # Select Run and choose the target board to run. At this moment, just use default configuration for a Debug session. High-level Generated Code # F411RE_Blink_Cube_HAL.zip Step 1: Select the Target device # Same as Low-Level Generated Code Example: Use STM32F411RETx . Step 2: Select the target Firmware Package # Same as Low-Level Generated Code Example: Use C Language in a STM32Cube Project . Step 3: Assign the LED pin # Same as Low-Level Generated Code Example: Set pin PA5 to GPIO_Output and name it LED . Step 4: Select Clock paths # Same as Low-Level Generated Code Example: Leave every in default state to select HSI at 16 MHz. Step 5: Select HAL firmware package # In the Project Manager , under the Advanced Settings , make sure Driver Selector is HAL for RCC (Clock Configs) and GPIO (Pin Output). Select HAL as the Driver Step 6: Generate HAL Code # Press Alt + K or click on menu Project \u2192 Generate Code . The STM32F4xx_HAL_Driver with HAL source code and the CMSIS driver are copied to the project folder. Low-Level LL files are copied to the project HAL HAL files are copied to the project The Clock Configs : Low-Level void SystemClock_Config ( void ) { LL_FLASH_SetLatency ( LL_FLASH_LATENCY_0 ); while ( LL_FLASH_GetLatency () != LL_FLASH_LATENCY_0 ){} LL_PWR_SetRegulVoltageScaling ( LL_PWR_REGU_VOLTAGE_SCALE1 ); LL_RCC_HSI_SetCalibTrimming ( 16 ); LL_RCC_HSI_Enable (); /* Wait till HSI is ready */ while ( LL_RCC_HSI_IsReady () != 1 ){} LL_RCC_SetAHBPrescaler ( LL_RCC_SYSCLK_DIV_1 ); LL_RCC_SetAPB1Prescaler ( LL_RCC_APB1_DIV_1 ); LL_RCC_SetAPB2Prescaler ( LL_RCC_APB2_DIV_1 ); LL_RCC_SetSysClkSource ( LL_RCC_SYS_CLKSOURCE_HSI ); /* Wait till System clock is ready */ while ( LL_RCC_GetSysClkSource () != LL_RCC_SYS_CLKSOURCE_STATUS_HSI ){} LL_Init1msTick ( 16000000 ); LL_SetSystemCoreClock ( 16000000 ); LL_RCC_SetTIMPrescaler ( LL_RCC_TIM_PRESCALER_TWICE ); } HAL void SystemClock_Config ( void ) { RCC_OscInitTypeDef RCC_OscInitStruct = { 0 }; RCC_ClkInitTypeDef RCC_ClkInitStruct = { 0 }; __HAL_RCC_PWR_CLK_ENABLE (); __HAL_PWR_VOLTAGESCALING_CONFIG ( PWR_REGULATOR_VOLTAGE_SCALE1 ); RCC_OscInitStruct . OscillatorType = RCC_OSCILLATORTYPE_HSI ; RCC_OscInitStruct . HSIState = RCC_HSI_ON ; RCC_OscInitStruct . HSICalibrationValue = RCC_HSICALIBRATION_DEFAULT ; RCC_OscInitStruct . PLL . PLLState = RCC_PLL_NONE ; if ( HAL_RCC_OscConfig ( & RCC_OscInitStruct ) != HAL_OK ){ Error_Handler (); } RCC_ClkInitStruct . ClockType = RCC_CLOCKTYPE_HCLK | RCC_CLOCKTYPE_SYSCLK | RCC_CLOCKTYPE_PCLK1 | RCC_CLOCKTYPE_PCLK2 ; RCC_ClkInitStruct . SYSCLKSource = RCC_SYSCLKSOURCE_HSI ; RCC_ClkInitStruct . AHBCLKDivider = RCC_SYSCLK_DIV1 ; RCC_ClkInitStruct . APB1CLKDivider = RCC_HCLK_DIV1 ; RCC_ClkInitStruct . APB2CLKDivider = RCC_HCLK_DIV1 ; if ( HAL_RCC_ClockConfig ( & RCC_ClkInitStruct , FLASH_LATENCY_0 ) != HAL_OK ){ Error_Handler (); } } The GPIO Configs : Low-Level static void MX_GPIO_Init ( void ) { LL_GPIO_InitTypeDef GPIO_InitStruct = { 0 }; /* GPIO Ports Clock Enable */ LL_AHB1_GRP1_EnableClock ( LL_AHB1_GRP1_PERIPH_GPIOA ); /**/ LL_GPIO_ResetOutputPin ( LED_GPIO_Port , LED_Pin ); /**/ GPIO_InitStruct . Pin = LED_Pin ; GPIO_InitStruct . Mode = LL_GPIO_MODE_OUTPUT ; GPIO_InitStruct . Speed = LL_GPIO_SPEED_FREQ_LOW ; GPIO_InitStruct . OutputType = LL_GPIO_OUTPUT_PUSHPULL ; GPIO_InitStruct . Pull = LL_GPIO_PULL_NO ; LL_GPIO_Init ( LED_GPIO_Port , & GPIO_InitStruct ); } HAL static void MX_GPIO_Init ( void ) { GPIO_InitTypeDef GPIO_InitStruct = { 0 }; /* GPIO Ports Clock Enable */ __HAL_RCC_GPIOA_CLK_ENABLE (); /*Configure GPIO pin Output Level */ HAL_GPIO_WritePin ( LED_GPIO_Port , LED_Pin , GPIO_PIN_RESET ); /*Configure GPIO pin : LED_Pin */ GPIO_InitStruct . Pin = LED_Pin ; GPIO_InitStruct . Mode = GPIO_MODE_OUTPUT_PP ; GPIO_InitStruct . Pull = GPIO_NOPULL ; GPIO_InitStruct . Speed = GPIO_SPEED_FREQ_LOW ; HAL_GPIO_Init ( LED_GPIO_Port , & GPIO_InitStruct ); } Step 7: Blink LED using HAL API # The Hardware Abstract Layer (HAL) is designed so that it abstracts from the specific peripheral memory mapping. But, it also provides a general and more user-friendly way to configure the peripheral, without forcing the programmers to now how to configure its registers in detail. For the GPIO module, you should read the document Description of STM32F4 HAL and low-layer drivers , you will find an instruction: To set/reset the level of a pin configured in output mode use HAL_GPIO_WritePin() or HAL_GPIO_TogglePin() Now, blink the LED in the main while loop, note that, we also have a delay function HAL_Delay() . Low-Level while ( 1 ) { LL_GPIO_SetOutputPin ( LED_GPIO_Port , LED_Pin ); LL_mDelay ( DELAY_MAX ); LL_GPIO_ResetOutputPin ( LED_GPIO_Port , LED_Pin ); LL_mDelay ( DELAY_MAX ); } HAL while ( 1 ) { HAL_GPIO_WritePin ( LED_GPIO_Port , LED_Pin , GPIO_PIN_SET ); HAL_Delay ( DELAY_MAX ); HAL_GPIO_WritePin ( LED_GPIO_Port , LED_Pin , GPIO_PIN_RESET ); HAL_Delay ( DELAY_MAX ); } Step 8: Check the compilation settings # There are some setting groups we need to check, right-click on the Project and select Properties : Paths and Symbols Includes are the directories to find headers, note the STM32F4xx_HAL_Driver and CMSIS Symbols are extra definitions enable/disable some block of code. Note the symbol USE_HAL_DRIVER and the target MCU STM32F411xE Source Location are the directories containing source code which is going to be compiled Compilation Settings Same as the Low-Level Generated Code Example. Step 9: Check build output # Just only Blink a LED, the resource usage is twice of the Low-level case, and 6 times of the Register-based case. Resource report when using HAL Step 10: Run on board # Select Run and choose the target board to run. At this moment, just use default configuration for a Debug session.","title":"Blink - say Hello to the World"},{"location":"blog/stm32/blink/#programming-level","text":"High-level or Low-Level programming? There are many topics on the internet discussing how to learn MCU though generated code or through self-written bare-metal/register-based code. Here is my opinion to learn MCU which I\u2019ve followed to get better understanding: First, start with bare-metal/ register-based programming This step requires you to read document carefully, to understand every bit of the hardware configurations and how they work. At this step, you should work on small application only, on simple peripherals first. Second, work with Low-level Library (CMSIS, LL) At this step, you should use an abstraction layer to reduce your own code. This also makes your code portable, reusable, and usually more coverage rate. Low-Level Lib also uses register-based programming. You can use LL as reference for the first step. Cortex Microcontroller Software Interface Standard (CMSIS) can be used at this stage. ST also provides LL Library for this purpose. ST LL can be integrated in Code generation. Third, work with High-level Library (HAL) In more complicated projects, Hardware-Abstraction Layer (HAL) is used for a quick development. HAL is preferred to use in production as it is built and test in long time, and of course, it reduces time-to-market. However, HAL is big, and make your application slower. It\u2019s also hard to debug due to overriding or function pointers. ST provides HAL Lib, and this lib is integrated with Code generation. Another open source HAL for STM32 is libopencm3 . Quick Comparison Just to blink an LED: Programming Level Flash RAM User Code Difficulty What need to do Register-based 800 Bytes 32 Bytes 13 lines Very Hard Read Reference Manual \u2192 Define Register & Bitfields \u2192 Implement Controller CMSIS Library 800 Bytes 32 Bytes 8 lines Hard Read Reference Manual \u2192 Call Defined Register & Bitfields \u2192 Implement Controller Low-Level Library 2540 Bytes 32 Bytes 4 lines Medium Read Low-Level API \u2192 Call APIs \u2192 Implement Controller Hardware Abstract Layer Library 5300 Bytes 44 Bytes 4 lines Easy Read HAL APIs \u2192 Call APIs \u2192 Implement Callbacks","title":"Programming Level"},{"location":"blog/stm32/blink/#requirements","text":"This tutorial will show both 3 levels of programming. You can use any development board you have as the steps below are general guide. The only one requirement: Blink a LED at 10 Hz Solution: Repeat forever Turn on the LED 50 ms Delay 50 ms Turn off the LED 50 ms Delay 50 ms","title":"Requirements"},{"location":"blog/stm32/blink/#hardware","text":"You can use any STM32 board because this is just a very simple project. Refer to different types listed in Development boards and choose one suit for you. I choose to use a Nucleo-64 board with STM32F411RE. ST Nucleo-64 with STM32F411RE Arduino Headers on Nucleo 64 Morpho Headers on Nucleo 64 The Green LED is connected to the pin PA5 of the MCU. Schematic of the Green LED on STM3 Nucleo-64 board Learn through example Please note that the below examples just do a very simple thing, but ther are explained in details, so it may be quite difficult to follow if you are not familiar to programming MCU at low-level. Let see what we can learn.","title":"Hardware"},{"location":"blog/stm32/blink/#register-based-code-example","text":"F411RE_Blink_RB.zip","title":"Register-based Code Example"},{"location":"blog/stm32/blink/#step-1-select-the-target-device","text":"You can find the target using either MCU Selector or Board Selector . Select the target device","title":"Step 1: Select the Target device"},{"location":"blog/stm32/blink/#step-2-select-project-type","text":"In this example, we do not use any help from the CubeMX, so let choose Empty in project type option. Select Empty project type The project will be created with minimal number of files. You will see a startup file, some source files for System Calls, Memory Management; however, at this moment, you don\u2019t need to understand them, because most of their content are dummy or default settings. No additional file is copied","title":"Step 2: Select Project type"},{"location":"blog/stm32/blink/#step-3-configure-registers","text":"So, this is a difficult step. You don\u2019t know where to start, do you? Go back to the Documents guide and start reading and find what we want. Read the Reference manual first!!! Check the Memory Map to know the address of Peripherals: Table 1. STM32F411xC/E register boundary addresses Boundary address Bus Peripheral 0x40023800 - 0x40023BFF AHB1 RCC (Clock) 0x40020000 - 0x400203FF AHB1 GPIOA (I/O) So, define the base addresses: #define RCC_BASE 0x40023800UL #define GPIOA_BASE 0x40020000UL Configure Clock Read the register description to know the offset and config value: 6.3.1 Clock control register (RCC_CR) Address offset: 0x00 Reset value: 0x0000XX81 \u2192 HSION is enabled by default. HSI is 16 MHz. 6.3.3 Clock configuration register (RCC_CFGR) Address offset: 0x08 Reset value: 0x00000000 \u2192 HSI oscillator is used as the system clock, no divider activated. System is clocked at 16 MHz (equal to HSI\u2019s Frequency). The GPIOA is on AHB1 bus, therefore, check the clock on AHB Bus: 6.3.9 AHB peripheral clock enable register (RCC_AHB1ENR) Address offset: 0x30 Reset value: 0x00000000 \u2192 GPIO Clock is disabled by default. Need to enable GPIOAEN bit : #define RCC_AHB1ENR RCC_BASE + 0x30 * ( uint32_t * )( RCC_AHB1ENR ) |= ( 1 << 0 ); Configure GPIO Port and Pin Read the register description to know the offset and config value: 8 General-purpose I/Os (GPIO) Each general-purpose I/O port has four 32-bit configuration registers ( GPIOx_MODER , GPIOx_OTYPER , GPIOx_OSPEEDR and GPIOx_PUPDR ), two 32-bit data registers ( GPIOx_IDR and GPIOx_ODR ) and a 32-bit set/reset register ( GPIOx_BSRR ). 8.3.5 I/O data bitwise handling The bit set reset register (GPIOx_BSRR) is a 32-bit register which allows the application to set and reset each individual bit in the output data register ( GPIOx_ODR ). When written to 1 , bit BS(i) sets the corresponding ODR(i) bit. When written to 1 , bit BR(i) resets the ODR(i) corresponding bit. Writing any bit to 0 in GPIOx_BSRR does not have any effect on the corresponding bit in GPIOx_ODR . If there is an attempt to both set and reset a bit in GPIOx_BSRR , the set action takes priority Using the GPIOx_BSRR register to change the values of individual bits in GPIOx_ODR is a \u201cone-shot\u201d effect that does not lock the GPIOx_ODR bits. Do the same reading and understanding as we do with Clock registers, here are what we have to do: Set Pin 5 on Port A to Output mode on bit [11:10] of the GPIOA_MODER register To output HIGH value, set bit 5 of the GPIOA_BSRR register To output LOW value, set bit 21 of the GPIOA_BSRR register #define GPIOA_MODER GPIOA_BASE + 0x00 #define GPIOA_BSRR GPIOA_BASE + 0x18 * ( uint32_t * )( GPIOA_MODER ) &= ~ ( 1 << 11 ); * ( uint32_t * )( GPIOA_MODER ) |= ( 1 << 10 ); * ( uint32_t * )( GPIOA_BSRR ) |= ( 1 << ( 5 )); * ( uint32_t * )( GPIOA_BSRR ) |= ( 1 << ( 5 + 16 )); Delay We know that MCU is running at 16 MHz (HSI), we can make a loop for delay as below. If each loop needs 10 instruction cycles, to delay 50 ms, the number of iterations is: \\(\\frac{0.05 \\times 16000000}{10} = 80000\\) Note that this is a blocking delay, MCU is only doing the loop. #define DELAY_MAX 80000; for ( uint32_t i = DELAY_MAX ; i -- ;);","title":"Step 3: Configure registers"},{"location":"blog/stm32/blink/#step-4-the-complete-code","text":"You can assemble all above pieces of code in the main.c file. #include <stdint.h> /* Register Addresses*/ /* Clock */ #define RCC_BASE 0x40023800UL #define RCC_AHB1ENR RCC_BASE + 0x30 /* GPIO */ #define GPIOA_BASE 0x40020000UL #define GPIOA_MODER GPIOA_BASE + 0x00 #define GPIOA_BSRR GPIOA_BASE + 0x18 /* delay counter */ #define DELAY_MAX 50000 int main ( void ) { /* turn on clock on GPIOA */ * ( uint32_t * )( RCC_AHB1ENR ) |= ( 1 << 0 ); /* set PA5 to output mode */ * ( uint32_t * )( GPIOA_MODER ) &= ~ ( 1 << 11 ); * ( uint32_t * )( GPIOA_MODER ) |= ( 1 << 10 ); while ( 1 ) { /* set HIGH value on pin PA5 */ * ( uint32_t * )( GPIOA_BSRR ) |= ( 1 << 5 ); for ( uint32_t i = DELAY_MAX ; i -- ;); /* set LOW value on pin PA5 */ * ( uint32_t * )( GPIOA_BSRR ) |= ( 1 << ( 5 + 16 )); for ( uint32_t i = DELAY_MAX ; i -- ;); } }","title":"Step 4: The complete code"},{"location":"blog/stm32/blink/#step-5-check-the-compilation-settings","text":"There are some setting groups we need to check, right-click on the Project and select Properties : Paths and Symbols Includes are the directories to find headers, note that there is no extra included folder Symbols are extra definitions enable/disable some blocks of code. Note the symbol STM32 , STM32F4 and the target MCU STM32F411RETx are added automatically. For debug session, the symbol DEBUG is added too. Source Location are the directories containing source code which is going to be compiled Compilation Settings MCU Settings : the Floating Point Unit = FPv4-SP-D16 ; use -mfloat-abi=hard the library for C is Reduced C --specs=nano.specs GCC Assembler : Target specs, including CPU, Debug Inline assembler: -x assembler-with-cpp Target specs: -mcpu=cortex-m4 -mthumb -mfpu=fpv4-sp-d16 -mfloat-abi=hard Library specs: --specs=nano.specs Debug level: -DDEBUG -g3 GCC Compiler : C language standard: -std=gnu11 Target specs: -mcpu=cortex-m4 -mthumb -mfpu=fpv4-sp-d16 -mfloat-abi=hard Library specs: --specs=nano.specs Debug level: -DDEBUG -g3 Preprocessor: -DSTM32 -DSTM32F4 -DSTM32F411RETx Include paths: -I <paths> Optimization: No optimization -O0 , but place functions and data in separated sections for clean up dead code -ffunction-sections -fdata-sections Warning: -Wall Stack Usage analysis: -fstack-usage GCC Linker : Target specs: -mcpu=cortex-m4 -mthumb -mfpu=fpv4-sp-d16 -mfloat-abi=hard Library specs: --specs=nano.specs System call: Minimal implementation --specs=nosys.specs Generate Map file: -Wl,-Map={file} Clean up unused sections: -Wl,--gc-sections Linker file: -T\"<file>\" Library: -lc -lm , these libraries will be search in a loop to check forward declaration and cross-dependency, so they are inside the marks -Wl,--start-group and -Wl,--end-group","title":"Step 5: Check the compilation settings"},{"location":"blog/stm32/blink/#step-6-check-build-output","text":"Just only Blink a LED, the resource usage is about 800 B of Flash, 32 B allocated on RAM Resource report when using only Register","title":"Step 6: Check build output"},{"location":"blog/stm32/blink/#step-7-run-on-board","text":"Select Run and choose the target board to run. At this moment, just use default configuration for a Debug session. Hook a Logic Analyzer to check the output waveform: 10 Hz Square Wave output on PA5","title":"Step 7: Run on board"},{"location":"blog/stm32/blink/#low-level-cmsis-code-example","text":"F411RE_Blink_CMSIS.zip","title":"Low-Level CMSIS Code Example"},{"location":"blog/stm32/blink/#step-1-select-the-target-device_1","text":"Same as Register-based Code Example: Use STM32F411RETx .","title":"Step 1: Select the Target device"},{"location":"blog/stm32/blink/#step-2-select-the-target-firmware-package","text":"Same as Register-based Code Example: Use C Language in an Empty Project .","title":"Step 2: Select the target Firmware Package"},{"location":"blog/stm32/blink/#step-3-integrate-cmsis-pack","text":"The Common Microcontroller Software Interface Standard (CMSIS) is a vendor-independent abstraction layer for microcontrollers that are based on Arm Cortex processors. CMSIS defines generic tool interfaces and enables consistent device support. This layer is adopted by leading semiconductor companies, embedded software and tools vendors across the Arm architecture. This means you can find a CMSIS-Pack for your target MCU if the MCU\u2019s vendor is registered with ARM. Integrate the CMSIS to your project : Download CMSIS Core, the latest version is CMSIS 5 . The filename, for example, is ARM.CMSIS.5.8.0.pack , you can unzip it as a normal zip file. Copy the header files in ARM.CMSIS.5.8.0.pack/CMSIS/Core/Include to your project Download CMSIS-Pack for the target MCU: Select STMicroelectronics \u2192 STM32F4 Series \u2192 STM32F411 \u2192 STM32F41RE \u2192 STM32F411RETx Download the STM32F4 Device Support Package (DSP) . Filename is Keil.STM32F4xx_DFP.2.16.0.pack , for example. You can unzip it as a zip file. Copy the header files in Keil.STM32F4xx_DFP.2.16.0.pack/Drivers/CMSIS/Device/ST/STM32F4xx/Include to your project Add header paths to project by opening adding CMSIS/Core/Include and CMSIS/Device/ST/STM32F4xx/Include to project Paths and Symbols : Include CMSIS and STMF4xx headers Add a symbol STM32F411xE to enable target inclusion in the general header file stm32f4xx.h Add STM32F411xE symbol Add system_stm32f4xx.c to project source code, as this file implements SystemInit() and SystemCoreClockUpdate() Only add system_stm32f4xx.c and ignore all other templates Include the header file of the target device, such as: #include <stm32f4xx.h> Register-based No additional file copied CMSIS Projects with CMSIS files added","title":"Step 3: Integrate CMSIS Pack"},{"location":"blog/stm32/blink/#step-4-use-defined-registers","text":"Follow the same rule of reading the Reference Manual document which can be found in the Keil.STM32F4xx_DFP.2.16.0/Documentation folder, you will have to do the same steps of configuring clocks, GPIO. However, this time, you can use the definitions and macros written in the device header files. All registers name listed in the Reference Manual document are available to use. Configure Clock Use the RCC peripheral, set the bit RCC_AHB1ENR_GPIOAEN in the AHB1ENR register to enable clock for GPIOA. RCC -> AHB1ENR |= RCC_AHB1ENR_GPIOAEN ; Configure GPIOA Use the GPIOA peripheral, set the field MODER8 to 01 in the register MODER to set pin PA5 as output. GPIOA -> MODER &= ~ GPIO_MODER_MODER8_1 ; GPIOA -> MODER |= GPIO_MODER_MODER8_0 ; To set HIGH value, set the bit GPIO_BSRR_BS_5 on the BSRR register. To clear the value, set the bit GPIO_BSRR_BR_5 on the BSRR register. GPIOA -> BSRR |= GPIO_BSRR_BS_5 ; GPIOA -> BSRR |= GPIO_BSRR_BR_5 ; That\u2019s it! Very simple and easy to understand the source code.","title":"Step 4: Use defined registers"},{"location":"blog/stm32/blink/#step-5-the-completed-code","text":"You can assemble all above pieces of code in the main.c file. #include <stdint.h> #include <stm32f4xx.h> /* delay counter */ #define DELAY_MAX 50000 int main ( void ) { /* turn on clock on GPIOA */ RCC -> AHB1ENR |= RCC_AHB1ENR_GPIOAEN ; /* set PA5 to output mode */ GPIOA -> MODER &= ~ GPIO_MODER_MODE5_1 ; GPIOA -> MODER |= GPIO_MODER_MODE5_0 ; while ( 1 ) { /* set HIGH value on pin PA5 */ GPIOA -> BSRR |= GPIO_BSRR_BS_5 ; for ( uint32_t i = DELAY_MAX ; i -- ;); /* set LOW value on pin PA5 */ GPIOA -> BSRR |= GPIO_BSRR_BR_5 ; for ( uint32_t i = DELAY_MAX ; i -- ;); } } Register-based /* turn on clock on GPIOA */ * ( uint32_t * )( RCC_AHB1ENR ) |= ( 1 << 0 ); Register-based CMSIS /* turn on clock on GPIOA */ RCC -> AHB1ENR |= RCC_AHB1ENR_GPIOAEN ; /* set GPIOA to output mode */ * ( uint32_t * )( GPIOA_MODER ) &= ~ ( 1 << 11 ); * ( uint32_t * )( GPIOA_MODER ) |= ( 1 << 10 ); /* set GPIOA to output mode */ GPIOA -> MODER &= ~ GPIO_MODER_MODE5_1 ; GPIOA -> MODER |= GPIO_MODER_MODE5_0 ; while ( 1 ) { /* set HIGH value on pin PA5 */ * ( uint32_t * )( GPIOA_BSRR ) |= ( 1 << 5 ); for ( uint32_t i = DELAY_MAX ; i -- ;); /* set LOW value on pin PA5 */ * ( uint32_t * )( GPIOA_BSRR ) |= ( 1 << ( 5 + 16 )); for ( uint32_t i = DELAY_MAX ; i -- ;); } while ( 1 ) { /* set HIGH value on pin PA5 */ GPIOA -> BSRR |= GPIO_BSRR_BS_5 ; for ( uint32_t i = DELAY_MAX ; i -- ;); /* set LOW value on pin PA5 */ GPIOA -> BSRR |= GPIO_BSRR_BR_5 ; for ( uint32_t i = DELAY_MAX ; i -- ;); }","title":"Step 5: The completed code"},{"location":"blog/stm32/blink/#step-6-check-the-compilation-settings","text":"There are some setting groups we need to check, right-click on the Project and select Properties : Paths and Symbols Includes are the directories to find headers, note that there is no extra included folder Symbols are extra definitions enable/disable some block of code. Note the symbol STM32 , STM32F4 and the target MCU STM32F411RETx are added automatically. To use the header file stm32f4xx.h , you must add the definition STM32F411xE in the Project Symbols. Source Location are the directories containing source code which is going to be compiled Compilation Settings The same as the Register-based Code Example.","title":"Step 6: Check the compilation settings"},{"location":"blog/stm32/blink/#step-7-check-build-output","text":"Just only Blink a LED, the resource usage is the same as the Register-base Code Example, as we still access directly to register using their names. Resource report when using CMSIS","title":"Step 7: Check build output"},{"location":"blog/stm32/blink/#step-8-run-on-board","text":"Select Run and choose the target board to run. At this moment, just use default configuration for a Debug session.","title":"Step 8: Run on board"},{"location":"blog/stm32/blink/#low-level-generated-code-example","text":"F411RE_Blink_Cube_LL.zip","title":"Low-Level Generated Code Example"},{"location":"blog/stm32/blink/#step-1-select-the-target-device_2","text":"Same as Register-based Code Example: Use STM32F411RETx .","title":"Step 1: Select the Target device"},{"location":"blog/stm32/blink/#step-2-select-the-target-firmware-package_1","text":"You have to choose a name for your project. Then select STM32Cube as the targeted type, and then use a targeted Firmware Package. Select CubeMX and Firmware Package","title":"Step 2: Select the target Firmware Package"},{"location":"blog/stm32/blink/#step-3-assign-the-led-pin","text":"In the Pinout & Configuration tab: Click on the pin PA5 and select GPIO Output Change its name to LED using the right click. Under the GPIO Configuration panel, take note the default settings for PA5 : GPIO Output Level : Low , this pin is at Low level at startup GPIO Mode : Output Push-Pull , this pin is kept connected to the driven signal, read more in GPIO Output Modes GPIO Pull-up/Pull-down : No Pull , because in Output Push-Pull mode, internal resistor does not take effect. Only in Output Open-Drain mode, Pull-Up resister can help to drive the pin at High level Max Output Speed : Low , this is crew rate meaning how fast the signal can change its level User label : LED , a name to use instead of the pin name PA5 Assign PA5 as GPIO Output with name \u201cLED\u201d","title":"Step 3: Assign the LED pin"},{"location":"blog/stm32/blink/#step-4-select-clock-paths","text":"In the Clock Configuration , check the default settings for the Clock: System Clock Mux : HSI , this is high-speed internal clock at 8 MHz All prescaler : 1 , there is no modification on clock line, therefore, the core and all peripherals use the SYSCLK at 16 MHz Select Clock source and settings","title":"Step 4: Select Clock paths"},{"location":"blog/stm32/blink/#step-5-select-ll-firmware-packages","text":"In the Project Manager , under the Advanced Settings , make sure Driver Selector is LL for RCC (Clock Configs) and GPIO (Pin Output). Select LL as the Driver","title":"Step 5: Select LL firmware packages"},{"location":"blog/stm32/blink/#step-6-generate-ll-code","text":"Press Alt + K or click on menu Project \u2192 Generate Code . The STM32F4xx_HAL_Driver with LL source code and the CMSIS driver are copied to the project folder. CMSIS No additional file is copied Low-Level LL files are copied to the project The Clock Configs : CMSIS /* turn on clock on GPIOA */ RCC -> AHB1ENR |= RCC_AHB1ENR_GPIOAEN ; Low-Level void SystemClock_Config ( void ) { LL_FLASH_SetLatency ( LL_FLASH_LATENCY_0 ); while ( LL_FLASH_GetLatency () != LL_FLASH_LATENCY_0 ){} LL_PWR_SetRegulVoltageScaling ( LL_PWR_REGU_VOLTAGE_SCALE1 ); LL_RCC_HSI_SetCalibTrimming ( 16 ); LL_RCC_HSI_Enable (); /* Wait till HSI is ready */ while ( LL_RCC_HSI_IsReady () != 1 ){} LL_RCC_SetAHBPrescaler ( LL_RCC_SYSCLK_DIV_1 ); LL_RCC_SetAPB1Prescaler ( LL_RCC_APB1_DIV_1 ); LL_RCC_SetAPB2Prescaler ( LL_RCC_APB2_DIV_1 ); LL_RCC_SetSysClkSource ( LL_RCC_SYS_CLKSOURCE_HSI ); /* Wait till System clock is ready */ while ( LL_RCC_GetSysClkSource () != LL_RCC_SYS_CLKSOURCE_STATUS_HSI ){} LL_Init1msTick ( 16000000 ); LL_SetSystemCoreClock ( 16000000 ); LL_RCC_SetTIMPrescaler ( LL_RCC_TIM_PRESCALER_TWICE ); } The GPIO Configs : CMSIS /* set GPIOA to output mode */ GPIOA -> MODER &= ~ GPIO_MODER_MODE5_1 ; GPIOA -> MODER |= GPIO_MODER_MODE5_0 ; Low-Level static void MX_GPIO_Init ( void ) { LL_GPIO_InitTypeDef GPIO_InitStruct = { 0 }; /* GPIO Ports Clock Enable */ LL_AHB1_GRP1_EnableClock ( LL_AHB1_GRP1_PERIPH_GPIOA ); /**/ LL_GPIO_ResetOutputPin ( LED_GPIO_Port , LED_Pin ); /**/ GPIO_InitStruct . Pin = LED_Pin ; GPIO_InitStruct . Mode = LL_GPIO_MODE_OUTPUT ; GPIO_InitStruct . Speed = LL_GPIO_SPEED_FREQ_LOW ; GPIO_InitStruct . OutputType = LL_GPIO_OUTPUT_PUSHPULL ; GPIO_InitStruct . Pull = LL_GPIO_PULL_NO ; LL_GPIO_Init ( LED_GPIO_Port , & GPIO_InitStruct ); }","title":"Step 6: Generate LL Code"},{"location":"blog/stm32/blink/#step-7-blink-led-using-ll-apis","text":"The low-layer (LL) drivers are designed to offer a fast light-weight expert-oriented layer which is closer to the hardware. For the GPIO module, you should read the document UM1725 - Description of STM32F4 HAL and low-layer drivers , you will find an instruction: To set/reset the level of a pin configured in output mode use LL_GPIO_SetOutputPin() or LL_GPIO_ResetOutputPin() Now, blink the LED in the main while loop, note that, we also have a delay function LL_mDelay() . CMSIS while ( 1 ) { /* set HIGH value on pin PA5 */ GPIOA -> BSRR |= GPIO_BSRR_BS_5 ; for ( uint32_t i = DELAY_MAX ; i -- ;); /* set LOW value on pin PA5 */ GPIOA -> BSRR |= GPIO_BSRR_BR_5 ; for ( uint32_t i = DELAY_MAX ; i -- ;); } Low-Level while ( 1 ) { LL_GPIO_SetOutputPin ( LED_GPIO_Port , LED_Pin ); LL_mDelay ( DELAY_MAX ); LL_GPIO_ResetOutputPin ( LED_GPIO_Port , LED_Pin ); LL_mDelay ( DELAY_MAX ); }","title":"Step 7: Blink LED using LL APIs"},{"location":"blog/stm32/blink/#step-8-check-the-compilation-settings","text":"There are some setting groups we need to check, right-click on the Project and select Properties : Paths and Symbols Includes are the directories to find headers, note the STM32F4xx_HAL_Driver and CMSIS Symbols are extra definitions enable/disable some block of code. Note the symbol USE_FULL_LL_DRIVER and the target MCU STM32F411xE There are also many other definitions such as HSI_VALUE HSE_VALUE for clock settings; DATA_CACHE_ENABLE , INSTRUCTION_CACHE_ENABLE , PREFETCH_ENABLE for pipeline settings; Source Location are the directories containing source code which is going to be compiled Compilation Settings Same as the Register-based Code Example.","title":"Step 8: Check the compilation settings"},{"location":"blog/stm32/blink/#step-9-check-build-output","text":"Just only Blink a LED, the resource usage more than 3 times of Registered-based example, as it uses 2.48 KB of Flash. Resource report when using LL","title":"Step 9: Check build output"},{"location":"blog/stm32/blink/#step-10-run-on-board","text":"Select Run and choose the target board to run. At this moment, just use default configuration for a Debug session.","title":"Step 10: Run on board"},{"location":"blog/stm32/blink/#high-level-generated-code","text":"F411RE_Blink_Cube_HAL.zip","title":"High-level Generated Code"},{"location":"blog/stm32/blink/#step-1-select-the-target-device_3","text":"Same as Low-Level Generated Code Example: Use STM32F411RETx .","title":"Step 1: Select the Target device"},{"location":"blog/stm32/blink/#step-2-select-the-target-firmware-package_2","text":"Same as Low-Level Generated Code Example: Use C Language in a STM32Cube Project .","title":"Step 2: Select the target Firmware Package"},{"location":"blog/stm32/blink/#step-3-assign-the-led-pin_1","text":"Same as Low-Level Generated Code Example: Set pin PA5 to GPIO_Output and name it LED .","title":"Step 3: Assign the LED pin"},{"location":"blog/stm32/blink/#step-4-select-clock-paths_1","text":"Same as Low-Level Generated Code Example: Leave every in default state to select HSI at 16 MHz.","title":"Step 4: Select Clock paths"},{"location":"blog/stm32/blink/#step-5-select-hal-firmware-package","text":"In the Project Manager , under the Advanced Settings , make sure Driver Selector is HAL for RCC (Clock Configs) and GPIO (Pin Output). Select HAL as the Driver","title":"Step 5: Select HAL firmware package"},{"location":"blog/stm32/blink/#step-6-generate-hal-code","text":"Press Alt + K or click on menu Project \u2192 Generate Code . The STM32F4xx_HAL_Driver with HAL source code and the CMSIS driver are copied to the project folder. Low-Level LL files are copied to the project HAL HAL files are copied to the project The Clock Configs : Low-Level void SystemClock_Config ( void ) { LL_FLASH_SetLatency ( LL_FLASH_LATENCY_0 ); while ( LL_FLASH_GetLatency () != LL_FLASH_LATENCY_0 ){} LL_PWR_SetRegulVoltageScaling ( LL_PWR_REGU_VOLTAGE_SCALE1 ); LL_RCC_HSI_SetCalibTrimming ( 16 ); LL_RCC_HSI_Enable (); /* Wait till HSI is ready */ while ( LL_RCC_HSI_IsReady () != 1 ){} LL_RCC_SetAHBPrescaler ( LL_RCC_SYSCLK_DIV_1 ); LL_RCC_SetAPB1Prescaler ( LL_RCC_APB1_DIV_1 ); LL_RCC_SetAPB2Prescaler ( LL_RCC_APB2_DIV_1 ); LL_RCC_SetSysClkSource ( LL_RCC_SYS_CLKSOURCE_HSI ); /* Wait till System clock is ready */ while ( LL_RCC_GetSysClkSource () != LL_RCC_SYS_CLKSOURCE_STATUS_HSI ){} LL_Init1msTick ( 16000000 ); LL_SetSystemCoreClock ( 16000000 ); LL_RCC_SetTIMPrescaler ( LL_RCC_TIM_PRESCALER_TWICE ); } HAL void SystemClock_Config ( void ) { RCC_OscInitTypeDef RCC_OscInitStruct = { 0 }; RCC_ClkInitTypeDef RCC_ClkInitStruct = { 0 }; __HAL_RCC_PWR_CLK_ENABLE (); __HAL_PWR_VOLTAGESCALING_CONFIG ( PWR_REGULATOR_VOLTAGE_SCALE1 ); RCC_OscInitStruct . OscillatorType = RCC_OSCILLATORTYPE_HSI ; RCC_OscInitStruct . HSIState = RCC_HSI_ON ; RCC_OscInitStruct . HSICalibrationValue = RCC_HSICALIBRATION_DEFAULT ; RCC_OscInitStruct . PLL . PLLState = RCC_PLL_NONE ; if ( HAL_RCC_OscConfig ( & RCC_OscInitStruct ) != HAL_OK ){ Error_Handler (); } RCC_ClkInitStruct . ClockType = RCC_CLOCKTYPE_HCLK | RCC_CLOCKTYPE_SYSCLK | RCC_CLOCKTYPE_PCLK1 | RCC_CLOCKTYPE_PCLK2 ; RCC_ClkInitStruct . SYSCLKSource = RCC_SYSCLKSOURCE_HSI ; RCC_ClkInitStruct . AHBCLKDivider = RCC_SYSCLK_DIV1 ; RCC_ClkInitStruct . APB1CLKDivider = RCC_HCLK_DIV1 ; RCC_ClkInitStruct . APB2CLKDivider = RCC_HCLK_DIV1 ; if ( HAL_RCC_ClockConfig ( & RCC_ClkInitStruct , FLASH_LATENCY_0 ) != HAL_OK ){ Error_Handler (); } } The GPIO Configs : Low-Level static void MX_GPIO_Init ( void ) { LL_GPIO_InitTypeDef GPIO_InitStruct = { 0 }; /* GPIO Ports Clock Enable */ LL_AHB1_GRP1_EnableClock ( LL_AHB1_GRP1_PERIPH_GPIOA ); /**/ LL_GPIO_ResetOutputPin ( LED_GPIO_Port , LED_Pin ); /**/ GPIO_InitStruct . Pin = LED_Pin ; GPIO_InitStruct . Mode = LL_GPIO_MODE_OUTPUT ; GPIO_InitStruct . Speed = LL_GPIO_SPEED_FREQ_LOW ; GPIO_InitStruct . OutputType = LL_GPIO_OUTPUT_PUSHPULL ; GPIO_InitStruct . Pull = LL_GPIO_PULL_NO ; LL_GPIO_Init ( LED_GPIO_Port , & GPIO_InitStruct ); } HAL static void MX_GPIO_Init ( void ) { GPIO_InitTypeDef GPIO_InitStruct = { 0 }; /* GPIO Ports Clock Enable */ __HAL_RCC_GPIOA_CLK_ENABLE (); /*Configure GPIO pin Output Level */ HAL_GPIO_WritePin ( LED_GPIO_Port , LED_Pin , GPIO_PIN_RESET ); /*Configure GPIO pin : LED_Pin */ GPIO_InitStruct . Pin = LED_Pin ; GPIO_InitStruct . Mode = GPIO_MODE_OUTPUT_PP ; GPIO_InitStruct . Pull = GPIO_NOPULL ; GPIO_InitStruct . Speed = GPIO_SPEED_FREQ_LOW ; HAL_GPIO_Init ( LED_GPIO_Port , & GPIO_InitStruct ); }","title":"Step 6: Generate HAL Code"},{"location":"blog/stm32/blink/#step-7-blink-led-using-hal-api","text":"The Hardware Abstract Layer (HAL) is designed so that it abstracts from the specific peripheral memory mapping. But, it also provides a general and more user-friendly way to configure the peripheral, without forcing the programmers to now how to configure its registers in detail. For the GPIO module, you should read the document Description of STM32F4 HAL and low-layer drivers , you will find an instruction: To set/reset the level of a pin configured in output mode use HAL_GPIO_WritePin() or HAL_GPIO_TogglePin() Now, blink the LED in the main while loop, note that, we also have a delay function HAL_Delay() . Low-Level while ( 1 ) { LL_GPIO_SetOutputPin ( LED_GPIO_Port , LED_Pin ); LL_mDelay ( DELAY_MAX ); LL_GPIO_ResetOutputPin ( LED_GPIO_Port , LED_Pin ); LL_mDelay ( DELAY_MAX ); } HAL while ( 1 ) { HAL_GPIO_WritePin ( LED_GPIO_Port , LED_Pin , GPIO_PIN_SET ); HAL_Delay ( DELAY_MAX ); HAL_GPIO_WritePin ( LED_GPIO_Port , LED_Pin , GPIO_PIN_RESET ); HAL_Delay ( DELAY_MAX ); }","title":"Step 7: Blink LED using HAL API"},{"location":"blog/stm32/blink/#step-8-check-the-compilation-settings_1","text":"There are some setting groups we need to check, right-click on the Project and select Properties : Paths and Symbols Includes are the directories to find headers, note the STM32F4xx_HAL_Driver and CMSIS Symbols are extra definitions enable/disable some block of code. Note the symbol USE_HAL_DRIVER and the target MCU STM32F411xE Source Location are the directories containing source code which is going to be compiled Compilation Settings Same as the Low-Level Generated Code Example.","title":"Step 8: Check the compilation settings"},{"location":"blog/stm32/blink/#step-9-check-build-output_1","text":"Just only Blink a LED, the resource usage is twice of the Low-level case, and 6 times of the Register-based case. Resource report when using HAL","title":"Step 9: Check build output"},{"location":"blog/stm32/blink/#step-10-run-on-board_1","text":"Select Run and choose the target board to run. At this moment, just use default configuration for a Debug session.","title":"Step 10: Run on board"},{"location":"blog/stm32/compilation/","tags":["arm","stm32"],"text":"STM32-Tutorials Overview # Following are the steps that a program goes through until it is translated into an executable form: Preprocessing Compilation Assembly Linking In general, compilation for Microprocessors is the same as the Compilation process for executables on an Operating System. However, there are some main different points: Cross-compilation: MCUs can not run a compiler itself, therefore, there must be a cross-compiler for MCUs Library: MCUs use a light-weight version of libraries to reduce the program footprint and might increase performance Hardware-depend: Many libraries only implement minimal code which mainly does nothing, such as the standard I/O. On a specific hardware, the actual implementation must be done. Linking: The executables have to define sections stored in different memory spaces in runtime (Flash/ RAM). On MCU, CPU can directly execute instructions on Flash device. For the general steps in compilation, refer to the Compilation for C/C++ on OS . ARM Toolchain # If you use STM32Cube IDE, the IDE already has a toolchain for STM32 MCUs. If you start without the IDE, you can start with Arm GNU Toolchain . A good alternative toolchain package is The xPack Build Framework : The xPack project aims to provide a set of cross-platform tools to manage, configure and build complex, modular, multi-target (multi-architecture, multi-board, multi-toolchain) projects, with an emphasis on C/C++ and bare-metal embedded projects. @xpack-dev-tools/arm-none-eabi-gcc - the xPack Arm Embedded GCC toolchain @xpack-dev-tools/openocd - the xPack OpenOCD Download and install them. Note to add the binary folders to the system environment. Add Arm GNU toolchain to System Environment EABI The default ARM tool chain application binary interface is the Embedded Application Binary Interface (EABI). It defines the conventions for files, data types, register mapping, stack frame and parameter passing rules. The EABI is commonly used on ARM and PowerPC CPUs. Example program # nostdlib.zip This is the Blink - Hello World program: Blink a LED at 10 Hz . You can use any STM32 board because this is just a very simple project. I choose to use a Nucleo-64 board with STM32F411RE. The main code to blink LED on PA5 by using registers: main.c #include <stdint.h> #include \"delay.h\" /* Clock */ #define RCC_AHB1ENR *((volatile uint32_t*) (0x40023830)) /* GPIO A */ #define GPIOA_MODER *((volatile uint32_t*) (0x40020000)) #define GPIOA_BSRR *((volatile uint32_t*) (0x40020018)) /* Global initialized variable */ uint32_t isLoop = 1 ; int main () { /* turn on clock on GPIOA */ RCC_AHB1ENR |= ( 1 << 0 ); /* set PA5 to output mode */ GPIOA_MODER &= ~ ( 1 << 11 ); GPIOA_MODER |= ( 1 << 10 ); while ( isLoop ) { /* set HIGH on PA5 */ GPIOA_BSRR |= ( 1 << 5 ); delay (); /* set LOW on PA5 */ GPIOA_BSRR |= ( 1 << ( 5 + 16 )); delay (); } return 0 ; } The delay function using a busy loop: delay.c #include <stdint.h> /* Global Read-only variable */ const uint32_t DELAY_MAX = 0x0000BEEF ; /* Global Uninitialized varible */ uint32_t delay_counter ; void delay () { for ( delay_counter = DELAY_MAX ; delay_counter -- ;); } Firstly, just try to compile the program without any specific option: arm-none-eabi-gcc \\ main.c delay.c \\ -o main.elf /arm-none-eabi/bin/ld.exe: /arm-none-eabi/lib\\libc.a(lib_a-exit.o): in function `exit': (.text.exit+0x2c) : undefined reference to `_exit' Of course, you can not compile the source code! By default, GCC tries to link the application with libc in newlib package, and there is no implementation for the function _exit . At this time, we will tell the compiler to not use the standard libraries. arm-none-eabi-gcc \\ -nostdlib \\ main.c delay.c \\ -o main.elf Just ignore the warning about entry symbol. We\u2019ll fix it later. Compiler options # In the Step 5: Check the compilation settings , the STM32Cube IDE automatically sets some compilation flags. How do you select those flags? GNU Online Documentation is available for different versions. Target Architecture We can either use -march= or -mcpu= options, but -mcpu=cortex-m4 is easy to understand and remember. Note that Cortex-M only supports Thumb instruction set, so you have to use -mthumb option. Let use soft Floating Point at this moment. -mcpu=cortex-m4 -mthumb -mfloat-abi=soft Target GNU standard -std=gnu11 Target Libraries GNU ARM libraries use newlib to provide standard implementation of C libraries. To reduce the code size and make it independent to hardware, there is a lightweight version newlib-nano used in MCUs. However, newlib-nano does not provide an implementation of low-level system calls which are used by C standard libraries, such as print() or scan() . To make the application compilable, a new library named nosys should be added. This library just provide a simple implementation of low-level system calls which mostly return a by-pass value. To use newlib-nano and nosys libs: --specs=nano.specs --specs=nosys.specs At this moment, we ignore the standard libraries, and check on it later. Compilation warnings To see potential errors, enable Warning for all: -Wall Debug level Turn on debug if needed: -g Hence, the build command will be: arm-none-eabi-gcc \\ -mcpu = cortex-m4 -mthumb -mfloat-abi = soft \\ -std = gnu11 \\ -nostdlib \\ -Wall \\ main.c delay.c \\ -o main.elf Just ignore the warning about the entry symbol Reset_Handler. We\u2019ll fix it later. Program sections # Run arm-none-eabi-objdump to see the sections and code of the output arm-none-eabi-gcc \\ -mcpu = cortex-m4 -mthumb -mfloat-abi = soft \\ -std = gnu11 \\ -nostdlib \\ -Wall \\ -c main.c \\ -o main.o arm-none-eabi-objdump -h main.o > main.o.obj_h main.o.obj_h main.o: file format elf32-littlearm Sections: Idx Name Size VMA LMA File off Algn 0 .text 00000068 00000000 00000000 00000034 2**2 CONTENTS, ALLOC, LOAD, RELOC, READONLY, CODE 1 .data 00000004 00000000 00000000 0000009c 2**2 CONTENTS, ALLOC, LOAD, DATA 2 .bss 00000000 00000000 00000000 000000a0 2**0 ALLOC 3 .comment 0000003a 00000000 00000000 000000a0 2**0 CONTENTS, READONLY 4 .ARM.attributes 0000002e 00000000 00000000 000000da 2**0 CONTENTS, READONLY arm-none-eabi-gcc \\ -mcpu = cortex-m4 -mthumb \\ -nostdlib \\ -std = gnu11 \\ -Wall \\ -c delay.c \\ -o delay.o arm-none-eabi-objdump -h delay.o > delay.o.obj_h main.o.obj_h delay.o: file format elf32-littlearm Sections: Idx Name Size VMA LMA File off Algn 0 .text 0000002c 00000000 00000000 00000034 2**2 CONTENTS, ALLOC, LOAD, RELOC, READONLY, CODE 1 .data 00000000 00000000 00000000 00000060 2**0 CONTENTS, ALLOC, LOAD, DATA 2 .bss 00000004 00000000 00000000 00000060 2**2 ALLOC 3 .rodata 00000004 00000000 00000000 00000060 2**2 CONTENTS, ALLOC, LOAD, READONLY, DATA 4 .comment 0000003a 00000000 00000000 00000064 2**0 CONTENTS, READONLY 5 .ARM.attributes 0000002e 00000000 00000000 0000009e 2**0 CONTENTS, READONLY .text : Code and Data The code containing instructions which are located in Flash. The text code also store constant values which are encoded as raw bytes at the end of a function. .data : Initialized variable Variables can change their values, so variables are copied from Flash to RAM by the startup code. In this example, in main.o , there are 4 bytes for uint32_t isLoop = 1 ; . .bss : Uninitialized variables Variables can change their values, so variables are copied from Flash to RAM. However, because these values are uninitialized, so we do not need to store their values, we just need to reserve memory for them. The entire .bss segment is described by a single number, probably 4 bytes or 8 bytes, that gives its size in the running process, whereas the .data section is as big as the sum of sizes of the initialized variables. In this example, in delay.o , there are 4 bytes for uint32_t delay_counter ; . .rodata : Read-only data Constant variables are stored in Flash. In this example, in delay.o , there are 4 bytes for const uint32_t DELAY_MAX = 0x0000BEEF ; . Section locations Data (variable) Load time Run time Section Note Global initialized Flash RAM .data Copy from Flash to RAM by startup code Global static initialized Local static initialized Global uninitialized - RAM .bss Reserved space by startup code Global static uninitialized Local static uninitialized All global constants Flash - .rodata All other local - RAM (Stack) - App code uses stack to store Linker and Locator # Linker is used to merge all sections from different binaries into the final executable file. main.c --> main.o { .text, .data, .bss, .rodata } delay.c --> delay.o { .text, .data, .bss, .rodata} main.elf = main.o + delay.o = { .text = .text(main) + .text(delay)} .data = .data(main) + .data(delay)} .bss = .bss(main) + .bss(delay)} .rodata = .rodata(main) + .rodata(delay)} } A linker script is used to decribe the Memory Layout: ENTRY command Set the Entry point address in the header, which tell GDB to know the first instruction to be executed ENTRY(address) MEMORY command Describe different memory parts in the system. Linker uses this information to calculate address MEMORY { name (attribute): ORIGIN = <address>, LENGTH = <size> } SECTIONS command Create memory layout by creating section name, section order. In each section, choose which data is used, how data is stored, and loaded. Location Counter is a special symbol denoted by a dot . . Linker will automatically update it with current location information. A variable can be used to save location to mark boundaries. Location counter can be set also. SECTIONS { <symbol> = LOADADDR(<symbol>); .<section>: { <symbol> = .; *(.sub_section); . = ALIGN(n); } ><Run Location> [AT> Storage Location] } Here is the linker script: linker.ld ENTRY ( Reset_Handler ) MEMORY { RAM ( xrw ) : ORIGIN = 0x20000000 , LENGTH = 128 K FLASH ( rx ) : ORIGIN = 0x08000000 , LENGTH = 512 K } _estack = ORIGIN ( RAM ) + LENGTH ( RAM ) ; SECTIONS { .isr_vector : { *( .isr_vector ) } > FLASH .text : { *( .text ) _etext = . ; } > FLASH .rodata : { *( .rodata ) } > FLASH _lddata = LOADADDR (. data ) ; .data : { _sdata = . ; *( .data ) _edata = . ; } > RAM AT > FLASH .bss : { _sbss = . ; *( .bss ) _ebss = . ; } > RAM } In the Linker Script, we define some symbols: _etext : End address of .text section _lddata : Load address (from Flash) of .data section _sdata : Start address of .data section _edata : End address of .data section _sbss : Start address of .bss section _ebss : End address of .bss section To build with Linker script, use -T <linkerfile> . The option -Wl,-Map=<output> to show the full memory mapping. arm-none-eabi-gcc \\ -mcpu = cortex-m4 -mthumb -mfloat-abi = soft \\ -std = gnu11 \\ -nostdlib \\ -Wall \\ -T linker.ld -Wl,-Map = main.tmp.map \\ main.o delay.o \\ -o main.tmp Open the file main.tmp.map to see the addresses assigned to symbols in the linker scripts. main.tmp.map Memory Configuration Name Origin Length Attributes RAM 0x0000000020000000 0x0000000000020000 xrw FLASH 0x0000000008000000 0x0000000000080000 xr * default * 0x0000000000000000 0xffffffffffffffff Linker script and memory map LOAD main . o LOAD delay . o 0x0000000020020000 _estack = ( ORIGIN ( RAM ) + LENGTH ( RAM )) . isr_vector * (. isr_vector ) . text 0x0000000008000000 0x94 * (. text ) . text 0x0000000008000000 0x68 main . o 0x0000000008000000 main . text 0x0000000008000068 0x2c delay . o 0x0000000008000068 delay 0x0000000008000094 _etext = . . glue_7 0x0000000008000094 0x0 . glue_7 0x0000000008000094 0x0 linker stubs . glue_7t 0x0000000008000094 0x0 . glue_7t 0x0000000008000094 0x0 linker stubs . vfp11_veneer 0x0000000008000094 0x0 . vfp11_veneer 0x0000000008000094 0x0 linker stubs . v4_bx 0x0000000008000094 0x0 . v4_bx 0x0000000008000094 0x0 linker stubs . iplt 0x0000000008000094 0x0 . iplt 0x0000000008000094 0x0 main . o . rodata 0x0000000008000094 0x4 * (. rodata ) . rodata 0x0000000008000094 0x4 delay . o 0x0000000008000094 DELAY_MAX 0x0000000008000098 _lddata = LOADADDR (. data ) . rel . dyn 0x0000000008000098 0x0 . rel . iplt 0x0000000008000098 0x0 main . o . data 0x0000000020000000 0x4 load address 0x0000000008000098 0x0000000020000000 _sdata = . * (. data ) . data 0x0000000020000000 0x4 main . o 0x0000000020000000 isLoop . data 0x0000000020000004 0x0 delay . o 0x0000000020000004 _edata = . . igot . plt 0x0000000020000004 0x0 load address 0x000000000800009c . igot . plt 0x0000000020000004 0x0 main . o . bss 0x0000000020000004 0x4 load address 0x000000000800009c 0x0000000020000004 _sbss = . * (. bss ) . bss 0x0000000020000004 0x0 main . o . bss 0x0000000020000004 0x4 delay . o 0x0000000020000004 delay_counter 0x0000000020000008 _ebss = . OUTPUT ( main . tmp elf32 - littlearm ) LOAD linker stubs . comment 0x0000000000000000 0x39 . comment 0x0000000000000000 0x39 main . o 0x3a ( size before relaxing ) . comment 0x0000000000000039 0x3a delay . o . ARM . attributes 0x0000000000000000 0x2e . ARM . attributes 0x0000000000000000 0x2e main . o . ARM . attributes 0x000000000000002e 0x2e delay . o The section .data started at 0x20000000 (loaded at 0x08000098 ) is only 4 bytes for uint32_t isLoop = 1 ; . The section .bss started at 0x20000004 (loaded at 0x0800009c ) is 4 bytes for uint32_t delay_counter . The section .rodata started at 0x08000094 is 4 bytes for const uint32_t DELAY_MAX = 0x0000BEEF ; To find the symbols and their addresses : arm-none-eabi-nm main.tmp main.tmp.sym 20000008 B _ebss 20000004 D _edata 20020000 T _estack 08000094 T _etext 08000098 A _lddata 20000004 B _sbss 20000000 D _sdata 08000068 T delay 20000004 B delay_counter 08000094 R DELAY_MAX 20000000 D isLoop 08000000 T main U Reset_Handler Linker Symbols # BinUtils Source Code Reference document Accessing a linker script defined variable from source code is not intuitive. In particular a linker script symbol is not equivalent to a variable declaration in a high level language, it is instead a symbol that does not have a value. Before going further, it is important to note that compilers often transform names in the source code into different names when they are stored in the symbol table. For example, Fortran compilers commonly prepend or append an underscore, and C++ performs extensive name mangling . Therefore there might be a discrepancy between the name of a variable as it is used in source code and the name of the same variable as it is defined in a linker script. For example in C a linker script variable might be referred to as: extern int foo ; But in the linker script it might be defined as: _foo = 1000 ; In the remaining examples however it is assumed that no name transformation has taken place. When a symbol is declared in a high level language such as C, two things happen: The first is that the compiler reserves enough space in the program\u2019s memory to hold the value of the symbol. The second is that the compiler creates an entry in the program\u2019s symbol table which holds the symbol\u2019s address. ie the symbol table contains the address of the block of memory holding the symbol\u2019s value. So for example the following C declaration, at file scope: int foo = 1000 ; creates an entry called foo in the symbol table. This entry holds the address of an int sized block of memory where the number 1000 is initially stored. When a program references a symbol the compiler generates code that first accesses the symbol table to find the address of the symbol\u2019s memory block and then code to read the value from that memory block. So: foo = 1 ; looks up the symbol foo in the symbol table, gets the address associated with this symbol and then writes the value 1 into that address. Whereas: int * a = & foo ; looks up the symbol foo in the symbol table, gets its address and then copies this address into the block of memory associated with the variable a . Linker scripts symbol declarations, by contrast, create an entry in the symbol table but do not assign any memory to them. Thus they are an address without a value. So for example the linker script definition: foo = 1000 ; creates an entry in the symbol table called foo which holds the address of memory location 1000 , but nothing special is stored at address 1000 . This means that you cannot access the value of a linker script defined symbol - it has no value - all you can do is access the address of a linker script defined symbol. Hence, when you are using a linker script defined symbol in source code you should always take the address of the symbol , and never attempt to use its value. For example suppose you want to copy the contents of a section of memory called .ROM into a section called .FLASH and the linker script contains these declarations: start_of_ROM = . ROM ; end_of_ROM = . ROM + sizeof (. ROM ); start_of_FLASH = . FLASH ; Then the C source code to perform the copy would be as below. Note the use of the & operators. These are correct. extern char start_of_ROM , end_of_ROM , start_of_FLASH ; memcpy ( & start_of_FLASH , & start_of_ROM , & end_of_ROM - & start_of_ROM ); Alternatively the symbols can be treated as the names of vectors or arrays and then the code will again work as expected: extern char start_of_ROM [], end_of_ROM [], start_of_FLASH []; memcpy ( start_of_FLASH , start_of_ROM , end_of_ROM - start_of_ROM ); Note how using this method does not require the use of & operators. Vector Table # On reset, the processor loads the MSP with the value from address 0x00000000 , then starts code execution from the memory at 0x00000004 which must be the Reset_Handler function. There are 15 system exceptions, included Reset Handler, and there are up-to 240 interruptions. The Table 37. Vector table for STM32F411xC/E in the document RM0383: Reference manual STM32F411xC/E advanced Arm\u00ae-based 32-bit MCUs shows the supported Exceptions and Interrupts: Vector table for F411xC/E vector.c #include <stdint.h> #define RAM_START 0x20000000 #define RAM_SIZE 128 * 1024 #define RAM_END ((RAM_START) + (RAM_SIZE)) void Default_Handler ( void ) { while ( 1 ) {} } void Reset_Handler ( void ) __attribute__ (( weak , alias ( \"Default_Handler\" ))); void NMI_Handler ( void ) __attribute__ (( weak , alias ( \"Default_Handler\" ))); void HardFault_Handler ( void ) __attribute__ (( weak , alias ( \"Default_Handler\" ))); void MemManage_Handler ( void ) __attribute__ (( weak , alias ( \"Default_Handler\" ))); void BusFault_Handler ( void ) __attribute__ (( weak , alias ( \"Default_Handler\" ))); void UsageFault_Handler ( void ) __attribute__ (( weak , alias ( \"Default_Handler\" ))); void SVC_Handler ( void ) __attribute__ (( weak , alias ( \"Default_Handler\" ))); void DebugMon_Handler ( void ) __attribute__ (( weak , alias ( \"Default_Handler\" ))); void PendSV_Handler ( void ) __attribute__ (( weak , alias ( \"Default_Handler\" ))); void SysTick_Handler ( void ) __attribute__ (( weak , alias ( \"Default_Handler\" ))); void WWDG_IRQHandler ( void ) __attribute__ (( weak , alias ( \"Default_Handler\" ))); void PVD_IRQHandler ( void ) __attribute__ (( weak , alias ( \"Default_Handler\" ))); void TAMP_STAMP_IRQHandler ( void ) __attribute__ (( weak , alias ( \"Default_Handler\" ))); void RTC_WKUP_IRQHandler ( void ) __attribute__ (( weak , alias ( \"Default_Handler\" ))); void FLASH_IRQHandler ( void ) __attribute__ (( weak , alias ( \"Default_Handler\" ))); void RCC_IRQHandler ( void ) __attribute__ (( weak , alias ( \"Default_Handler\" ))); void EXTI0_IRQHandler ( void ) __attribute__ (( weak , alias ( \"Default_Handler\" ))); void EXTI1_IRQHandler ( void ) __attribute__ (( weak , alias ( \"Default_Handler\" ))); void EXTI2_IRQHandler ( void ) __attribute__ (( weak , alias ( \"Default_Handler\" ))); void EXTI3_IRQHandler ( void ) __attribute__ (( weak , alias ( \"Default_Handler\" ))); void EXTI4_IRQHandler ( void ) __attribute__ (( weak , alias ( \"Default_Handler\" ))); void DMA1_Stream0_IRQHandler ( void ) __attribute__ (( weak , alias ( \"Default_Handler\" ))); void DMA1_Stream1_IRQHandler ( void ) __attribute__ (( weak , alias ( \"Default_Handler\" ))); void DMA1_Stream2_IRQHandler ( void ) __attribute__ (( weak , alias ( \"Default_Handler\" ))); void DMA1_Stream3_IRQHandler ( void ) __attribute__ (( weak , alias ( \"Default_Handler\" ))); void DMA1_Stream4_IRQHandler ( void ) __attribute__ (( weak , alias ( \"Default_Handler\" ))); void DMA1_Stream5_IRQHandler ( void ) __attribute__ (( weak , alias ( \"Default_Handler\" ))); void DMA1_Stream6_IRQHandler ( void ) __attribute__ (( weak , alias ( \"Default_Handler\" ))); void ADC_IRQHandler ( void ) __attribute__ (( weak , alias ( \"Default_Handler\" ))); void EXTI9_5_IRQHandler ( void ) __attribute__ (( weak , alias ( \"Default_Handler\" ))); void TIM1_BRK_TIM9_IRQHandler ( void ) __attribute__ (( weak , alias ( \"Default_Handler\" ))); void TIM1_UP_TIM10_IRQHandler ( void ) __attribute__ (( weak , alias ( \"Default_Handler\" ))); void TIM1_TRG_COM_TIM11_IRQHandler ( void ) __attribute__ (( weak , alias ( \"Default_Handler\" ))); void TIM1_CC_IRQHandler ( void ) __attribute__ (( weak , alias ( \"Default_Handler\" ))); void TIM2_IRQHandler ( void ) __attribute__ (( weak , alias ( \"Default_Handler\" ))); void TIM3_IRQHandler ( void ) __attribute__ (( weak , alias ( \"Default_Handler\" ))); void TIM4_IRQHandler ( void ) __attribute__ (( weak , alias ( \"Default_Handler\" ))); void I2C1_EV_IRQHandler ( void ) __attribute__ (( weak , alias ( \"Default_Handler\" ))); void I2C1_ER_IRQHandler ( void ) __attribute__ (( weak , alias ( \"Default_Handler\" ))); void I2C2_EV_IRQHandler ( void ) __attribute__ (( weak , alias ( \"Default_Handler\" ))); void I2C2_ER_IRQHandler ( void ) __attribute__ (( weak , alias ( \"Default_Handler\" ))); void SPI1_IRQHandler ( void ) __attribute__ (( weak , alias ( \"Default_Handler\" ))); void SPI2_IRQHandler ( void ) __attribute__ (( weak , alias ( \"Default_Handler\" ))); void USART1_IRQHandler ( void ) __attribute__ (( weak , alias ( \"Default_Handler\" ))); void USART2_IRQHandler ( void ) __attribute__ (( weak , alias ( \"Default_Handler\" ))); void EXTI15_10_IRQHandler ( void ) __attribute__ (( weak , alias ( \"Default_Handler\" ))); void RTC_Alarm_IRQHandler ( void ) __attribute__ (( weak , alias ( \"Default_Handler\" ))); void OTG_FS_WKUP_IRQHandler ( void ) __attribute__ (( weak , alias ( \"Default_Handler\" ))); void DMA1_Stream7_IRQHandler ( void ) __attribute__ (( weak , alias ( \"Default_Handler\" ))); void SDIO_IRQHandler ( void ) __attribute__ (( weak , alias ( \"Default_Handler\" ))); void TIM5_IRQHandler ( void ) __attribute__ (( weak , alias ( \"Default_Handler\" ))); void SPI3_IRQHandler ( void ) __attribute__ (( weak , alias ( \"Default_Handler\" ))); void DMA2_Stream0_IRQHandler ( void ) __attribute__ (( weak , alias ( \"Default_Handler\" ))); void DMA2_Stream1_IRQHandler ( void ) __attribute__ (( weak , alias ( \"Default_Handler\" ))); void DMA2_Stream2_IRQHandler ( void ) __attribute__ (( weak , alias ( \"Default_Handler\" ))); void DMA2_Stream3_IRQHandler ( void ) __attribute__ (( weak , alias ( \"Default_Handler\" ))); void DMA2_Stream4_IRQHandler ( void ) __attribute__ (( weak , alias ( \"Default_Handler\" ))); void OTG_FS_IRQHandler ( void ) __attribute__ (( weak , alias ( \"Default_Handler\" ))); void DMA2_Stream5_IRQHandler ( void ) __attribute__ (( weak , alias ( \"Default_Handler\" ))); void DMA2_Stream6_IRQHandler ( void ) __attribute__ (( weak , alias ( \"Default_Handler\" ))); void DMA2_Stream7_IRQHandler ( void ) __attribute__ (( weak , alias ( \"Default_Handler\" ))); void USART6_IRQHandler ( void ) __attribute__ (( weak , alias ( \"Default_Handler\" ))); void I2C3_EV_IRQHandler ( void ) __attribute__ (( weak , alias ( \"Default_Handler\" ))); void I2C3_ER_IRQHandler ( void ) __attribute__ (( weak , alias ( \"Default_Handler\" ))); void FPU_IRQHandler ( void ) __attribute__ (( weak , alias ( \"Default_Handler\" ))); void SPI4_IRQHandler ( void ) __attribute__ (( weak , alias ( \"Default_Handler\" ))); void SPI5_IRQHandler ( void ) __attribute__ (( weak , alias ( \"Default_Handler\" ))); __attribute__ (( section ( \".isr_vector\" ))) uint32_t vector_table [] = { ( uint32_t ) RAM_END , ( uint32_t ) Reset_Handler , ( uint32_t ) NMI_Handler , ( uint32_t ) HardFault_Handler , ( uint32_t ) MemManage_Handler , ( uint32_t ) BusFault_Handler , ( uint32_t ) UsageFault_Handler , ( uint32_t ) 0 , ( uint32_t ) 0 , ( uint32_t ) 0 , ( uint32_t ) 0 , ( uint32_t ) SVC_Handler , ( uint32_t ) DebugMon_Handler , ( uint32_t ) 0 , ( uint32_t ) PendSV_Handler , ( uint32_t ) SysTick_Handler , ( uint32_t ) WWDG_IRQHandler , ( uint32_t ) PVD_IRQHandler , ( uint32_t ) TAMP_STAMP_IRQHandler , ( uint32_t ) RTC_WKUP_IRQHandler , ( uint32_t ) FLASH_IRQHandler , ( uint32_t ) RCC_IRQHandler , ( uint32_t ) EXTI0_IRQHandler , ( uint32_t ) EXTI1_IRQHandler , ( uint32_t ) EXTI2_IRQHandler , ( uint32_t ) EXTI3_IRQHandler , ( uint32_t ) EXTI4_IRQHandler , ( uint32_t ) DMA1_Stream0_IRQHandler , ( uint32_t ) DMA1_Stream1_IRQHandler , ( uint32_t ) DMA1_Stream2_IRQHandler , ( uint32_t ) DMA1_Stream3_IRQHandler , ( uint32_t ) DMA1_Stream4_IRQHandler , ( uint32_t ) DMA1_Stream5_IRQHandler , ( uint32_t ) DMA1_Stream6_IRQHandler , ( uint32_t ) ADC_IRQHandler , ( uint32_t ) 0 , ( uint32_t ) 0 , ( uint32_t ) 0 , ( uint32_t ) 0 , ( uint32_t ) EXTI9_5_IRQHandler , ( uint32_t ) TIM1_BRK_TIM9_IRQHandler , ( uint32_t ) TIM1_UP_TIM10_IRQHandler , ( uint32_t ) TIM1_TRG_COM_TIM11_IRQHandler , ( uint32_t ) TIM1_CC_IRQHandler , ( uint32_t ) TIM2_IRQHandler , ( uint32_t ) TIM3_IRQHandler , ( uint32_t ) TIM4_IRQHandler , ( uint32_t ) I2C1_EV_IRQHandler , ( uint32_t ) I2C1_ER_IRQHandler , ( uint32_t ) I2C2_EV_IRQHandler , ( uint32_t ) I2C2_ER_IRQHandler , ( uint32_t ) SPI1_IRQHandler , ( uint32_t ) SPI2_IRQHandler , ( uint32_t ) USART1_IRQHandler , ( uint32_t ) USART2_IRQHandler , ( uint32_t ) 0 , ( uint32_t ) EXTI15_10_IRQHandler , ( uint32_t ) RTC_Alarm_IRQHandler , ( uint32_t ) OTG_FS_WKUP_IRQHandler , ( uint32_t ) 0 , ( uint32_t ) 0 , ( uint32_t ) 0 , ( uint32_t ) 0 , ( uint32_t ) DMA1_Stream7_IRQHandler , ( uint32_t ) 0 , ( uint32_t ) SDIO_IRQHandler , ( uint32_t ) TIM5_IRQHandler , ( uint32_t ) SPI3_IRQHandler , ( uint32_t ) 0 , ( uint32_t ) 0 , ( uint32_t ) 0 , ( uint32_t ) 0 , ( uint32_t ) DMA2_Stream0_IRQHandler , ( uint32_t ) DMA2_Stream1_IRQHandler , ( uint32_t ) DMA2_Stream2_IRQHandler , ( uint32_t ) DMA2_Stream3_IRQHandler , ( uint32_t ) DMA2_Stream4_IRQHandler , ( uint32_t ) 0 , ( uint32_t ) 0 , ( uint32_t ) 0 , ( uint32_t ) 0 , ( uint32_t ) 0 , ( uint32_t ) 0 , ( uint32_t ) OTG_FS_IRQHandler , ( uint32_t ) DMA2_Stream5_IRQHandler , ( uint32_t ) DMA2_Stream6_IRQHandler , ( uint32_t ) DMA2_Stream7_IRQHandler , ( uint32_t ) USART6_IRQHandler , ( uint32_t ) I2C3_EV_IRQHandler , ( uint32_t ) I2C3_ER_IRQHandler , ( uint32_t ) 0 , ( uint32_t ) 0 , ( uint32_t ) 0 , ( uint32_t ) 0 , ( uint32_t ) 0 , ( uint32_t ) 0 , ( uint32_t ) 0 , ( uint32_t ) FPU_IRQHandler , ( uint32_t ) 0 , ( uint32_t ) 0 , ( uint32_t ) SPI4_IRQHandler , ( uint32_t ) SPI5_IRQHandler , }; weak and alias attribute The exception handlers are user defined, so the Default Handler is only used in case the corresponding Handler is not implemented. section attribute Code can be assigned to a memory location by labeling the code with sections. Now, include the vector table in linker, you will see the section .isr_vector is now filled: arm-none-eabi-gcc \\ -mcpu = cortex-m4 -mthumb -mfloat-abi = soft \\ -std = gnu11 \\ -nostdlib \\ -Wall \\ -T linker.ld -Wl,-Map = vector.tmp.map \\ main.o delay.o vector.o \\ -o vector.tmp vector.tmp.map . isr_vector 0x0000000008000000 0x198 * (. isr_vector ) . isr_vector 0x0000000008000000 0x198 vector . o 0x0000000008000000 vector_table Startup code # The startup code is responsible for setting up the right environment for the main code to run. Provide the vector table Implement Reset Handler Copy .data section from Flash to RAM Reserve memory for .bss section Call to main function startup.c #include <stdint.h> extern uint32_t _sdata ; extern uint32_t _edata ; extern uint32_t _lddata ; extern uint32_t _sbss ; extern uint32_t _ebss ; extern void main ( void ); void Reset_Handler ( void ) { // copy .data section from flash to ram uint32_t size = ( uint32_t ) & _edata - ( uint32_t ) & _sdata ; uint8_t * pRAM = ( uint8_t * ) & _sdata ; uint8_t * pFlash = ( uint8_t * ) & _lddata ; for ( int i = 0 ; i < size ; i ++ ) { pRAM [ i ] = pFlash [ i ]; } // initialize .bss section size = ( uint32_t ) & _ebss - ( uint32_t ) & _sbss ; pRAM = ( uint8_t * ) & _sbss ; for ( int i = 0 ; i < size ; i ++ ) { pRAM [ i ] = 0 ; } // call to main main (); } Examine the binary file # Build all files: arm-none-eabi-gcc \\ -mcpu = cortex-m4 -mthumb -mfloat-abi = soft \\ -std = gnu11 \\ -nostdlib \\ -Wall \\ -T linker.ld -Wl,-Map = main.elf.map \\ main.o delay.o vector.o startup.o \\ -o main.elf The elf file is a wrapper of a binary file because it contains extra metadata, such as the symbol table: arm-none-eabi-nm main.elf > main.elf.sym main.elf.sym 20000008 B _ebss 20000004 D _edata 20020000 D _estack 080002 b8 T _etext 080002 bc A _lddata 20000004 B _sbss 20000000 D _sdata 0800022 c W ADC_IRQHandler 0800022 c W BusFault_Handler 0800022 c W DebugMon_Handler 0800022 c T Default_Handler 08000200 T delay 20000004 B delay_counter 080002 b8 R DELAY_MAX 0800022 c W DMA1_Stream0_IRQHandler 0800022 c W DMA1_Stream1_IRQHandler 0800022 c W DMA1_Stream2_IRQHandler 0800022 c W DMA1_Stream3_IRQHandler 0800022 c W DMA1_Stream4_IRQHandler 0800022 c W DMA1_Stream5_IRQHandler 0800022 c W DMA1_Stream6_IRQHandler 0800022 c W DMA1_Stream7_IRQHandler 0800022 c W DMA2_Stream0_IRQHandler 0800022 c W DMA2_Stream1_IRQHandler 0800022 c W DMA2_Stream2_IRQHandler 0800022 c W DMA2_Stream3_IRQHandler 0800022 c W DMA2_Stream4_IRQHandler 0800022 c W DMA2_Stream5_IRQHandler 0800022 c W DMA2_Stream6_IRQHandler 0800022 c W DMA2_Stream7_IRQHandler 0800022 c W EXTI0_IRQHandler 0800022 c W EXTI1_IRQHandler 0800022 c W EXTI15_10_IRQHandler 0800022 c W EXTI2_IRQHandler 0800022 c W EXTI3_IRQHandler 0800022 c W EXTI4_IRQHandler 0800022 c W EXTI9_5_IRQHandler 0800022 c W FLASH_IRQHandler 0800022 c W FPU_IRQHandler 0800022 c W HardFault_Handler 0800022 c W I2C1_ER_IRQHandler 0800022 c W I2C1_EV_IRQHandler 0800022 c W I2C2_ER_IRQHandler 0800022 c W I2C2_EV_IRQHandler 0800022 c W I2C3_ER_IRQHandler 0800022 c W I2C3_EV_IRQHandler 20000000 D isLoop 08000198 T main 0800022 c W MemManage_Handler 0800022 c W NMI_Handler 0800022 c W OTG_FS_IRQHandler 0800022 c W OTG_FS_WKUP_IRQHandler 0800022 c W PendSV_Handler 0800022 c W PVD_IRQHandler 0800022 c W RCC_IRQHandler 08000234 T Reset_Handler 0800022 c W RTC_Alarm_IRQHandler 0800022 c W RTC_WKUP_IRQHandler 0800022 c W SDIO_IRQHandler 0800022 c W SPI1_IRQHandler 0800022 c W SPI2_IRQHandler 0800022 c W SPI3_IRQHandler 0800022 c W SPI4_IRQHandler 0800022 c W SPI5_IRQHandler 0800022 c W SVC_Handler 0800022 c W SysTick_Handler 0800022 c W TAMP_STAMP_IRQHandler 0800022 c W TIM1_BRK_TIM9_IRQHandler 0800022 c W TIM1_CC_IRQHandler 0800022 c W TIM1_TRG_COM_TIM11_IRQHandler 0800022 c W TIM1_UP_TIM10_IRQHandler 0800022 c W TIM2_IRQHandler 0800022 c W TIM3_IRQHandler 0800022 c W TIM4_IRQHandler 0800022 c W TIM5_IRQHandler 0800022 c W UsageFault_Handler 0800022 c W USART1_IRQHandler 0800022 c W USART2_IRQHandler 0800022 c W USART6_IRQHandler 08000000 D vector_table 0800022 c W WWDG_IRQHandler The Reset_Handler is at 0x08000234 , the Default_Handler is at 0x0800022c . Extract binary content : arm-none-eabi-objcopy -O binary main.elf main.bin Examine binary file Check isr_vector at 0x08000000 : group 4 bytes, use little-endian, start at 0, size 32 bytes xxd -g4 -e -s0 -l32 main.bin 00000000: 20020000 08000235 0800022d 0800022d ... 5...-...-... 00000010: 0800022d 0800022d 0800022d 00000000 -...-...-....... You will notice that: The MSP value at the address 0x00000000 is the RAN_END value 0x20020000 . The Reset Handler address is written at 0x00000004 , which is 0x08000235 (note that the LSB bit is 1 to indicate Thumb state). Let check the value of DELAY_MAX at the address 0x080002bc : xxd -g4 -e -s0x2bc -l4 main.bin 000002bc: 0000beef You will notice the constant value 0x0000BEEF is stored at that address. Review assembly code You can read the assembly code from the elf file using arm-none-eabi-objdump -S main.elf main.elf.s main.elf: file format elf32-littlearm Disassembly of section .text : 08000198 < main > : 8000198: b580 push { r7 , lr } 800019 a: af00 add r7 , sp , #0 800019 c: 4 b14 ldr r3 , [ pc , #80 ] ; (80001f0 <main+0x58>) 800019 e: 681 b ldr r3 , [ r3 , #0 ] 80001 a0: 4 a13 ldr r2 , [ pc , #76 ] ; (80001f0 <main+0x58>) 80001 a2: f043 0301 orr.w r3 , r3 , #1 80001 a6: 6013 str r3 , [ r2 , #0 ] 80001 a8: 4 b12 ldr r3 , [ pc , #72 ] ; (80001f4 <main+0x5c>) 80001 aa: 681 b ldr r3 , [ r3 , #0 ] 80001 ac: 4 a11 ldr r2 , [ pc , #68 ] ; (80001f4 <main+0x5c>) 80001 ae: f423 6300 bic.w r3 , r3 , #2048 ; 0x800 80001 b2: 6013 str r3 , [ r2 , #0 ] 80001 b4: 4 b0f ldr r3 , [ pc , #60 ] ; (80001f4 <main+0x5c>) 80001 b6: 681 b ldr r3 , [ r3 , #0 ] 80001 b8: 4 a0e ldr r2 , [ pc , #56 ] ; (80001f4 <main+0x5c>) 80001 ba: f443 6380 orr.w r3 , r3 , #1024 ; 0x400 80001 be: 6013 str r3 , [ r2 , #0 ] 80001 c0: e00f b.n 80001e2 < main + 0x4a > 80001 c2: 4 b0d ldr r3 , [ pc , #52 ] ; (80001f8 <main+0x60>) 80001 c4: 681 b ldr r3 , [ r3 , #0 ] 80001 c6: 4 a0c ldr r2 , [ pc , #48 ] ; (80001f8 <main+0x60>) 80001 c8: f043 0320 orr.w r3 , r3 , #32 80001 cc: 6013 str r3 , [ r2 , #0 ] 80001 ce: f000 f817 bl 8000200 < delay > 80001 d2: 4 b09 ldr r3 , [ pc , #36 ] ; (80001f8 <main+0x60>) 80001 d4: 681 b ldr r3 , [ r3 , #0 ] 80001 d6: 4 a08 ldr r2 , [ pc , #32 ] ; (80001f8 <main+0x60>) 80001 d8: f443 1300 orr.w r3 , r3 , #2097152 ; 0x200000 80001 dc: 6013 str r3 , [ r2 , #0 ] 80001 de: f000 f80f bl 8000200 < delay > 80001 e2: 4 b06 ldr r3 , [ pc , #24 ] ; (80001fc <main+0x64>) 80001 e4: 681 b ldr r3 , [ r3 , #0 ] 80001 e6: 2 b00 cmp r3 , #0 80001 e8: d1eb bne.n 80001c2 < main + 0x2a > 80001 ea: 2300 movs r3 , #0 80001 ec: 4618 mov r0 , r3 80001 ee: bd80 pop { r7 , pc } 80001 f0: 40023830 .word 0x40023830 80001 f4: 40020000 .word 0x40020000 80001 f8: 40020018 .word 0x40020018 80001 fc: 20000000 .word 0x20000000 08000200 < delay > : 8000200: b480 push { r7 } 8000202: af00 add r7 , sp , #0 8000204: f64b 62 ef movw r2 , #48879 ; 0xbeef 8000208: 4 b07 ldr r3 , [ pc , #28 ] ; (8000228 <delay+0x28>) 800020 a: 601 a str r2 , [ r3 , #0 ] 800020 c: bf00 nop 800020 e: 4 b06 ldr r3 , [ pc , #24 ] ; (8000228 <delay+0x28>) 8000210: 681 b ldr r3 , [ r3 , #0 ] 8000212: 1 e5a subs r2 , r3 , #1 8000214: 4904 ldr r1 , [ pc , #16 ] ; (8000228 <delay+0x28>) 8000216: 600 a str r2 , [ r1 , #0 ] 8000218: 2 b00 cmp r3 , #0 800021 a: d1f8 bne.n 800020e < delay + 0xe > 800021 c: bf00 nop 800021 e: bf00 nop 8000220: 46 bd mov sp , r7 8000222: bc80 pop { r7 } 8000224: 4770 bx lr 8000226: bf00 nop 8000228: 20000004 .word 0x20000004 0800022 c < Default_Handler > : 800022 c: b480 push { r7 } 800022 e: af00 add r7 , sp , #0 8000230: e7fe b.n 8000230 < Default_Handler + 0x4 > ... 08000234 < Reset_Handler > : 8000234: b580 push { r7 , lr } 8000236: b086 sub sp , #24 8000238: af00 add r7 , sp , #0 800023 a: 4 a1a ldr r2 , [ pc , #104 ] ; (80002a4 <Reset_Handler+0x70>) 800023 c: 4 b1a ldr r3 , [ pc , #104 ] ; (80002a8 <Reset_Handler+0x74>) 800023 e: 1 ad3 subs r3 , r2 , r3 8000240: 60 fb str r3 , [ r7 , #12 ] 8000242: 4 b19 ldr r3 , [ pc , #100 ] ; (80002a8 <Reset_Handler+0x74>) 8000244: 60 bb str r3 , [ r7 , #8 ] 8000246: 4 b19 ldr r3 , [ pc , #100 ] ; (80002ac <Reset_Handler+0x78>) 8000248: 607 b str r3 , [ r7 , #4 ] 800024 a: 2300 movs r3 , #0 800024 c: 617 b str r3 , [ r7 , #20 ] 800024 e: e00a b.n 8000266 < Reset_Handler + 0x32 > 8000250: 697 b ldr r3 , [ r7 , #20 ] 8000252: 687 a ldr r2 , [ r7 , #4 ] 8000254: 441 a add r2 , r3 8000256: 697 b ldr r3 , [ r7 , #20 ] 8000258: 68 b9 ldr r1 , [ r7 , #8 ] 800025 a: 440 b add r3 , r1 800025 c: 7812 ldrb r2 , [ r2 , #0 ] 800025 e: 701 a strb r2 , [ r3 , #0 ] 8000260: 697 b ldr r3 , [ r7 , #20 ] 8000262: 3301 adds r3 , #1 8000264: 617 b str r3 , [ r7 , #20 ] 8000266: 697 b ldr r3 , [ r7 , #20 ] 8000268: 68 fa ldr r2 , [ r7 , #12 ] 800026 a: 429 a cmp r2 , r3 800026 c: d8f0 bhi.n 8000250 < Reset_Handler + 0x1c > 800026 e: 4 a10 ldr r2 , [ pc , #64 ] ; (80002b0 <Reset_Handler+0x7c>) 8000270: 4 b10 ldr r3 , [ pc , #64 ] ; (80002b4 <Reset_Handler+0x80>) 8000272: 1 ad3 subs r3 , r2 , r3 8000274: 60 fb str r3 , [ r7 , #12 ] 8000276: 4 b0f ldr r3 , [ pc , #60 ] ; (80002b4 <Reset_Handler+0x80>) 8000278: 60 bb str r3 , [ r7 , #8 ] 800027 a: 2300 movs r3 , #0 800027 c: 613 b str r3 , [ r7 , #16 ] 800027 e: e007 b.n 8000290 < Reset_Handler + 0x5c > 8000280: 693 b ldr r3 , [ r7 , #16 ] 8000282: 68 ba ldr r2 , [ r7 , #8 ] 8000284: 4413 add r3 , r2 8000286: 2200 movs r2 , #0 8000288: 701 a strb r2 , [ r3 , #0 ] 800028 a: 693 b ldr r3 , [ r7 , #16 ] 800028 c: 3301 adds r3 , #1 800028 e: 613 b str r3 , [ r7 , #16 ] 8000290: 693 b ldr r3 , [ r7 , #16 ] 8000292: 68 fa ldr r2 , [ r7 , #12 ] 8000294: 429 a cmp r2 , r3 8000296: d8f3 bhi.n 8000280 < Reset_Handler + 0x4c > 8000298: f7ff ff7e bl 8000198 < main > 800029 c: bf00 nop 800029 e: 3718 adds r7 , #24 80002 a0: 46 bd mov sp , r7 80002 a2: bd80 pop { r7 , pc } 80002 a4: 20000004 .word 0x20000004 80002 a8: 20000000 .word 0x20000000 80002 ac: 080002 bc .word 0x080002bc 80002 b0: 20000008 .word 0x20000008 80002 b4: 20000004 .word 0x20000004 Download and Debug # Run OpenOCD Each target has its own configurations, such as _CPUTAPID , _ENDIAN , or Debug registers. You will need this configuration file to work with your target. For example, target an STM32F411 MCU: stm32f4x.cfg # script for stm32f4x family # # stm32 devices support both JTAG and SWD transports. # source [find target/swj-dp.tcl] source [find mem_helper.tcl] if { [info exists CHIPNAME] } { set _CHIPNAME $CHIPNAME } else { set _CHIPNAME stm32f4x } set _ENDIAN little # Work-area is a space in RAM used for flash programming # By default use 32kB (Available RAM in smallest device STM32F410) if { [info exists WORKAREASIZE] } { set _WORKAREASIZE $WORKAREASIZE } else { set _WORKAREASIZE 0x8000 } #jtag scan chain if { [info exists CPUTAPID] } { set _CPUTAPID $CPUTAPID } else { if { [using_jtag] } { # See STM Document RM0090 # Section 38.6.3 - corresponds to Cortex-M4 r0p1 set _CPUTAPID 0x4ba00477 } { set _CPUTAPID 0x2ba01477 } } swj_newdap $_CHIPNAME cpu -irlen 4 -ircapture 0x1 -irmask 0xf -expected-id $_CPUTAPID dap create $_CHIPNAME.dap -chain-position $_CHIPNAME.cpu tpiu create $_CHIPNAME.tpiu -dap $_CHIPNAME.dap -ap-num 0 -baseaddr 0xE0040000 if {[using_jtag]} { jtag newtap $_CHIPNAME bs -irlen 5 } set _TARGETNAME $_CHIPNAME.cpu target create $_TARGETNAME cortex_m -endian $_ENDIAN -dap $_CHIPNAME.dap $_TARGETNAME configure -work-area-phys 0x20000000 -work-area-size $_WORKAREASIZE -work-area-backup 0 set _FLASHNAME $_CHIPNAME.flash flash bank $_FLASHNAME stm32f2x 0 0 0 0 $_TARGETNAME flash bank $_CHIPNAME.otp stm32f2x 0x1fff7800 0 0 0 $_TARGETNAME if { [info exists QUADSPI] && $QUADSPI } { set a [llength [flash list]] set _QSPINAME $_CHIPNAME.qspi flash bank $_QSPINAME stmqspi 0x90000000 0 0 0 $_TARGETNAME 0xA0001000 } # JTAG speed should be <= F_CPU/6. F_CPU after reset is 16MHz, so use F_JTAG = 2MHz # # Since we may be running of an RC oscilator, we crank down the speed a # bit more to be on the safe side. Perhaps superstition, but if are # running off a crystal, we can run closer to the limit. Note # that there can be a pretty wide band where things are more or less stable. adapter speed 2000 adapter srst delay 100 if {[using_jtag]} { jtag_ntrst_delay 100 } reset_config srst_nogate if {![using_hla]} { # if srst is not fitted use SYSRESETREQ to # perform a soft reset cortex_m reset_config sysresetreq } $_TARGETNAME configure -event examine-end { # Enable debug during low power modes (uses more power) # DBGMCU_CR |= DBG_STANDBY | DBG_STOP | DBG_SLEEP mmw 0xE0042004 0x00000007 0 # Stop watchdog counters during halt # DBGMCU_APB1_FZ |= DBG_IWDG_STOP | DBG_WWDG_STOP mmw 0xE0042008 0x00001800 0 } proc proc_post_enable {_chipname} { targets $_chipname.cpu if { [$_chipname.tpiu cget -protocol] eq \"sync\" } { switch [$_chipname.tpiu cget -port-width] { 1 { mmw 0xE0042004 0x00000060 0x000000c0 mmw 0x40021020 0x00000000 0x0000ff00 mmw 0x40021000 0x000000a0 0x000000f0 mmw 0x40021008 0x000000f0 0x00000000 } 2 { mmw 0xE0042004 0x000000a0 0x000000c0 mmw 0x40021020 0x00000000 0x000fff00 mmw 0x40021000 0x000002a0 0x000003f0 mmw 0x40021008 0x000003f0 0x00000000 } 4 { mmw 0xE0042004 0x000000e0 0x000000c0 mmw 0x40021020 0x00000000 0x0fffff00 mmw 0x40021000 0x00002aa0 0x00003ff0 mmw 0x40021008 0x00003ff0 0x00000000 } } } else { mmw 0xE0042004 0x00000020 0x000000c0 } } $_CHIPNAME.tpiu configure -event post-enable \"proc_post_enable $_CHIPNAME\" $_TARGETNAME configure -event reset-init { # Configure PLL to boost clock to HSI x 4 (64 MHz) mww 0x40023804 0x08012008 ;# RCC_PLLCFGR 16 Mhz /8 (M) * 128 (N) /4(P) mww 0x40023C00 0x00000102 ;# FLASH_ACR = PRFTBE | 2(Latency) mmw 0x40023800 0x01000000 0 ;# RCC_CR |= PLLON sleep 10 ;# Wait for PLL to lock mmw 0x40023808 0x00001000 0 ;# RCC_CFGR |= RCC_CFGR_PPRE1_DIV2 mmw 0x40023808 0x00000002 0 ;# RCC_CFGR |= RCC_CFGR_SW_PLL # Boost JTAG frequency adapter speed 8000 } $_TARGETNAME configure -event reset-start { # Reduce speed since CPU speed will slow down to 16MHz with the reset adapter speed 2000 } On a board with an ST Link debugger: board.cfg source [find interface/stlink.cfg] transport select hla_swd # increase working area to 64KB set WORKAREASIZE 0x10000 source [find target/stm32f4x.cfg] reset_config srst_only You can use any STM32 compatible debuggers such as ST_Link V\u2154, J-Link to connect with Serial Wire Debug (SWD) interface on the target MCU. Debugging a target board openocd -f board.cfg xPack OpenOCD x86_64 Open On-Chip Debugger 0.11.0+dev (2022-03-25-17:32) Licensed under GNU GPL v2 For bug reports, read http://openocd.org/doc/doxygen/bugs.html Info : The selected transport took over low-level target control. The results might differ compared to plain JTAG/SWD srst_only separate srst_nogate srst_open_drain connect_deassert_srst Info : Listening on port 6666 for tcl connections Info : Listening on port 4444 for telnet connections Info : clock speed 2000 kHz Info : STLINK V2J39M27 (API v2) VID:PID 0483:374B Info : Target voltage: 3.276040 Info : [stm32f4x.cpu] Cortex-M4 r0p1 processor detected Info : [stm32f4x.cpu] target has 6 breakpoints, 4 watchpoints Info : starting gdb server for stm32f4x.cpu on 3333 Info : Listening on port 3333 for gdb connections OpenOCD Commands are available online and examples. Telnet client Run Telnet: Run the Telnet client: telnet 127 .0.0.1 4444 Telnet is used access to OpenOCD server and use OpenOCD commands directly. flash write_image erase main.elf reset halt resume Use Telnet to connect to OpenOCD GDB Client Prepare a debug version with -g option, named it main-debug.elf arm-none-eabi-gcc \\ -mcpu = cortex-m4 -mthumb -mfloat-abi = soft \\ -nostdlib \\ -std = gnu11 \\ -Wall \\ -g \\ -T linker.ld -Wl,-Map = main-debug.elf.map \\ main.c delay.c vector.c startup.c \\ -o main-debug.elf Run the GDB client with debug version: arm-none-eabi-gdb main-debug.elf Then connect to OpenOCD server: target extended-remote localhost:3333 All OpenOCD command must be start with monitor tag (gdb) monitor flash write_image erase main.elf monitor reset halt monitor resume GDB has its own command set, you can use it too: (gdb) br main step Use GDB to connect to OpenOCD Use standard library # newlib-nano.zip Let see a new example that uses the standard library. The source code is from the above example, but added some mofifications: Add stdio.h library for using printf() function Use Semihosting for output if macro USE_SEMIHOSTING is defined #include <stdint.h> #include <stdio.h> #include \"delay.h\" /* Clock */ #define RCC_AHB1ENR *((volatile uint32_t*) (0x40023830)) /* GPIO A */ #define GPIOA_MODER *((volatile uint32_t*) (0x40020000)) #define GPIOA_BSRR *((volatile uint32_t*) (0x40020018)) /* Global initialized variable */ uint32_t isLoop = 1 ; #ifdef USE_SEMIHOSTING /* Semohosting */ extern void initialise_monitor_handles ( void ); #endif int main () { char counter = 0 ; #ifdef USE_SEMIHOSTING initialise_monitor_handles (); #endif /* turn on clock on GPIOA */ RCC_AHB1ENR |= ( 1 << 0 ); /* set PA5 to output mode */ GPIOA_MODER &= ~ ( 1 << 11 ); GPIOA_MODER |= ( 1 << 10 ); while ( isLoop ) { /* set HIGH on PA5 */ GPIOA_BSRR |= ( 1 << 5 ); delay (); /* set LOW on PA5 */ GPIOA_BSRR |= ( 1 << ( 5 + 16 )); delay (); /* output */ printf ( \"counter = %d \\n \" , counter ); counter ++ ; } return 0 ; } Let try to compile: arm-none-eabi-gcc \\ -mcpu = cortex-m4 -mthumb -mfloat-abi = soft \\ -std = gnu11 \\ -Wall \\ -T linker.ld -Wl,-Map = main.elf.map \\ main.c delay.c vector.c startup.c \\ -o main.elf \\crt0.o: in function `_mainCRTStartup': (.text+0x64): undefined reference to `__bss_start__' (.text+0x68): undefined reference to `__bss_end__' \\libc.a(lib_a-exit.o): in function `exit': (.text.exit+0x16): undefined reference to `_exit' \\libc.a(lib_a-sbrkr.o): in function `_sbrk_r': (.text._sbrk_r+0xc): undefined reference to `_sbrk' \\libc.a(lib_a-writer.o): in function `_write_r': (.text._write_r+0x14): undefined reference to `_write' \\libc.a(lib_a-closer.o): in function `_close_r': (.text._close_r+0xc): undefined reference to `_close' \\libc.a(lib_a-fstatr.o): in function `_fstat_r': (.text._fstat_r+0x12): undefined reference to `_fstat' \\libc.a(lib_a-isattyr.o): in function `_isatty_r': (.text._isatty_r+0xc): undefined reference to `_isatty' \\libc.a(lib_a-lseekr.o): in function `_lseek_r': (.text._lseek_r+0x14): undefined reference to `_lseek' \\libc.a(lib_a-readr.o): in function `_read_r': (.text._read_r+0x14): undefined reference to `_read' \\libc.a(lib_a-abort.o): in function `abort': (.text.abort+0xa): undefined reference to `_exit' \\libc.a(lib_a-signalr.o): in function `_kill_r': (.text._kill_r+0x12): undefined reference to `_kill' \\libc.a(lib_a-signalr.o): in function `_getpid_r': (.text._getpid_r+0x0): undefined reference to `_getpid' \\libgcc.a(unwind-arm.o): in function `get_eit_entry': (.text.get_eit_entry+0x90): undefined reference to `__exidx_start' (.text.get_eit_entry+0x94): undefined reference to `__exidx_end' We see that the compiler link to the libc by default. Standard C libraries GNU ARM libraries use newlib to provide standard implementation of C libraries. To reduce the code size and make it independent to hardware, there is a lightweight version newlib-nano used in MCUs. However, newlib-nano does not provide an implementation of low-level system calls which are used by C standard libraries, such as print() or scan() . To make the application compilable, a new library named nosys should be added. This library just provide a simple implementation of low-level system calls which mostly return a by-pass value. The lib newlib-nano is enabled via linker options --specs=nano.specs , and nosys is enabled via linker option --specs=nosys.specs . These two libraries are included by default in GCC linker options in generated project, check it here . arm-none-eabi-gcc \\ -mcpu = cortex-m4 -mthumb -mfloat-abi = soft \\ -std = gnu11 \\ --specs = nano.specs --specs = nosys.specs \\ -Wall \\ -T linker.ld -Wl,-Map = main.elf.map \\ main.c delay.c vector.c startup.c \\ -o main.elf \\crt0.o: in function `_mainCRTStartup': (.text+0x64): undefined reference to `__bss_start__' (.text+0x68): undefined reference to `__bss_end__' \\libnosys.a(sbrk.o): in function `_sbrk': (.text._sbrk+0x18): undefined reference to `end' There are still few errors that need fixed in Linker script. Let download the source code of newlib from newlib ftp directory . Search for __bss_start__ , __bss_start__ and you can see a note: * `mcore/crt0.S` : Renamed file from `crt0.s` . Only invoke `init()` and `fini()` routines for ELF builds. Use `__bss_start__` and `__bss_end__` to locate `.bss` section. Search for the function _sbrk you can see a note in source code, which mentions that end symbol should be end of heap. void * _sbrk ( ptrdiff_t incr ) { extern char end asm ( \"end\" ); /* Defined by the linker. */ static char * heap_end ; char * prev_heap_end ; if ( heap_end == NULL ) heap_end = & end ; Update linker sections # The linker should update below sections: add alignment to each section include subsections, e.g. *(.text*) new heap section to check reserved memory for stack and heap linker.ld ENTRY ( Reset_Handler ) MEMORY { RAM ( xrw ) : ORIGIN = 0x20000000 , LENGTH = 128 K FLASH ( rx ) : ORIGIN = 0x08000000 , LENGTH = 512 K } _estack = ORIGIN ( RAM ) + LENGTH ( RAM ) ; _Min_Heap_Size = 0x200 ; /* required amount of heap */ _Min_Stack_Size = 0x400 ; /* required amount of stack */ SECTIONS { .isr_vector : { . = ALIGN ( 4 ) ; KEEP (*(. isr_vector )) /* Startup code */ . = ALIGN ( 4 ) ; } > FLASH .text : { . = ALIGN ( 4 ) ; *( .text ) *( .text *) *( .glue_7 ) /* glue arm to thumb code */ *( .glue_7t ) /* glue thumb to arm code */ *( .eh_frame ) KEEP (*(. init )) KEEP (*(. fini )) . = ALIGN ( 4 ) ; _etext = . ; } > FLASH .rodata : { . = ALIGN ( 4 ) ; *( .rodata ) *( .rodata *) . = ALIGN ( 4 ) ; } > FLASH .ARM : { . = ALIGN ( 4 ) ; __exidx_start = . ; *( .ARM.exidx *) __exidx_end = . ; . = ALIGN ( 4 ) ; } > FLASH _lddata = LOADADDR (. data ) ; .data : { . = ALIGN ( 4 ) ; _sdata = . ; *( .data ) *( .data *) . = ALIGN ( 4 ) ; _edata = . ; } > RAM AT > FLASH .bss : { . = ALIGN ( 4 ) ; _sbss = . ; __bss_start__ = _sbss ; *( .bss ) *( .bss. *) *( COMMON ) . = ALIGN ( 4 ) ; _ebss = . ; __bss_end__ = _ebss ; } > RAM ._user_heap_stack : { . = ALIGN ( 8 ) ; end = . ; _end = . ; __end__ = . ; . = . + _Min_Heap_Size ; . = . + _Min_Stack_Size ; . = ALIGN ( 8 ) ; } > RAM /* Remove information from the compiler libraries */ / DISCARD / : { libc.a ( * ) libm.a ( * ) libgcc.a ( * ) } .ARM.attributes 0 : { *(. ARM.attributes ) } } Update startup code # startup.c #include <stdint.h> extern uint32_t _sdata ; extern uint32_t _edata ; extern uint32_t _lddata ; extern uint32_t _sbss ; extern uint32_t _ebss ; extern void main ( void ) ; extern void __libc_init_array ( void ) ; void Reset_Handler ( void ) { // copy .data section from flash to ram uint32_t size = ( uint32_t ) & _edata - ( uint32_t ) & _sdata ; uint8_t * pRAM = ( uint8_t *) & _sdata ; uint8_t * pFlash = ( uint8_t *) & _lddata ; for ( int i = 0 ; i<size; i++) { pRAM [ i ] = pFlash [ i ] ; } // initialize .bss section size = ( uint32_t ) & _ebss - ( uint32_t ) & _sbss ; pRAM = ( uint8_t *) & _sbss ; for ( int i = 0 ; i<size; i++) { pRAM [ i ] = 0 ; } // init libc __libc_init_array () ; // call to main main () ; } Run OpenOCD with Semihosting # Compile with Semihosting: Use --specs=rdimon.specs Use -DUSE_SEMIHOSTING Use -lrdimon arm-none-eabi-gcc \\ -mcpu = cortex-m4 -mthumb -mfloat-abi = soft \\ -std = gnu11 \\ --specs = rdimon.specs \\ -Wall \\ -DUSE_SEMIHOSTING -T linker.ld -Wl,-Map = main.elf.map -lrdimon \\ main.c delay.c vector.c startup.c \\ -o main-semi.elf Run OpenOCD, and use Telnet to connect and run below command arm semihosting enable halt flash write_image erase main-semi.elf reset halt resume Use Semihosting with OpenOCD","title":"Compilation process with Linker and Startup code"},{"location":"blog/stm32/compilation/#overview","text":"Following are the steps that a program goes through until it is translated into an executable form: Preprocessing Compilation Assembly Linking In general, compilation for Microprocessors is the same as the Compilation process for executables on an Operating System. However, there are some main different points: Cross-compilation: MCUs can not run a compiler itself, therefore, there must be a cross-compiler for MCUs Library: MCUs use a light-weight version of libraries to reduce the program footprint and might increase performance Hardware-depend: Many libraries only implement minimal code which mainly does nothing, such as the standard I/O. On a specific hardware, the actual implementation must be done. Linking: The executables have to define sections stored in different memory spaces in runtime (Flash/ RAM). On MCU, CPU can directly execute instructions on Flash device. For the general steps in compilation, refer to the Compilation for C/C++ on OS .","title":"Overview"},{"location":"blog/stm32/compilation/#arm-toolchain","text":"If you use STM32Cube IDE, the IDE already has a toolchain for STM32 MCUs. If you start without the IDE, you can start with Arm GNU Toolchain . A good alternative toolchain package is The xPack Build Framework : The xPack project aims to provide a set of cross-platform tools to manage, configure and build complex, modular, multi-target (multi-architecture, multi-board, multi-toolchain) projects, with an emphasis on C/C++ and bare-metal embedded projects. @xpack-dev-tools/arm-none-eabi-gcc - the xPack Arm Embedded GCC toolchain @xpack-dev-tools/openocd - the xPack OpenOCD Download and install them. Note to add the binary folders to the system environment. Add Arm GNU toolchain to System Environment EABI The default ARM tool chain application binary interface is the Embedded Application Binary Interface (EABI). It defines the conventions for files, data types, register mapping, stack frame and parameter passing rules. The EABI is commonly used on ARM and PowerPC CPUs.","title":"ARM Toolchain"},{"location":"blog/stm32/compilation/#example-program","text":"nostdlib.zip This is the Blink - Hello World program: Blink a LED at 10 Hz . You can use any STM32 board because this is just a very simple project. I choose to use a Nucleo-64 board with STM32F411RE. The main code to blink LED on PA5 by using registers: main.c #include <stdint.h> #include \"delay.h\" /* Clock */ #define RCC_AHB1ENR *((volatile uint32_t*) (0x40023830)) /* GPIO A */ #define GPIOA_MODER *((volatile uint32_t*) (0x40020000)) #define GPIOA_BSRR *((volatile uint32_t*) (0x40020018)) /* Global initialized variable */ uint32_t isLoop = 1 ; int main () { /* turn on clock on GPIOA */ RCC_AHB1ENR |= ( 1 << 0 ); /* set PA5 to output mode */ GPIOA_MODER &= ~ ( 1 << 11 ); GPIOA_MODER |= ( 1 << 10 ); while ( isLoop ) { /* set HIGH on PA5 */ GPIOA_BSRR |= ( 1 << 5 ); delay (); /* set LOW on PA5 */ GPIOA_BSRR |= ( 1 << ( 5 + 16 )); delay (); } return 0 ; } The delay function using a busy loop: delay.c #include <stdint.h> /* Global Read-only variable */ const uint32_t DELAY_MAX = 0x0000BEEF ; /* Global Uninitialized varible */ uint32_t delay_counter ; void delay () { for ( delay_counter = DELAY_MAX ; delay_counter -- ;); } Firstly, just try to compile the program without any specific option: arm-none-eabi-gcc \\ main.c delay.c \\ -o main.elf /arm-none-eabi/bin/ld.exe: /arm-none-eabi/lib\\libc.a(lib_a-exit.o): in function `exit': (.text.exit+0x2c) : undefined reference to `_exit' Of course, you can not compile the source code! By default, GCC tries to link the application with libc in newlib package, and there is no implementation for the function _exit . At this time, we will tell the compiler to not use the standard libraries. arm-none-eabi-gcc \\ -nostdlib \\ main.c delay.c \\ -o main.elf Just ignore the warning about entry symbol. We\u2019ll fix it later.","title":"Example program"},{"location":"blog/stm32/compilation/#compiler-options","text":"In the Step 5: Check the compilation settings , the STM32Cube IDE automatically sets some compilation flags. How do you select those flags? GNU Online Documentation is available for different versions. Target Architecture We can either use -march= or -mcpu= options, but -mcpu=cortex-m4 is easy to understand and remember. Note that Cortex-M only supports Thumb instruction set, so you have to use -mthumb option. Let use soft Floating Point at this moment. -mcpu=cortex-m4 -mthumb -mfloat-abi=soft Target GNU standard -std=gnu11 Target Libraries GNU ARM libraries use newlib to provide standard implementation of C libraries. To reduce the code size and make it independent to hardware, there is a lightweight version newlib-nano used in MCUs. However, newlib-nano does not provide an implementation of low-level system calls which are used by C standard libraries, such as print() or scan() . To make the application compilable, a new library named nosys should be added. This library just provide a simple implementation of low-level system calls which mostly return a by-pass value. To use newlib-nano and nosys libs: --specs=nano.specs --specs=nosys.specs At this moment, we ignore the standard libraries, and check on it later. Compilation warnings To see potential errors, enable Warning for all: -Wall Debug level Turn on debug if needed: -g Hence, the build command will be: arm-none-eabi-gcc \\ -mcpu = cortex-m4 -mthumb -mfloat-abi = soft \\ -std = gnu11 \\ -nostdlib \\ -Wall \\ main.c delay.c \\ -o main.elf Just ignore the warning about the entry symbol Reset_Handler. We\u2019ll fix it later.","title":"Compiler options"},{"location":"blog/stm32/compilation/#program-sections","text":"Run arm-none-eabi-objdump to see the sections and code of the output arm-none-eabi-gcc \\ -mcpu = cortex-m4 -mthumb -mfloat-abi = soft \\ -std = gnu11 \\ -nostdlib \\ -Wall \\ -c main.c \\ -o main.o arm-none-eabi-objdump -h main.o > main.o.obj_h main.o.obj_h main.o: file format elf32-littlearm Sections: Idx Name Size VMA LMA File off Algn 0 .text 00000068 00000000 00000000 00000034 2**2 CONTENTS, ALLOC, LOAD, RELOC, READONLY, CODE 1 .data 00000004 00000000 00000000 0000009c 2**2 CONTENTS, ALLOC, LOAD, DATA 2 .bss 00000000 00000000 00000000 000000a0 2**0 ALLOC 3 .comment 0000003a 00000000 00000000 000000a0 2**0 CONTENTS, READONLY 4 .ARM.attributes 0000002e 00000000 00000000 000000da 2**0 CONTENTS, READONLY arm-none-eabi-gcc \\ -mcpu = cortex-m4 -mthumb \\ -nostdlib \\ -std = gnu11 \\ -Wall \\ -c delay.c \\ -o delay.o arm-none-eabi-objdump -h delay.o > delay.o.obj_h main.o.obj_h delay.o: file format elf32-littlearm Sections: Idx Name Size VMA LMA File off Algn 0 .text 0000002c 00000000 00000000 00000034 2**2 CONTENTS, ALLOC, LOAD, RELOC, READONLY, CODE 1 .data 00000000 00000000 00000000 00000060 2**0 CONTENTS, ALLOC, LOAD, DATA 2 .bss 00000004 00000000 00000000 00000060 2**2 ALLOC 3 .rodata 00000004 00000000 00000000 00000060 2**2 CONTENTS, ALLOC, LOAD, READONLY, DATA 4 .comment 0000003a 00000000 00000000 00000064 2**0 CONTENTS, READONLY 5 .ARM.attributes 0000002e 00000000 00000000 0000009e 2**0 CONTENTS, READONLY .text : Code and Data The code containing instructions which are located in Flash. The text code also store constant values which are encoded as raw bytes at the end of a function. .data : Initialized variable Variables can change their values, so variables are copied from Flash to RAM by the startup code. In this example, in main.o , there are 4 bytes for uint32_t isLoop = 1 ; . .bss : Uninitialized variables Variables can change their values, so variables are copied from Flash to RAM. However, because these values are uninitialized, so we do not need to store their values, we just need to reserve memory for them. The entire .bss segment is described by a single number, probably 4 bytes or 8 bytes, that gives its size in the running process, whereas the .data section is as big as the sum of sizes of the initialized variables. In this example, in delay.o , there are 4 bytes for uint32_t delay_counter ; . .rodata : Read-only data Constant variables are stored in Flash. In this example, in delay.o , there are 4 bytes for const uint32_t DELAY_MAX = 0x0000BEEF ; . Section locations Data (variable) Load time Run time Section Note Global initialized Flash RAM .data Copy from Flash to RAM by startup code Global static initialized Local static initialized Global uninitialized - RAM .bss Reserved space by startup code Global static uninitialized Local static uninitialized All global constants Flash - .rodata All other local - RAM (Stack) - App code uses stack to store","title":"Program sections"},{"location":"blog/stm32/compilation/#linker-and-locator","text":"Linker is used to merge all sections from different binaries into the final executable file. main.c --> main.o { .text, .data, .bss, .rodata } delay.c --> delay.o { .text, .data, .bss, .rodata} main.elf = main.o + delay.o = { .text = .text(main) + .text(delay)} .data = .data(main) + .data(delay)} .bss = .bss(main) + .bss(delay)} .rodata = .rodata(main) + .rodata(delay)} } A linker script is used to decribe the Memory Layout: ENTRY command Set the Entry point address in the header, which tell GDB to know the first instruction to be executed ENTRY(address) MEMORY command Describe different memory parts in the system. Linker uses this information to calculate address MEMORY { name (attribute): ORIGIN = <address>, LENGTH = <size> } SECTIONS command Create memory layout by creating section name, section order. In each section, choose which data is used, how data is stored, and loaded. Location Counter is a special symbol denoted by a dot . . Linker will automatically update it with current location information. A variable can be used to save location to mark boundaries. Location counter can be set also. SECTIONS { <symbol> = LOADADDR(<symbol>); .<section>: { <symbol> = .; *(.sub_section); . = ALIGN(n); } ><Run Location> [AT> Storage Location] } Here is the linker script: linker.ld ENTRY ( Reset_Handler ) MEMORY { RAM ( xrw ) : ORIGIN = 0x20000000 , LENGTH = 128 K FLASH ( rx ) : ORIGIN = 0x08000000 , LENGTH = 512 K } _estack = ORIGIN ( RAM ) + LENGTH ( RAM ) ; SECTIONS { .isr_vector : { *( .isr_vector ) } > FLASH .text : { *( .text ) _etext = . ; } > FLASH .rodata : { *( .rodata ) } > FLASH _lddata = LOADADDR (. data ) ; .data : { _sdata = . ; *( .data ) _edata = . ; } > RAM AT > FLASH .bss : { _sbss = . ; *( .bss ) _ebss = . ; } > RAM } In the Linker Script, we define some symbols: _etext : End address of .text section _lddata : Load address (from Flash) of .data section _sdata : Start address of .data section _edata : End address of .data section _sbss : Start address of .bss section _ebss : End address of .bss section To build with Linker script, use -T <linkerfile> . The option -Wl,-Map=<output> to show the full memory mapping. arm-none-eabi-gcc \\ -mcpu = cortex-m4 -mthumb -mfloat-abi = soft \\ -std = gnu11 \\ -nostdlib \\ -Wall \\ -T linker.ld -Wl,-Map = main.tmp.map \\ main.o delay.o \\ -o main.tmp Open the file main.tmp.map to see the addresses assigned to symbols in the linker scripts. main.tmp.map Memory Configuration Name Origin Length Attributes RAM 0x0000000020000000 0x0000000000020000 xrw FLASH 0x0000000008000000 0x0000000000080000 xr * default * 0x0000000000000000 0xffffffffffffffff Linker script and memory map LOAD main . o LOAD delay . o 0x0000000020020000 _estack = ( ORIGIN ( RAM ) + LENGTH ( RAM )) . isr_vector * (. isr_vector ) . text 0x0000000008000000 0x94 * (. text ) . text 0x0000000008000000 0x68 main . o 0x0000000008000000 main . text 0x0000000008000068 0x2c delay . o 0x0000000008000068 delay 0x0000000008000094 _etext = . . glue_7 0x0000000008000094 0x0 . glue_7 0x0000000008000094 0x0 linker stubs . glue_7t 0x0000000008000094 0x0 . glue_7t 0x0000000008000094 0x0 linker stubs . vfp11_veneer 0x0000000008000094 0x0 . vfp11_veneer 0x0000000008000094 0x0 linker stubs . v4_bx 0x0000000008000094 0x0 . v4_bx 0x0000000008000094 0x0 linker stubs . iplt 0x0000000008000094 0x0 . iplt 0x0000000008000094 0x0 main . o . rodata 0x0000000008000094 0x4 * (. rodata ) . rodata 0x0000000008000094 0x4 delay . o 0x0000000008000094 DELAY_MAX 0x0000000008000098 _lddata = LOADADDR (. data ) . rel . dyn 0x0000000008000098 0x0 . rel . iplt 0x0000000008000098 0x0 main . o . data 0x0000000020000000 0x4 load address 0x0000000008000098 0x0000000020000000 _sdata = . * (. data ) . data 0x0000000020000000 0x4 main . o 0x0000000020000000 isLoop . data 0x0000000020000004 0x0 delay . o 0x0000000020000004 _edata = . . igot . plt 0x0000000020000004 0x0 load address 0x000000000800009c . igot . plt 0x0000000020000004 0x0 main . o . bss 0x0000000020000004 0x4 load address 0x000000000800009c 0x0000000020000004 _sbss = . * (. bss ) . bss 0x0000000020000004 0x0 main . o . bss 0x0000000020000004 0x4 delay . o 0x0000000020000004 delay_counter 0x0000000020000008 _ebss = . OUTPUT ( main . tmp elf32 - littlearm ) LOAD linker stubs . comment 0x0000000000000000 0x39 . comment 0x0000000000000000 0x39 main . o 0x3a ( size before relaxing ) . comment 0x0000000000000039 0x3a delay . o . ARM . attributes 0x0000000000000000 0x2e . ARM . attributes 0x0000000000000000 0x2e main . o . ARM . attributes 0x000000000000002e 0x2e delay . o The section .data started at 0x20000000 (loaded at 0x08000098 ) is only 4 bytes for uint32_t isLoop = 1 ; . The section .bss started at 0x20000004 (loaded at 0x0800009c ) is 4 bytes for uint32_t delay_counter . The section .rodata started at 0x08000094 is 4 bytes for const uint32_t DELAY_MAX = 0x0000BEEF ; To find the symbols and their addresses : arm-none-eabi-nm main.tmp main.tmp.sym 20000008 B _ebss 20000004 D _edata 20020000 T _estack 08000094 T _etext 08000098 A _lddata 20000004 B _sbss 20000000 D _sdata 08000068 T delay 20000004 B delay_counter 08000094 R DELAY_MAX 20000000 D isLoop 08000000 T main U Reset_Handler","title":"Linker and Locator"},{"location":"blog/stm32/compilation/#linker-symbols","text":"BinUtils Source Code Reference document Accessing a linker script defined variable from source code is not intuitive. In particular a linker script symbol is not equivalent to a variable declaration in a high level language, it is instead a symbol that does not have a value. Before going further, it is important to note that compilers often transform names in the source code into different names when they are stored in the symbol table. For example, Fortran compilers commonly prepend or append an underscore, and C++ performs extensive name mangling . Therefore there might be a discrepancy between the name of a variable as it is used in source code and the name of the same variable as it is defined in a linker script. For example in C a linker script variable might be referred to as: extern int foo ; But in the linker script it might be defined as: _foo = 1000 ; In the remaining examples however it is assumed that no name transformation has taken place. When a symbol is declared in a high level language such as C, two things happen: The first is that the compiler reserves enough space in the program\u2019s memory to hold the value of the symbol. The second is that the compiler creates an entry in the program\u2019s symbol table which holds the symbol\u2019s address. ie the symbol table contains the address of the block of memory holding the symbol\u2019s value. So for example the following C declaration, at file scope: int foo = 1000 ; creates an entry called foo in the symbol table. This entry holds the address of an int sized block of memory where the number 1000 is initially stored. When a program references a symbol the compiler generates code that first accesses the symbol table to find the address of the symbol\u2019s memory block and then code to read the value from that memory block. So: foo = 1 ; looks up the symbol foo in the symbol table, gets the address associated with this symbol and then writes the value 1 into that address. Whereas: int * a = & foo ; looks up the symbol foo in the symbol table, gets its address and then copies this address into the block of memory associated with the variable a . Linker scripts symbol declarations, by contrast, create an entry in the symbol table but do not assign any memory to them. Thus they are an address without a value. So for example the linker script definition: foo = 1000 ; creates an entry in the symbol table called foo which holds the address of memory location 1000 , but nothing special is stored at address 1000 . This means that you cannot access the value of a linker script defined symbol - it has no value - all you can do is access the address of a linker script defined symbol. Hence, when you are using a linker script defined symbol in source code you should always take the address of the symbol , and never attempt to use its value. For example suppose you want to copy the contents of a section of memory called .ROM into a section called .FLASH and the linker script contains these declarations: start_of_ROM = . ROM ; end_of_ROM = . ROM + sizeof (. ROM ); start_of_FLASH = . FLASH ; Then the C source code to perform the copy would be as below. Note the use of the & operators. These are correct. extern char start_of_ROM , end_of_ROM , start_of_FLASH ; memcpy ( & start_of_FLASH , & start_of_ROM , & end_of_ROM - & start_of_ROM ); Alternatively the symbols can be treated as the names of vectors or arrays and then the code will again work as expected: extern char start_of_ROM [], end_of_ROM [], start_of_FLASH []; memcpy ( start_of_FLASH , start_of_ROM , end_of_ROM - start_of_ROM ); Note how using this method does not require the use of & operators.","title":"Linker Symbols"},{"location":"blog/stm32/compilation/#vector-table","text":"On reset, the processor loads the MSP with the value from address 0x00000000 , then starts code execution from the memory at 0x00000004 which must be the Reset_Handler function. There are 15 system exceptions, included Reset Handler, and there are up-to 240 interruptions. The Table 37. Vector table for STM32F411xC/E in the document RM0383: Reference manual STM32F411xC/E advanced Arm\u00ae-based 32-bit MCUs shows the supported Exceptions and Interrupts: Vector table for F411xC/E vector.c #include <stdint.h> #define RAM_START 0x20000000 #define RAM_SIZE 128 * 1024 #define RAM_END ((RAM_START) + (RAM_SIZE)) void Default_Handler ( void ) { while ( 1 ) {} } void Reset_Handler ( void ) __attribute__ (( weak , alias ( \"Default_Handler\" ))); void NMI_Handler ( void ) __attribute__ (( weak , alias ( \"Default_Handler\" ))); void HardFault_Handler ( void ) __attribute__ (( weak , alias ( \"Default_Handler\" ))); void MemManage_Handler ( void ) __attribute__ (( weak , alias ( \"Default_Handler\" ))); void BusFault_Handler ( void ) __attribute__ (( weak , alias ( \"Default_Handler\" ))); void UsageFault_Handler ( void ) __attribute__ (( weak , alias ( \"Default_Handler\" ))); void SVC_Handler ( void ) __attribute__ (( weak , alias ( \"Default_Handler\" ))); void DebugMon_Handler ( void ) __attribute__ (( weak , alias ( \"Default_Handler\" ))); void PendSV_Handler ( void ) __attribute__ (( weak , alias ( \"Default_Handler\" ))); void SysTick_Handler ( void ) __attribute__ (( weak , alias ( \"Default_Handler\" ))); void WWDG_IRQHandler ( void ) __attribute__ (( weak , alias ( \"Default_Handler\" ))); void PVD_IRQHandler ( void ) __attribute__ (( weak , alias ( \"Default_Handler\" ))); void TAMP_STAMP_IRQHandler ( void ) __attribute__ (( weak , alias ( \"Default_Handler\" ))); void RTC_WKUP_IRQHandler ( void ) __attribute__ (( weak , alias ( \"Default_Handler\" ))); void FLASH_IRQHandler ( void ) __attribute__ (( weak , alias ( \"Default_Handler\" ))); void RCC_IRQHandler ( void ) __attribute__ (( weak , alias ( \"Default_Handler\" ))); void EXTI0_IRQHandler ( void ) __attribute__ (( weak , alias ( \"Default_Handler\" ))); void EXTI1_IRQHandler ( void ) __attribute__ (( weak , alias ( \"Default_Handler\" ))); void EXTI2_IRQHandler ( void ) __attribute__ (( weak , alias ( \"Default_Handler\" ))); void EXTI3_IRQHandler ( void ) __attribute__ (( weak , alias ( \"Default_Handler\" ))); void EXTI4_IRQHandler ( void ) __attribute__ (( weak , alias ( \"Default_Handler\" ))); void DMA1_Stream0_IRQHandler ( void ) __attribute__ (( weak , alias ( \"Default_Handler\" ))); void DMA1_Stream1_IRQHandler ( void ) __attribute__ (( weak , alias ( \"Default_Handler\" ))); void DMA1_Stream2_IRQHandler ( void ) __attribute__ (( weak , alias ( \"Default_Handler\" ))); void DMA1_Stream3_IRQHandler ( void ) __attribute__ (( weak , alias ( \"Default_Handler\" ))); void DMA1_Stream4_IRQHandler ( void ) __attribute__ (( weak , alias ( \"Default_Handler\" ))); void DMA1_Stream5_IRQHandler ( void ) __attribute__ (( weak , alias ( \"Default_Handler\" ))); void DMA1_Stream6_IRQHandler ( void ) __attribute__ (( weak , alias ( \"Default_Handler\" ))); void ADC_IRQHandler ( void ) __attribute__ (( weak , alias ( \"Default_Handler\" ))); void EXTI9_5_IRQHandler ( void ) __attribute__ (( weak , alias ( \"Default_Handler\" ))); void TIM1_BRK_TIM9_IRQHandler ( void ) __attribute__ (( weak , alias ( \"Default_Handler\" ))); void TIM1_UP_TIM10_IRQHandler ( void ) __attribute__ (( weak , alias ( \"Default_Handler\" ))); void TIM1_TRG_COM_TIM11_IRQHandler ( void ) __attribute__ (( weak , alias ( \"Default_Handler\" ))); void TIM1_CC_IRQHandler ( void ) __attribute__ (( weak , alias ( \"Default_Handler\" ))); void TIM2_IRQHandler ( void ) __attribute__ (( weak , alias ( \"Default_Handler\" ))); void TIM3_IRQHandler ( void ) __attribute__ (( weak , alias ( \"Default_Handler\" ))); void TIM4_IRQHandler ( void ) __attribute__ (( weak , alias ( \"Default_Handler\" ))); void I2C1_EV_IRQHandler ( void ) __attribute__ (( weak , alias ( \"Default_Handler\" ))); void I2C1_ER_IRQHandler ( void ) __attribute__ (( weak , alias ( \"Default_Handler\" ))); void I2C2_EV_IRQHandler ( void ) __attribute__ (( weak , alias ( \"Default_Handler\" ))); void I2C2_ER_IRQHandler ( void ) __attribute__ (( weak , alias ( \"Default_Handler\" ))); void SPI1_IRQHandler ( void ) __attribute__ (( weak , alias ( \"Default_Handler\" ))); void SPI2_IRQHandler ( void ) __attribute__ (( weak , alias ( \"Default_Handler\" ))); void USART1_IRQHandler ( void ) __attribute__ (( weak , alias ( \"Default_Handler\" ))); void USART2_IRQHandler ( void ) __attribute__ (( weak , alias ( \"Default_Handler\" ))); void EXTI15_10_IRQHandler ( void ) __attribute__ (( weak , alias ( \"Default_Handler\" ))); void RTC_Alarm_IRQHandler ( void ) __attribute__ (( weak , alias ( \"Default_Handler\" ))); void OTG_FS_WKUP_IRQHandler ( void ) __attribute__ (( weak , alias ( \"Default_Handler\" ))); void DMA1_Stream7_IRQHandler ( void ) __attribute__ (( weak , alias ( \"Default_Handler\" ))); void SDIO_IRQHandler ( void ) __attribute__ (( weak , alias ( \"Default_Handler\" ))); void TIM5_IRQHandler ( void ) __attribute__ (( weak , alias ( \"Default_Handler\" ))); void SPI3_IRQHandler ( void ) __attribute__ (( weak , alias ( \"Default_Handler\" ))); void DMA2_Stream0_IRQHandler ( void ) __attribute__ (( weak , alias ( \"Default_Handler\" ))); void DMA2_Stream1_IRQHandler ( void ) __attribute__ (( weak , alias ( \"Default_Handler\" ))); void DMA2_Stream2_IRQHandler ( void ) __attribute__ (( weak , alias ( \"Default_Handler\" ))); void DMA2_Stream3_IRQHandler ( void ) __attribute__ (( weak , alias ( \"Default_Handler\" ))); void DMA2_Stream4_IRQHandler ( void ) __attribute__ (( weak , alias ( \"Default_Handler\" ))); void OTG_FS_IRQHandler ( void ) __attribute__ (( weak , alias ( \"Default_Handler\" ))); void DMA2_Stream5_IRQHandler ( void ) __attribute__ (( weak , alias ( \"Default_Handler\" ))); void DMA2_Stream6_IRQHandler ( void ) __attribute__ (( weak , alias ( \"Default_Handler\" ))); void DMA2_Stream7_IRQHandler ( void ) __attribute__ (( weak , alias ( \"Default_Handler\" ))); void USART6_IRQHandler ( void ) __attribute__ (( weak , alias ( \"Default_Handler\" ))); void I2C3_EV_IRQHandler ( void ) __attribute__ (( weak , alias ( \"Default_Handler\" ))); void I2C3_ER_IRQHandler ( void ) __attribute__ (( weak , alias ( \"Default_Handler\" ))); void FPU_IRQHandler ( void ) __attribute__ (( weak , alias ( \"Default_Handler\" ))); void SPI4_IRQHandler ( void ) __attribute__ (( weak , alias ( \"Default_Handler\" ))); void SPI5_IRQHandler ( void ) __attribute__ (( weak , alias ( \"Default_Handler\" ))); __attribute__ (( section ( \".isr_vector\" ))) uint32_t vector_table [] = { ( uint32_t ) RAM_END , ( uint32_t ) Reset_Handler , ( uint32_t ) NMI_Handler , ( uint32_t ) HardFault_Handler , ( uint32_t ) MemManage_Handler , ( uint32_t ) BusFault_Handler , ( uint32_t ) UsageFault_Handler , ( uint32_t ) 0 , ( uint32_t ) 0 , ( uint32_t ) 0 , ( uint32_t ) 0 , ( uint32_t ) SVC_Handler , ( uint32_t ) DebugMon_Handler , ( uint32_t ) 0 , ( uint32_t ) PendSV_Handler , ( uint32_t ) SysTick_Handler , ( uint32_t ) WWDG_IRQHandler , ( uint32_t ) PVD_IRQHandler , ( uint32_t ) TAMP_STAMP_IRQHandler , ( uint32_t ) RTC_WKUP_IRQHandler , ( uint32_t ) FLASH_IRQHandler , ( uint32_t ) RCC_IRQHandler , ( uint32_t ) EXTI0_IRQHandler , ( uint32_t ) EXTI1_IRQHandler , ( uint32_t ) EXTI2_IRQHandler , ( uint32_t ) EXTI3_IRQHandler , ( uint32_t ) EXTI4_IRQHandler , ( uint32_t ) DMA1_Stream0_IRQHandler , ( uint32_t ) DMA1_Stream1_IRQHandler , ( uint32_t ) DMA1_Stream2_IRQHandler , ( uint32_t ) DMA1_Stream3_IRQHandler , ( uint32_t ) DMA1_Stream4_IRQHandler , ( uint32_t ) DMA1_Stream5_IRQHandler , ( uint32_t ) DMA1_Stream6_IRQHandler , ( uint32_t ) ADC_IRQHandler , ( uint32_t ) 0 , ( uint32_t ) 0 , ( uint32_t ) 0 , ( uint32_t ) 0 , ( uint32_t ) EXTI9_5_IRQHandler , ( uint32_t ) TIM1_BRK_TIM9_IRQHandler , ( uint32_t ) TIM1_UP_TIM10_IRQHandler , ( uint32_t ) TIM1_TRG_COM_TIM11_IRQHandler , ( uint32_t ) TIM1_CC_IRQHandler , ( uint32_t ) TIM2_IRQHandler , ( uint32_t ) TIM3_IRQHandler , ( uint32_t ) TIM4_IRQHandler , ( uint32_t ) I2C1_EV_IRQHandler , ( uint32_t ) I2C1_ER_IRQHandler , ( uint32_t ) I2C2_EV_IRQHandler , ( uint32_t ) I2C2_ER_IRQHandler , ( uint32_t ) SPI1_IRQHandler , ( uint32_t ) SPI2_IRQHandler , ( uint32_t ) USART1_IRQHandler , ( uint32_t ) USART2_IRQHandler , ( uint32_t ) 0 , ( uint32_t ) EXTI15_10_IRQHandler , ( uint32_t ) RTC_Alarm_IRQHandler , ( uint32_t ) OTG_FS_WKUP_IRQHandler , ( uint32_t ) 0 , ( uint32_t ) 0 , ( uint32_t ) 0 , ( uint32_t ) 0 , ( uint32_t ) DMA1_Stream7_IRQHandler , ( uint32_t ) 0 , ( uint32_t ) SDIO_IRQHandler , ( uint32_t ) TIM5_IRQHandler , ( uint32_t ) SPI3_IRQHandler , ( uint32_t ) 0 , ( uint32_t ) 0 , ( uint32_t ) 0 , ( uint32_t ) 0 , ( uint32_t ) DMA2_Stream0_IRQHandler , ( uint32_t ) DMA2_Stream1_IRQHandler , ( uint32_t ) DMA2_Stream2_IRQHandler , ( uint32_t ) DMA2_Stream3_IRQHandler , ( uint32_t ) DMA2_Stream4_IRQHandler , ( uint32_t ) 0 , ( uint32_t ) 0 , ( uint32_t ) 0 , ( uint32_t ) 0 , ( uint32_t ) 0 , ( uint32_t ) 0 , ( uint32_t ) OTG_FS_IRQHandler , ( uint32_t ) DMA2_Stream5_IRQHandler , ( uint32_t ) DMA2_Stream6_IRQHandler , ( uint32_t ) DMA2_Stream7_IRQHandler , ( uint32_t ) USART6_IRQHandler , ( uint32_t ) I2C3_EV_IRQHandler , ( uint32_t ) I2C3_ER_IRQHandler , ( uint32_t ) 0 , ( uint32_t ) 0 , ( uint32_t ) 0 , ( uint32_t ) 0 , ( uint32_t ) 0 , ( uint32_t ) 0 , ( uint32_t ) 0 , ( uint32_t ) FPU_IRQHandler , ( uint32_t ) 0 , ( uint32_t ) 0 , ( uint32_t ) SPI4_IRQHandler , ( uint32_t ) SPI5_IRQHandler , }; weak and alias attribute The exception handlers are user defined, so the Default Handler is only used in case the corresponding Handler is not implemented. section attribute Code can be assigned to a memory location by labeling the code with sections. Now, include the vector table in linker, you will see the section .isr_vector is now filled: arm-none-eabi-gcc \\ -mcpu = cortex-m4 -mthumb -mfloat-abi = soft \\ -std = gnu11 \\ -nostdlib \\ -Wall \\ -T linker.ld -Wl,-Map = vector.tmp.map \\ main.o delay.o vector.o \\ -o vector.tmp vector.tmp.map . isr_vector 0x0000000008000000 0x198 * (. isr_vector ) . isr_vector 0x0000000008000000 0x198 vector . o 0x0000000008000000 vector_table","title":"Vector Table"},{"location":"blog/stm32/compilation/#startup-code","text":"The startup code is responsible for setting up the right environment for the main code to run. Provide the vector table Implement Reset Handler Copy .data section from Flash to RAM Reserve memory for .bss section Call to main function startup.c #include <stdint.h> extern uint32_t _sdata ; extern uint32_t _edata ; extern uint32_t _lddata ; extern uint32_t _sbss ; extern uint32_t _ebss ; extern void main ( void ); void Reset_Handler ( void ) { // copy .data section from flash to ram uint32_t size = ( uint32_t ) & _edata - ( uint32_t ) & _sdata ; uint8_t * pRAM = ( uint8_t * ) & _sdata ; uint8_t * pFlash = ( uint8_t * ) & _lddata ; for ( int i = 0 ; i < size ; i ++ ) { pRAM [ i ] = pFlash [ i ]; } // initialize .bss section size = ( uint32_t ) & _ebss - ( uint32_t ) & _sbss ; pRAM = ( uint8_t * ) & _sbss ; for ( int i = 0 ; i < size ; i ++ ) { pRAM [ i ] = 0 ; } // call to main main (); }","title":"Startup code"},{"location":"blog/stm32/compilation/#examine-the-binary-file","text":"Build all files: arm-none-eabi-gcc \\ -mcpu = cortex-m4 -mthumb -mfloat-abi = soft \\ -std = gnu11 \\ -nostdlib \\ -Wall \\ -T linker.ld -Wl,-Map = main.elf.map \\ main.o delay.o vector.o startup.o \\ -o main.elf The elf file is a wrapper of a binary file because it contains extra metadata, such as the symbol table: arm-none-eabi-nm main.elf > main.elf.sym main.elf.sym 20000008 B _ebss 20000004 D _edata 20020000 D _estack 080002 b8 T _etext 080002 bc A _lddata 20000004 B _sbss 20000000 D _sdata 0800022 c W ADC_IRQHandler 0800022 c W BusFault_Handler 0800022 c W DebugMon_Handler 0800022 c T Default_Handler 08000200 T delay 20000004 B delay_counter 080002 b8 R DELAY_MAX 0800022 c W DMA1_Stream0_IRQHandler 0800022 c W DMA1_Stream1_IRQHandler 0800022 c W DMA1_Stream2_IRQHandler 0800022 c W DMA1_Stream3_IRQHandler 0800022 c W DMA1_Stream4_IRQHandler 0800022 c W DMA1_Stream5_IRQHandler 0800022 c W DMA1_Stream6_IRQHandler 0800022 c W DMA1_Stream7_IRQHandler 0800022 c W DMA2_Stream0_IRQHandler 0800022 c W DMA2_Stream1_IRQHandler 0800022 c W DMA2_Stream2_IRQHandler 0800022 c W DMA2_Stream3_IRQHandler 0800022 c W DMA2_Stream4_IRQHandler 0800022 c W DMA2_Stream5_IRQHandler 0800022 c W DMA2_Stream6_IRQHandler 0800022 c W DMA2_Stream7_IRQHandler 0800022 c W EXTI0_IRQHandler 0800022 c W EXTI1_IRQHandler 0800022 c W EXTI15_10_IRQHandler 0800022 c W EXTI2_IRQHandler 0800022 c W EXTI3_IRQHandler 0800022 c W EXTI4_IRQHandler 0800022 c W EXTI9_5_IRQHandler 0800022 c W FLASH_IRQHandler 0800022 c W FPU_IRQHandler 0800022 c W HardFault_Handler 0800022 c W I2C1_ER_IRQHandler 0800022 c W I2C1_EV_IRQHandler 0800022 c W I2C2_ER_IRQHandler 0800022 c W I2C2_EV_IRQHandler 0800022 c W I2C3_ER_IRQHandler 0800022 c W I2C3_EV_IRQHandler 20000000 D isLoop 08000198 T main 0800022 c W MemManage_Handler 0800022 c W NMI_Handler 0800022 c W OTG_FS_IRQHandler 0800022 c W OTG_FS_WKUP_IRQHandler 0800022 c W PendSV_Handler 0800022 c W PVD_IRQHandler 0800022 c W RCC_IRQHandler 08000234 T Reset_Handler 0800022 c W RTC_Alarm_IRQHandler 0800022 c W RTC_WKUP_IRQHandler 0800022 c W SDIO_IRQHandler 0800022 c W SPI1_IRQHandler 0800022 c W SPI2_IRQHandler 0800022 c W SPI3_IRQHandler 0800022 c W SPI4_IRQHandler 0800022 c W SPI5_IRQHandler 0800022 c W SVC_Handler 0800022 c W SysTick_Handler 0800022 c W TAMP_STAMP_IRQHandler 0800022 c W TIM1_BRK_TIM9_IRQHandler 0800022 c W TIM1_CC_IRQHandler 0800022 c W TIM1_TRG_COM_TIM11_IRQHandler 0800022 c W TIM1_UP_TIM10_IRQHandler 0800022 c W TIM2_IRQHandler 0800022 c W TIM3_IRQHandler 0800022 c W TIM4_IRQHandler 0800022 c W TIM5_IRQHandler 0800022 c W UsageFault_Handler 0800022 c W USART1_IRQHandler 0800022 c W USART2_IRQHandler 0800022 c W USART6_IRQHandler 08000000 D vector_table 0800022 c W WWDG_IRQHandler The Reset_Handler is at 0x08000234 , the Default_Handler is at 0x0800022c . Extract binary content : arm-none-eabi-objcopy -O binary main.elf main.bin Examine binary file Check isr_vector at 0x08000000 : group 4 bytes, use little-endian, start at 0, size 32 bytes xxd -g4 -e -s0 -l32 main.bin 00000000: 20020000 08000235 0800022d 0800022d ... 5...-...-... 00000010: 0800022d 0800022d 0800022d 00000000 -...-...-....... You will notice that: The MSP value at the address 0x00000000 is the RAN_END value 0x20020000 . The Reset Handler address is written at 0x00000004 , which is 0x08000235 (note that the LSB bit is 1 to indicate Thumb state). Let check the value of DELAY_MAX at the address 0x080002bc : xxd -g4 -e -s0x2bc -l4 main.bin 000002bc: 0000beef You will notice the constant value 0x0000BEEF is stored at that address. Review assembly code You can read the assembly code from the elf file using arm-none-eabi-objdump -S main.elf main.elf.s main.elf: file format elf32-littlearm Disassembly of section .text : 08000198 < main > : 8000198: b580 push { r7 , lr } 800019 a: af00 add r7 , sp , #0 800019 c: 4 b14 ldr r3 , [ pc , #80 ] ; (80001f0 <main+0x58>) 800019 e: 681 b ldr r3 , [ r3 , #0 ] 80001 a0: 4 a13 ldr r2 , [ pc , #76 ] ; (80001f0 <main+0x58>) 80001 a2: f043 0301 orr.w r3 , r3 , #1 80001 a6: 6013 str r3 , [ r2 , #0 ] 80001 a8: 4 b12 ldr r3 , [ pc , #72 ] ; (80001f4 <main+0x5c>) 80001 aa: 681 b ldr r3 , [ r3 , #0 ] 80001 ac: 4 a11 ldr r2 , [ pc , #68 ] ; (80001f4 <main+0x5c>) 80001 ae: f423 6300 bic.w r3 , r3 , #2048 ; 0x800 80001 b2: 6013 str r3 , [ r2 , #0 ] 80001 b4: 4 b0f ldr r3 , [ pc , #60 ] ; (80001f4 <main+0x5c>) 80001 b6: 681 b ldr r3 , [ r3 , #0 ] 80001 b8: 4 a0e ldr r2 , [ pc , #56 ] ; (80001f4 <main+0x5c>) 80001 ba: f443 6380 orr.w r3 , r3 , #1024 ; 0x400 80001 be: 6013 str r3 , [ r2 , #0 ] 80001 c0: e00f b.n 80001e2 < main + 0x4a > 80001 c2: 4 b0d ldr r3 , [ pc , #52 ] ; (80001f8 <main+0x60>) 80001 c4: 681 b ldr r3 , [ r3 , #0 ] 80001 c6: 4 a0c ldr r2 , [ pc , #48 ] ; (80001f8 <main+0x60>) 80001 c8: f043 0320 orr.w r3 , r3 , #32 80001 cc: 6013 str r3 , [ r2 , #0 ] 80001 ce: f000 f817 bl 8000200 < delay > 80001 d2: 4 b09 ldr r3 , [ pc , #36 ] ; (80001f8 <main+0x60>) 80001 d4: 681 b ldr r3 , [ r3 , #0 ] 80001 d6: 4 a08 ldr r2 , [ pc , #32 ] ; (80001f8 <main+0x60>) 80001 d8: f443 1300 orr.w r3 , r3 , #2097152 ; 0x200000 80001 dc: 6013 str r3 , [ r2 , #0 ] 80001 de: f000 f80f bl 8000200 < delay > 80001 e2: 4 b06 ldr r3 , [ pc , #24 ] ; (80001fc <main+0x64>) 80001 e4: 681 b ldr r3 , [ r3 , #0 ] 80001 e6: 2 b00 cmp r3 , #0 80001 e8: d1eb bne.n 80001c2 < main + 0x2a > 80001 ea: 2300 movs r3 , #0 80001 ec: 4618 mov r0 , r3 80001 ee: bd80 pop { r7 , pc } 80001 f0: 40023830 .word 0x40023830 80001 f4: 40020000 .word 0x40020000 80001 f8: 40020018 .word 0x40020018 80001 fc: 20000000 .word 0x20000000 08000200 < delay > : 8000200: b480 push { r7 } 8000202: af00 add r7 , sp , #0 8000204: f64b 62 ef movw r2 , #48879 ; 0xbeef 8000208: 4 b07 ldr r3 , [ pc , #28 ] ; (8000228 <delay+0x28>) 800020 a: 601 a str r2 , [ r3 , #0 ] 800020 c: bf00 nop 800020 e: 4 b06 ldr r3 , [ pc , #24 ] ; (8000228 <delay+0x28>) 8000210: 681 b ldr r3 , [ r3 , #0 ] 8000212: 1 e5a subs r2 , r3 , #1 8000214: 4904 ldr r1 , [ pc , #16 ] ; (8000228 <delay+0x28>) 8000216: 600 a str r2 , [ r1 , #0 ] 8000218: 2 b00 cmp r3 , #0 800021 a: d1f8 bne.n 800020e < delay + 0xe > 800021 c: bf00 nop 800021 e: bf00 nop 8000220: 46 bd mov sp , r7 8000222: bc80 pop { r7 } 8000224: 4770 bx lr 8000226: bf00 nop 8000228: 20000004 .word 0x20000004 0800022 c < Default_Handler > : 800022 c: b480 push { r7 } 800022 e: af00 add r7 , sp , #0 8000230: e7fe b.n 8000230 < Default_Handler + 0x4 > ... 08000234 < Reset_Handler > : 8000234: b580 push { r7 , lr } 8000236: b086 sub sp , #24 8000238: af00 add r7 , sp , #0 800023 a: 4 a1a ldr r2 , [ pc , #104 ] ; (80002a4 <Reset_Handler+0x70>) 800023 c: 4 b1a ldr r3 , [ pc , #104 ] ; (80002a8 <Reset_Handler+0x74>) 800023 e: 1 ad3 subs r3 , r2 , r3 8000240: 60 fb str r3 , [ r7 , #12 ] 8000242: 4 b19 ldr r3 , [ pc , #100 ] ; (80002a8 <Reset_Handler+0x74>) 8000244: 60 bb str r3 , [ r7 , #8 ] 8000246: 4 b19 ldr r3 , [ pc , #100 ] ; (80002ac <Reset_Handler+0x78>) 8000248: 607 b str r3 , [ r7 , #4 ] 800024 a: 2300 movs r3 , #0 800024 c: 617 b str r3 , [ r7 , #20 ] 800024 e: e00a b.n 8000266 < Reset_Handler + 0x32 > 8000250: 697 b ldr r3 , [ r7 , #20 ] 8000252: 687 a ldr r2 , [ r7 , #4 ] 8000254: 441 a add r2 , r3 8000256: 697 b ldr r3 , [ r7 , #20 ] 8000258: 68 b9 ldr r1 , [ r7 , #8 ] 800025 a: 440 b add r3 , r1 800025 c: 7812 ldrb r2 , [ r2 , #0 ] 800025 e: 701 a strb r2 , [ r3 , #0 ] 8000260: 697 b ldr r3 , [ r7 , #20 ] 8000262: 3301 adds r3 , #1 8000264: 617 b str r3 , [ r7 , #20 ] 8000266: 697 b ldr r3 , [ r7 , #20 ] 8000268: 68 fa ldr r2 , [ r7 , #12 ] 800026 a: 429 a cmp r2 , r3 800026 c: d8f0 bhi.n 8000250 < Reset_Handler + 0x1c > 800026 e: 4 a10 ldr r2 , [ pc , #64 ] ; (80002b0 <Reset_Handler+0x7c>) 8000270: 4 b10 ldr r3 , [ pc , #64 ] ; (80002b4 <Reset_Handler+0x80>) 8000272: 1 ad3 subs r3 , r2 , r3 8000274: 60 fb str r3 , [ r7 , #12 ] 8000276: 4 b0f ldr r3 , [ pc , #60 ] ; (80002b4 <Reset_Handler+0x80>) 8000278: 60 bb str r3 , [ r7 , #8 ] 800027 a: 2300 movs r3 , #0 800027 c: 613 b str r3 , [ r7 , #16 ] 800027 e: e007 b.n 8000290 < Reset_Handler + 0x5c > 8000280: 693 b ldr r3 , [ r7 , #16 ] 8000282: 68 ba ldr r2 , [ r7 , #8 ] 8000284: 4413 add r3 , r2 8000286: 2200 movs r2 , #0 8000288: 701 a strb r2 , [ r3 , #0 ] 800028 a: 693 b ldr r3 , [ r7 , #16 ] 800028 c: 3301 adds r3 , #1 800028 e: 613 b str r3 , [ r7 , #16 ] 8000290: 693 b ldr r3 , [ r7 , #16 ] 8000292: 68 fa ldr r2 , [ r7 , #12 ] 8000294: 429 a cmp r2 , r3 8000296: d8f3 bhi.n 8000280 < Reset_Handler + 0x4c > 8000298: f7ff ff7e bl 8000198 < main > 800029 c: bf00 nop 800029 e: 3718 adds r7 , #24 80002 a0: 46 bd mov sp , r7 80002 a2: bd80 pop { r7 , pc } 80002 a4: 20000004 .word 0x20000004 80002 a8: 20000000 .word 0x20000000 80002 ac: 080002 bc .word 0x080002bc 80002 b0: 20000008 .word 0x20000008 80002 b4: 20000004 .word 0x20000004","title":"Examine the binary file"},{"location":"blog/stm32/compilation/#download-and-debug","text":"Run OpenOCD Each target has its own configurations, such as _CPUTAPID , _ENDIAN , or Debug registers. You will need this configuration file to work with your target. For example, target an STM32F411 MCU: stm32f4x.cfg # script for stm32f4x family # # stm32 devices support both JTAG and SWD transports. # source [find target/swj-dp.tcl] source [find mem_helper.tcl] if { [info exists CHIPNAME] } { set _CHIPNAME $CHIPNAME } else { set _CHIPNAME stm32f4x } set _ENDIAN little # Work-area is a space in RAM used for flash programming # By default use 32kB (Available RAM in smallest device STM32F410) if { [info exists WORKAREASIZE] } { set _WORKAREASIZE $WORKAREASIZE } else { set _WORKAREASIZE 0x8000 } #jtag scan chain if { [info exists CPUTAPID] } { set _CPUTAPID $CPUTAPID } else { if { [using_jtag] } { # See STM Document RM0090 # Section 38.6.3 - corresponds to Cortex-M4 r0p1 set _CPUTAPID 0x4ba00477 } { set _CPUTAPID 0x2ba01477 } } swj_newdap $_CHIPNAME cpu -irlen 4 -ircapture 0x1 -irmask 0xf -expected-id $_CPUTAPID dap create $_CHIPNAME.dap -chain-position $_CHIPNAME.cpu tpiu create $_CHIPNAME.tpiu -dap $_CHIPNAME.dap -ap-num 0 -baseaddr 0xE0040000 if {[using_jtag]} { jtag newtap $_CHIPNAME bs -irlen 5 } set _TARGETNAME $_CHIPNAME.cpu target create $_TARGETNAME cortex_m -endian $_ENDIAN -dap $_CHIPNAME.dap $_TARGETNAME configure -work-area-phys 0x20000000 -work-area-size $_WORKAREASIZE -work-area-backup 0 set _FLASHNAME $_CHIPNAME.flash flash bank $_FLASHNAME stm32f2x 0 0 0 0 $_TARGETNAME flash bank $_CHIPNAME.otp stm32f2x 0x1fff7800 0 0 0 $_TARGETNAME if { [info exists QUADSPI] && $QUADSPI } { set a [llength [flash list]] set _QSPINAME $_CHIPNAME.qspi flash bank $_QSPINAME stmqspi 0x90000000 0 0 0 $_TARGETNAME 0xA0001000 } # JTAG speed should be <= F_CPU/6. F_CPU after reset is 16MHz, so use F_JTAG = 2MHz # # Since we may be running of an RC oscilator, we crank down the speed a # bit more to be on the safe side. Perhaps superstition, but if are # running off a crystal, we can run closer to the limit. Note # that there can be a pretty wide band where things are more or less stable. adapter speed 2000 adapter srst delay 100 if {[using_jtag]} { jtag_ntrst_delay 100 } reset_config srst_nogate if {![using_hla]} { # if srst is not fitted use SYSRESETREQ to # perform a soft reset cortex_m reset_config sysresetreq } $_TARGETNAME configure -event examine-end { # Enable debug during low power modes (uses more power) # DBGMCU_CR |= DBG_STANDBY | DBG_STOP | DBG_SLEEP mmw 0xE0042004 0x00000007 0 # Stop watchdog counters during halt # DBGMCU_APB1_FZ |= DBG_IWDG_STOP | DBG_WWDG_STOP mmw 0xE0042008 0x00001800 0 } proc proc_post_enable {_chipname} { targets $_chipname.cpu if { [$_chipname.tpiu cget -protocol] eq \"sync\" } { switch [$_chipname.tpiu cget -port-width] { 1 { mmw 0xE0042004 0x00000060 0x000000c0 mmw 0x40021020 0x00000000 0x0000ff00 mmw 0x40021000 0x000000a0 0x000000f0 mmw 0x40021008 0x000000f0 0x00000000 } 2 { mmw 0xE0042004 0x000000a0 0x000000c0 mmw 0x40021020 0x00000000 0x000fff00 mmw 0x40021000 0x000002a0 0x000003f0 mmw 0x40021008 0x000003f0 0x00000000 } 4 { mmw 0xE0042004 0x000000e0 0x000000c0 mmw 0x40021020 0x00000000 0x0fffff00 mmw 0x40021000 0x00002aa0 0x00003ff0 mmw 0x40021008 0x00003ff0 0x00000000 } } } else { mmw 0xE0042004 0x00000020 0x000000c0 } } $_CHIPNAME.tpiu configure -event post-enable \"proc_post_enable $_CHIPNAME\" $_TARGETNAME configure -event reset-init { # Configure PLL to boost clock to HSI x 4 (64 MHz) mww 0x40023804 0x08012008 ;# RCC_PLLCFGR 16 Mhz /8 (M) * 128 (N) /4(P) mww 0x40023C00 0x00000102 ;# FLASH_ACR = PRFTBE | 2(Latency) mmw 0x40023800 0x01000000 0 ;# RCC_CR |= PLLON sleep 10 ;# Wait for PLL to lock mmw 0x40023808 0x00001000 0 ;# RCC_CFGR |= RCC_CFGR_PPRE1_DIV2 mmw 0x40023808 0x00000002 0 ;# RCC_CFGR |= RCC_CFGR_SW_PLL # Boost JTAG frequency adapter speed 8000 } $_TARGETNAME configure -event reset-start { # Reduce speed since CPU speed will slow down to 16MHz with the reset adapter speed 2000 } On a board with an ST Link debugger: board.cfg source [find interface/stlink.cfg] transport select hla_swd # increase working area to 64KB set WORKAREASIZE 0x10000 source [find target/stm32f4x.cfg] reset_config srst_only You can use any STM32 compatible debuggers such as ST_Link V\u2154, J-Link to connect with Serial Wire Debug (SWD) interface on the target MCU. Debugging a target board openocd -f board.cfg xPack OpenOCD x86_64 Open On-Chip Debugger 0.11.0+dev (2022-03-25-17:32) Licensed under GNU GPL v2 For bug reports, read http://openocd.org/doc/doxygen/bugs.html Info : The selected transport took over low-level target control. The results might differ compared to plain JTAG/SWD srst_only separate srst_nogate srst_open_drain connect_deassert_srst Info : Listening on port 6666 for tcl connections Info : Listening on port 4444 for telnet connections Info : clock speed 2000 kHz Info : STLINK V2J39M27 (API v2) VID:PID 0483:374B Info : Target voltage: 3.276040 Info : [stm32f4x.cpu] Cortex-M4 r0p1 processor detected Info : [stm32f4x.cpu] target has 6 breakpoints, 4 watchpoints Info : starting gdb server for stm32f4x.cpu on 3333 Info : Listening on port 3333 for gdb connections OpenOCD Commands are available online and examples. Telnet client Run Telnet: Run the Telnet client: telnet 127 .0.0.1 4444 Telnet is used access to OpenOCD server and use OpenOCD commands directly. flash write_image erase main.elf reset halt resume Use Telnet to connect to OpenOCD GDB Client Prepare a debug version with -g option, named it main-debug.elf arm-none-eabi-gcc \\ -mcpu = cortex-m4 -mthumb -mfloat-abi = soft \\ -nostdlib \\ -std = gnu11 \\ -Wall \\ -g \\ -T linker.ld -Wl,-Map = main-debug.elf.map \\ main.c delay.c vector.c startup.c \\ -o main-debug.elf Run the GDB client with debug version: arm-none-eabi-gdb main-debug.elf Then connect to OpenOCD server: target extended-remote localhost:3333 All OpenOCD command must be start with monitor tag (gdb) monitor flash write_image erase main.elf monitor reset halt monitor resume GDB has its own command set, you can use it too: (gdb) br main step Use GDB to connect to OpenOCD","title":"Download and Debug"},{"location":"blog/stm32/compilation/#use-standard-library","text":"newlib-nano.zip Let see a new example that uses the standard library. The source code is from the above example, but added some mofifications: Add stdio.h library for using printf() function Use Semihosting for output if macro USE_SEMIHOSTING is defined #include <stdint.h> #include <stdio.h> #include \"delay.h\" /* Clock */ #define RCC_AHB1ENR *((volatile uint32_t*) (0x40023830)) /* GPIO A */ #define GPIOA_MODER *((volatile uint32_t*) (0x40020000)) #define GPIOA_BSRR *((volatile uint32_t*) (0x40020018)) /* Global initialized variable */ uint32_t isLoop = 1 ; #ifdef USE_SEMIHOSTING /* Semohosting */ extern void initialise_monitor_handles ( void ); #endif int main () { char counter = 0 ; #ifdef USE_SEMIHOSTING initialise_monitor_handles (); #endif /* turn on clock on GPIOA */ RCC_AHB1ENR |= ( 1 << 0 ); /* set PA5 to output mode */ GPIOA_MODER &= ~ ( 1 << 11 ); GPIOA_MODER |= ( 1 << 10 ); while ( isLoop ) { /* set HIGH on PA5 */ GPIOA_BSRR |= ( 1 << 5 ); delay (); /* set LOW on PA5 */ GPIOA_BSRR |= ( 1 << ( 5 + 16 )); delay (); /* output */ printf ( \"counter = %d \\n \" , counter ); counter ++ ; } return 0 ; } Let try to compile: arm-none-eabi-gcc \\ -mcpu = cortex-m4 -mthumb -mfloat-abi = soft \\ -std = gnu11 \\ -Wall \\ -T linker.ld -Wl,-Map = main.elf.map \\ main.c delay.c vector.c startup.c \\ -o main.elf \\crt0.o: in function `_mainCRTStartup': (.text+0x64): undefined reference to `__bss_start__' (.text+0x68): undefined reference to `__bss_end__' \\libc.a(lib_a-exit.o): in function `exit': (.text.exit+0x16): undefined reference to `_exit' \\libc.a(lib_a-sbrkr.o): in function `_sbrk_r': (.text._sbrk_r+0xc): undefined reference to `_sbrk' \\libc.a(lib_a-writer.o): in function `_write_r': (.text._write_r+0x14): undefined reference to `_write' \\libc.a(lib_a-closer.o): in function `_close_r': (.text._close_r+0xc): undefined reference to `_close' \\libc.a(lib_a-fstatr.o): in function `_fstat_r': (.text._fstat_r+0x12): undefined reference to `_fstat' \\libc.a(lib_a-isattyr.o): in function `_isatty_r': (.text._isatty_r+0xc): undefined reference to `_isatty' \\libc.a(lib_a-lseekr.o): in function `_lseek_r': (.text._lseek_r+0x14): undefined reference to `_lseek' \\libc.a(lib_a-readr.o): in function `_read_r': (.text._read_r+0x14): undefined reference to `_read' \\libc.a(lib_a-abort.o): in function `abort': (.text.abort+0xa): undefined reference to `_exit' \\libc.a(lib_a-signalr.o): in function `_kill_r': (.text._kill_r+0x12): undefined reference to `_kill' \\libc.a(lib_a-signalr.o): in function `_getpid_r': (.text._getpid_r+0x0): undefined reference to `_getpid' \\libgcc.a(unwind-arm.o): in function `get_eit_entry': (.text.get_eit_entry+0x90): undefined reference to `__exidx_start' (.text.get_eit_entry+0x94): undefined reference to `__exidx_end' We see that the compiler link to the libc by default. Standard C libraries GNU ARM libraries use newlib to provide standard implementation of C libraries. To reduce the code size and make it independent to hardware, there is a lightweight version newlib-nano used in MCUs. However, newlib-nano does not provide an implementation of low-level system calls which are used by C standard libraries, such as print() or scan() . To make the application compilable, a new library named nosys should be added. This library just provide a simple implementation of low-level system calls which mostly return a by-pass value. The lib newlib-nano is enabled via linker options --specs=nano.specs , and nosys is enabled via linker option --specs=nosys.specs . These two libraries are included by default in GCC linker options in generated project, check it here . arm-none-eabi-gcc \\ -mcpu = cortex-m4 -mthumb -mfloat-abi = soft \\ -std = gnu11 \\ --specs = nano.specs --specs = nosys.specs \\ -Wall \\ -T linker.ld -Wl,-Map = main.elf.map \\ main.c delay.c vector.c startup.c \\ -o main.elf \\crt0.o: in function `_mainCRTStartup': (.text+0x64): undefined reference to `__bss_start__' (.text+0x68): undefined reference to `__bss_end__' \\libnosys.a(sbrk.o): in function `_sbrk': (.text._sbrk+0x18): undefined reference to `end' There are still few errors that need fixed in Linker script. Let download the source code of newlib from newlib ftp directory . Search for __bss_start__ , __bss_start__ and you can see a note: * `mcore/crt0.S` : Renamed file from `crt0.s` . Only invoke `init()` and `fini()` routines for ELF builds. Use `__bss_start__` and `__bss_end__` to locate `.bss` section. Search for the function _sbrk you can see a note in source code, which mentions that end symbol should be end of heap. void * _sbrk ( ptrdiff_t incr ) { extern char end asm ( \"end\" ); /* Defined by the linker. */ static char * heap_end ; char * prev_heap_end ; if ( heap_end == NULL ) heap_end = & end ;","title":"Use standard library"},{"location":"blog/stm32/compilation/#update-linker-sections","text":"The linker should update below sections: add alignment to each section include subsections, e.g. *(.text*) new heap section to check reserved memory for stack and heap linker.ld ENTRY ( Reset_Handler ) MEMORY { RAM ( xrw ) : ORIGIN = 0x20000000 , LENGTH = 128 K FLASH ( rx ) : ORIGIN = 0x08000000 , LENGTH = 512 K } _estack = ORIGIN ( RAM ) + LENGTH ( RAM ) ; _Min_Heap_Size = 0x200 ; /* required amount of heap */ _Min_Stack_Size = 0x400 ; /* required amount of stack */ SECTIONS { .isr_vector : { . = ALIGN ( 4 ) ; KEEP (*(. isr_vector )) /* Startup code */ . = ALIGN ( 4 ) ; } > FLASH .text : { . = ALIGN ( 4 ) ; *( .text ) *( .text *) *( .glue_7 ) /* glue arm to thumb code */ *( .glue_7t ) /* glue thumb to arm code */ *( .eh_frame ) KEEP (*(. init )) KEEP (*(. fini )) . = ALIGN ( 4 ) ; _etext = . ; } > FLASH .rodata : { . = ALIGN ( 4 ) ; *( .rodata ) *( .rodata *) . = ALIGN ( 4 ) ; } > FLASH .ARM : { . = ALIGN ( 4 ) ; __exidx_start = . ; *( .ARM.exidx *) __exidx_end = . ; . = ALIGN ( 4 ) ; } > FLASH _lddata = LOADADDR (. data ) ; .data : { . = ALIGN ( 4 ) ; _sdata = . ; *( .data ) *( .data *) . = ALIGN ( 4 ) ; _edata = . ; } > RAM AT > FLASH .bss : { . = ALIGN ( 4 ) ; _sbss = . ; __bss_start__ = _sbss ; *( .bss ) *( .bss. *) *( COMMON ) . = ALIGN ( 4 ) ; _ebss = . ; __bss_end__ = _ebss ; } > RAM ._user_heap_stack : { . = ALIGN ( 8 ) ; end = . ; _end = . ; __end__ = . ; . = . + _Min_Heap_Size ; . = . + _Min_Stack_Size ; . = ALIGN ( 8 ) ; } > RAM /* Remove information from the compiler libraries */ / DISCARD / : { libc.a ( * ) libm.a ( * ) libgcc.a ( * ) } .ARM.attributes 0 : { *(. ARM.attributes ) } }","title":"Update linker sections"},{"location":"blog/stm32/compilation/#update-startup-code","text":"startup.c #include <stdint.h> extern uint32_t _sdata ; extern uint32_t _edata ; extern uint32_t _lddata ; extern uint32_t _sbss ; extern uint32_t _ebss ; extern void main ( void ) ; extern void __libc_init_array ( void ) ; void Reset_Handler ( void ) { // copy .data section from flash to ram uint32_t size = ( uint32_t ) & _edata - ( uint32_t ) & _sdata ; uint8_t * pRAM = ( uint8_t *) & _sdata ; uint8_t * pFlash = ( uint8_t *) & _lddata ; for ( int i = 0 ; i<size; i++) { pRAM [ i ] = pFlash [ i ] ; } // initialize .bss section size = ( uint32_t ) & _ebss - ( uint32_t ) & _sbss ; pRAM = ( uint8_t *) & _sbss ; for ( int i = 0 ; i<size; i++) { pRAM [ i ] = 0 ; } // init libc __libc_init_array () ; // call to main main () ; }","title":"Update startup code"},{"location":"blog/stm32/compilation/#run-openocd-with-semihosting","text":"Compile with Semihosting: Use --specs=rdimon.specs Use -DUSE_SEMIHOSTING Use -lrdimon arm-none-eabi-gcc \\ -mcpu = cortex-m4 -mthumb -mfloat-abi = soft \\ -std = gnu11 \\ --specs = rdimon.specs \\ -Wall \\ -DUSE_SEMIHOSTING -T linker.ld -Wl,-Map = main.elf.map -lrdimon \\ main.c delay.c vector.c startup.c \\ -o main-semi.elf Run OpenOCD, and use Telnet to connect and run below command arm semihosting enable halt flash write_image erase main-semi.elf reset halt resume Use Semihosting with OpenOCD","title":"Run OpenOCD with Semihosting"},{"location":"blog/stm32/docs/","tags":["arm","stm32"],"text":"Datasheet (Product Specifications) # This document contains highlight of the target microprocessor with main features and capabilities . Many people are confused with Reference Manual, but when comparing the content, they are written for different purpose. This document is helpful when designing a PCB . It gives recommended layout for things like signal characteristic , NRST pin, ADC pins, Boot mode, etc. Datasheet provides the following: General description including product line, speed, memory, operating voltage, temperature range Device overview with block diagram, available peripherals and functions Pinouts and pin descriptions Memory map and memory ranges Electrical Characteristics Package information, for modeling PCB footprints Ordering Information Excerpt from DS10314 \u2014 STM32F411xC STM32F411xE Datasheet The system block diagram Boot modes At startup, the boot pin and boot selector option bit are used to select one of the three boot options: boot from User Flash memory boot from System Memory boot from embedded SRAM The bootloader is located in system memory. It is used to reprogram the Flash memory by using USART1(PA9/10), USART2(PD\u215a), USB OTG FS in device mode (PA11/12) through DFU (device firmware upgrade), I2C1(PB6/7), I2C2(PB10/3), I2C3(PA8/PB4), SPI1(PA\u2158/6/7), SPI2(PB12/13/14/15) or SPI3(PA15, PC10/11/12). For more detailed information on the bootloader, refer to Application Note: AN2606, STM32 microcontroller system memory boot mode. Pinout table I/O structure with marker FT for 5 V-tolerant I/O, TT or TC for 3.3 V-only I/O. Unless otherwise specified by a note, all I/Os are set as floating inputs during and after reset. The pinout description Alternate functions Memory map and boundary address Operating condition Speed modes on IO Reference Manual # This is by far the most important document in order to program the target device . It defines all information about the core and peripheral at register level with bit-by-bit description . By using only this document, developer still can program the chip without any higher level API \u2014 usually called Bare-metal/Register-based programming. Reference Manual provides the following: System Architecture with bus, peripherals, and connections Memory map and boundary address Boot configuration and vector table relocation Peripheral with details features, descriptions, and structure Register name and bit-fields for all accessible registers Code examples using CMSIS header files Excerpt from RM0383 \u2014 STM32F411xC/E advanced Arm\u00ae-based 32-bit MCUs System architecture for STM32F0x Boot configuration The boot mode configuration is latched on the 4 th rising edge of SYSCLK after a reset, and is also re-sampled when exiting from Standby mode. After this startup delay has elapsed, the CPU always fetches the top-of-stack value from address 0x00000000 , then starts code execution from the boot memory at 0x00000004 . Depending on the selected boot mode, main Flash memory, system memory or SRAM is accessible as follows: Boot from main Flash memory: the main Flash memory is aliased in the boot memory space 0x00000000 , but still accessible from its original memory space 0x08000000 . Boot from system memory: the system memory is aliased in the boot memory space 0x00000000 , but still accessible from its original memory space 0x1FFF0000 . Boot from the embedded SRAM: the SRAM is aliased in the boot memory space 0x00000000 , but it is still accessible from its original memory space 0x20000000 . Physical remap For application code which is located in a different address than 0x08000000 , some additional code must be added in order to be able to serve the application interrupts. A solution will be to relocate by software the vector table to the internal SRAM, at the initialization phase: Copy the vector table from the Flash (mapped at the base of the application load address) to the base address of the SRAM at 0x20000000 Remap SRAM at address 0x00000000 , using SYSCFG configuration register 1 Embedded bootloader The embedded bootloader mode is used to reprogram the Flash memory using one of the following serial interfaces: USART1 (PA9/PA10) USART2 (PD5/PD6) I2C1 (PB6/PB7) I2C2 (PB10/PB3) I2C3 (PA8/PB4) SPI1 (PA4/PA5/PA6/PA7) SPI2 (PB12/PB13/PB14/PB15) SPI3 (PA15/PC10/PC11/PC12) USB OTG FS (PA11/12) in Device mode (DFU: device firmware upgrade). The USART peripherals operate at the internal 16 MHz oscillator (HSI) frequency, while the USB OTG FS require an external clock (HSE) multiple of 1 MHz (ranging from 4 to 26 MHz). The embedded bootloader code is located in system memory. It is programmed by ST during production. Debug pin During and just after reset, the alternate functions are not active and most of the I/O ports are configured in input floating mode, except the debug pins are in AF pull-up/pull-down mode immediately: PA15: JTDI in pull-up PA14: JTCK/SWCLK in pull-down PA13: JTMS/SWDAT in pull-up PB4: NJTRST in pull-up PB3: JTDO in floating state The clock paths The structure of an IO pin The waveform of a General Timer Programming Manual # This programming manual provides information for application and system-level software developers . It gives a full description of the STM32 Cortex\u2122-M0 processor programming model, instruction set and core peripherals . Programming Manual provides the following: Processor Modes, Stacks Memory model Exception model, the Vector table and the interrupt service routines Fault handling Power management: enter Sleep mode, Wake up The Instruction Set CMSIS intrinsic functions Core Peripherals: Memory Protection Unit (MPU) Nested vectored interrupt controller (NVIC) System control block (SCB) SysTick timer (STK) Excerpt from PM0214 \u2014 STM32 Cortex\u00ae-M4 MCUs and MPUs programming manual Registers Processor modes Thread mode : Used to execute application software. The processor enters Thread mode when it comes out of reset Handler mode : Used to handle exceptions. The processor returns to Thread mode when it has finished exception processing. Stacks The processor uses a full descending stack. This means the stack pointer indicates the last stacked item on the stack memory. The processor implements two stacks, with independent copies of the stack pointer: The main stack and The process stack In Thread mode, the CONTROL register controls whether the processor uses the main stack or the process stack: 0 : Main Stack Pointer (MSP)(reset value). On reset, the processor loads the MSP with the value from address 0x00000000 . 1 : Process Stack Pointer (PSP). In Handler mode, the processor always uses the main stack. Memory endianness The processor views memory in little-endian format. It stores the least significant byte (lsbyte) of a word at the lowest-numbered byte, and the most significant byte (msbyte) at the highest-numbered byte. The Little-Endian memory layout Vector table On system reset, the vector table is fixed at address 0x00000000 . The least-significant bit of each vector must be 1, indicating that the exception handler is Thumb code. The exception types Application Note # There many Application Note documents provided by ST. Each document present the usage, design, and advice for a specific application or feature . Application Note provides the following: Peripherals architecture in hardware and software Operation characteristic Excerpt from AN4031 \u2014 Using the STM32F2, STM32F4 and STM32F7 Series DMA controller DMA transfer timing For the case where only one DMA channel is active, a new hardware back-to-back request can not be handled by the DMA before the completion of the previous one, adding one AHB clock cycle for the final idle phase of the DMA request-acknowledge handshake protocol. DMA Block diagram When more than one channel is requesting a DMA transfer, the DMA request arbitration can be performed meanwhile the two last cycles of when the AHB bus is accessed by the DMA. Request arbitration overhead is then masked by the AHB bus transfer time. In case not only two channels, but two DMA controllers are used (in products that offer this possibility), two DMA transfers can be processed in parallel, as long as they are not conflicting within the bus matrix, not accessing the same slave device. Timing of Two DMA channel on AHB Bus Excerpt from AN2834 \u2014 How to get the best ADC accuracy in STM32 microcontrollers SAR ADC internal structure The ADC embedded in STM32 microcontrollers uses the SAR (successive approximation register) principle, by which the conversion is performed in several steps. The number of conversion steps is equal to the number of bits in the ADC converter. Each step is driven by the ADC clock. Each ADC clock produces one bit from result to output. The ADC internal design is based on the switched-capacitor technique. Basic schematic of SAR switched-capacitor ADC How to get the best ADC accuracy Reduce the effects of ADC-related ADC errors Offset and gain errors can be easily compensated using the STM32 ADC self-calibration feature or by microcontroller firmware. Minimize ADC errors related to external environment of ADC It is recommended to connect capacitors with good high-frequency characteristics between the power and ground lines. That is, a 0.1 \u00b5F and a 1 to 10 \u00b5F capacitor should be placed close to the power source. In most STM32 microcontrollers, the VDD and VSS pins are placed close to each other. So are the VREF+ and VSSA pins. A capacitor can therefore be connected very close to the microcontroller with very short leads. For multiple VDD and VSS pins, use separate decoupling capacitors. Platform API Manual # When using a software platform as a base for application development, the API manual document provides the usage and use case of available functions, settings, and parameters . STM32 MCUs come with Hardware Abstract Layer (HAL) and Low-Layer (LL) library which are used in code generation from STM32CubeMX. Excerpt from UM1725 \u2014 Description of STM32F4 HAL and low-layer drivers GPIO Firmware driver API description Enable the GPIO AHB clock using the following function __HAL_RCC_GPIOx_CLK_ENABLE() . Configure the GPIO pin(s) using HAL_GPIO_Init() . Configure the IO mode using Mode member from GPIO_InitTypeDef structure Activate Pull-up, Pull-down resistor using Pull member from GPIO_InitTypeDef structure. In case of Output or alternate function mode selection: the speed is configured through Speed member from GPIO_InitTypeDef structure. In alternate mode is selection, the alternate function connected to the IO is configured through Alternate member from GPIO_InitTypeDef structure. Analog mode is required when a pin is to be used as ADC channel or DAC output. In case of external interrupt/event selection the Mode member from GPIO_InitTypeDef structure select the type (interrupt or event) and the corresponding trigger event (rising or falling or both). In case of external interrupt/event mode selection, configure NVIC IRQ priority mapped to the EXTI line using HAL_NVIC_SetPriority() and enable it using HAL_NVIC_EnableIRQ() . HAL_GPIO_DeInit() allows to set register values to their reset value. It\u2019s also recommended to use it to un-configure pin which was used as an external interrupt or in event mode. That\u2019s the only way to reset corresponding bit in EXTI & SYSCFG registers. To get the level of a pin configured in input mode use HAL_GPIO_ReadPin() . To set/reset the level of a pin configured in output mode use HAL_GPIO_WritePin() / HAL_GPIO_TogglePin() . To lock pin configuration until next reset use HAL_GPIO_LockPin() . During and just after reset, the alternate functions are not active and the GPIO pins are configured in input floating mode (except JTAG/SWD pins). The LSE oscillator pins OSC32_IN and OSC32_OUT can be used as general purpose ( PC14 and PC15 , respectively) when the LSE oscillator is off. The LSE has priority over the GPIO function. The HSE oscillator pins OSC_IN and OSC_OUT can be used as general purpose PF0 and PF1 , respectively, when the HSE oscillator is off. The HSE has priority over the GPIO function. Main board schematic # It is better to get a schematic of the board which is under the development, to know wires, connected pins, signal level and characteristic . Main board schematic provides the following: Input and Output characteristics (Pull-up, Pull-down, Open, Voltage level) Connection points (internal wires, connectors, test point) Working conditions (Power level, Voltage Level tolerance) When downloading schematic from ST, please check the version of hardware on the board, such as MB1136 rev C . In old Manual Document, there is a section for schematic. Excerpt from MB11136 rev C.3 \u2014 STM32 NUCLEO-XXXXRX schematic STM32 Nucleo-64 Extension Connectors Board-specific document # When using an official board from ST, there are some board-specific documents provided to users: Peripheral firmware example Migration and compatibility guidelines Application integration # When using RTOS or other application later, it is recommended to read their guides and API documents. For example: UM1722 \u2014 Developing applications on STM32Cube with RTOS This document is a reference to program user application in RTOS. This document has below content: FreeRTOS: overview, APIs, memory management, low power managements, and configuration CMSIS-RTOS: a higher layer to communicate between CMSIS and FreeRTOS Usage to create thread, use Semaphore, Queues, and Timer CMSIS \u2014 Cortex Microcontroller Software Interface Standard ARM develops the Cortex Microcontroller Software Interface Standard (CMSIS) to allow microcontroller and software vendor to use a consistent software infrastructure to develop software solutions for Cortex-M microcontroller. It is a set of APIs for application or middleware developers to access the features on the Cortex-M processor regardless of the microcontroller devices or tool chain used. To use the CMSIS-Core (Cortex-M) the following files are added to the embedded application: Startup File startup_<device>.c with reset handler and exception vectors. System Configuration Files system_<device>.c and system_<device>.h with general device configuration (i.e. for clock and BUS setup). Device Header File <device.h> gives access to processor core and all peripherals. Register names and bit-fields are defined in the Reference Manual of the process. Source Code # Reading a source code and understanding how it works is one of a good way to know about the target system. There are comments in the source code too, and they usually explain about a corner case, issue, or the particular purpose of the implementation. Website # ST provides good product pages which have links to all available documents, such as STM32 Nucleo-64 . You can search and download from there. STM32CubeIDE has a better way to list all related documents of selected processor, and it can download documents too. Find the documents in menu Help \u2192 Target device docs and resources if you have a project using CubeMX. List of documents for a target And finally, search on the internet, read them all, sometime ask people, and try to answer other\u2019s question.","title":"Documents for programming a microcontroller"},{"location":"blog/stm32/docs/#datasheet-product-specifications","text":"This document contains highlight of the target microprocessor with main features and capabilities . Many people are confused with Reference Manual, but when comparing the content, they are written for different purpose. This document is helpful when designing a PCB . It gives recommended layout for things like signal characteristic , NRST pin, ADC pins, Boot mode, etc. Datasheet provides the following: General description including product line, speed, memory, operating voltage, temperature range Device overview with block diagram, available peripherals and functions Pinouts and pin descriptions Memory map and memory ranges Electrical Characteristics Package information, for modeling PCB footprints Ordering Information Excerpt from DS10314 \u2014 STM32F411xC STM32F411xE Datasheet The system block diagram Boot modes At startup, the boot pin and boot selector option bit are used to select one of the three boot options: boot from User Flash memory boot from System Memory boot from embedded SRAM The bootloader is located in system memory. It is used to reprogram the Flash memory by using USART1(PA9/10), USART2(PD\u215a), USB OTG FS in device mode (PA11/12) through DFU (device firmware upgrade), I2C1(PB6/7), I2C2(PB10/3), I2C3(PA8/PB4), SPI1(PA\u2158/6/7), SPI2(PB12/13/14/15) or SPI3(PA15, PC10/11/12). For more detailed information on the bootloader, refer to Application Note: AN2606, STM32 microcontroller system memory boot mode. Pinout table I/O structure with marker FT for 5 V-tolerant I/O, TT or TC for 3.3 V-only I/O. Unless otherwise specified by a note, all I/Os are set as floating inputs during and after reset. The pinout description Alternate functions Memory map and boundary address Operating condition Speed modes on IO","title":"Datasheet (Product Specifications)"},{"location":"blog/stm32/docs/#reference-manual","text":"This is by far the most important document in order to program the target device . It defines all information about the core and peripheral at register level with bit-by-bit description . By using only this document, developer still can program the chip without any higher level API \u2014 usually called Bare-metal/Register-based programming. Reference Manual provides the following: System Architecture with bus, peripherals, and connections Memory map and boundary address Boot configuration and vector table relocation Peripheral with details features, descriptions, and structure Register name and bit-fields for all accessible registers Code examples using CMSIS header files Excerpt from RM0383 \u2014 STM32F411xC/E advanced Arm\u00ae-based 32-bit MCUs System architecture for STM32F0x Boot configuration The boot mode configuration is latched on the 4 th rising edge of SYSCLK after a reset, and is also re-sampled when exiting from Standby mode. After this startup delay has elapsed, the CPU always fetches the top-of-stack value from address 0x00000000 , then starts code execution from the boot memory at 0x00000004 . Depending on the selected boot mode, main Flash memory, system memory or SRAM is accessible as follows: Boot from main Flash memory: the main Flash memory is aliased in the boot memory space 0x00000000 , but still accessible from its original memory space 0x08000000 . Boot from system memory: the system memory is aliased in the boot memory space 0x00000000 , but still accessible from its original memory space 0x1FFF0000 . Boot from the embedded SRAM: the SRAM is aliased in the boot memory space 0x00000000 , but it is still accessible from its original memory space 0x20000000 . Physical remap For application code which is located in a different address than 0x08000000 , some additional code must be added in order to be able to serve the application interrupts. A solution will be to relocate by software the vector table to the internal SRAM, at the initialization phase: Copy the vector table from the Flash (mapped at the base of the application load address) to the base address of the SRAM at 0x20000000 Remap SRAM at address 0x00000000 , using SYSCFG configuration register 1 Embedded bootloader The embedded bootloader mode is used to reprogram the Flash memory using one of the following serial interfaces: USART1 (PA9/PA10) USART2 (PD5/PD6) I2C1 (PB6/PB7) I2C2 (PB10/PB3) I2C3 (PA8/PB4) SPI1 (PA4/PA5/PA6/PA7) SPI2 (PB12/PB13/PB14/PB15) SPI3 (PA15/PC10/PC11/PC12) USB OTG FS (PA11/12) in Device mode (DFU: device firmware upgrade). The USART peripherals operate at the internal 16 MHz oscillator (HSI) frequency, while the USB OTG FS require an external clock (HSE) multiple of 1 MHz (ranging from 4 to 26 MHz). The embedded bootloader code is located in system memory. It is programmed by ST during production. Debug pin During and just after reset, the alternate functions are not active and most of the I/O ports are configured in input floating mode, except the debug pins are in AF pull-up/pull-down mode immediately: PA15: JTDI in pull-up PA14: JTCK/SWCLK in pull-down PA13: JTMS/SWDAT in pull-up PB4: NJTRST in pull-up PB3: JTDO in floating state The clock paths The structure of an IO pin The waveform of a General Timer","title":"Reference Manual"},{"location":"blog/stm32/docs/#programming-manual","text":"This programming manual provides information for application and system-level software developers . It gives a full description of the STM32 Cortex\u2122-M0 processor programming model, instruction set and core peripherals . Programming Manual provides the following: Processor Modes, Stacks Memory model Exception model, the Vector table and the interrupt service routines Fault handling Power management: enter Sleep mode, Wake up The Instruction Set CMSIS intrinsic functions Core Peripherals: Memory Protection Unit (MPU) Nested vectored interrupt controller (NVIC) System control block (SCB) SysTick timer (STK) Excerpt from PM0214 \u2014 STM32 Cortex\u00ae-M4 MCUs and MPUs programming manual Registers Processor modes Thread mode : Used to execute application software. The processor enters Thread mode when it comes out of reset Handler mode : Used to handle exceptions. The processor returns to Thread mode when it has finished exception processing. Stacks The processor uses a full descending stack. This means the stack pointer indicates the last stacked item on the stack memory. The processor implements two stacks, with independent copies of the stack pointer: The main stack and The process stack In Thread mode, the CONTROL register controls whether the processor uses the main stack or the process stack: 0 : Main Stack Pointer (MSP)(reset value). On reset, the processor loads the MSP with the value from address 0x00000000 . 1 : Process Stack Pointer (PSP). In Handler mode, the processor always uses the main stack. Memory endianness The processor views memory in little-endian format. It stores the least significant byte (lsbyte) of a word at the lowest-numbered byte, and the most significant byte (msbyte) at the highest-numbered byte. The Little-Endian memory layout Vector table On system reset, the vector table is fixed at address 0x00000000 . The least-significant bit of each vector must be 1, indicating that the exception handler is Thumb code. The exception types","title":"Programming Manual"},{"location":"blog/stm32/docs/#application-note","text":"There many Application Note documents provided by ST. Each document present the usage, design, and advice for a specific application or feature . Application Note provides the following: Peripherals architecture in hardware and software Operation characteristic Excerpt from AN4031 \u2014 Using the STM32F2, STM32F4 and STM32F7 Series DMA controller DMA transfer timing For the case where only one DMA channel is active, a new hardware back-to-back request can not be handled by the DMA before the completion of the previous one, adding one AHB clock cycle for the final idle phase of the DMA request-acknowledge handshake protocol. DMA Block diagram When more than one channel is requesting a DMA transfer, the DMA request arbitration can be performed meanwhile the two last cycles of when the AHB bus is accessed by the DMA. Request arbitration overhead is then masked by the AHB bus transfer time. In case not only two channels, but two DMA controllers are used (in products that offer this possibility), two DMA transfers can be processed in parallel, as long as they are not conflicting within the bus matrix, not accessing the same slave device. Timing of Two DMA channel on AHB Bus Excerpt from AN2834 \u2014 How to get the best ADC accuracy in STM32 microcontrollers SAR ADC internal structure The ADC embedded in STM32 microcontrollers uses the SAR (successive approximation register) principle, by which the conversion is performed in several steps. The number of conversion steps is equal to the number of bits in the ADC converter. Each step is driven by the ADC clock. Each ADC clock produces one bit from result to output. The ADC internal design is based on the switched-capacitor technique. Basic schematic of SAR switched-capacitor ADC How to get the best ADC accuracy Reduce the effects of ADC-related ADC errors Offset and gain errors can be easily compensated using the STM32 ADC self-calibration feature or by microcontroller firmware. Minimize ADC errors related to external environment of ADC It is recommended to connect capacitors with good high-frequency characteristics between the power and ground lines. That is, a 0.1 \u00b5F and a 1 to 10 \u00b5F capacitor should be placed close to the power source. In most STM32 microcontrollers, the VDD and VSS pins are placed close to each other. So are the VREF+ and VSSA pins. A capacitor can therefore be connected very close to the microcontroller with very short leads. For multiple VDD and VSS pins, use separate decoupling capacitors.","title":"Application Note"},{"location":"blog/stm32/docs/#platform-api-manual","text":"When using a software platform as a base for application development, the API manual document provides the usage and use case of available functions, settings, and parameters . STM32 MCUs come with Hardware Abstract Layer (HAL) and Low-Layer (LL) library which are used in code generation from STM32CubeMX. Excerpt from UM1725 \u2014 Description of STM32F4 HAL and low-layer drivers GPIO Firmware driver API description Enable the GPIO AHB clock using the following function __HAL_RCC_GPIOx_CLK_ENABLE() . Configure the GPIO pin(s) using HAL_GPIO_Init() . Configure the IO mode using Mode member from GPIO_InitTypeDef structure Activate Pull-up, Pull-down resistor using Pull member from GPIO_InitTypeDef structure. In case of Output or alternate function mode selection: the speed is configured through Speed member from GPIO_InitTypeDef structure. In alternate mode is selection, the alternate function connected to the IO is configured through Alternate member from GPIO_InitTypeDef structure. Analog mode is required when a pin is to be used as ADC channel or DAC output. In case of external interrupt/event selection the Mode member from GPIO_InitTypeDef structure select the type (interrupt or event) and the corresponding trigger event (rising or falling or both). In case of external interrupt/event mode selection, configure NVIC IRQ priority mapped to the EXTI line using HAL_NVIC_SetPriority() and enable it using HAL_NVIC_EnableIRQ() . HAL_GPIO_DeInit() allows to set register values to their reset value. It\u2019s also recommended to use it to un-configure pin which was used as an external interrupt or in event mode. That\u2019s the only way to reset corresponding bit in EXTI & SYSCFG registers. To get the level of a pin configured in input mode use HAL_GPIO_ReadPin() . To set/reset the level of a pin configured in output mode use HAL_GPIO_WritePin() / HAL_GPIO_TogglePin() . To lock pin configuration until next reset use HAL_GPIO_LockPin() . During and just after reset, the alternate functions are not active and the GPIO pins are configured in input floating mode (except JTAG/SWD pins). The LSE oscillator pins OSC32_IN and OSC32_OUT can be used as general purpose ( PC14 and PC15 , respectively) when the LSE oscillator is off. The LSE has priority over the GPIO function. The HSE oscillator pins OSC_IN and OSC_OUT can be used as general purpose PF0 and PF1 , respectively, when the HSE oscillator is off. The HSE has priority over the GPIO function.","title":"Platform API Manual"},{"location":"blog/stm32/docs/#main-board-schematic","text":"It is better to get a schematic of the board which is under the development, to know wires, connected pins, signal level and characteristic . Main board schematic provides the following: Input and Output characteristics (Pull-up, Pull-down, Open, Voltage level) Connection points (internal wires, connectors, test point) Working conditions (Power level, Voltage Level tolerance) When downloading schematic from ST, please check the version of hardware on the board, such as MB1136 rev C . In old Manual Document, there is a section for schematic. Excerpt from MB11136 rev C.3 \u2014 STM32 NUCLEO-XXXXRX schematic STM32 Nucleo-64 Extension Connectors","title":"Main board schematic"},{"location":"blog/stm32/docs/#board-specific-document","text":"When using an official board from ST, there are some board-specific documents provided to users: Peripheral firmware example Migration and compatibility guidelines","title":"Board-specific document"},{"location":"blog/stm32/docs/#application-integration","text":"When using RTOS or other application later, it is recommended to read their guides and API documents. For example: UM1722 \u2014 Developing applications on STM32Cube with RTOS This document is a reference to program user application in RTOS. This document has below content: FreeRTOS: overview, APIs, memory management, low power managements, and configuration CMSIS-RTOS: a higher layer to communicate between CMSIS and FreeRTOS Usage to create thread, use Semaphore, Queues, and Timer CMSIS \u2014 Cortex Microcontroller Software Interface Standard ARM develops the Cortex Microcontroller Software Interface Standard (CMSIS) to allow microcontroller and software vendor to use a consistent software infrastructure to develop software solutions for Cortex-M microcontroller. It is a set of APIs for application or middleware developers to access the features on the Cortex-M processor regardless of the microcontroller devices or tool chain used. To use the CMSIS-Core (Cortex-M) the following files are added to the embedded application: Startup File startup_<device>.c with reset handler and exception vectors. System Configuration Files system_<device>.c and system_<device>.h with general device configuration (i.e. for clock and BUS setup). Device Header File <device.h> gives access to processor core and all peripherals. Register names and bit-fields are defined in the Reference Manual of the process.","title":"Application integration"},{"location":"blog/stm32/docs/#source-code","text":"Reading a source code and understanding how it works is one of a good way to know about the target system. There are comments in the source code too, and they usually explain about a corner case, issue, or the particular purpose of the implementation.","title":"Source Code"},{"location":"blog/stm32/docs/#website","text":"ST provides good product pages which have links to all available documents, such as STM32 Nucleo-64 . You can search and download from there. STM32CubeIDE has a better way to list all related documents of selected processor, and it can download documents too. Find the documents in menu Help \u2192 Target device docs and resources if you have a project using CubeMX. List of documents for a target And finally, search on the internet, read them all, sometime ask people, and try to answer other\u2019s question.","title":"Website"},{"location":"blog/stm32/exception/","tags":["arm","stm32"],"text":"Exception model # The current executing application on a processor can be interrupted by either internal system exception or external interrupt. Whenever the processor meets an exception or interrupt, the core will stop the application code, change its mode to \u201cHandler mode\u201d to process that event. Cortex-M processors have 15 system Exceptions and 240 Interrupts. Exception states # Inactive The exception is not active and not pending. Pending The exception is waiting to be serviced by the processor. An interrupt request from a peripheral or from software can change the state of the corresponding interrupt to pending. Active An exception that is being serviced by the processor but has not completed. Note: An exception handler can interrupt the execution of another exception handler. In this case both exceptions are in the active state. Active and pending The exception is being serviced by the processor and there is a pending exception from the same source Exception types # Whenever an interrupt happens, the processor stops the current code, and handle the interrupt by running an Interrupt Service Routines (ISR) which is located in a pre-defined table called Vector Interrupt Table (VIC) . The Vector Interrupt Table defines different types with priority of handling order as below: Exception Number IRQ Number Exception Type Priority Function 1 -15 Reset -3, the highest Reset 2 -14 NMI -2 Non-Maskable Interrupt 3 -13 Hard Fault -1 All faults that hang the processor 4 -12 Memory Fault Configurable Memory issue 5 -11 Bus Fault Configurable Data Bus issue 6 -10 Usage Fault Configurable Instruction/State/Access issue 7 ~ 10 Reserved \u2014 Reserved 11 -5 SVCall Configurable System Service Call when call SVC instruction 12 Debug Configurable Debug monitor (via SWD) 13 Reserved \u2014 Reserved 14 -2 PendSV Configurable For context switching in an OS 15 -1 SysTick Configurable System Timer 16 ~ 255 0~239 Interrupt (IRQ) Configurable Interrupt Request by a peripheral, or software request IRQ Number To simplify the software layer, the CMSIS only uses IRQ numbers and therefore uses negative values for exceptions other than interrupts. The IPSR returns the Exception number. Exception priorities All exceptions have an associated priority: A lower number value indicating a higher priority. If software does not configure any priorities, then all exceptions with a configurable priority have a priority of 0 . Configurable priority values are in the range 0-15 . Rule of order of execution: Higher priority (as the same as lower number) runs first If the same priority in pending, the lowest exception number takes precedence When the processor is executing an exception handler, the exception handler is preempted if a higher priority exception occurs. If an exception occurs with the same priority as the exception being handled, the handler is not preempted, irrespective of the exception number. However, the status of the new interrupt changes to pending. Exception Vector Table # The Vector Interrupt Table is implemented in assembly code in the startup file of MCU startup_*.s . . section . isr_vector , \"a\" , % progbits . type g_pfnVectors , % object . size g_pfnVectors , . - g_pfnVectors g_pfnVectors : . word _estack /* MSP value */ . word Reset_Handler /* Reset routine */ . word NMI_Handler /* No-Maskable Interrupt */ . word HardFault_Handler /* System faults */ . word MemManage_Handler /* Memory access issues */ . word BusFault_Handler /* Bus access issues */ . word UsageFault_Handler /* Instruction/State issues */ . word 0 . word 0 . word 0 . word 0 . word SVC_Handler /* System Service Call */ . word DebugMon_Handler /* Serial Wire Debug */ . word 0 . word PendSV_Handler /* Context Switching */ . word SysTick_Handler /* System Timer */ . word WWDG_IRQHandler /* Window Watchdog interrupt */ . word PVD_IRQHandler /* EXTI Line 16 interrupt / PVD through EXTI */ ... For convention, the vector table starts at the hardware address 0x00000000 in all Cortex-M based processors. If the vector table resides in the internal flash memory (this is what usually happens), and since the flash in all STM32 MCUs is mapped from 0x08000000 address, alias is used when Boot mode is from Flash to map 0x08000000 to 0x00000000 at CPU boot up. Read about the Boot mode in the Reference Manual. Entry zero of this array is the address of the Main Stack Pointer (MSP) inside the SRAM. Usually, this address corresponds to the end of the SRAM _estack . Example of Vector Interrupt Table in memory Exception entry and return # Preemption When the processor is executing an exception handler, an exception can preempt the exception handler if its priority is higher than the priority of the exception being handled.When one exception preempts another, the exceptions are called nested exceptions. Preemption example with IRQ1 > IRQ2 > IRQ3 Tail-chaining This mechanism speeds up exception servicing. When an interrupt (exception) is fired, the main (foreground) code context is saved (pushed) to the stack and the processor branches to the corresponding interrupt vector to start executing the ISR handler. At the end of the ISR, the context saved in the stack is popped out, so the processor can resume the main (foreground) code instructions. However, and if a new exception is already pended, the context push & pop are skipped. And the processor handler the second ISR without any additional overhead. Tail-chaining when IRQ2 comes while IRQ1 is executing Late-arriving : This mechanism speeds up preemption. If a higher priority exception occurs during state saving for a previous exception, the processor switches to handle the higher priority exception and initiates the vector fetch for that exception. State saving is not affected by late arrival because the state saved is the same for both exceptions. Therefore, the state saving continues uninterrupted. The processor can accept a late arriving exception until the first instruction of the exception handler of the original exception enters to execute stage of the processor. On return from the exception handler of the late-arriving exception, the normal tail-chaining rules apply. Late arrival is detected when IRQ1 comes while IRQ2 is about to start Return This occurs when the exception handler is completed, and: There is no pending exception with sufficient priority to be serviced The completed exception handler was not handling a late-arriving exception Exception enabling # By default, not all exceptions and interrupts are enabled to be handled. Exception Default state Handling behavior Reset Always enabled Asynchronous NMI Always enabled Asynchronous Hard Fault Always enabled, can be masked - Memory Fault Disabled by default Synchronous Bus Fault Disabled by default Synchronous Usage Fault Disabled by default Synchronous SVC Always enabled Synchronous Debug Disabled by default Synchronous PendSV Disabled by default Asynchronous SysTick Disabled by default Asynchronous Interrupts Disabled by default Asynchronous For an asynchronous exception other than reset, the processor can execute another instruction between when the exception is triggered and when the processor enters the exception handler. Nested Vectored Interrupt Controller # Nested Vectored Interrupt Controller (NVIC) is a method of prioritizing interrupts, improving the MCU\u2019s performance and reducing interrupt latency. NVIC also provides implementation schemes for handling interrupts that occur when other interrupts are being executed or when the CPU is in the process of restoring its previous state and resuming its suspended process. NVIC module in STM32 MCUs Components that are connected to NVIC inlcude: Clock Security System (CSS) interrupt is connected to Non-Maskable Interrupt (NMI) lines Peripheral interrupts are connected to Interrupt Requests (IRQ) lines GPIO interrupts are connected to an External Interrupt/Event Controller (EXTI) before connecting to the IRQ lines External Interrupts are grouped by lines which connect to GPIO. As processor may have many GPIOs, an EXTI line is shared by multiple pins. In one line (group), only one pin can be set to generate interrupt, and software must be able to discriminate which lines generated the interrupt. External Interrupt lines NVIC provides a wide range of register to configure up to 240 interrupts. The IRQ Numbers is defined in the The Vector Interrupt Table . STM32 interrupts are both level-sensitive and pulse-sensitive. Pulse interrupts are also described as edge-triggered interrupts. The external interrupt can be fired on rising edge , or falling edge , or both . A level-sensitive interrupt is held asserted until the peripheral de-asserts the interrupt signal. Typically, this happens because the ISR accesses the peripheral, causing it to clear the interrupt request. A pulse interrupt is an interrupt signal sampled synchronously on the rising edge of the processor clock. To ensure the NVIC detects the interrupt, the peripheral must assert the interrupt signal for at least one clock cycle, during which the NVIC detects the pulse and latches the interrupt. The Peripheral Pending bit # When an interrupt takes place, the most of STM32 peripherals assert a specific signal connected to the NVIC, which is mapped in the peripheral memory through a dedicated bit. This Peripheral Pending bit will be held high until it is manually cleared by the application code. The ISR Pending bit is different to the Peripheral Pending bit: When the processor starts servicing the ISR, the ISR pending bit is cleared automatically The peripheral pending bit will be held high until it is cleared by the application code : If the Peripheral Pending bit is not clear, the interrupt will be fired again and the ISR will run again It is able to manually set the Peripheral Pending bit to force the ISR run Exception Lifecycle # An exception can: Either be disabled (default behavior) or enabled ; either be pending (a request is waiting to be served) or not pending ; either be in an active (being served) or inactive state. When an exception fires, it is marked as pending until the processor can serve it. If no other exception is currently being processed, it\u2019s pending state is automatically cleared by the processor, then it starts get served. ISR A then ISR B The lower priority ISR has to wait in pending state until no higher priority ISR is being processed. It can be put into inactive state when it is preempted by a higher priority ISR. ISR A preempts ISR B An exception can be forced to fire again during its execution, simply setting its pending bit again. However, the executing exception will complete before re-calling itself. ISR A preempts ISR B In the same way, the execution of an exception can be canceled clearing its pending bit while it is in pending state. ISR A preempts ISR B Exception Behavior # When an exception occurs, the current instruction stream is stopped and the processor accesses the exceptions vector table: The vector address of that exception is loaded from the vector table. The exception handler starts to be executed in handler mode. The exception handler returns to main (assuming no further nesting). Here are more details: Interrupt Stacking (Context Saving) The processor will finish the current instruction as long as it\u2019s not a multi-cycle instruction The processor state (context) is automatically saved to the stack. Eight registers are pushed ( PC , R0 - R3 , R12 , LR , xPSR and FPU registers). During or after context saving, the address of the corresponding ISR is loaded from the exception/interrupt vector table The link register is modified for return after interrupt The first instruction of the ISR starts to be executed by the CPU. For Cortex-M3/M4, the whole latency this process takes is 12 cycles. However, IRQ latency is improved if late-arrival or tail-chaining has occurred. Interrupt Service Routine (ISR) Handling ISR should clear the interrupt source flag if required Interrupt nesting won\u2019t affect the way the ISR is written however, attention should be paid to the main stack overflow that may occur. Given that certain exceptions/interrupts are to be serviced hundreds or thousands of times per second. So it must run so quickly and no delays are permitted within ISR handlers Return From ISR (Context Restoration) Detect tail-chaining interrupt, if you have, call to the ISR without restoring the context to speed up The EXC_RETURN instruction is fetched and gets executed to restore the PC and pop the CPU registers. The return from interrupt (context restoration) on ARM Cortex-M3/M4 requires 10 clock cycles Example # Refer to an example in Fault Handler .","title":"Exception and Interrupt"},{"location":"blog/stm32/exception/#exception-model","text":"The current executing application on a processor can be interrupted by either internal system exception or external interrupt. Whenever the processor meets an exception or interrupt, the core will stop the application code, change its mode to \u201cHandler mode\u201d to process that event. Cortex-M processors have 15 system Exceptions and 240 Interrupts.","title":"Exception model"},{"location":"blog/stm32/exception/#exception-states","text":"Inactive The exception is not active and not pending. Pending The exception is waiting to be serviced by the processor. An interrupt request from a peripheral or from software can change the state of the corresponding interrupt to pending. Active An exception that is being serviced by the processor but has not completed. Note: An exception handler can interrupt the execution of another exception handler. In this case both exceptions are in the active state. Active and pending The exception is being serviced by the processor and there is a pending exception from the same source","title":"Exception states"},{"location":"blog/stm32/exception/#exception-types","text":"Whenever an interrupt happens, the processor stops the current code, and handle the interrupt by running an Interrupt Service Routines (ISR) which is located in a pre-defined table called Vector Interrupt Table (VIC) . The Vector Interrupt Table defines different types with priority of handling order as below: Exception Number IRQ Number Exception Type Priority Function 1 -15 Reset -3, the highest Reset 2 -14 NMI -2 Non-Maskable Interrupt 3 -13 Hard Fault -1 All faults that hang the processor 4 -12 Memory Fault Configurable Memory issue 5 -11 Bus Fault Configurable Data Bus issue 6 -10 Usage Fault Configurable Instruction/State/Access issue 7 ~ 10 Reserved \u2014 Reserved 11 -5 SVCall Configurable System Service Call when call SVC instruction 12 Debug Configurable Debug monitor (via SWD) 13 Reserved \u2014 Reserved 14 -2 PendSV Configurable For context switching in an OS 15 -1 SysTick Configurable System Timer 16 ~ 255 0~239 Interrupt (IRQ) Configurable Interrupt Request by a peripheral, or software request IRQ Number To simplify the software layer, the CMSIS only uses IRQ numbers and therefore uses negative values for exceptions other than interrupts. The IPSR returns the Exception number. Exception priorities All exceptions have an associated priority: A lower number value indicating a higher priority. If software does not configure any priorities, then all exceptions with a configurable priority have a priority of 0 . Configurable priority values are in the range 0-15 . Rule of order of execution: Higher priority (as the same as lower number) runs first If the same priority in pending, the lowest exception number takes precedence When the processor is executing an exception handler, the exception handler is preempted if a higher priority exception occurs. If an exception occurs with the same priority as the exception being handled, the handler is not preempted, irrespective of the exception number. However, the status of the new interrupt changes to pending.","title":"Exception types"},{"location":"blog/stm32/exception/#exception-vector-table","text":"The Vector Interrupt Table is implemented in assembly code in the startup file of MCU startup_*.s . . section . isr_vector , \"a\" , % progbits . type g_pfnVectors , % object . size g_pfnVectors , . - g_pfnVectors g_pfnVectors : . word _estack /* MSP value */ . word Reset_Handler /* Reset routine */ . word NMI_Handler /* No-Maskable Interrupt */ . word HardFault_Handler /* System faults */ . word MemManage_Handler /* Memory access issues */ . word BusFault_Handler /* Bus access issues */ . word UsageFault_Handler /* Instruction/State issues */ . word 0 . word 0 . word 0 . word 0 . word SVC_Handler /* System Service Call */ . word DebugMon_Handler /* Serial Wire Debug */ . word 0 . word PendSV_Handler /* Context Switching */ . word SysTick_Handler /* System Timer */ . word WWDG_IRQHandler /* Window Watchdog interrupt */ . word PVD_IRQHandler /* EXTI Line 16 interrupt / PVD through EXTI */ ... For convention, the vector table starts at the hardware address 0x00000000 in all Cortex-M based processors. If the vector table resides in the internal flash memory (this is what usually happens), and since the flash in all STM32 MCUs is mapped from 0x08000000 address, alias is used when Boot mode is from Flash to map 0x08000000 to 0x00000000 at CPU boot up. Read about the Boot mode in the Reference Manual. Entry zero of this array is the address of the Main Stack Pointer (MSP) inside the SRAM. Usually, this address corresponds to the end of the SRAM _estack . Example of Vector Interrupt Table in memory","title":"Exception Vector Table"},{"location":"blog/stm32/exception/#exception-entry-and-return","text":"Preemption When the processor is executing an exception handler, an exception can preempt the exception handler if its priority is higher than the priority of the exception being handled.When one exception preempts another, the exceptions are called nested exceptions. Preemption example with IRQ1 > IRQ2 > IRQ3 Tail-chaining This mechanism speeds up exception servicing. When an interrupt (exception) is fired, the main (foreground) code context is saved (pushed) to the stack and the processor branches to the corresponding interrupt vector to start executing the ISR handler. At the end of the ISR, the context saved in the stack is popped out, so the processor can resume the main (foreground) code instructions. However, and if a new exception is already pended, the context push & pop are skipped. And the processor handler the second ISR without any additional overhead. Tail-chaining when IRQ2 comes while IRQ1 is executing Late-arriving : This mechanism speeds up preemption. If a higher priority exception occurs during state saving for a previous exception, the processor switches to handle the higher priority exception and initiates the vector fetch for that exception. State saving is not affected by late arrival because the state saved is the same for both exceptions. Therefore, the state saving continues uninterrupted. The processor can accept a late arriving exception until the first instruction of the exception handler of the original exception enters to execute stage of the processor. On return from the exception handler of the late-arriving exception, the normal tail-chaining rules apply. Late arrival is detected when IRQ1 comes while IRQ2 is about to start Return This occurs when the exception handler is completed, and: There is no pending exception with sufficient priority to be serviced The completed exception handler was not handling a late-arriving exception","title":"Exception entry and return"},{"location":"blog/stm32/exception/#exception-enabling","text":"By default, not all exceptions and interrupts are enabled to be handled. Exception Default state Handling behavior Reset Always enabled Asynchronous NMI Always enabled Asynchronous Hard Fault Always enabled, can be masked - Memory Fault Disabled by default Synchronous Bus Fault Disabled by default Synchronous Usage Fault Disabled by default Synchronous SVC Always enabled Synchronous Debug Disabled by default Synchronous PendSV Disabled by default Asynchronous SysTick Disabled by default Asynchronous Interrupts Disabled by default Asynchronous For an asynchronous exception other than reset, the processor can execute another instruction between when the exception is triggered and when the processor enters the exception handler.","title":"Exception enabling"},{"location":"blog/stm32/exception/#nested-vectored-interrupt-controller","text":"Nested Vectored Interrupt Controller (NVIC) is a method of prioritizing interrupts, improving the MCU\u2019s performance and reducing interrupt latency. NVIC also provides implementation schemes for handling interrupts that occur when other interrupts are being executed or when the CPU is in the process of restoring its previous state and resuming its suspended process. NVIC module in STM32 MCUs Components that are connected to NVIC inlcude: Clock Security System (CSS) interrupt is connected to Non-Maskable Interrupt (NMI) lines Peripheral interrupts are connected to Interrupt Requests (IRQ) lines GPIO interrupts are connected to an External Interrupt/Event Controller (EXTI) before connecting to the IRQ lines External Interrupts are grouped by lines which connect to GPIO. As processor may have many GPIOs, an EXTI line is shared by multiple pins. In one line (group), only one pin can be set to generate interrupt, and software must be able to discriminate which lines generated the interrupt. External Interrupt lines NVIC provides a wide range of register to configure up to 240 interrupts. The IRQ Numbers is defined in the The Vector Interrupt Table . STM32 interrupts are both level-sensitive and pulse-sensitive. Pulse interrupts are also described as edge-triggered interrupts. The external interrupt can be fired on rising edge , or falling edge , or both . A level-sensitive interrupt is held asserted until the peripheral de-asserts the interrupt signal. Typically, this happens because the ISR accesses the peripheral, causing it to clear the interrupt request. A pulse interrupt is an interrupt signal sampled synchronously on the rising edge of the processor clock. To ensure the NVIC detects the interrupt, the peripheral must assert the interrupt signal for at least one clock cycle, during which the NVIC detects the pulse and latches the interrupt.","title":"Nested Vectored Interrupt Controller"},{"location":"blog/stm32/exception/#the-peripheral-pending-bit","text":"When an interrupt takes place, the most of STM32 peripherals assert a specific signal connected to the NVIC, which is mapped in the peripheral memory through a dedicated bit. This Peripheral Pending bit will be held high until it is manually cleared by the application code. The ISR Pending bit is different to the Peripheral Pending bit: When the processor starts servicing the ISR, the ISR pending bit is cleared automatically The peripheral pending bit will be held high until it is cleared by the application code : If the Peripheral Pending bit is not clear, the interrupt will be fired again and the ISR will run again It is able to manually set the Peripheral Pending bit to force the ISR run","title":"The Peripheral Pending bit"},{"location":"blog/stm32/exception/#exception-lifecycle","text":"An exception can: Either be disabled (default behavior) or enabled ; either be pending (a request is waiting to be served) or not pending ; either be in an active (being served) or inactive state. When an exception fires, it is marked as pending until the processor can serve it. If no other exception is currently being processed, it\u2019s pending state is automatically cleared by the processor, then it starts get served. ISR A then ISR B The lower priority ISR has to wait in pending state until no higher priority ISR is being processed. It can be put into inactive state when it is preempted by a higher priority ISR. ISR A preempts ISR B An exception can be forced to fire again during its execution, simply setting its pending bit again. However, the executing exception will complete before re-calling itself. ISR A preempts ISR B In the same way, the execution of an exception can be canceled clearing its pending bit while it is in pending state. ISR A preempts ISR B","title":"Exception Lifecycle"},{"location":"blog/stm32/exception/#exception-behavior","text":"When an exception occurs, the current instruction stream is stopped and the processor accesses the exceptions vector table: The vector address of that exception is loaded from the vector table. The exception handler starts to be executed in handler mode. The exception handler returns to main (assuming no further nesting). Here are more details: Interrupt Stacking (Context Saving) The processor will finish the current instruction as long as it\u2019s not a multi-cycle instruction The processor state (context) is automatically saved to the stack. Eight registers are pushed ( PC , R0 - R3 , R12 , LR , xPSR and FPU registers). During or after context saving, the address of the corresponding ISR is loaded from the exception/interrupt vector table The link register is modified for return after interrupt The first instruction of the ISR starts to be executed by the CPU. For Cortex-M3/M4, the whole latency this process takes is 12 cycles. However, IRQ latency is improved if late-arrival or tail-chaining has occurred. Interrupt Service Routine (ISR) Handling ISR should clear the interrupt source flag if required Interrupt nesting won\u2019t affect the way the ISR is written however, attention should be paid to the main stack overflow that may occur. Given that certain exceptions/interrupts are to be serviced hundreds or thousands of times per second. So it must run so quickly and no delays are permitted within ISR handlers Return From ISR (Context Restoration) Detect tail-chaining interrupt, if you have, call to the ISR without restoring the context to speed up The EXC_RETURN instruction is fetched and gets executed to restore the PC and pop the CPU registers. The return from interrupt (context restoration) on ARM Cortex-M3/M4 requires 10 clock cycles","title":"Exception Behavior"},{"location":"blog/stm32/exception/#example","text":"Refer to an example in Fault Handler .","title":"Example"},{"location":"blog/stm32/fault-handler/","tags":["arm","stm32","asm"],"text":"STM32-Tutorials F411RE_Fault_Handlers.zip Fault exception # A fault is an exception generated by the processor to indicate an error. When there is something violates the design rules of the processor, a fault is triggered. Whenever a fault happens, internal processor registers will be updated to record the type of fault, the address of instruction at which fault happened, and if an associated exception is enabled, the exception handler will be called. The fault handler can report, resolve, or recover the system from the fault. For example: Dividing a number by zero causes DIVBYZERO fault, which will invoke Usage Fault Handler in which you can get rid of the problem such as closing the problematic task. The Vector Interrupt Table defines different types with priority of handling order as below: Exception Number IRQ Number Exception Type Priority Function 3 -13 Hard Fault -1 All faults that hang the processor 4 -12 Memory Fault Configurable Memory issue 5 -11 Bus Fault Configurable Data Bus issue 6 -10 Usage Fault Configurable Instruction/State/Access issue By default, not all exceptions and interrupts are enabled to be handled. Exception Default state Handling behavior Hard Fault Always enabled, can be masked - Memory Fault Disabled by default Synchronous Bus Fault Disabled by default Synchronous Usage Fault Disabled by default Synchronous The Vector Interrupt Table is implemented in assembly code in the startup file of MCU startup_*.s . g_pfnVectors : . word _estack /* MSP value */ . word Reset_Handler /* Reset routine */ . word NMI_Handler /* No-Maskable Interrupt */ . word HardFault_Handler /* System faults */ . word MemManage_Handler /* Memory access issues */ . word BusFault_Handler /* Bus access issues */ . word UsageFault_Handler /* Instruction/State issues */ ... Fault types # Fault Handler Bit name Fault status register Bus error on a vector read HardFault_Handler VECTTBL Hard fault status register (HFSR) Fault escalated to a hard fault FORCED MPU or default memory map mismatch: MemManage_Handler - Memory management fault address register (MMFSR, MMFAR) \u2013 on instruction access IACCVIOL \u2013 on data access DACCVIOL \u2013 during exception stacking MSTKERR \u2013 during exception unstacking MUNSKERR \u2013 during lazy floating-point state preservation MLSPERR Bus error BusFault_Handler - Bus fault address register (BFSR, BFAR) \u2013 During exception stacking STKERR \u2013 During exception unstacking UNSTKERR \u2013 During instruction prefetch IBUSERR \u2013 During lazy floating-point state preservation LSPERR Precise data bus error PRECISERR Imprecise data bus error IMPRECISERR Attempt to access a coprocessor Usage fault NOCP Configurable fault status register (CFSR ; UFSR+BFSR+MMFSR) Undefined instruction UNDEFINSTR Attempt to enter an invalid instruction set state INVSTATE Invalid EXC_RETURN value INVPC Illegal unaligned load or store UNALIGNED Divide By 0 DIVBYZERO Fault escalation and hard faults All faults exceptions except for hard fault have configurable exception priority, as described in System handler priority registers (SHPRx). Software can disable execution of the handlers for these faults. Usually, the exception priority, together with the values of the exception mask registers, determines whether the processor enters the fault handler, and whether a fault handler can preempt another fault handler. In some situations, a fault with configurable priority is treated as a hard fault. This is called priority escalation, and the fault is described as escalated to hard fault. Escalation to hard fault occurs when: A fault handler causes the same kind of fault as the one it is servicing. This escalation to hard fault occurs when a fault handler cannot preempt itself because it must have the same priority as the current priority level. A fault handler causes a fault with the same or lower priority as the fault it is servicing. This is because the handler for the new fault cannot preempt the currently executing fault handler. An exception handler causes a fault for which the priority is the same as or lower than the currently executing exception. A fault occurs and the handler for that fault is not enabled. If a bus fault occurs during a stack push when entering a bus fault handler, the bus fault does not escalate to a hard fault. This means that if a corrupted stack causes a fault, the fault handler executes even though the stack push for the handler failed. The fault handler operates, but the stack contents are corrupted. Only Reset and NMI can preempt the fixed priority hard fault. A hard fault can preempt any exception other than Reset, NMI, or another hard fault. Lockup state The processor enters a lockup state if a hard fault occurs when executing the NMI or hard fault handlers. When the processor is in lockup state it does not execute any instructions. The processor remains in lockup state until either: It is reset An NMI occurs It is halted by a debugger If lockup state occurs from the NMI handler a subsequent NMI does not cause the processor to leave lockup state. Example # This example enables all configurable fault exceptions, implement fault exceptions handlers, and trigger faults by following methods: Execute an undefined instruction Divide by Zero Execute instruction from peripheral region Execute SVC inside the SVC Handler Execute SVC inside an interrupt handler whose priority is same or less than SVC priority Step 0: Create a new project You should create a bare-metal project which just has a few files including a linker and a main. Step 1: Enable all fault exceptions In the document PM0214: STM32 Cortex\u00ae-M4 MCUs and MPUs programming manual , look at the below section: 4.4 System control block (SCB The System control block (SCB) provides system implementation information, and system control. This includes configuration, control, and reporting of the system exceptions. The System handler control and state register (SHCSR) is at the address 0xE000ED24 4.4.7 Configuration and control register (CCR) The CCR controls entry to Thread mode and enables: The handlers for NMI, hard fault and faults escalated by FAULTMASK to ignore bus faults Trapping of divide by zero and unaligned accesses Access to the STIR by unprivileged software Configuration and control register (CCR) 4.4.9 System handler control and state register (SHCSR) The SHCSR enables the system handlers, and indicates: The pending status of the bus fault, memory management fault, and SVC exceptions The active status of the system handlers If you disable a system handler and the corresponding fault occurs, the processor treats the fault as a hard fault. System handler control and state register (SHCSR) We can use direct memory access method to configure this SHCSR register: // enable handlers uint32_t * pSHCSR = ( uint32_t * ) 0xE000ED24 ; * pSHCSR |= ( 1 << 16 ); // Memory Fault * pSHCSR |= ( 1 << 17 ); // Bus Fault * pSHCSR |= ( 1 << 18 ); // Usage Fault // enable Divide by Zero Trap uint32_t * pCCR = ( uint32_t * ) 0xE000ED14 ; * pCCR |= ( 1 << 4 ); // Div by Zero Step 2: Implement Fault Handlers The names of handlers are defined in the Interrupt Vector Table: g_pfnVectors : . word _estack /* MSP value */ . word Reset_Handler /* Reset routine */ . word NMI_Handler /* No-Maskable Interrupt */ . word HardFault_Handler /* System faults */ . word MemManage_Handler /* Memory access issues */ . word BusFault_Handler /* Bus access issues */ . word UsageFault_Handler /* Instruction/State issues */ We can directly override those functions in the main file, for example: void UsageFault_Handler () { printf ( \"Exception: Usage Fault \\n \" ); while ( 1 ); } Step 3: Trigger Usage Fault We will try to call a function at a location where there is invalid instruction: /* Fill a meaningless value */ * ( uint32_t * ) 0x20010000 = 0xFFFFFFFF ; /* Set PC with LSB being 1 to indicate Thumb State */ void ( * pFunc )( void ) = ( void * ) 0x20010001 ; /* call function */ pFunc (); Compile and run the program, you will get Usage Fault exception: Usage Fault: Undefined Instruction To find out which line of code caused the exception, you can refer to the Fault Analyzer tool. Note that this tool dumps all saved registers during Stacking of Context Switching . Note that the LR register save the address of the next instruction of what was being executed. In our example, if LR contains 0x80004b7 , we can find the address 0x80004b7 or 0x80004b6 in the disassembly file. The previous instruction of the found instruction at 0x80004b6 mostly the hot spot which caused the fault. Use Fault Analyzer to find the executing instruction Exercise Try to cause Divide by Zero exception If disable Usage Fault in SHCSR register, which Fault Exception will be raised? Fault Handler # We can not plug a debugger all the time to catch the state of system after a Fault happened. A good method is to capture the system state to file or memory for later analysis. We know that when exception occurs, CPU automatically saves some context registers before jumping to a Fault Handler. We can implement a way to dump those saved registers. Naked function to capture Stack Frame A normal function call always has Prologue and Epilogue sequences added by compiler. In the Prologue, some line of code is added to prepare the stack for the function. However, that action will change the Stack Pointer value. Therefore, a naked function should be used to keep the Stack Pointer value. __attribute__ (( naked )) void UsageFault_Handler ( void ) { // get current Stack Pointer __asm volatile ( \"MRS R0, MSP\" ); __asm volatile ( \"B UsageFault_Handler_main\" ); } This naked function will save the MSP register to R0 , and pass R0 to the actual handler: void UsageFault_Handler_main ( uint32_t * pMSP ) { printf ( \"Exception: Usage Fault \\n \" ); DumpExceptionRegister ( pMSP ); uint32_t * pUFSR = ( uint32_t * ) 0xE000ED2A ; printf ( \"UFSR = 0x%lx \\n \" , * pUFSR & 0xFFFF ); while ( 1 ); } Helper function to dump Stack Frame We can write a general dumper to print out the Stack Frame: void DumpExceptionRegister ( uint32_t * pMSP ) { printf ( \" MSP = %p \\n \" , pMSP ); printf ( \" R0 = 0x%lx \\n \" , pMSP [ 0 ]); // May have argument of function printf ( \" R1 = 0x%lx \\n \" , pMSP [ 1 ]); // May have argument of function printf ( \" R2 = 0x%lx \\n \" , pMSP [ 2 ]); // May have argument of function printf ( \" R3 = 0x%lx \\n \" , pMSP [ 3 ]); // May have argument of function printf ( \" R12 = 0x%lx \\n \" , pMSP [ 4 ]); // IP holds an intermediate value of a calculation printf ( \" LR = 0x%lx \\n \" , pMSP [ 5 ]); // Address of the next instruction before the exception printf ( \" PC = 0x%lx \\n \" , pMSP [ 6 ]); // CPU was executing the instruction at PC printf ( \"xPSR = 0x%lx \\n \" , pMSP [ 7 ]); // Status of system before execution at PC completes } You can use any technique to redirect the Standard IO from printf to UART terminal, or SWD Terminal. Dump saved Stack Frame to SWD","title":"Fault Handlers"},{"location":"blog/stm32/fault-handler/#fault-exception","text":"A fault is an exception generated by the processor to indicate an error. When there is something violates the design rules of the processor, a fault is triggered. Whenever a fault happens, internal processor registers will be updated to record the type of fault, the address of instruction at which fault happened, and if an associated exception is enabled, the exception handler will be called. The fault handler can report, resolve, or recover the system from the fault. For example: Dividing a number by zero causes DIVBYZERO fault, which will invoke Usage Fault Handler in which you can get rid of the problem such as closing the problematic task. The Vector Interrupt Table defines different types with priority of handling order as below: Exception Number IRQ Number Exception Type Priority Function 3 -13 Hard Fault -1 All faults that hang the processor 4 -12 Memory Fault Configurable Memory issue 5 -11 Bus Fault Configurable Data Bus issue 6 -10 Usage Fault Configurable Instruction/State/Access issue By default, not all exceptions and interrupts are enabled to be handled. Exception Default state Handling behavior Hard Fault Always enabled, can be masked - Memory Fault Disabled by default Synchronous Bus Fault Disabled by default Synchronous Usage Fault Disabled by default Synchronous The Vector Interrupt Table is implemented in assembly code in the startup file of MCU startup_*.s . g_pfnVectors : . word _estack /* MSP value */ . word Reset_Handler /* Reset routine */ . word NMI_Handler /* No-Maskable Interrupt */ . word HardFault_Handler /* System faults */ . word MemManage_Handler /* Memory access issues */ . word BusFault_Handler /* Bus access issues */ . word UsageFault_Handler /* Instruction/State issues */ ...","title":"Fault exception"},{"location":"blog/stm32/fault-handler/#fault-types","text":"Fault Handler Bit name Fault status register Bus error on a vector read HardFault_Handler VECTTBL Hard fault status register (HFSR) Fault escalated to a hard fault FORCED MPU or default memory map mismatch: MemManage_Handler - Memory management fault address register (MMFSR, MMFAR) \u2013 on instruction access IACCVIOL \u2013 on data access DACCVIOL \u2013 during exception stacking MSTKERR \u2013 during exception unstacking MUNSKERR \u2013 during lazy floating-point state preservation MLSPERR Bus error BusFault_Handler - Bus fault address register (BFSR, BFAR) \u2013 During exception stacking STKERR \u2013 During exception unstacking UNSTKERR \u2013 During instruction prefetch IBUSERR \u2013 During lazy floating-point state preservation LSPERR Precise data bus error PRECISERR Imprecise data bus error IMPRECISERR Attempt to access a coprocessor Usage fault NOCP Configurable fault status register (CFSR ; UFSR+BFSR+MMFSR) Undefined instruction UNDEFINSTR Attempt to enter an invalid instruction set state INVSTATE Invalid EXC_RETURN value INVPC Illegal unaligned load or store UNALIGNED Divide By 0 DIVBYZERO Fault escalation and hard faults All faults exceptions except for hard fault have configurable exception priority, as described in System handler priority registers (SHPRx). Software can disable execution of the handlers for these faults. Usually, the exception priority, together with the values of the exception mask registers, determines whether the processor enters the fault handler, and whether a fault handler can preempt another fault handler. In some situations, a fault with configurable priority is treated as a hard fault. This is called priority escalation, and the fault is described as escalated to hard fault. Escalation to hard fault occurs when: A fault handler causes the same kind of fault as the one it is servicing. This escalation to hard fault occurs when a fault handler cannot preempt itself because it must have the same priority as the current priority level. A fault handler causes a fault with the same or lower priority as the fault it is servicing. This is because the handler for the new fault cannot preempt the currently executing fault handler. An exception handler causes a fault for which the priority is the same as or lower than the currently executing exception. A fault occurs and the handler for that fault is not enabled. If a bus fault occurs during a stack push when entering a bus fault handler, the bus fault does not escalate to a hard fault. This means that if a corrupted stack causes a fault, the fault handler executes even though the stack push for the handler failed. The fault handler operates, but the stack contents are corrupted. Only Reset and NMI can preempt the fixed priority hard fault. A hard fault can preempt any exception other than Reset, NMI, or another hard fault. Lockup state The processor enters a lockup state if a hard fault occurs when executing the NMI or hard fault handlers. When the processor is in lockup state it does not execute any instructions. The processor remains in lockup state until either: It is reset An NMI occurs It is halted by a debugger If lockup state occurs from the NMI handler a subsequent NMI does not cause the processor to leave lockup state.","title":"Fault types"},{"location":"blog/stm32/fault-handler/#example","text":"This example enables all configurable fault exceptions, implement fault exceptions handlers, and trigger faults by following methods: Execute an undefined instruction Divide by Zero Execute instruction from peripheral region Execute SVC inside the SVC Handler Execute SVC inside an interrupt handler whose priority is same or less than SVC priority Step 0: Create a new project You should create a bare-metal project which just has a few files including a linker and a main. Step 1: Enable all fault exceptions In the document PM0214: STM32 Cortex\u00ae-M4 MCUs and MPUs programming manual , look at the below section: 4.4 System control block (SCB The System control block (SCB) provides system implementation information, and system control. This includes configuration, control, and reporting of the system exceptions. The System handler control and state register (SHCSR) is at the address 0xE000ED24 4.4.7 Configuration and control register (CCR) The CCR controls entry to Thread mode and enables: The handlers for NMI, hard fault and faults escalated by FAULTMASK to ignore bus faults Trapping of divide by zero and unaligned accesses Access to the STIR by unprivileged software Configuration and control register (CCR) 4.4.9 System handler control and state register (SHCSR) The SHCSR enables the system handlers, and indicates: The pending status of the bus fault, memory management fault, and SVC exceptions The active status of the system handlers If you disable a system handler and the corresponding fault occurs, the processor treats the fault as a hard fault. System handler control and state register (SHCSR) We can use direct memory access method to configure this SHCSR register: // enable handlers uint32_t * pSHCSR = ( uint32_t * ) 0xE000ED24 ; * pSHCSR |= ( 1 << 16 ); // Memory Fault * pSHCSR |= ( 1 << 17 ); // Bus Fault * pSHCSR |= ( 1 << 18 ); // Usage Fault // enable Divide by Zero Trap uint32_t * pCCR = ( uint32_t * ) 0xE000ED14 ; * pCCR |= ( 1 << 4 ); // Div by Zero Step 2: Implement Fault Handlers The names of handlers are defined in the Interrupt Vector Table: g_pfnVectors : . word _estack /* MSP value */ . word Reset_Handler /* Reset routine */ . word NMI_Handler /* No-Maskable Interrupt */ . word HardFault_Handler /* System faults */ . word MemManage_Handler /* Memory access issues */ . word BusFault_Handler /* Bus access issues */ . word UsageFault_Handler /* Instruction/State issues */ We can directly override those functions in the main file, for example: void UsageFault_Handler () { printf ( \"Exception: Usage Fault \\n \" ); while ( 1 ); } Step 3: Trigger Usage Fault We will try to call a function at a location where there is invalid instruction: /* Fill a meaningless value */ * ( uint32_t * ) 0x20010000 = 0xFFFFFFFF ; /* Set PC with LSB being 1 to indicate Thumb State */ void ( * pFunc )( void ) = ( void * ) 0x20010001 ; /* call function */ pFunc (); Compile and run the program, you will get Usage Fault exception: Usage Fault: Undefined Instruction To find out which line of code caused the exception, you can refer to the Fault Analyzer tool. Note that this tool dumps all saved registers during Stacking of Context Switching . Note that the LR register save the address of the next instruction of what was being executed. In our example, if LR contains 0x80004b7 , we can find the address 0x80004b7 or 0x80004b6 in the disassembly file. The previous instruction of the found instruction at 0x80004b6 mostly the hot spot which caused the fault. Use Fault Analyzer to find the executing instruction Exercise Try to cause Divide by Zero exception If disable Usage Fault in SHCSR register, which Fault Exception will be raised?","title":"Example"},{"location":"blog/stm32/fault-handler/#fault-handler","text":"We can not plug a debugger all the time to catch the state of system after a Fault happened. A good method is to capture the system state to file or memory for later analysis. We know that when exception occurs, CPU automatically saves some context registers before jumping to a Fault Handler. We can implement a way to dump those saved registers. Naked function to capture Stack Frame A normal function call always has Prologue and Epilogue sequences added by compiler. In the Prologue, some line of code is added to prepare the stack for the function. However, that action will change the Stack Pointer value. Therefore, a naked function should be used to keep the Stack Pointer value. __attribute__ (( naked )) void UsageFault_Handler ( void ) { // get current Stack Pointer __asm volatile ( \"MRS R0, MSP\" ); __asm volatile ( \"B UsageFault_Handler_main\" ); } This naked function will save the MSP register to R0 , and pass R0 to the actual handler: void UsageFault_Handler_main ( uint32_t * pMSP ) { printf ( \"Exception: Usage Fault \\n \" ); DumpExceptionRegister ( pMSP ); uint32_t * pUFSR = ( uint32_t * ) 0xE000ED2A ; printf ( \"UFSR = 0x%lx \\n \" , * pUFSR & 0xFFFF ); while ( 1 ); } Helper function to dump Stack Frame We can write a general dumper to print out the Stack Frame: void DumpExceptionRegister ( uint32_t * pMSP ) { printf ( \" MSP = %p \\n \" , pMSP ); printf ( \" R0 = 0x%lx \\n \" , pMSP [ 0 ]); // May have argument of function printf ( \" R1 = 0x%lx \\n \" , pMSP [ 1 ]); // May have argument of function printf ( \" R2 = 0x%lx \\n \" , pMSP [ 2 ]); // May have argument of function printf ( \" R3 = 0x%lx \\n \" , pMSP [ 3 ]); // May have argument of function printf ( \" R12 = 0x%lx \\n \" , pMSP [ 4 ]); // IP holds an intermediate value of a calculation printf ( \" LR = 0x%lx \\n \" , pMSP [ 5 ]); // Address of the next instruction before the exception printf ( \" PC = 0x%lx \\n \" , pMSP [ 6 ]); // CPU was executing the instruction at PC printf ( \"xPSR = 0x%lx \\n \" , pMSP [ 7 ]); // Status of system before execution at PC completes } You can use any technique to redirect the Standard IO from printf to UART terminal, or SWD Terminal. Dump saved Stack Frame to SWD","title":"Fault Handler"},{"location":"blog/stm32/interrupt/","tags":["arm","stm32"],"text":"window.location.href = \"../exception/\" This page has been merged to a new page Exception !","title":"Exception and Interrupt"},{"location":"blog/stm32/intro/","tags":["arm","stm32"],"text":"ARM Cortex-M processors # .red { color: red; } The ARM (Advanced RISC Machines) processors use Reduced Instruction Set Computing (RISC) architectures, and nowadays have many revisions (ARMv6, ARMv6-M, ARMv7, ARMv7-A, etc.). ARM Cortex is a wide set of 32/64-bit core architectures, which are based on ARM architecture revisions. For example, a processor based on the Cortex-M4 core is designed on the ARMv7-M architecture. ARM Cortex microcontrollers are divided into three main subfamilies: Cortex-A which stands for A pplication Cortex-R which stand for R eal-Time Cortex-M which stands for E M bedded Operational Modes # The processor gives 2 Operational Modes: Thread mode (default) Used to execute application software The processor enters Thread mode when it comes out of reset Can be in privileged or unprivileged access level, using bit nPRIV in the CONTROL register Handler mode Used to handle exceptions. The Interrupt Program Status register IPSR contains the exception type number of the current Interrupt Service Routine (ISR) The processor returns to Thread mode when it has finished exception processing Always in privileged access level Access Levels # Unprivileged Has limited access to the MSR and MRS instructions, and cannot use the CPS instruction. Cannot access the system timer, NVIC, or system control block. Might have restricted access to memory or peripherals. Must use the SVC instruction to make a supervisor call to transfer control to privileged software. Privileged (default) Can use all the instructions and has access to all resources. Can write to the CONTROL register to change the privilege level for software execution Stacks # The processor implements two stacks, the main stack and the process stack, with independent copies of the stack pointer. The Stack Pointer (SP) is register R13. In Thread mode, bit[1] of the CONTROL register indicates the stack pointer to use: 0 : Main Stack Pointer (MSP). This is the reset value. 1 : Process Stack Pointer (PSP). On reset, the processor loads the MSP with the value from address 0x00000000 . Handler mode always uses the MSP, so the processor ignores explicit writes to the active stack pointer bit of the CONTROL register when in Handler mode. The exception entry and return mechanisms update the CONTROL register. In an OS environment, it is recommended that threads running in Thread mode use the process stack, and the kernel and exception handlers use the main stack. Core Registers # Like all RISC architectures, Cortex-M processors are load/store machines, which perform operations only on CPU registers except for two categories of instructions: load and store , used to transfer data between CPU registers and memory locations Processor register set on ARM Cortex-M Microprocessor R0 ~ R12 are general-purpose registers , and can be used as operands for ARM instructions. Some general-purpose registers, however, can be used by the compiler as registers with special functions. R13 is the Stack Pointer (SP) register, which is also said to be banked. This means that the register content changes according to the current CPU mode ( privileged or unprivileged ). This function is typically used by Real Time Operating Systems (RTOS) to do context switching. R14 is the Link Register (LR) register, which is a special-purpose register which holds the address to return to when a function call completes. This is more efficient than the more traditional scheme of storing return addresses on a call stack, sometimes called a machine stack. The linker register does not require the writes and reads of the memory containing the stack which can save a considerable percentage of execution time with repeated calls of small subroutines. R15 is the Program Counter (PC) register, which has the address of the next instruction to be executed from memory. Usually, the PC is incremented after fetching an instruction. However, control transfer instructions can change the sequence by placing a new value in the PC register. In debugger, the PC register contains the address of the instruction which will be executed in next step. It is the displayed address of the instruction in the xecute stage. The actual PC value is the address of the instruction in the fetch stage (2 instruction ahead!). Read more in Load instruction example . Program status register (PSR) combines Application Program Status Register (APSR) , Interrupt Program Status Register (IPSR) , Execution Program Status Register (EPSR) PRIMASK is the Priority Mask register which prevents the activation of all exceptions with configurable priority FAULTMASK is the Fault Mask register which prevents activation of all exceptions except for Non-Maskable Interrupt (NMI) CONTROL is the register that controls the stack used and the privilege level for software execution when the processor is in Thread mode and indicates whether the FPU state is active Memory Map # ARM defines a standardized memory address space common to all Cortex-M cores, which ensures code portability among different silicon manufacturer. The address space is 4 GB wide (due to 32-bit address line), and it is organized in several subregions with different logical functionalities. Fixed memory map for ARM cores The first 512 MB are dedicated to code area : All Cortex-M processors map the code area starting at address 0x00000000 . This area also includes the pointer to the beginning of the stack (usually placed in SRAM) and the system interrupt vector table. An area starting at address 0x08000000 is bound to the internal MCU flash memory, and it is the area where program code resides. With a specific boot configuration, this area is also aliased from address 0x00000000 . This means that it is perfectly possible to refer to the content of the flash memory both starting at address 0x08000000 and 0x00000000 . System Memory is a ROM region filled with official pre-programmed Bootloader which can be used to load code from several peripherals, including USARTs, USB and CAN bus. Option Bytes region contains a series of bit flags which can be used to configure several aspects of the MCU (such as flash read protection, hardware watchdog, boot mode and so on) and are related to a specific microcontroller. Next 512 MB is mapped to Internal SRAM : It starts at address 0x20000000 and can potentially extend to 0x3FFFFFFF . This area also can be aliased to the start-up address at 0x00000000 to execute code in internal RAM. The left space is for peripherals and other stuff : Other memory regions are mapped to external RAM, peripherals and the internal core registers. All Cortex processor registers are at fixed locations for all Cortex-based microcontrollers. This allows code to be more easily ported between different core variants and indeed other vendors\u2019 Cortex-based microcontrollers. Memory Map for Code Area Bit-Banding # In embedded applications, it is quite common to work with a single bit of a word using bit-masking. For example: uint8_t flags = 0 ; flags |= 0x4 ; // set the 4-th bit generates assembly code : 0 x0a: 79 fb ldrb r3 , [ r7 , #7] 0 x0c: f043 0304 orr.w r3 , r3 , #4 0 x10: 71 fb strb r3 , [ r7 , #7] Such a simple operation requires three assembly instructions (fetch, modify, save). This leads to a problem if an interruption happens between processing bit mask. Bit-banding is the ability to map each bit of a given area of memory to a whole word in the aliased bit-banding memory region, allowing atomic access to such bit. Memory Map of an address in a bit-banding region ARM defines two bit-band regions for Cortex-M based MCUs, each one is 1 MB wide and mapped to a 32 Mbit bit-band alias region. The first one starts at 0x20000000 and ends at 0x200FFFFF , and it is aliased from 0x22000000 to 0x23FFFFFF . It is dedicated to the bit access of SRAM memory locations. Another bit-banding region starts at 0x40000000 and ends at 0x400FFFFF , which is dedicated to the memory mapping of peripherals, from 0x42000000 to 0x43FFFFFF . Define two macros in C that allow to easily compute bit-band alias addresses: /* MEMORY BIT-BANDING */ // Define base address of bit-band #define BITBAND_SRAM_BASE 0x20000000 // Define base address of alias band #define ALIAS_SRAM_BASE 0x22000000 // Convert SRAM address to alias region #define BITBAND_SRAM(a,b) ((ALIAS_SRAM_BASE + ((uint32_t)&(a)-BITBAND_SRAM_BASE)*32 + (b*4))) /* PERIPHERAL BIT-BANDING */ // Define base address of peripheral bit-band #define BITBAND_PERI_BASE 0x40000000 // Define base address of peripheral alias band #define ALIAS_PERI_BASE 0x42000000 // Convert PERI address to alias region #define BITBAND_PERI(a,b) ((ALIAS_PERI_BASE + ((uint32_t)a-BITBAND_PERI_BASE)*32 + (b*4))) Example that quickly modifies the state of PIN5 of the GPIOA port as follows: #define GPIOA_PERH_ADDR 0x40020000 #define ODR_ADDR_OFF 0x14 uint32_t * GPIOA_ODR = GPIOA_PERH_ADDR + ODR_ADDR_OFF uint32_t * GPIOA_PIN5 = BITBAND_PERI ( GPIOA_ODR , 5 ); * GPIOA_PIN5 = 0x1 ; // Turns GPIO HIGH Memory Map for Bit-banding Area Thumb Instruction Set # ARM Cortex-M processors provide a 32-bit instruction set, not only allows for a rich set of instructions, but also guarantees the best performance. However, memory footprint of the firmware has bigger cost. To address such issues, ARM introduced the Thumb 16-bit instruction set which is transparently expanded to full 32-bit ARM instructions in real time, without performance loss. Afterwards, ARM introduced the Thumb-2 instruction set, which is a mix of 16 and 32-bit instruction sets in one operation state. The T bit of EPS Register The Execution Program Status Register (EPSR) as a T bit to indicate Thumb state. If T but is 1 , next instruction is Thumb ISA. If T but is 0 , next instruction is ARM ISA. The Cortex-M4 processor only supports execution of instructions in Thumb state. Hence, the T bit must be always 1 . The LSB (bit 0) of the Program Counter (PC) register is loaded to that T bit when the PC register is written. Therefore, any address that is put into PC register must be odd. This is usually taken care by the compiler. In case you call a function by an address manually, you have to take care the LSB bit of the address yourself. void myfunc () { __asm volatile ( \"nop\" ); } int main () { // at 0x080001d8, but compiler will assign value 0x080001d9 void ( * pfunc_by_name )() = myfunc ; pfunc_by_name (); // manual load an address shoule be careful // use 0x080001d8 will cause Usage Fault Exception: Invalid State void ( * pfunc_by_addr )() = ( void * ) 0x080001d9 ; pfunc_by_addr (); } Compiler changes the address of a function to maintain the T bit Instruction Pipeline # Before an instruction is executed, the CPU has to fetch it from memory and decode it. So, it has 3 stages to complete an instruction. Modern CPUs introduce a way to parallelize these operations in order to increase their instructions\u2019 throughput. The basic instruction cycle is broken up into a series of steps, as if the instructions traveled along a pipeline . 3-stage instruction pipeline When dealing with pipelines, branching is an issue to be addressed. When branching causes the invalidation of pipeline streams, the last two instructions which have been loaded into the pipeline will be discarded. Memory Alignment # Aligned and Unaligned memory access ARM based CPUs are traditionally capable of accessing byte (8-bit), half word (16-bit) and word (32-bit) signed and unsigned variables, without increasing the number of assembly instructions as it happens on 8-bit MCU architectures which reads byte by byte. Aligned memory access causes a waste of memory locations. Interrupts and Exceptions # Interrupts and exceptions are asynchronous events that alter the program flow. When an exception or an interrupt occurs, the CPU suspends the execution of the current task, saves its context (that is, its stack pointer) and starts the execution of a routine designed to handle the interrupting event. This routine is called Exception Handler in case of exceptions and Interrupt Service Routine (ISR) in case of an interrupt. After the exception or interrupt has been handled, the CPU resumes the previous execution flow, and the previous task can continue its execution. In the ARM architecture, interrupts are one type of exception. Interrupts are usually generated from on-chip peripherals (e.g., a timer) or external inputs (e.g. a tactile switch connected to a GPIO), and in some cases they can be triggered by software. Exceptions are, instead, related to software execution, and the CPU itself can be a source of exceptions. Each exception (and hence interrupt) has a number which uniquely identifies it. Cortex-M cores has pre-defined exception table which contains the addresses of function to handle those exceptions. Number Exception Type Priority Function 1 Reset -3 Reset 2 NMI -2 Non-Maskable Interrupt 3 Hard Fault -1 All faults that hang the processor 4 Memory Fault Configurable Memory issue 5 Bus Fault Configurable Data bus issue 6 Usage Fault Configurable Data bus issue 7 ~ 10 Reserved \u2014 Reserved 11 SVCall Configurable System service call (SVC instruction) 12 Debug Configurable Debug monitor (via SWD) 13 Reserved \u2014 Reserved 14 PendSV Configurable Pending request for System Service call 15 SysTick Configurable System Timer 16 ~ 240 IRQ Configurable Interrupt Request System Timer # Cortex-M based processors can optionally provide a System Timer, also known as SysTick which is a 24-bit down-counting timer used to provide a system tick for Real Time Operating Systems (RTOS). It is used to generate periodic interrupts to scheduled tasks, or measure delay. When the timer reach zero, it fires an interrupt number 15, as seen in the Interrupt Table above. Power Mode # Cortex-M processors provide several levels of power management which can be set via System Control Register (SCR) . Run mode : full clock speed, all using peripherals are activated Sleep mode : reduced clock speed, some peripherals are suspended Deep sleep mode : clock is stopped, need external event to wake-up CMSIS for SW development # Cortex Microcontroller Software Interface Standard (CMSIS) is a vendor-independent hardware abstraction layer for the Cortex-M processor series and specifies debugger interfaces. The CMSIS consists of the following components: CMSIS-CORE : API for the Cortex-M processor core and peripherals CMSIS-Driver : defines generic peripheral driver interfaces for middleware making them reusable across supported devices CMSIS-DSP : API for process signal and data such as fixed-point, single precision floating-point CMSIS-RTOS API: Common API for Real-Time Operating Systems CMSIS-Pack : a set of collections which includes source, header, library files, documentation, flash programming algorithms, source code templates and example projects CMSIS-SVD : System View Description for Peripherals CMSIS-DAP : Debug Access Port Cortex-M comparison # A table excerpted from ARM website. Feature Cortex-M0 Cortex-M0+ Cortex-M3 Cortex-M4 Cortex-M33 Cortex-M7 ISA Armv6-M Armv6-M Armv7-M Armv7-M Armv8-M Mainline Armv7-M Thumb, Thumb-2 Pipeline stages 3 2 3 3 3 6 Memory Protection Unit No Yes Yes Yes Yes Yes Maximum MPU regions 0 8 8 8 16 16 Trace (ETM or MTB) No MTB ETMv3 ETMv3 MTB and/or ETMv4 ETMv4 DSP No No No Yes Yes Yes Floating point hardware No No No Yes Yes Yes Bus protocol AHB Lite AHB Lite AHB Lite, APB AHB Lite, APB AHB5 AXI4, AHB Lite, APB, TCM Maximum # external interrupts 32 32 240 240 480 240 CMSIS Support Yes STM32 Microcontrollers # STM32 is a broad range of ARM Cortex-M microcontrollers divided in nine subfamilies. Internally, each microcontroller consists of the processor core, static RAM, flash memory, debugging interface, and various peripherals. Here are advantages of using STM32 MCUs: Cortex-M based MCUs have a large community, supported by free tool-chain, and is written in many shared knowledge articles The Pin-to-Pin compatibility for most of STM32 MCUs helps to change the MCU while keeping pin assignments Almost pins are 5V tolerant, that means it can interface with other devices which do not use 3.3V without using level shifter Cheap is an advantage of using STM32 MCUs with ARM based processors and supported RTOS Integrated bootloader is shipped with internal ROM which allows to reprogram the internal flash memory using some communication peripherals STM32 MCUs STM32 MCUs comparison Type Family Core Max Frequency Flash High Performance STM32H7 Cortex-M7 / Cortex -M4 480 MHz / 240 MHz 1 to 2 MB STM32F7 Cortex-M7 216 MHz 256 KB to 2 MB STM32F4 Cortex-M4 180 MHz 64 KB to 2 MB STM32F2 Cortex-M3 120 MHz 128 KB to 1 MB Mainstream STM32G4 Cortex-M4 170 MHz 32 to 512 KB STM32F3 Cortex-M4 72 MHz 16 to 512 KB STM32F1 Cortex-M3 72 MHz 16 KB to 1 MB STM32G0 Cortex-M0+ 64 MHz 16 to 512 KB STM32F0 Cortex-M0 48 MHz 16 to 256 KB Ultra-low-power STM32L5 Cortex-M33 110 MHz 256 to 512 KB STM32L4+ Cortex-M4 120 MHz 512 KB to 2 MB STM32L4 Cortex-M4 80 MHz 64 KB to 1 MB STM32L1 Cortex-M3 32 MHz 32 to 512 KB STM32L0 Cortex-M0+ 32 MHz 8 to 192 KB Wireless STM32WB Cortex-M4 / Cortex-M0+ 64 MHz / 32 MHz 256 KB to 1 MB STM32WL Cortex-M4 48 MHz 64 KB to 256 KB","title":"Introduction to ARM Cortex-M & STM32 MCUs"},{"location":"blog/stm32/intro/#arm-cortex-m-processors","text":".red { color: red; } The ARM (Advanced RISC Machines) processors use Reduced Instruction Set Computing (RISC) architectures, and nowadays have many revisions (ARMv6, ARMv6-M, ARMv7, ARMv7-A, etc.). ARM Cortex is a wide set of 32/64-bit core architectures, which are based on ARM architecture revisions. For example, a processor based on the Cortex-M4 core is designed on the ARMv7-M architecture. ARM Cortex microcontrollers are divided into three main subfamilies: Cortex-A which stands for A pplication Cortex-R which stand for R eal-Time Cortex-M which stands for E M bedded","title":"ARM Cortex-M processors"},{"location":"blog/stm32/intro/#operational-modes","text":"The processor gives 2 Operational Modes: Thread mode (default) Used to execute application software The processor enters Thread mode when it comes out of reset Can be in privileged or unprivileged access level, using bit nPRIV in the CONTROL register Handler mode Used to handle exceptions. The Interrupt Program Status register IPSR contains the exception type number of the current Interrupt Service Routine (ISR) The processor returns to Thread mode when it has finished exception processing Always in privileged access level","title":"Operational Modes"},{"location":"blog/stm32/intro/#access-levels","text":"Unprivileged Has limited access to the MSR and MRS instructions, and cannot use the CPS instruction. Cannot access the system timer, NVIC, or system control block. Might have restricted access to memory or peripherals. Must use the SVC instruction to make a supervisor call to transfer control to privileged software. Privileged (default) Can use all the instructions and has access to all resources. Can write to the CONTROL register to change the privilege level for software execution","title":"Access Levels"},{"location":"blog/stm32/intro/#stacks","text":"The processor implements two stacks, the main stack and the process stack, with independent copies of the stack pointer. The Stack Pointer (SP) is register R13. In Thread mode, bit[1] of the CONTROL register indicates the stack pointer to use: 0 : Main Stack Pointer (MSP). This is the reset value. 1 : Process Stack Pointer (PSP). On reset, the processor loads the MSP with the value from address 0x00000000 . Handler mode always uses the MSP, so the processor ignores explicit writes to the active stack pointer bit of the CONTROL register when in Handler mode. The exception entry and return mechanisms update the CONTROL register. In an OS environment, it is recommended that threads running in Thread mode use the process stack, and the kernel and exception handlers use the main stack.","title":"Stacks"},{"location":"blog/stm32/intro/#core-registers","text":"Like all RISC architectures, Cortex-M processors are load/store machines, which perform operations only on CPU registers except for two categories of instructions: load and store , used to transfer data between CPU registers and memory locations Processor register set on ARM Cortex-M Microprocessor R0 ~ R12 are general-purpose registers , and can be used as operands for ARM instructions. Some general-purpose registers, however, can be used by the compiler as registers with special functions. R13 is the Stack Pointer (SP) register, which is also said to be banked. This means that the register content changes according to the current CPU mode ( privileged or unprivileged ). This function is typically used by Real Time Operating Systems (RTOS) to do context switching. R14 is the Link Register (LR) register, which is a special-purpose register which holds the address to return to when a function call completes. This is more efficient than the more traditional scheme of storing return addresses on a call stack, sometimes called a machine stack. The linker register does not require the writes and reads of the memory containing the stack which can save a considerable percentage of execution time with repeated calls of small subroutines. R15 is the Program Counter (PC) register, which has the address of the next instruction to be executed from memory. Usually, the PC is incremented after fetching an instruction. However, control transfer instructions can change the sequence by placing a new value in the PC register. In debugger, the PC register contains the address of the instruction which will be executed in next step. It is the displayed address of the instruction in the xecute stage. The actual PC value is the address of the instruction in the fetch stage (2 instruction ahead!). Read more in Load instruction example . Program status register (PSR) combines Application Program Status Register (APSR) , Interrupt Program Status Register (IPSR) , Execution Program Status Register (EPSR) PRIMASK is the Priority Mask register which prevents the activation of all exceptions with configurable priority FAULTMASK is the Fault Mask register which prevents activation of all exceptions except for Non-Maskable Interrupt (NMI) CONTROL is the register that controls the stack used and the privilege level for software execution when the processor is in Thread mode and indicates whether the FPU state is active","title":"Core Registers"},{"location":"blog/stm32/intro/#memory-map","text":"ARM defines a standardized memory address space common to all Cortex-M cores, which ensures code portability among different silicon manufacturer. The address space is 4 GB wide (due to 32-bit address line), and it is organized in several subregions with different logical functionalities. Fixed memory map for ARM cores The first 512 MB are dedicated to code area : All Cortex-M processors map the code area starting at address 0x00000000 . This area also includes the pointer to the beginning of the stack (usually placed in SRAM) and the system interrupt vector table. An area starting at address 0x08000000 is bound to the internal MCU flash memory, and it is the area where program code resides. With a specific boot configuration, this area is also aliased from address 0x00000000 . This means that it is perfectly possible to refer to the content of the flash memory both starting at address 0x08000000 and 0x00000000 . System Memory is a ROM region filled with official pre-programmed Bootloader which can be used to load code from several peripherals, including USARTs, USB and CAN bus. Option Bytes region contains a series of bit flags which can be used to configure several aspects of the MCU (such as flash read protection, hardware watchdog, boot mode and so on) and are related to a specific microcontroller. Next 512 MB is mapped to Internal SRAM : It starts at address 0x20000000 and can potentially extend to 0x3FFFFFFF . This area also can be aliased to the start-up address at 0x00000000 to execute code in internal RAM. The left space is for peripherals and other stuff : Other memory regions are mapped to external RAM, peripherals and the internal core registers. All Cortex processor registers are at fixed locations for all Cortex-based microcontrollers. This allows code to be more easily ported between different core variants and indeed other vendors\u2019 Cortex-based microcontrollers. Memory Map for Code Area","title":"Memory Map"},{"location":"blog/stm32/intro/#bit-banding","text":"In embedded applications, it is quite common to work with a single bit of a word using bit-masking. For example: uint8_t flags = 0 ; flags |= 0x4 ; // set the 4-th bit generates assembly code : 0 x0a: 79 fb ldrb r3 , [ r7 , #7] 0 x0c: f043 0304 orr.w r3 , r3 , #4 0 x10: 71 fb strb r3 , [ r7 , #7] Such a simple operation requires three assembly instructions (fetch, modify, save). This leads to a problem if an interruption happens between processing bit mask. Bit-banding is the ability to map each bit of a given area of memory to a whole word in the aliased bit-banding memory region, allowing atomic access to such bit. Memory Map of an address in a bit-banding region ARM defines two bit-band regions for Cortex-M based MCUs, each one is 1 MB wide and mapped to a 32 Mbit bit-band alias region. The first one starts at 0x20000000 and ends at 0x200FFFFF , and it is aliased from 0x22000000 to 0x23FFFFFF . It is dedicated to the bit access of SRAM memory locations. Another bit-banding region starts at 0x40000000 and ends at 0x400FFFFF , which is dedicated to the memory mapping of peripherals, from 0x42000000 to 0x43FFFFFF . Define two macros in C that allow to easily compute bit-band alias addresses: /* MEMORY BIT-BANDING */ // Define base address of bit-band #define BITBAND_SRAM_BASE 0x20000000 // Define base address of alias band #define ALIAS_SRAM_BASE 0x22000000 // Convert SRAM address to alias region #define BITBAND_SRAM(a,b) ((ALIAS_SRAM_BASE + ((uint32_t)&(a)-BITBAND_SRAM_BASE)*32 + (b*4))) /* PERIPHERAL BIT-BANDING */ // Define base address of peripheral bit-band #define BITBAND_PERI_BASE 0x40000000 // Define base address of peripheral alias band #define ALIAS_PERI_BASE 0x42000000 // Convert PERI address to alias region #define BITBAND_PERI(a,b) ((ALIAS_PERI_BASE + ((uint32_t)a-BITBAND_PERI_BASE)*32 + (b*4))) Example that quickly modifies the state of PIN5 of the GPIOA port as follows: #define GPIOA_PERH_ADDR 0x40020000 #define ODR_ADDR_OFF 0x14 uint32_t * GPIOA_ODR = GPIOA_PERH_ADDR + ODR_ADDR_OFF uint32_t * GPIOA_PIN5 = BITBAND_PERI ( GPIOA_ODR , 5 ); * GPIOA_PIN5 = 0x1 ; // Turns GPIO HIGH Memory Map for Bit-banding Area","title":"Bit-Banding"},{"location":"blog/stm32/intro/#thumb-instruction-set","text":"ARM Cortex-M processors provide a 32-bit instruction set, not only allows for a rich set of instructions, but also guarantees the best performance. However, memory footprint of the firmware has bigger cost. To address such issues, ARM introduced the Thumb 16-bit instruction set which is transparently expanded to full 32-bit ARM instructions in real time, without performance loss. Afterwards, ARM introduced the Thumb-2 instruction set, which is a mix of 16 and 32-bit instruction sets in one operation state. The T bit of EPS Register The Execution Program Status Register (EPSR) as a T bit to indicate Thumb state. If T but is 1 , next instruction is Thumb ISA. If T but is 0 , next instruction is ARM ISA. The Cortex-M4 processor only supports execution of instructions in Thumb state. Hence, the T bit must be always 1 . The LSB (bit 0) of the Program Counter (PC) register is loaded to that T bit when the PC register is written. Therefore, any address that is put into PC register must be odd. This is usually taken care by the compiler. In case you call a function by an address manually, you have to take care the LSB bit of the address yourself. void myfunc () { __asm volatile ( \"nop\" ); } int main () { // at 0x080001d8, but compiler will assign value 0x080001d9 void ( * pfunc_by_name )() = myfunc ; pfunc_by_name (); // manual load an address shoule be careful // use 0x080001d8 will cause Usage Fault Exception: Invalid State void ( * pfunc_by_addr )() = ( void * ) 0x080001d9 ; pfunc_by_addr (); } Compiler changes the address of a function to maintain the T bit","title":"Thumb Instruction Set"},{"location":"blog/stm32/intro/#instruction-pipeline","text":"Before an instruction is executed, the CPU has to fetch it from memory and decode it. So, it has 3 stages to complete an instruction. Modern CPUs introduce a way to parallelize these operations in order to increase their instructions\u2019 throughput. The basic instruction cycle is broken up into a series of steps, as if the instructions traveled along a pipeline . 3-stage instruction pipeline When dealing with pipelines, branching is an issue to be addressed. When branching causes the invalidation of pipeline streams, the last two instructions which have been loaded into the pipeline will be discarded.","title":"Instruction Pipeline"},{"location":"blog/stm32/intro/#memory-alignment","text":"Aligned and Unaligned memory access ARM based CPUs are traditionally capable of accessing byte (8-bit), half word (16-bit) and word (32-bit) signed and unsigned variables, without increasing the number of assembly instructions as it happens on 8-bit MCU architectures which reads byte by byte. Aligned memory access causes a waste of memory locations.","title":"Memory Alignment"},{"location":"blog/stm32/intro/#interrupts-and-exceptions","text":"Interrupts and exceptions are asynchronous events that alter the program flow. When an exception or an interrupt occurs, the CPU suspends the execution of the current task, saves its context (that is, its stack pointer) and starts the execution of a routine designed to handle the interrupting event. This routine is called Exception Handler in case of exceptions and Interrupt Service Routine (ISR) in case of an interrupt. After the exception or interrupt has been handled, the CPU resumes the previous execution flow, and the previous task can continue its execution. In the ARM architecture, interrupts are one type of exception. Interrupts are usually generated from on-chip peripherals (e.g., a timer) or external inputs (e.g. a tactile switch connected to a GPIO), and in some cases they can be triggered by software. Exceptions are, instead, related to software execution, and the CPU itself can be a source of exceptions. Each exception (and hence interrupt) has a number which uniquely identifies it. Cortex-M cores has pre-defined exception table which contains the addresses of function to handle those exceptions. Number Exception Type Priority Function 1 Reset -3 Reset 2 NMI -2 Non-Maskable Interrupt 3 Hard Fault -1 All faults that hang the processor 4 Memory Fault Configurable Memory issue 5 Bus Fault Configurable Data bus issue 6 Usage Fault Configurable Data bus issue 7 ~ 10 Reserved \u2014 Reserved 11 SVCall Configurable System service call (SVC instruction) 12 Debug Configurable Debug monitor (via SWD) 13 Reserved \u2014 Reserved 14 PendSV Configurable Pending request for System Service call 15 SysTick Configurable System Timer 16 ~ 240 IRQ Configurable Interrupt Request","title":"Interrupts and Exceptions"},{"location":"blog/stm32/intro/#system-timer","text":"Cortex-M based processors can optionally provide a System Timer, also known as SysTick which is a 24-bit down-counting timer used to provide a system tick for Real Time Operating Systems (RTOS). It is used to generate periodic interrupts to scheduled tasks, or measure delay. When the timer reach zero, it fires an interrupt number 15, as seen in the Interrupt Table above.","title":"System Timer"},{"location":"blog/stm32/intro/#power-mode","text":"Cortex-M processors provide several levels of power management which can be set via System Control Register (SCR) . Run mode : full clock speed, all using peripherals are activated Sleep mode : reduced clock speed, some peripherals are suspended Deep sleep mode : clock is stopped, need external event to wake-up","title":"Power Mode"},{"location":"blog/stm32/intro/#cmsis-for-sw-development","text":"Cortex Microcontroller Software Interface Standard (CMSIS) is a vendor-independent hardware abstraction layer for the Cortex-M processor series and specifies debugger interfaces. The CMSIS consists of the following components: CMSIS-CORE : API for the Cortex-M processor core and peripherals CMSIS-Driver : defines generic peripheral driver interfaces for middleware making them reusable across supported devices CMSIS-DSP : API for process signal and data such as fixed-point, single precision floating-point CMSIS-RTOS API: Common API for Real-Time Operating Systems CMSIS-Pack : a set of collections which includes source, header, library files, documentation, flash programming algorithms, source code templates and example projects CMSIS-SVD : System View Description for Peripherals CMSIS-DAP : Debug Access Port","title":"CMSIS for SW development"},{"location":"blog/stm32/intro/#cortex-m-comparison","text":"A table excerpted from ARM website. Feature Cortex-M0 Cortex-M0+ Cortex-M3 Cortex-M4 Cortex-M33 Cortex-M7 ISA Armv6-M Armv6-M Armv7-M Armv7-M Armv8-M Mainline Armv7-M Thumb, Thumb-2 Pipeline stages 3 2 3 3 3 6 Memory Protection Unit No Yes Yes Yes Yes Yes Maximum MPU regions 0 8 8 8 16 16 Trace (ETM or MTB) No MTB ETMv3 ETMv3 MTB and/or ETMv4 ETMv4 DSP No No No Yes Yes Yes Floating point hardware No No No Yes Yes Yes Bus protocol AHB Lite AHB Lite AHB Lite, APB AHB Lite, APB AHB5 AXI4, AHB Lite, APB, TCM Maximum # external interrupts 32 32 240 240 480 240 CMSIS Support Yes","title":"Cortex-M comparison"},{"location":"blog/stm32/intro/#stm32-microcontrollers","text":"STM32 is a broad range of ARM Cortex-M microcontrollers divided in nine subfamilies. Internally, each microcontroller consists of the processor core, static RAM, flash memory, debugging interface, and various peripherals. Here are advantages of using STM32 MCUs: Cortex-M based MCUs have a large community, supported by free tool-chain, and is written in many shared knowledge articles The Pin-to-Pin compatibility for most of STM32 MCUs helps to change the MCU while keeping pin assignments Almost pins are 5V tolerant, that means it can interface with other devices which do not use 3.3V without using level shifter Cheap is an advantage of using STM32 MCUs with ARM based processors and supported RTOS Integrated bootloader is shipped with internal ROM which allows to reprogram the internal flash memory using some communication peripherals STM32 MCUs STM32 MCUs comparison Type Family Core Max Frequency Flash High Performance STM32H7 Cortex-M7 / Cortex -M4 480 MHz / 240 MHz 1 to 2 MB STM32F7 Cortex-M7 216 MHz 256 KB to 2 MB STM32F4 Cortex-M4 180 MHz 64 KB to 2 MB STM32F2 Cortex-M3 120 MHz 128 KB to 1 MB Mainstream STM32G4 Cortex-M4 170 MHz 32 to 512 KB STM32F3 Cortex-M4 72 MHz 16 to 512 KB STM32F1 Cortex-M3 72 MHz 16 KB to 1 MB STM32G0 Cortex-M0+ 64 MHz 16 to 512 KB STM32F0 Cortex-M0 48 MHz 16 to 256 KB Ultra-low-power STM32L5 Cortex-M33 110 MHz 256 to 512 KB STM32L4+ Cortex-M4 120 MHz 512 KB to 2 MB STM32L4 Cortex-M4 80 MHz 64 KB to 1 MB STM32L1 Cortex-M3 32 MHz 32 to 512 KB STM32L0 Cortex-M0+ 32 MHz 8 to 192 KB Wireless STM32WB Cortex-M4 / Cortex-M0+ 64 MHz / 32 MHz 256 KB to 1 MB STM32WL Cortex-M4 48 MHz 64 KB to 256 KB","title":"STM32 Microcontrollers"},{"location":"blog/stm32/prepare/","tags":["arm","stm32"],"text":"Always use original products when you can afford to buy! Development boards # There are many boards available in the market, which are from the ST, or from a 3 rd party company, or just from a seller. Here are the list of some popular boards for beginners, as they are cheap and easy to buy from a retailer. STM32 Nucleo boards # These boards come with a cheap price and an integrated ST-LINK debugger. The advantages of this Nucleo board line is to have access directly to all GPIOs, and to have compliant Arduino connector. Many users who are familiar with Arduino like to use Nucleo boards, because they can keep using these STM32 boards as an Arduino. Starter boards can be: Nucleo-F103RB Nucleo-F401RE/F411RE Nucleo-F103RB Nucleo-H743 STM32 Discovery kits # This line of board allows either for beginner or for experienced users to get started on new projects. These boards are cheap, and have complete solutions for demonstrating the capabilities of the devices. Some boards come with many peripherals such as LCD, MEM sensors, touchpad. They also have integrated ST-LINK debugger/ programmer. Starter boards can be: STM32F072-Discovery STM32F429-Discovery STM32F072-Discovery STM32F429-Discovery Evaluation board # The STM32 Evaluation boards have been designed as a complete demonstration and development platform for the STM32 MCUs and MPUs. They are meant to be used to execute a comprehensive evaluation of ST Microelectronics solutions. These boards have integrated ST-LINK debugger/ programmer. They carry external circuitry, such as transceivers, sensors, memory interfaces, displays and many more. The evaluation boards can be considered as a reference design for application development. Starter boards can be: STM32L476-EVAL STM32F407-EVAL STM32L476-EVAL STM32F407-EVAL Custom board # Many users still find that the price of original boards is still high. There are many clones which use either authorized MCUs or even fake ones, with reduced peripherals. They are usually customized as different starter boards in small size and exposed just USB and debugging pins. The popular custom boards are \u201cBlue Pills\u201d STM32F103, and \u201cBlack Pills\u201d STM32F4x1. They are cheap and have many exposed pins. There is no debugger or programmer in these custom boards. Users have to use an external one, such as ST-LINK or J-LINK. A blue pill STM32F103 A black pill STM32Fx1 Power conflict On a custom board, there may be no power protection circuit added, therefore, do not connect 3.3 V power pin of the debugger to the board if the on-board USB port is plugged because the USB port already powers the board using 5 V line. Counterfeit chip There are counterfeit chips on the market that are blocked to work with ST-Link/ J-Link to flash and debug. Please make sure to not buy them, even there is a method to workaround with OpenOCD Update: new version of OpenOCD doesn't work with counterfeit chips anymore . Programmer & Debugger # Programmer is used to write application code into MCU. It can read the application and make a copy of the firmware. Debugger is used to read CPU registers, memory, and logging data to help developers see how application runs. It can halt the CPU too. In monitoring mode, it lets CPU run and read memory in background through some special channels to gather information of application and system in real-time. ST-LINK # All official boards from ST have integrated ST-Link debugger / programmer in version 2 or 3. They work on a Serial Wire Debug (SWD) interface. ST-Link comes with good performance and some extra feature such as Serial Wire Output (SWO), Virtual COM port, Mass-storage for drag-and-drop programming. On custom boards, there is no on-board debugger, so that an external debugger is needed. There are both original and clone version in the market. Original ST-LINK/V2 A clone of ST-LINK/V2 Missing SWO pin on ST-LINK clones Many ST-LINK clones only expose SWD interface ( SWCLK and SWDIO ). The pin for SWO is not exposed. There is a quick fix for this problem: wire the PA10 of the on-board STM32 chip to a pin on the header, read more in Export SWO pin note. J-LINK # One of a popular (and expensive) debugger manufacturer is SEGGER . They provide many tools for embedded systems. Their J-Link is quite expensive but comes with a lot of high performance features beside standard ones in ST-LINK, such as Real-time logging, system view, profiling. There are also cloned J-Link devices which are actually an STM32F0 MCU running a SEGGER firmware but have limitation in features due to missing hardware component and license. One interesting thing is SEGGER provides a tool to convert on-board ST-LINK/V2 to a J-LINK OB model with some limitations. You still are able to convert it back to original ST-Link debugger. After reverting to ST-Link, it\u2019s recommended to re-flash ST-Link firmware if you run into any problem. J-Link Pro Cloned J-Link OB Power Supplier # There are many ways to power the board. Always check the Voltage and the Maximum Current of the power source. During the development, the board should be powered through the debugger which connects to PC via a USB port. If the on-board USB port is connected to power source, do not connect the power pin from the debugger . In the final production, the board will run without a debugger connected to a host PC, the power can be connected to the USB port or the power pins directly either on 5 V or 3.3 V pin. A portable power source can be a Power bank, or a Li-Po battery. Also keep in mind that if the board would occasionally go to sleep state and the consumption current drops below 50 \u2013 70 mA, many power banks would drop the supply, so the system will shut down catastrophically. Logic Analyzer (optional) # A Logic Analyzer can capture (and display) multiple signals on a system. The output can be visualized in timing diagrams, and then analyzed or decoded to get detailed information about the signal or the protocol and data. There are small portable Logic Analyzers which just do capturing data, and then the captured data is transferred to a host PC via USB. Finally, the data is visualized by an application. Saleae Logic Cloned Logic The bandwidth of data collection heavily depends on the USB Host Controller on the the host PC. Modern laptops have only one USB 3.0 Host Controller and bandwidth is shared to many USB Devices, that sigifincantly reduce avaiable bandwidth reserved for your Logic Analyser\u2019s USB port.","title":"Prepare boards and equipment"},{"location":"blog/stm32/prepare/#development-boards","text":"There are many boards available in the market, which are from the ST, or from a 3 rd party company, or just from a seller. Here are the list of some popular boards for beginners, as they are cheap and easy to buy from a retailer.","title":"Development boards"},{"location":"blog/stm32/prepare/#stm32-nucleo-boards","text":"These boards come with a cheap price and an integrated ST-LINK debugger. The advantages of this Nucleo board line is to have access directly to all GPIOs, and to have compliant Arduino connector. Many users who are familiar with Arduino like to use Nucleo boards, because they can keep using these STM32 boards as an Arduino. Starter boards can be: Nucleo-F103RB Nucleo-F401RE/F411RE Nucleo-F103RB Nucleo-H743","title":"STM32 Nucleo boards"},{"location":"blog/stm32/prepare/#stm32-discovery-kits","text":"This line of board allows either for beginner or for experienced users to get started on new projects. These boards are cheap, and have complete solutions for demonstrating the capabilities of the devices. Some boards come with many peripherals such as LCD, MEM sensors, touchpad. They also have integrated ST-LINK debugger/ programmer. Starter boards can be: STM32F072-Discovery STM32F429-Discovery STM32F072-Discovery STM32F429-Discovery","title":"STM32 Discovery kits"},{"location":"blog/stm32/prepare/#evaluation-board","text":"The STM32 Evaluation boards have been designed as a complete demonstration and development platform for the STM32 MCUs and MPUs. They are meant to be used to execute a comprehensive evaluation of ST Microelectronics solutions. These boards have integrated ST-LINK debugger/ programmer. They carry external circuitry, such as transceivers, sensors, memory interfaces, displays and many more. The evaluation boards can be considered as a reference design for application development. Starter boards can be: STM32L476-EVAL STM32F407-EVAL STM32L476-EVAL STM32F407-EVAL","title":"Evaluation board"},{"location":"blog/stm32/prepare/#custom-board","text":"Many users still find that the price of original boards is still high. There are many clones which use either authorized MCUs or even fake ones, with reduced peripherals. They are usually customized as different starter boards in small size and exposed just USB and debugging pins. The popular custom boards are \u201cBlue Pills\u201d STM32F103, and \u201cBlack Pills\u201d STM32F4x1. They are cheap and have many exposed pins. There is no debugger or programmer in these custom boards. Users have to use an external one, such as ST-LINK or J-LINK. A blue pill STM32F103 A black pill STM32Fx1 Power conflict On a custom board, there may be no power protection circuit added, therefore, do not connect 3.3 V power pin of the debugger to the board if the on-board USB port is plugged because the USB port already powers the board using 5 V line. Counterfeit chip There are counterfeit chips on the market that are blocked to work with ST-Link/ J-Link to flash and debug. Please make sure to not buy them, even there is a method to workaround with OpenOCD Update: new version of OpenOCD doesn't work with counterfeit chips anymore .","title":"Custom board"},{"location":"blog/stm32/prepare/#programmer--debugger","text":"Programmer is used to write application code into MCU. It can read the application and make a copy of the firmware. Debugger is used to read CPU registers, memory, and logging data to help developers see how application runs. It can halt the CPU too. In monitoring mode, it lets CPU run and read memory in background through some special channels to gather information of application and system in real-time.","title":"Programmer &amp; Debugger"},{"location":"blog/stm32/prepare/#st-link","text":"All official boards from ST have integrated ST-Link debugger / programmer in version 2 or 3. They work on a Serial Wire Debug (SWD) interface. ST-Link comes with good performance and some extra feature such as Serial Wire Output (SWO), Virtual COM port, Mass-storage for drag-and-drop programming. On custom boards, there is no on-board debugger, so that an external debugger is needed. There are both original and clone version in the market. Original ST-LINK/V2 A clone of ST-LINK/V2 Missing SWO pin on ST-LINK clones Many ST-LINK clones only expose SWD interface ( SWCLK and SWDIO ). The pin for SWO is not exposed. There is a quick fix for this problem: wire the PA10 of the on-board STM32 chip to a pin on the header, read more in Export SWO pin note.","title":"ST-LINK"},{"location":"blog/stm32/prepare/#j-link","text":"One of a popular (and expensive) debugger manufacturer is SEGGER . They provide many tools for embedded systems. Their J-Link is quite expensive but comes with a lot of high performance features beside standard ones in ST-LINK, such as Real-time logging, system view, profiling. There are also cloned J-Link devices which are actually an STM32F0 MCU running a SEGGER firmware but have limitation in features due to missing hardware component and license. One interesting thing is SEGGER provides a tool to convert on-board ST-LINK/V2 to a J-LINK OB model with some limitations. You still are able to convert it back to original ST-Link debugger. After reverting to ST-Link, it\u2019s recommended to re-flash ST-Link firmware if you run into any problem. J-Link Pro Cloned J-Link OB","title":"J-LINK"},{"location":"blog/stm32/prepare/#power-supplier","text":"There are many ways to power the board. Always check the Voltage and the Maximum Current of the power source. During the development, the board should be powered through the debugger which connects to PC via a USB port. If the on-board USB port is connected to power source, do not connect the power pin from the debugger . In the final production, the board will run without a debugger connected to a host PC, the power can be connected to the USB port or the power pins directly either on 5 V or 3.3 V pin. A portable power source can be a Power bank, or a Li-Po battery. Also keep in mind that if the board would occasionally go to sleep state and the consumption current drops below 50 \u2013 70 mA, many power banks would drop the supply, so the system will shut down catastrophically.","title":"Power Supplier"},{"location":"blog/stm32/prepare/#logic-analyzer-optional","text":"A Logic Analyzer can capture (and display) multiple signals on a system. The output can be visualized in timing diagrams, and then analyzed or decoded to get detailed information about the signal or the protocol and data. There are small portable Logic Analyzers which just do capturing data, and then the captured data is transferred to a host PC via USB. Finally, the data is visualized by an application. Saleae Logic Cloned Logic The bandwidth of data collection heavily depends on the USB Host Controller on the the host PC. Modern laptops have only one USB 3.0 Host Controller and bandwidth is shared to many USB Devices, that sigifincantly reduce avaiable bandwidth reserved for your Logic Analyser\u2019s USB port.","title":"Logic Analyzer (optional)"},{"location":"blog/stm32/segger-rtt/","tags":["arm","stm32","debug","rtt"],"text":"J-Link RTT \u2014 Manual SEGGER_RTT.zip STM32-Tutorials SEGGER RTT integration Download SEGGER_RTT.zip then add files to project Call SEGGER_RTT_Init (); at the beginning of the main function Use SEGGER_RTT_printf () to send output to up-channels Enable SEGGER_REDIRECTION if you want to override the system calls to use native printf() . scanf() Debugging # There are some debug techniques used to inspect the firmware running on ARM-based MCUs: Semihosting : built-in to every ARM chips, need adding additional library and running in debug mode. Console log : forward to a native UART port , a Virtual COM port through a USB port. Serial Wire View (SWV) : fast output over dedicated Single Wire Output (SWO) pin, but it\u2019s only available on Cortex-M3+, and this is uni-direction communication. Real Time Transfer (RTT) : extremely fast but only work with SEGGER Debugger, can have a real-time bi-direction communication. Ways to print debug Real Time Transfer # Visit the official J-Link RTT \u2013 Real Time Transfer on SEGGER website for more information. SEGGER\u2019s J-Link RTT utilizes the background memory access feature on Debug Access Port (DAP) on Cortex-M and RX MCUs to communicate between the MCU and the PC\u2019s host application, through J-Link probes. RTT supports multiple channels in both directions, up to the host and down to the target, which can be used for different purposes and provide the most possible freedom to the user. SEGGER RTT does not need any additional pin or hardware , it can be connected via the standard debug port (SWD) to the target. It does not require any configuration of the target or in the debugging environment and can even be used with varying target speeds. RTT can be used in parallel to a running debug session, without intrusion, as well as without any IDE or debugger at all. SEGGER RTT can run on all ARM target through the SWD interface on a J-Link probe . The RTT target code is shipped as part of the J-Link Software and Documentation Pack which can be found after installing the J-Link Software in the folder <installaton folder>/Samples/RTT . How RTT Works # Real Time Transfer uses a SEGGER RTT Control Block structure in the target\u2019s memory to manage data reads and writes. The control block contains an ID to make it findable in memory by a connected J-Link and a ring buffer structure for each available channel, describing the channel buffer and its state. When RTT is active on the host computer, J-Link automatically searches for the SEGGER RTT Control Block in the target\u2019s known RAM regions. The RAM regions or the specific address of the Control Block can also be set via the host applications to speed up detection or the block cannot be found automatically. The default implementation uses one channel per direction, which are meant for printable terminal input and output. An additional up (to host) channel can for example be used to send profiling or event tracing data. Each channel can be configured to be blocking or non-blocking . In blocking mode the application will wait when the buffer is full, until all memory could be written, resulting in a blocked application state but preventing data from getting lost. In non-blocking mode only data which fits into the buffer, or none at all, will be written, and the rest will be discarded. This allows running in real time, even when no debugger is connected. The developer does not have to create a special debug version and the code can stay in place in a release application. RTT Performance # The performance of SEGGER RTT is significantly higher than any other technology used to output data to a host PC. An average line of text can be output in one microsecond or less. Basically it is only the time to do a single memcopy() call. RTT Performance in comparison with Semihosting and SWO The maximum speed at which output data can be sent to the host depends on the target buffer size and target interface speed. Even with a small target buffer of 512 Bytes an RTT speed of up to 1 MiB/s is possible with a high interface speed and 0.5 MiB/s are possible with a regular J-Link model. RTT APIs # The SEGGER RTT implementation is written in ANSI C and can be integrated into any embedded application. RTT can be used via a simple and easy to use API. It is even possible to override the standard printf() functions to use RTT. Using RTT reduces the time taken for printf() to a minimum and allows printing debug information to the host PC, while the application is performing time critical, real time tasks. The SEGGER RTT implementation includes a simple implementation of printf() which can be used to write a formatted string via RTT. SEGGER_RTT_Printf() is smaller than most standard library implementations and does not require heap and only a configurable amount of stack. However, it does not support printing double or float numbers . Function Name Description SEGGER_RTT_Read() Read data from an input buffer. SEGGER_RTT_Write() Write data to an output buffer. SEGGER_RTT_WriteString() Write a zero-terminated string to an output buffer. SEGGER_RTT_printf() Write a formatted string to an output buffer. SEGGER_RTT_GetKey() Get one character from input buffer 0. (non-blocking) SEGGER_RTT_HasKey() Check if a character is available in input buffer 0. SEGGER_RTT_WaitKey() Wait for a character to be available in input buffer 0 and get it. (blocking) SEGGER_RTT_ConfigUpBuffer() Configure an up (output) buffer. SEGGER_RTT_ConfigDownBuffer() Configure a down (input) buffer. SEGGER_RTT_Init() Initialize RTT Control Block structure when using RAM only targets. SEGGER_RTT_SetTerminal() Set the \u201cvirtual\u201d Terminal to use for output on channel 0 via Write and WriteString . SEGGER_RTT_TerminalOut() Send a zero-terminated string via a \u201cvirtual\u201d terminal. Integrate RTT # RTT in the target MCU is provided freely. Firstly, download the J-Link software and install it. Under the installation folder, the source code of RTT on MCU is found in Samples\\RTT . At the time of writing this guide, the version of J-Link is 7.64, therefore, user can find the SEGGER_RTT.zip file there. Add RTT files # \u2502 License.txt \u2502 README.txt \u2502 \u251c\u2500RTT \u2502 SEGGER_RTT_Conf.h # Configuration \u2502 SEGGER_RTT.h # Main header \u2502 SEGGER_RTT.c # Main implementation \u2502 SEGGER_RTT_printf.c # Print functions \u2502 SEGGER_RTT_ASM_ARMv7M.S # for Cortex-M3/M4/M7 \u2502 \u251c\u2500Syscalls \u2502 SEGGER_RTT_Syscalls_GCC.c # redirection for GCC and newlib \u2502 SEGGER_RTT_Syscalls_IAR.c # redirection for IAR \u2502 SEGGER_RTT_Syscalls_KEIL.c # redirection for KEIL ARM \u2502 SEGGER_RTT_Syscalls_SES.c # redirection for Segger Embedded System \u2502 \u2514\u2500Examples Main_RTT_InputEchoApp.c # echo characters Main_RTT_MenuApp.c # use character to select an option Main_RTT_PrintfTest.c # print log with format Main_RTT_SpeedTestApp.c # measure execution time As RTT implementation is target independent, so we will start with a bare project without using any CMSIS or LL/HAL library. Add RTT files Add Include paths # Open the _Project Properties__ \u2192 C/C++ Build \u2192 Settings . Then add ../SEGGER_RTT/Include into to the Include paths of both GCC Assembler and GCC Compiler Add RTT files to include paths Add Source files # To make RTT source files get compiled, add the folder /SEGGER_RTT/Source into the Source Location list, and add the folder /SEGGER_RTT/Include in the Paths and Symbols setting under the C/C++ General property. Add path and source files Usage RTT # F411RE_RTT.zip In the main.c file, include the SEGGER_RTT.h firstly to import RTT APIs. Inside the int main () function, call to SEGGER_RTT_Init() to initialize the SEGGER RTT Control Block and the Channel 0. We are going to: Add a new channel named Log on Channel 1 32 Bytes buffer, Up to Host Create a variable counter and increase it every second Send different data to virtual 0 , 1 , 2 on the Channel 0 (named Terminal by default) main.c #include <stdint.h> #include <SEGGER_RTT.h> /* add channel 1: log */ static uint8_t logBuffer [ 32 ]; char counter = 0 ; int main ( void ) { SEGGER_RTT_Init (); /* add channel 1: log */ SEGGER_RTT_ConfigUpBuffer ( 1 , \"Log\" , logBuffer , sizeof ( logBuffer ), SEGGER_RTT_MODE_NO_BLOCK_TRIM ); while ( 1 ) { // Channel 0 - virtual terminal 0 SEGGER_RTT_printf ( 0 , \"[0:0] counter = %d \\n \" , counter ++ ); // switch to Channel 0 - virtual terminal 1 SEGGER_RTT_SetTerminal ( 1 ); SEGGER_RTT_printf ( 0 , \"[0:1] negative = %d \\n \" , - counter ); // back to Channel 0 - virtual terminal 0 SEGGER_RTT_SetTerminal ( 0 ); // print to Channel 0 - virtual terminal 2 SEGGER_RTT_TerminalOut ( 2 , \"[0:2] nothing \\n \" ); // print to Channel 1 SEGGER_RTT_printf ( 1 , \"[1:x] last_digit = %d \\n \" , counter % 2 ); for ( int delay = 160000 ; delay -- ;); } } RTT Viewer # J-Link RTT Viewer is the main Windows GUI application to use all features of RTT on the debugging host. RTT Viewer can be used stand-alone, opening an own connection to J-Link and target or in parallel to a running debug session, attaching to it and using this existing J-Link connection. RTT Viewer supports all major features of RTT: Terminal output on Channel 0 Sending text input to Channel 0 Up to 16 virtual Terminals with only one target channel Controlling text output: Colored text, erasing the console Logging data on Channel 1 J-Link Probe Connect any J-Link probe into the SWD interface of the target MCU. Then start the J-Link RTT Viewer in the J-Link software package. J-Link Pro Cloned J-Link OB V2 J-Link JTAG connection J-Link SWD connection Convert ST-LINK to J-LINK SEGGER offers a firmware upgrading the ST-LINK on-board on the Nucleo and Discovery Boards to a J-LINK On-Board debugger. The configuration dialog will show up, select USB mode, and select the Target device from the list of supported devices. Then the viewer will open the Default Channel 0 to display RTT strings. RTT Viewer Configuration and Channel Info RTT Viewer can show messages from different virtual terminal in different colors. RTT Viewer showing messages from all terminals The Channel 1 can be logged in RTT Viewer. However, to log other channel, you have to use RTT Logger. RTT Logger Override syscalls # With the same method to redirect standard IO to SWV , UART or Virtual COM , two low-level functions _write() and _read() can be overridden to redirect to RTT. int _read ( int file , char * ptr , int len ) { * ptr = SEGGER_RTT_WaitKey (); return 1 ; } int _write ( int file , char * ptr , int len ) { SEGGER_RTT_Write ( 0 , ptr , len ); return len ; } Blocking Input The function SEGGER_RTT_WaitKey() intensionally block the application to read a character. Once a character is available, it is read and this function returns. Here is an example of reading a number using RTT redirection: int main ( void ) { SEGGER_RTT_Init (); printf ( \"Enter a number: \" ); int a ; scanf ( \"%d\" , & a ); printf ( \"Thanks! I got %d \\n \" , a ); } Use RTT redirection for scanf","title":"SEGGER Real-Time Transfer - very fast Debugging"},{"location":"blog/stm32/segger-rtt/#debugging","text":"There are some debug techniques used to inspect the firmware running on ARM-based MCUs: Semihosting : built-in to every ARM chips, need adding additional library and running in debug mode. Console log : forward to a native UART port , a Virtual COM port through a USB port. Serial Wire View (SWV) : fast output over dedicated Single Wire Output (SWO) pin, but it\u2019s only available on Cortex-M3+, and this is uni-direction communication. Real Time Transfer (RTT) : extremely fast but only work with SEGGER Debugger, can have a real-time bi-direction communication. Ways to print debug","title":"Debugging"},{"location":"blog/stm32/segger-rtt/#real-time-transfer","text":"Visit the official J-Link RTT \u2013 Real Time Transfer on SEGGER website for more information. SEGGER\u2019s J-Link RTT utilizes the background memory access feature on Debug Access Port (DAP) on Cortex-M and RX MCUs to communicate between the MCU and the PC\u2019s host application, through J-Link probes. RTT supports multiple channels in both directions, up to the host and down to the target, which can be used for different purposes and provide the most possible freedom to the user. SEGGER RTT does not need any additional pin or hardware , it can be connected via the standard debug port (SWD) to the target. It does not require any configuration of the target or in the debugging environment and can even be used with varying target speeds. RTT can be used in parallel to a running debug session, without intrusion, as well as without any IDE or debugger at all. SEGGER RTT can run on all ARM target through the SWD interface on a J-Link probe . The RTT target code is shipped as part of the J-Link Software and Documentation Pack which can be found after installing the J-Link Software in the folder <installaton folder>/Samples/RTT .","title":"Real Time Transfer"},{"location":"blog/stm32/segger-rtt/#how-rtt-works","text":"Real Time Transfer uses a SEGGER RTT Control Block structure in the target\u2019s memory to manage data reads and writes. The control block contains an ID to make it findable in memory by a connected J-Link and a ring buffer structure for each available channel, describing the channel buffer and its state. When RTT is active on the host computer, J-Link automatically searches for the SEGGER RTT Control Block in the target\u2019s known RAM regions. The RAM regions or the specific address of the Control Block can also be set via the host applications to speed up detection or the block cannot be found automatically. The default implementation uses one channel per direction, which are meant for printable terminal input and output. An additional up (to host) channel can for example be used to send profiling or event tracing data. Each channel can be configured to be blocking or non-blocking . In blocking mode the application will wait when the buffer is full, until all memory could be written, resulting in a blocked application state but preventing data from getting lost. In non-blocking mode only data which fits into the buffer, or none at all, will be written, and the rest will be discarded. This allows running in real time, even when no debugger is connected. The developer does not have to create a special debug version and the code can stay in place in a release application.","title":"How RTT Works"},{"location":"blog/stm32/segger-rtt/#rtt-performance","text":"The performance of SEGGER RTT is significantly higher than any other technology used to output data to a host PC. An average line of text can be output in one microsecond or less. Basically it is only the time to do a single memcopy() call. RTT Performance in comparison with Semihosting and SWO The maximum speed at which output data can be sent to the host depends on the target buffer size and target interface speed. Even with a small target buffer of 512 Bytes an RTT speed of up to 1 MiB/s is possible with a high interface speed and 0.5 MiB/s are possible with a regular J-Link model.","title":"RTT Performance"},{"location":"blog/stm32/segger-rtt/#rtt-apis","text":"The SEGGER RTT implementation is written in ANSI C and can be integrated into any embedded application. RTT can be used via a simple and easy to use API. It is even possible to override the standard printf() functions to use RTT. Using RTT reduces the time taken for printf() to a minimum and allows printing debug information to the host PC, while the application is performing time critical, real time tasks. The SEGGER RTT implementation includes a simple implementation of printf() which can be used to write a formatted string via RTT. SEGGER_RTT_Printf() is smaller than most standard library implementations and does not require heap and only a configurable amount of stack. However, it does not support printing double or float numbers . Function Name Description SEGGER_RTT_Read() Read data from an input buffer. SEGGER_RTT_Write() Write data to an output buffer. SEGGER_RTT_WriteString() Write a zero-terminated string to an output buffer. SEGGER_RTT_printf() Write a formatted string to an output buffer. SEGGER_RTT_GetKey() Get one character from input buffer 0. (non-blocking) SEGGER_RTT_HasKey() Check if a character is available in input buffer 0. SEGGER_RTT_WaitKey() Wait for a character to be available in input buffer 0 and get it. (blocking) SEGGER_RTT_ConfigUpBuffer() Configure an up (output) buffer. SEGGER_RTT_ConfigDownBuffer() Configure a down (input) buffer. SEGGER_RTT_Init() Initialize RTT Control Block structure when using RAM only targets. SEGGER_RTT_SetTerminal() Set the \u201cvirtual\u201d Terminal to use for output on channel 0 via Write and WriteString . SEGGER_RTT_TerminalOut() Send a zero-terminated string via a \u201cvirtual\u201d terminal.","title":"RTT APIs"},{"location":"blog/stm32/segger-rtt/#integrate-rtt","text":"RTT in the target MCU is provided freely. Firstly, download the J-Link software and install it. Under the installation folder, the source code of RTT on MCU is found in Samples\\RTT . At the time of writing this guide, the version of J-Link is 7.64, therefore, user can find the SEGGER_RTT.zip file there.","title":"Integrate RTT"},{"location":"blog/stm32/segger-rtt/#add-rtt-files","text":"\u2502 License.txt \u2502 README.txt \u2502 \u251c\u2500RTT \u2502 SEGGER_RTT_Conf.h # Configuration \u2502 SEGGER_RTT.h # Main header \u2502 SEGGER_RTT.c # Main implementation \u2502 SEGGER_RTT_printf.c # Print functions \u2502 SEGGER_RTT_ASM_ARMv7M.S # for Cortex-M3/M4/M7 \u2502 \u251c\u2500Syscalls \u2502 SEGGER_RTT_Syscalls_GCC.c # redirection for GCC and newlib \u2502 SEGGER_RTT_Syscalls_IAR.c # redirection for IAR \u2502 SEGGER_RTT_Syscalls_KEIL.c # redirection for KEIL ARM \u2502 SEGGER_RTT_Syscalls_SES.c # redirection for Segger Embedded System \u2502 \u2514\u2500Examples Main_RTT_InputEchoApp.c # echo characters Main_RTT_MenuApp.c # use character to select an option Main_RTT_PrintfTest.c # print log with format Main_RTT_SpeedTestApp.c # measure execution time As RTT implementation is target independent, so we will start with a bare project without using any CMSIS or LL/HAL library. Add RTT files","title":"Add RTT files"},{"location":"blog/stm32/segger-rtt/#add-include-paths","text":"Open the _Project Properties__ \u2192 C/C++ Build \u2192 Settings . Then add ../SEGGER_RTT/Include into to the Include paths of both GCC Assembler and GCC Compiler Add RTT files to include paths","title":"Add Include paths"},{"location":"blog/stm32/segger-rtt/#add-source-files","text":"To make RTT source files get compiled, add the folder /SEGGER_RTT/Source into the Source Location list, and add the folder /SEGGER_RTT/Include in the Paths and Symbols setting under the C/C++ General property. Add path and source files","title":"Add Source files"},{"location":"blog/stm32/segger-rtt/#usage-rtt","text":"F411RE_RTT.zip In the main.c file, include the SEGGER_RTT.h firstly to import RTT APIs. Inside the int main () function, call to SEGGER_RTT_Init() to initialize the SEGGER RTT Control Block and the Channel 0. We are going to: Add a new channel named Log on Channel 1 32 Bytes buffer, Up to Host Create a variable counter and increase it every second Send different data to virtual 0 , 1 , 2 on the Channel 0 (named Terminal by default) main.c #include <stdint.h> #include <SEGGER_RTT.h> /* add channel 1: log */ static uint8_t logBuffer [ 32 ]; char counter = 0 ; int main ( void ) { SEGGER_RTT_Init (); /* add channel 1: log */ SEGGER_RTT_ConfigUpBuffer ( 1 , \"Log\" , logBuffer , sizeof ( logBuffer ), SEGGER_RTT_MODE_NO_BLOCK_TRIM ); while ( 1 ) { // Channel 0 - virtual terminal 0 SEGGER_RTT_printf ( 0 , \"[0:0] counter = %d \\n \" , counter ++ ); // switch to Channel 0 - virtual terminal 1 SEGGER_RTT_SetTerminal ( 1 ); SEGGER_RTT_printf ( 0 , \"[0:1] negative = %d \\n \" , - counter ); // back to Channel 0 - virtual terminal 0 SEGGER_RTT_SetTerminal ( 0 ); // print to Channel 0 - virtual terminal 2 SEGGER_RTT_TerminalOut ( 2 , \"[0:2] nothing \\n \" ); // print to Channel 1 SEGGER_RTT_printf ( 1 , \"[1:x] last_digit = %d \\n \" , counter % 2 ); for ( int delay = 160000 ; delay -- ;); } }","title":"Usage RTT"},{"location":"blog/stm32/segger-rtt/#rtt-viewer","text":"J-Link RTT Viewer is the main Windows GUI application to use all features of RTT on the debugging host. RTT Viewer can be used stand-alone, opening an own connection to J-Link and target or in parallel to a running debug session, attaching to it and using this existing J-Link connection. RTT Viewer supports all major features of RTT: Terminal output on Channel 0 Sending text input to Channel 0 Up to 16 virtual Terminals with only one target channel Controlling text output: Colored text, erasing the console Logging data on Channel 1 J-Link Probe Connect any J-Link probe into the SWD interface of the target MCU. Then start the J-Link RTT Viewer in the J-Link software package. J-Link Pro Cloned J-Link OB V2 J-Link JTAG connection J-Link SWD connection Convert ST-LINK to J-LINK SEGGER offers a firmware upgrading the ST-LINK on-board on the Nucleo and Discovery Boards to a J-LINK On-Board debugger. The configuration dialog will show up, select USB mode, and select the Target device from the list of supported devices. Then the viewer will open the Default Channel 0 to display RTT strings. RTT Viewer Configuration and Channel Info RTT Viewer can show messages from different virtual terminal in different colors. RTT Viewer showing messages from all terminals The Channel 1 can be logged in RTT Viewer. However, to log other channel, you have to use RTT Logger. RTT Logger","title":"RTT Viewer"},{"location":"blog/stm32/segger-rtt/#override-syscalls","text":"With the same method to redirect standard IO to SWV , UART or Virtual COM , two low-level functions _write() and _read() can be overridden to redirect to RTT. int _read ( int file , char * ptr , int len ) { * ptr = SEGGER_RTT_WaitKey (); return 1 ; } int _write ( int file , char * ptr , int len ) { SEGGER_RTT_Write ( 0 , ptr , len ); return len ; } Blocking Input The function SEGGER_RTT_WaitKey() intensionally block the application to read a character. Once a character is available, it is read and this function returns. Here is an example of reading a number using RTT redirection: int main ( void ) { SEGGER_RTT_Init (); printf ( \"Enter a number: \" ); int a ; scanf ( \"%d\" , & a ); printf ( \"Thanks! I got %d \\n \" , a ); } Use RTT redirection for scanf","title":"Override syscalls"},{"location":"blog/stm32/segger-systemview/","tags":["arm","stm32","debug","rtt","sysview"],"text":"J-Link System View \u2014 Manual SEGGER_SysView.zip STM32-Tutorials System View # Visit the Official J-Link System View page on SEGGER website for more information. SEGGER\u2019s J-Link System View is written on top of the excellent J-Link Real-Time Transfer to record many types of events in real-time in an embedded system. Those events can be interrupts, timers, task switches and scheduling within an RTOS, API function calls and returns, or user events and messages. The events are retrieved from the target, analyzed and visualized in the System View Application , while the target keeps running. System View may be used with a non-commercial license for evaluation, educational and hobbyist purposes. When using System View under the non-commercial license, no activation is required. How System View works # To keep the communication overhead on the target system low, it only needs to record basic information, such as Function with ID X is called with parameter values y and z at the n ticks after the last event . System View analyzes all information from the events and shows: The recording time or system time when the call happened The task/context in which the call happened The interrupt name, timer ID, and marker name The API function name and its parameters and values The duration of the any pair of start-stop, enter-exit events The timestamps for events can be as accurate as 1 CPU cycle. A regular event is just 4 to 8 bytes long. What System View helps # Issues and inefficiencies in the system can be identified below ways: Incorrect task priorities or priority inversion leading to starvation Incorrect inter-task communication Inefficient delays and timeouts Spurious or unnecessary interrupts Unexpected log run-time of a short task High CPU Load can lead to: Bottlenecks which may lead to delayed execution of important tasks Dropped data or overflow of incoming buffer System View APIs # The SEGGER System View implementation is written in ANSI C on the top of RTT, therefore, it can be easily integrated into any embedded application. The System View needs to be initialized before it can be used. However, it does not automatically run to reduce CPU Load and power usage. System View only runs when it gets request from Host\u2019s System View Application. Control functions Function Description SEGGER_SYSVIEW_Init() Initializes the SYSVIEW module SEGGER_SYSVIEW_Start() Start recording System View events. This function is triggered by the System View Application on connect. SEGGER_SYSVIEW_Stop() Stop recording System View events. This function is triggered by the System View Application on disconnect. Configuration functions Function Description SEGGER_SYSVIEW_Conf() Initialize and configures System View SEGGER_SYSVIEW_SetRAMBase() Sets the RAM base address SEGGER_SYSVIEW_SendSysDesc() Send the system description string to the host SEGGER_SYSVIEW_SendTaskList() Send all tasks descriptors to the host SEGGER_SYSVIEW_SendTaskInfo() Send a Task Info Packet, containing TaskId for identification, task priority and task name SEGGER_SYSVIEW_X_GetTimestamp() Callback called by System View to get the timestamp in cycles Event recording functions Function Description SEGGER_SYSVIEW_RecordEnterISR() Format and send an ISR entry event SEGGER_SYSVIEW_RecordExitISR() Format and send an ISR exit event SEGGER_SYSVIEW_RecordEnterTimer() Format and send a Timer entry event SEGGER_SYSVIEW_RecordExitTimer() Format and send a Timer exit event SEGGER_SYSVIEW_OnIdle() Record an Idle event SEGGER_SYSVIEW_OnTaskCreate() Record a Task Create event SEGGER_SYSVIEW_OnTaskStartExec() Record a Task Start Execution event SEGGER_SYSVIEW_OnTaskStartReady() Record a Task Start Ready event SEGGER_SYSVIEW_OnTaskStopExec() Record a Task Stop Execution event SEGGER_SYSVIEW_OnTaskStopReady() Record a Task Stop Ready event SEGGER_SYSVIEW_OnTaskTerminate() Record a Task termination event SEGGER_SYSVIEW_MarkStart() Record a Performance Marker Start event to start measuring runtime SEGGER_SYSVIEW_Mark() Record a Performance Marker intermediate event SEGGER_SYSVIEW_MarkStop() Record a Performance Marker Stop event to stop measuring runtime User API recording functions Function Description SEGGER_SYSVIEW_RecordVoid() Formats and sends a System View packet with an empty payload SEGGER_SYSVIEW_RecordU32() Formats and sends a System View packet containing a single U32 parameter payload SEGGER_SYSVIEW_RecordU32x[2:10]() Formats and sends a System View packet containing [2:10] U32 parameter payload SEGGER_SYSVIEW_RecordString() Formats and sends a System View packet containing a string SEGGER_SYSVIEW_RecordEndCall() Format and send an End API Call event without return value. SEGGER_SYSVIEW_RecordEndCallU32() Format and send an End API Call event with a return value Message recording functions Function Description SEGGER_SYSVIEW_Print() Print a string to the host SEGGER_SYSVIEW_Warn() Print a warning string to the host SEGGER_SYSVIEW_Error() Print an error string to the host SEGGER_SYSVIEW_PrintfHost() Print a string which is formatted on the host by the System View Application SEGGER_SYSVIEW_WarnfHost() Print a string which is formatted on the host by the System View Application SEGGER_SYSVIEW_ErrorfHost() Print an error string which is formatted on the host by the System View Application To reduce CPU cycles used by System View to format strings, System View function *fHost() just sends a raw string and its params to the host! System View Integration # Install the System View Application firstly at System View download page . After installation, go the application folder to get the latest source code of System View target integration, for example C:\\Program Files\\SEGGER\\System View\\Src . Here is SEGGER_SysView.zip at version 3.32. \u251c\u2500Config \u2502 Global.h # Typedef for data types \u2502 SEGGER_RTT_Conf.h # Default RTT configs \u2502 SEGGER_SYSVIEW_Conf.h # User SysView Configs | \u251c\u2500\u2500SEGGER \u2502 \u2502 SEGGER.h # Segger common defines \u2502 \u2502 SEGGER_RTT.h # RTT Header \u2502 \u2502 SEGGER_RTT.c # RTT implementation \u2502 \u2502 SEGGER_RTT_ASM_ARMv7M.S # for Cortex-M3/M4 \u2502 \u2502 SEGGER_RTT_printf.c # Print functions \u2502 \u2502 SEGGER_SYSVIEW_ConfDefaults.h # SysView Default Configs \u2502 \u2502 SEGGER_SYSVIEW_Int.h # SysView Internal defines \u2502 \u2502 SEGGER_SYSVIEW.h # SysView header \u2502 \u2502 SEGGER_SYSVIEW.c # SysView implementation \u2502 \u2502 \u2502 \u2514\u2500\u2500\u2500Syscalls # Standard IO redirection \u2502 \u2514\u2500Sample # Sample configs for different targets \u251c\u2500\u2500\u2500COMM # Example to record on UART \u251c\u2500\u2500\u2500embOS # \u251c\u2500\u2500\u2500FreeRTOSV10 # \u251c\u2500\u2500\u2500FreeRTOSV8 # \u251c\u2500\u2500\u2500FreeRTOSV9 # \u251c\u2500\u2500\u2500MicriumOSKernel # \u251c\u2500\u2500\u2500uCOS-II # \u251c\u2500\u2500\u2500uCOS-III # \u2514\u2500\u2500\u2500NoOS # Run without OS \u2514\u2500\u2500\u2500Config \u251c\u2500\u2500\u2500RX \u251c\u2500\u2500\u2500Cortex-M # \u2502 SEGGER_SYSVIEW_Config_NoOS.c \u2514\u2500\u2500\u2500Cortex-M0 # Special setup for Cortex-M0 SEGGER_SYSVIEW_Config_NoOS_CM0.c You can copy all files to your projects and add them to Paths and Symbols settings. System View with No OS # F411RE_SysView_NoOS.zip This section will guide you on how to add System View into an application and record its activity to analyze them. As System View is based on RTT which runs through SWD interface, the guide to integrate on Cortex-M MCUs is the same in general. Purpose Visualize interruption activity Debug the issue of incorrect counter value when pressing on button Target application Blink an LED at 100 Hz using a general Timer Increase a counter value by one when press on a Button using External Interrupt Send the counter value on an UART port every 100 ms in the main loop Target platform library Use HAL library minimize setup code, and then focus only on System View integration Target hardware STM32 Nucleo-64 F411RE board with Cortex-M4 integration STM32 F0-Discovery F051R8 board with Cortex-M0 integration This guide show steps for F411RE MCU first! For the case of using F051R8, modification points will be shown in a separated section! Start a new project # The selected board is STM32 Nucleo-64 F411RE, refer to steps in Blink example to create a new project using STM32CubeMX. Here are main settings : USER BUTTON : Set PC13 to GPIO_EXTI13 , with mode External Interrupt with Falling Edge Trigger Detection , without any Pull-up or Pull-down resistor. GREEN LED : Set PA5 to GPIO_Output , with mode Push-Pull , without any Pull-up or Pull-down resistor. TIMER 10 : Enable TIM10 with Prescaler = 1600 and Counter Period = 1000 USART 2 : Enable USART2 on pin PA2 and PA3 , with baudrate = 115200 and parameters = 8N1 . This UART port is connected to ST-LINK Virtual COM port. NVIC : Enable Interrupt for EXTI line[15:10] , TIM10 Global , and USART2 Global The main program: Implement TIM10 Update Event callback to toggle the LED Implement EXTI13 External Interrupt callback to increase the counter value Declare UART TX Complete callback without any code (will be modified later) In main, start the TIM10 in Interrupt Mode In main loop, print out counter value via UART port main.c #include \"main.h\" #include <stdio.h> #include <string.h> //#define USE_UART_INTERRUPT TIM_HandleTypeDef htim10 ; UART_HandleTypeDef huart2 ; char counter = 0 ; char buffer [ 16 ] = { 0 }; // counter=xxx\\r\\n void SystemClock_Config ( void ); static void MX_GPIO_Init ( void ); static void MX_TIM10_Init ( void ); static void MX_USART2_UART_Init ( void ); void HAL_TIM_PeriodElapsedCallback ( TIM_HandleTypeDef * htim ) { if ( htim == & htim10 ) { HAL_GPIO_TogglePin ( LED_GPIO_Port , LED_Pin ); } } void HAL_GPIO_EXTI_Callback ( uint16_t GPIO_Pin ) { if ( GPIO_Pin == GPIO_PIN_13 ) { counter ++ ; } } void HAL_UART_TxCpltCallback ( UART_HandleTypeDef * huart ) { if ( huart == & huart2 ) { } } int main ( void ) { HAL_Init (); SystemClock_Config (); MX_GPIO_Init (); MX_TIM10_Init (); MX_USART2_UART_Init (); HAL_TIM_Base_Start_IT ( & htim10 ); while ( 1 ) { sprintf ( buffer , \"counter = %03d \\r\\n \" , counter ); #ifndef USE_UART_INTERRUPT HAL_UART_Transmit ( & huart2 , ( uint8_t * ) buffer , strlen ( buffer ), HAL_MAX_DELAY ); #else HAL_UART_Transmit_IT ( & huart2 , ( uint8_t * ) buffer , strlen ( buffer ), HAL_MAX_DELAY ); #endif HAL_Delay ( 100 ); } } Build and run the application, then press on the User Button, you will notice, sometimes the counter value is increased incorrectly!!! Press on button once, but counter value increased twice Import System View files # The base files of SEGGER System View can be added in a separated folder, e.g. SEGGER_SysView . SEGGER provides Sample files for different types of OS and CPU. Make sure to include correct header and source files for the target project. Read the System View Manual for more details of each type of OS and CPU support. We have to do some steps: Add Include Paths for Compiler Add Source Location for Compiler Exclude unrelated files, such as implementation source for Cortex-M0 Add Include Paths for Assembler Add SEGGER SysView files to project settings Configure System View # Before System View can be used, it needs to be initialized, including: Setup RTT base Set RAM Base address Send Device Information Send Interrupts description Set Timestamp source In this example, F411RE Cortex-M4 is used, therefore, we will change some configurations in the file SEGGER_SYSVIEW_Config_NoOS.c : The general information of the system: // The application name to be displayed in SystemViewer #define SYSVIEW_APP_NAME \"Demo Application\" #define SYSVIEW_DEVICE_NAME \"STM32F411RE\" #define SYSVIEW_CORE_NAME \"Cortex-M4\" #define SYSVIEW_OS_NAME \"NoOS\" The system clock : // SystemcoreClock is used in most CMSIS compatible projects. #define SYSVIEW_TIMESTAMP_FREQ (SystemCoreClock) #define SYSVIEW_CPU_FREQ (SystemCoreClock) Then set the RAM base address . Every variable\u2019s address will be subtracted to this base address to get an offset value which is later encoded in only 1 or 2 bytes. #define SYSVIEW_RAM_BASE (0x20000000) At beginning of the main function, SEGGER_SYSVIEW_Conf() is called to initialize the System View with System Clock Frequency (saved in SystemCoreClock variable) for timestamp resolution, and provide a _cbSendSystemDesc() callback function which will be executed when the host application requests to start monitoring. The function _cbSendSystemDesc() can be modified to provide more detail of the system: static void _cbSendSystemDesc ( void ) { SEGGER_SYSVIEW_SendSysDesc ( \"N=\" SYSVIEW_APP_NAME \",\" \"D=\" SYSVIEW_DEVICE_NAME \",\" \"C=\" SYSVIEW_CORE_NAME \",\" \"O=\" SYSVIEW_OS_NAME ); SEGGER_SYSVIEW_SendSysDesc ( \"I#15=SysTick\" ); SEGGER_SYSVIEW_SendSysDesc ( \"I#41=TIM1_UP_TIM10_IRQHandler\" ); SEGGER_SYSVIEW_SendSysDesc ( \"I#54=USART2_IRQHandler\" ); SEGGER_SYSVIEW_SendSysDesc ( \"I#56=EXTI15_10_IRQHandler\" ); } The SYSVIEW_OS_NAME also is used by System View Application to load useful descriptions for displaying analysed data. Read more in OS Description . The Interrupt number can be found in the g_pfnVectors table in the startup_stm32f411retx.s . Different cores have different interrupt mapping. Application should only send in-use interrupts to the host. g_pfnVectors: .word _estack .word Reset_Handler .word NMI_Handler .word HardFault_Handler .word MemManage_Handler .word BusFault_Handler .word UsageFault_Handler .word 0 .word 0 .word 0 .word 0 .word SVC_Handler .word DebugMon_Handler .word 0 .word PendSV_Handler .word SysTick_Handler /* External Interrupts */ .word WWDG_IRQHandler /* Window WatchDog */ ... .word TIM1_UP_TIM10_IRQHandler /* TIM1 Update and TIM10 */ ... .word USART2_IRQHandler /* USART2 */ .word 0 /* Reserved */ .word EXTI15_10_IRQHandler /* External Line [ 15 : 10 ] */ The final step is to help System View find the system timestamp which is used in all events for processing the timeline of recorded events. Cortex-M0 does not have Cycle Counter, therefore, it needs to be calculated manually based on the SysTick interrupt and the SysTick reload register. Other Cortex-M CPU has CPU Cycle Counter register to be used as system timestamp. Both of two methods provide 1-cycle resolution. #ifndef SEGGER_SYSVIEW_GET_TIMESTAMP #if defined (SEGGER_SYSVIEW_CORE) && (SEGGER_SYSVIEW_CORE == SEGGER_SYSVIEW_CORE_CM3) #define SEGGER_SYSVIEW_GET_TIMESTAMP() (*(U32 *)(0xE0001004)) #else #define SEGGER_SYSVIEW_GET_TIMESTAMP() SEGGER_SYSVIEW_X_GetTimestamp() #endif #endif Start the System View at the beginning of the main function: main.c #include \"SEGGER_SYSVIEW_Conf.h\" #include \"SEGGER_SYSVIEW.h\" int main () { SEGGER_SYSVIEW_Conf (); // initialize System View while ( 1 ) {...} } If there is no event is registered to be sent to host, System View is disabled by default. Print messages to host # To log the counter value to both the UART interface and the System View application, add the function call SEGGER_SYSVIEW_Print() which sends a string, or SEGGER_SYSVIEW_PrintfHost() which sends unformatted string to the host. while ( 1 ) { sprintf ( buffer , \"counter = %03d \\r\\n \" , counter ); HAL_UART_Transmit ( & huart2 , ( uint8_t * ) buffer , strlen ( buffer ), HAL_MAX_DELAY ); #if 0 SEGGER_SYSVIEW_Print(buffer); #else // better performance SEGGER_SYSVIEW_PrintfHost ( \"counter = %03d \\r\\n \" , counter ); #endif HAL_Delay ( 100 ); Run the System View # Connect any J-Link probe into the SWV interface of the target MCU. Then start the System View application on the host PC. J-Link Pro debugger J-Link SWV pins Convert ST-LINK to J-LINK SEGGER offers a firmware upgrading the ST-LINK on-board on the Nucleo and Discovery Boards to a J-LINK On-Board debugger. Start the System View for the first time, it will show a recorded example. Go to Tools \u2192 Preferences and uncheck the checkbox Load last data on start . When starting to record a new session, it is recommended to check and set the target device. Press Alt + Return to show the device selection: Select target device Press F5 or click on the start button to start recording. At the beginning step in this lab, the System View will display: Device information Messages of counter value System View with device info and some messages Record interrupts # In the file stm32f4xx_it.c , in each concerning interrupt handler, add a pair of ISR recording function SEGGER_SYSVIEW_RecordEnterISR() and SEGGER_SYSVIEW_RecordExitISR() to track the interrupts. It automatically retrieves the interrupt ID via a special register implemented in the SEGGER_SYSVIEW_GET_INTERRUPT_ID() function macro: stm32f4xx_it.c void SysTick_Handler ( void ) { SEGGER_SYSVIEW_RecordEnterISR (); HAL_IncTick (); SEGGER_SYSVIEW_RecordExitISR (); } void TIM1_UP_TIM10_IRQHandler ( void ) { SEGGER_SYSVIEW_RecordEnterISR (); HAL_TIM_IRQHandler ( & htim10 ); SEGGER_SYSVIEW_RecordExitISR (); } void EXTI15_10_IRQHandler ( void ) { SEGGER_SYSVIEW_RecordEnterISR (); HAL_GPIO_EXTI_IRQHandler ( BUTTON_Pin ); SEGGER_SYSVIEW_RecordExitISR (); } void USART2_IRQHandler ( void ) { SEGGER_SYSVIEW_RecordEnterISR (); HAL_UART_IRQHandler ( & huart2 ); SEGGER_SYSVIEW_RecordExitISR (); } This time, when recording with System View, there are many events captured. You will notice that between two log messages printed out, button interrupts are triggered twice. System View with Interrupt events Record functions # The System View records to enter and the exit event of an interrupt, but it does not automatically record a user function. To do that, application must manually set the starting point of the function\u2019s entry with one of: SEGGER_SYSVIEW_RecordVoid(EventId) , or SEGGER_SYSVIEW_RecordU32(EventId, Param) , or SEGGER_SYSVIEW_RecordU32*(EventId, ...) , or SEGGER_SYSVIEW_RecordString(EventId, char*) and the ending point of that function with one of: SEGGER_SYSVIEW_RecordEndCall(EventId) , or SEGGER_SYSVIEW_RecordEndCallU32(EventId, Param) function. These functions need an ID to distinguish the different APIs. ID is 2 bytes, comparing to an API function name which usually is much more than 2 bytes, it is very short to save sending bandwidth. For example, to measure the main loop, and user callback functions, define some IDs starting from 32 as below: SEGGER_SYSVIEW_Conf.h #define APP_EVTID_MAIN_LOOP 32 #define APP_EVTID_HAL_TIM_PeriodElapsedCallback 33 #define APP_EVTID_HAL_GPIO_EXTI_Callback 34 #define APP_EVTID_HAL_UART_TxCpltCallback 35 void HAL_TIM_PeriodElapsedCallback ( TIM_HandleTypeDef * htim ) { SEGGER_SYSVIEW_RecordU32 ( APP_EVTID_HAL_TIM_PeriodElapsedCallback , ( U32 ) htim -> Instance ); if ( htim == & htim10 ) { HAL_GPIO_TogglePin ( LED_GPIO_Port , LED_Pin ); } SEGGER_SYSVIEW_RecordEndCall ( APP_EVTID_HAL_TIM_PeriodElapsedCallback ); } void HAL_GPIO_EXTI_Callback ( uint16_t GPIO_Pin ) { SEGGER_SYSVIEW_RecordU32 ( APP_EVTID_HAL_GPIO_EXTI_Callback , ( U32 ) GPIO_Pin ); if ( GPIO_Pin == GPIO_PIN_13 ) { counter ++ ; } SEGGER_SYSVIEW_RecordEndCall ( APP_EVTID_HAL_GPIO_EXTI_Callback ); } void HAL_UART_TxCpltCallback ( UART_HandleTypeDef * huart ) { SEGGER_SYSVIEW_RecordVoid ( APP_EVTID_HAL_UART_TxCpltCallback ); if ( huart == & huart2 ) {} SEGGER_SYSVIEW_RecordEndCall ( APP_EVTID_HAL_UART_TxCpltCallback ); } int main ( void ) { while ( 1 ) { SEGGER_SYSVIEW_RecordVoid ( APP_EVTID_MAIN_LOOP ); sprintf ( buffer , \"counter = %03d \\r\\n \" , counter ); HAL_UART_Transmit ( & huart1 , ( uint8_t * ) buffer , strlen ( buffer ), HAL_MAX_DELAY ); SEGGER_SYSVIEW_Print ( buffer ); HAL_Delay ( 100 ); SEGGER_SYSVIEW_RecordEndCall ( APP_EVTID_MAIN_LOOP ); } } After this step, there are recorded events for starting and ending of a function. However, there is just event ID, not a human-friendly readable API name. In the below image, the TIM10 IRQ handler took 81 us to run, in which the user callback function with ID #33 took 25 us. System View shows event ID for recorded functions OS Description file # In order for System View to properly decode API calls it requires a description file to be present in the C:\\Program Files\\SEGGER\\SystemView\\Description directory of System View. The name of the file has to be SYSVIEW_<OSName>.txt where <OSName> is the name as sent in the system description. This lab use NoOS as the OS Name, therefore, it should be a SYSVIEW_NoOS.txt file in the description folder of System View. The user description folder is notified via System View log windows, e.g. C:\\Users\\<user>\\AppData\\Roaming\\SEGGER . System View can not find OS Description OS Description syntax A description file includes all API functions which can be recorded by the OS. Each line in the file is one function in the following format: <ID> <Name> <Parameters> | <ReturnValue> <Id> is the Id which is recorded for the API function. It can be in the range of 32 to 511. <Name> is the name of the API function, displayed in the Event column of System View. It may not contain spaces. <Parameters> and <ReturnValue> are the description string of the parameters which are recorded with the API functions. The ReturnValueDescription is optional. The parameter display can be configured by a set of modifiers: %b - Display parameter as binary. %B - Display parameter as hexadecimal string (e.g. 00 AA FF \u2026). %d - Display parameter as signed decimal integer. %D - Display parameter as time value. %I - Display parameter as a resource name if the resource id is known to System View. %p - Display parameter as 4 byte hexadecimal integer (e.g. 0xAABBCCDD). %s - Display parameter as string. %t - Display parameter as a task name if the task id is known to System View. %u - Display parameter as unsigned decimal integer. %x - Display parameter as hexadecimal integer. The following example shows a part of SYSVIEW_embOS.txt : 46 OS_CreateTask Task = %t Pri = %u Stack = %p Size = %u In addition to the default modifiers the description file can define NamedTypes to map numerical values to strings, which can for example be useful to display the textual value of enums or error codes. The special character * represents for all remaining unmapped values. NamedTypes have following format, can be used in the <Parameters> and the <ReturnValue> : NamedType <TypeName> <Key>=<Value> [<Key1>=<Value1> ...] The following example shows a part of SYSVIEW_embOS.txt : # Types for parameter formatters NamedType OSErr 0 = OS_ERR_NONE 10000 = OS_ERR_A # API Functions 34 OSFunc Param = %OSFlag | Returns %OSErr When a task pauses execution its state is recorded in the System View event. This task state can be converted to a textual representation in System View with the TaskState description. TaskState has following format: TaskState <Mask> <Key>=<Value>, [<Key1>=<Value1>, ...] For example: # Task States TaskState 0xFF 0 = Ready, 1 = Delayed or Timeout Always have an empty line in the OS description file to make the last line is parsed properly Write OS Description with Peripheral Info We will define a lookup table for TIMx instance. The record function sends the address of the being called Timer: SEGGER_SYSVIEW_RecordU32 ( APP_EVTID_HAL_TIM_PeriodElapsedCallback , ( U32 ) htim -> Instance ); Therefore, we can map the received address value with the instance name. Use the Table 1. STM32F411xC/E register boundary addresses in Reference Manual document to know the addresses. For the PIN number, we can need to call log2() function to get actual PIN in numeric order. SEGGER_SYSVIEW_RecordU32 ( APP_EVTID_HAL_GPIO_EXTI_Callback , ( U32 ) log2 ( GPIO_Pin ) ); Here is the sample OS Description for our project: SYSVIEW_NoOS.txt # Types NamedType TIMx * = %p 0x40010000 = TIM1 0x40014400 = TIM10 NamedType PINx * = %u NamedType UARTx * = %p 0x40011000 = USART1 0x40004400 = USART2 # API IDs 32 Main_Loop 33 HAL_TIM_PeriodElapsedCallback Instance = %TIMx 34 GPIO_EXTI_Callback GPIO_Pin = %Pinx 35 HAL_UART_TxCpltCallback Re-run the System Viewer, you now can see the function name, with more detail as described in the OS Description file: System View shows function name and its parameters Measure performance # To measure performance, System View uses Markers to calculate the execution time between a starting point and a corresponding ending point. The functions to measure performance is SEGGER_SYSVIEW_MarkStart() and SEGGER_SYSVIEW_MarkStop() , which need IDs to create pairs. Define the Marker IDs: SEGGER_SYSVIEW_Conf.h #define APP_MARKER_MAIN_LOOP 0 #define APP_MARKER_UART_TX_BLOCKING 1 #define APP_MARKER_UART_TX_INTERRUPT 2 Then send the marker names in the Device Information callback function: static void _cbSendSystemDesc ( void ) { SEGGER_SYSVIEW_SendSysDesc (...); SEGGER_SYSVIEW_NameMarker ( APP_MARKER_MAIN_LOOP , \"Main Loop\" ); SEGGER_SYSVIEW_NameMarker ( APP_MARKER_UART_TX_BLOCKING , \"UART_TX_Blocking\" ); SEGGER_SYSVIEW_NameMarker ( APP_MARKER_UART_TX_INTERRUPT , \"UART_TX_Interrupt\" ); } Compare Blocking and Non-Blocking Mode We will call to 2 methods of sending characters on USART: Blocking: function HAL_UART_Transmit() put on byte on TX line and wait for it to be sent, the put another bytes. CPU is kept to busy while waiting. Non-Blocking: function HAL_UART_Transmit_IT() set UART in interrupt mode: one byte is put on TX line the CPU does not wait for it to be sent, when a byte is sent, an interrupt is called to put next byte on TX again. CPU is free to run while a byte is being transmitted. while ( 1 ) { SEGGER_SYSVIEW_MarkStart ( APP_MARKER_MAIN_LOOP ); sprintf ( buffer , \"counter = %03d \\r\\n \" , counter ); #ifndef USE_UART_INTERRUPT // UART BLOCKING MODE SEGGER_SYSVIEW_MarkStart ( APP_MARKER_UART_TX_BLOCKING ); HAL_UART_Transmit ( & huart2 , ( uint8_t * ) buffer , strlen ( buffer ), HAL_MAX_DELAY ); SEGGER_SYSVIEW_MarkStop ( APP_MARKER_UART_TX_BLOCKING ); #else // UART INTERRUPT MODE SEGGER_SYSVIEW_MarkStart ( APP_MARKER_UART_TX_INTERRUPT ); HAL_UART_Transmit_IT ( & huart2 , ( uint8_t * ) buffer , strlen ( buffer ) ); #endif The result of measuring two performance points is as below: System View show a Blocking case System View show a Non-Blocking case Look at the above images, it\u2019s clear that in Non-Blocking case, the Main Loop has can finish a work faster as it can run while UART is transmitting a byte. System View with No OS on Cortex-M0 # F051R8_SysView_NoOS.zip This section is a guide for F051R8 on STM32F0-DISCOVERY board. SEGGER_SYSVIEW_Config_NoOS_CM0.c #define SYSVIEW_APP_NAME \"Demo Application\" #define SYSVIEW_DEVICE_NAME \"STM32F051R8\" #define SYSVIEW_CORE_NAME \"Cortex-M0\" #define SYSVIEW_OS_NAME \"CM0-NoOS\" static void _cbSendSystemDesc ( void ) { SEGGER_SYSVIEW_SendSysDesc ( \"N=\" SYSVIEW_APP_NAME \",\" \"D=\" SYSVIEW_DEVICE_NAME \",\" \"C=\" SYSVIEW_CORE_NAME \",\" \"O=\" SYSVIEW_OS_NAME ); SEGGER_SYSVIEW_SendSysDesc ( \"I#15=SysTick\" ); } For Cortex-M0, it is needed to increase the variable SEGGER_SYSVIEW_TickCnt in the SysTick interrupt, as soon as that handler is executed. This variable is used in the function SEGGER_SYSVIEW_X_GetTimestamp() to correctly calculate the clock cycles. stm32f0xx_it.c void SysTick_Handler ( void ) { SEGGER_SYSVIEW_TickCnt ++ ; // must be at the beginning SEGGER_SYSVIEW_RecordEnterISR (); HAL_IncTick (); SEGGER_SYSVIEW_RecordExitISR (); } Done! Cortex-M0 now can provide precision timestamp for System View. System View on RTOS # F411RE_SysView_RTOS.zip Using an RTOS makes system analysis more complicated. However, System View is designed to work with RTOS after some simple steps. Start a new project # Let\u2019s create a new project using FreeRTOS V10.3.1 using CMSIS-RTOS V2. Configure project to use RTOS Note: RTOS should use SysTick for its own OS delay function, while HAL function also needs a time-base to operate its own polling delay method. Import System View files # The core files of Segger System View is the same as they are used in the Non-OS firmware. The difference is the config files for RTOS, which are found in the target FreeRTOS version or any other RTOS such as embOS. FreeRTOSV10 \u2502 \u2502 SEGGER_SYSVIEW_FreeRTOS.c \u2502 SEGGER_SYSVIEW_FreeRTOS.h \u2502 \u251c\u2500\u2500\u2500Config \u2502 \u2514\u2500\u2500\u2500Cortex-M \u2502 SEGGER_SYSVIEW_Config_FreeRTOS.c \u2502 \u2514\u2500\u2500\u2500Patch FreeRTOSV10_Amazon_Core.patch FreeRTOSV10_Core.patch Copy all of those files to the project. Add System View files for RTOS Apply patch # The patch file may not be applied for newer FreeRTOS version, such as V10.3+. It easy to modify the patch to apply into a newer version, or download FreeRTOSV10.3.1_Core.patch . Apply System View patch to RTOS source Configure System View # Include SEGGER_SYSVIEW_FreeRTOS.h at the end of the file FreeRTOSConfig.h to override some RTOS definitions of tracing functions. Finally, configure System View in the file SEGGER_SYSVIEW_Config_FreeRTOS.c which sends System Information, Interrupt ID & Name, Timers and Markers. #define SYSVIEW_APP_NAME \"Demo RTOS Application\" #define SYSVIEW_DEVICE_NAME \"STM32F411RE\" #define SYSVIEW_CORE_NAME \"Cortex-M4\" #define SYSVIEW_OS_NAME \"FreeRTOS\" #define SYSVIEW_RAM_BASE (0x20000000) static void _cbSendSystemDesc ( void ) { SEGGER_SYSVIEW_SendSysDesc ( \"N=\" SYSVIEW_APP_NAME \",\" \"D=\" SYSVIEW_DEVICE_NAME \",\" \"C=\" SYSVIEW_CORE_NAME \",\" \"O=\" SYSVIEW_OS_NAME ); SEGGER_SYSVIEW_SendSysDesc ( \"I#15=SysTick\" ); } Include SEGGER\u2019s headers and call to SEGGER_SYSVIEW_Conf() to initialize System View: #include \"SEGGER_SYSVIEW_Conf.h\" #include \"SEGGER_SYSVIEW.h\" int main () { SEGGER_SYSVIEW_Conf (); ... } Run System View # Done! You can build and run System Viewer to see RTOS running with a Default Task and a Timer Service. System View shows RTOS running with a Default Task and a Timer Service","title":"J-Link SysView - Record and Visualize System Activities"},{"location":"blog/stm32/segger-systemview/#system-view","text":"Visit the Official J-Link System View page on SEGGER website for more information. SEGGER\u2019s J-Link System View is written on top of the excellent J-Link Real-Time Transfer to record many types of events in real-time in an embedded system. Those events can be interrupts, timers, task switches and scheduling within an RTOS, API function calls and returns, or user events and messages. The events are retrieved from the target, analyzed and visualized in the System View Application , while the target keeps running. System View may be used with a non-commercial license for evaluation, educational and hobbyist purposes. When using System View under the non-commercial license, no activation is required.","title":"System View"},{"location":"blog/stm32/segger-systemview/#how-system-view-works","text":"To keep the communication overhead on the target system low, it only needs to record basic information, such as Function with ID X is called with parameter values y and z at the n ticks after the last event . System View analyzes all information from the events and shows: The recording time or system time when the call happened The task/context in which the call happened The interrupt name, timer ID, and marker name The API function name and its parameters and values The duration of the any pair of start-stop, enter-exit events The timestamps for events can be as accurate as 1 CPU cycle. A regular event is just 4 to 8 bytes long.","title":"How System View works"},{"location":"blog/stm32/segger-systemview/#what-system-view-helps","text":"Issues and inefficiencies in the system can be identified below ways: Incorrect task priorities or priority inversion leading to starvation Incorrect inter-task communication Inefficient delays and timeouts Spurious or unnecessary interrupts Unexpected log run-time of a short task High CPU Load can lead to: Bottlenecks which may lead to delayed execution of important tasks Dropped data or overflow of incoming buffer","title":"What System View helps"},{"location":"blog/stm32/segger-systemview/#system-view-apis","text":"The SEGGER System View implementation is written in ANSI C on the top of RTT, therefore, it can be easily integrated into any embedded application. The System View needs to be initialized before it can be used. However, it does not automatically run to reduce CPU Load and power usage. System View only runs when it gets request from Host\u2019s System View Application. Control functions Function Description SEGGER_SYSVIEW_Init() Initializes the SYSVIEW module SEGGER_SYSVIEW_Start() Start recording System View events. This function is triggered by the System View Application on connect. SEGGER_SYSVIEW_Stop() Stop recording System View events. This function is triggered by the System View Application on disconnect. Configuration functions Function Description SEGGER_SYSVIEW_Conf() Initialize and configures System View SEGGER_SYSVIEW_SetRAMBase() Sets the RAM base address SEGGER_SYSVIEW_SendSysDesc() Send the system description string to the host SEGGER_SYSVIEW_SendTaskList() Send all tasks descriptors to the host SEGGER_SYSVIEW_SendTaskInfo() Send a Task Info Packet, containing TaskId for identification, task priority and task name SEGGER_SYSVIEW_X_GetTimestamp() Callback called by System View to get the timestamp in cycles Event recording functions Function Description SEGGER_SYSVIEW_RecordEnterISR() Format and send an ISR entry event SEGGER_SYSVIEW_RecordExitISR() Format and send an ISR exit event SEGGER_SYSVIEW_RecordEnterTimer() Format and send a Timer entry event SEGGER_SYSVIEW_RecordExitTimer() Format and send a Timer exit event SEGGER_SYSVIEW_OnIdle() Record an Idle event SEGGER_SYSVIEW_OnTaskCreate() Record a Task Create event SEGGER_SYSVIEW_OnTaskStartExec() Record a Task Start Execution event SEGGER_SYSVIEW_OnTaskStartReady() Record a Task Start Ready event SEGGER_SYSVIEW_OnTaskStopExec() Record a Task Stop Execution event SEGGER_SYSVIEW_OnTaskStopReady() Record a Task Stop Ready event SEGGER_SYSVIEW_OnTaskTerminate() Record a Task termination event SEGGER_SYSVIEW_MarkStart() Record a Performance Marker Start event to start measuring runtime SEGGER_SYSVIEW_Mark() Record a Performance Marker intermediate event SEGGER_SYSVIEW_MarkStop() Record a Performance Marker Stop event to stop measuring runtime User API recording functions Function Description SEGGER_SYSVIEW_RecordVoid() Formats and sends a System View packet with an empty payload SEGGER_SYSVIEW_RecordU32() Formats and sends a System View packet containing a single U32 parameter payload SEGGER_SYSVIEW_RecordU32x[2:10]() Formats and sends a System View packet containing [2:10] U32 parameter payload SEGGER_SYSVIEW_RecordString() Formats and sends a System View packet containing a string SEGGER_SYSVIEW_RecordEndCall() Format and send an End API Call event without return value. SEGGER_SYSVIEW_RecordEndCallU32() Format and send an End API Call event with a return value Message recording functions Function Description SEGGER_SYSVIEW_Print() Print a string to the host SEGGER_SYSVIEW_Warn() Print a warning string to the host SEGGER_SYSVIEW_Error() Print an error string to the host SEGGER_SYSVIEW_PrintfHost() Print a string which is formatted on the host by the System View Application SEGGER_SYSVIEW_WarnfHost() Print a string which is formatted on the host by the System View Application SEGGER_SYSVIEW_ErrorfHost() Print an error string which is formatted on the host by the System View Application To reduce CPU cycles used by System View to format strings, System View function *fHost() just sends a raw string and its params to the host!","title":"System View APIs"},{"location":"blog/stm32/segger-systemview/#system-view-integration","text":"Install the System View Application firstly at System View download page . After installation, go the application folder to get the latest source code of System View target integration, for example C:\\Program Files\\SEGGER\\System View\\Src . Here is SEGGER_SysView.zip at version 3.32. \u251c\u2500Config \u2502 Global.h # Typedef for data types \u2502 SEGGER_RTT_Conf.h # Default RTT configs \u2502 SEGGER_SYSVIEW_Conf.h # User SysView Configs | \u251c\u2500\u2500SEGGER \u2502 \u2502 SEGGER.h # Segger common defines \u2502 \u2502 SEGGER_RTT.h # RTT Header \u2502 \u2502 SEGGER_RTT.c # RTT implementation \u2502 \u2502 SEGGER_RTT_ASM_ARMv7M.S # for Cortex-M3/M4 \u2502 \u2502 SEGGER_RTT_printf.c # Print functions \u2502 \u2502 SEGGER_SYSVIEW_ConfDefaults.h # SysView Default Configs \u2502 \u2502 SEGGER_SYSVIEW_Int.h # SysView Internal defines \u2502 \u2502 SEGGER_SYSVIEW.h # SysView header \u2502 \u2502 SEGGER_SYSVIEW.c # SysView implementation \u2502 \u2502 \u2502 \u2514\u2500\u2500\u2500Syscalls # Standard IO redirection \u2502 \u2514\u2500Sample # Sample configs for different targets \u251c\u2500\u2500\u2500COMM # Example to record on UART \u251c\u2500\u2500\u2500embOS # \u251c\u2500\u2500\u2500FreeRTOSV10 # \u251c\u2500\u2500\u2500FreeRTOSV8 # \u251c\u2500\u2500\u2500FreeRTOSV9 # \u251c\u2500\u2500\u2500MicriumOSKernel # \u251c\u2500\u2500\u2500uCOS-II # \u251c\u2500\u2500\u2500uCOS-III # \u2514\u2500\u2500\u2500NoOS # Run without OS \u2514\u2500\u2500\u2500Config \u251c\u2500\u2500\u2500RX \u251c\u2500\u2500\u2500Cortex-M # \u2502 SEGGER_SYSVIEW_Config_NoOS.c \u2514\u2500\u2500\u2500Cortex-M0 # Special setup for Cortex-M0 SEGGER_SYSVIEW_Config_NoOS_CM0.c You can copy all files to your projects and add them to Paths and Symbols settings.","title":"System View Integration"},{"location":"blog/stm32/segger-systemview/#system-view-with-no-os","text":"F411RE_SysView_NoOS.zip This section will guide you on how to add System View into an application and record its activity to analyze them. As System View is based on RTT which runs through SWD interface, the guide to integrate on Cortex-M MCUs is the same in general. Purpose Visualize interruption activity Debug the issue of incorrect counter value when pressing on button Target application Blink an LED at 100 Hz using a general Timer Increase a counter value by one when press on a Button using External Interrupt Send the counter value on an UART port every 100 ms in the main loop Target platform library Use HAL library minimize setup code, and then focus only on System View integration Target hardware STM32 Nucleo-64 F411RE board with Cortex-M4 integration STM32 F0-Discovery F051R8 board with Cortex-M0 integration This guide show steps for F411RE MCU first! For the case of using F051R8, modification points will be shown in a separated section!","title":"System View with No OS"},{"location":"blog/stm32/segger-systemview/#start-a-new-project","text":"The selected board is STM32 Nucleo-64 F411RE, refer to steps in Blink example to create a new project using STM32CubeMX. Here are main settings : USER BUTTON : Set PC13 to GPIO_EXTI13 , with mode External Interrupt with Falling Edge Trigger Detection , without any Pull-up or Pull-down resistor. GREEN LED : Set PA5 to GPIO_Output , with mode Push-Pull , without any Pull-up or Pull-down resistor. TIMER 10 : Enable TIM10 with Prescaler = 1600 and Counter Period = 1000 USART 2 : Enable USART2 on pin PA2 and PA3 , with baudrate = 115200 and parameters = 8N1 . This UART port is connected to ST-LINK Virtual COM port. NVIC : Enable Interrupt for EXTI line[15:10] , TIM10 Global , and USART2 Global The main program: Implement TIM10 Update Event callback to toggle the LED Implement EXTI13 External Interrupt callback to increase the counter value Declare UART TX Complete callback without any code (will be modified later) In main, start the TIM10 in Interrupt Mode In main loop, print out counter value via UART port main.c #include \"main.h\" #include <stdio.h> #include <string.h> //#define USE_UART_INTERRUPT TIM_HandleTypeDef htim10 ; UART_HandleTypeDef huart2 ; char counter = 0 ; char buffer [ 16 ] = { 0 }; // counter=xxx\\r\\n void SystemClock_Config ( void ); static void MX_GPIO_Init ( void ); static void MX_TIM10_Init ( void ); static void MX_USART2_UART_Init ( void ); void HAL_TIM_PeriodElapsedCallback ( TIM_HandleTypeDef * htim ) { if ( htim == & htim10 ) { HAL_GPIO_TogglePin ( LED_GPIO_Port , LED_Pin ); } } void HAL_GPIO_EXTI_Callback ( uint16_t GPIO_Pin ) { if ( GPIO_Pin == GPIO_PIN_13 ) { counter ++ ; } } void HAL_UART_TxCpltCallback ( UART_HandleTypeDef * huart ) { if ( huart == & huart2 ) { } } int main ( void ) { HAL_Init (); SystemClock_Config (); MX_GPIO_Init (); MX_TIM10_Init (); MX_USART2_UART_Init (); HAL_TIM_Base_Start_IT ( & htim10 ); while ( 1 ) { sprintf ( buffer , \"counter = %03d \\r\\n \" , counter ); #ifndef USE_UART_INTERRUPT HAL_UART_Transmit ( & huart2 , ( uint8_t * ) buffer , strlen ( buffer ), HAL_MAX_DELAY ); #else HAL_UART_Transmit_IT ( & huart2 , ( uint8_t * ) buffer , strlen ( buffer ), HAL_MAX_DELAY ); #endif HAL_Delay ( 100 ); } } Build and run the application, then press on the User Button, you will notice, sometimes the counter value is increased incorrectly!!! Press on button once, but counter value increased twice","title":"Start a new project"},{"location":"blog/stm32/segger-systemview/#import-system-view-files","text":"The base files of SEGGER System View can be added in a separated folder, e.g. SEGGER_SysView . SEGGER provides Sample files for different types of OS and CPU. Make sure to include correct header and source files for the target project. Read the System View Manual for more details of each type of OS and CPU support. We have to do some steps: Add Include Paths for Compiler Add Source Location for Compiler Exclude unrelated files, such as implementation source for Cortex-M0 Add Include Paths for Assembler Add SEGGER SysView files to project settings","title":"Import System View files"},{"location":"blog/stm32/segger-systemview/#configure-system-view","text":"Before System View can be used, it needs to be initialized, including: Setup RTT base Set RAM Base address Send Device Information Send Interrupts description Set Timestamp source In this example, F411RE Cortex-M4 is used, therefore, we will change some configurations in the file SEGGER_SYSVIEW_Config_NoOS.c : The general information of the system: // The application name to be displayed in SystemViewer #define SYSVIEW_APP_NAME \"Demo Application\" #define SYSVIEW_DEVICE_NAME \"STM32F411RE\" #define SYSVIEW_CORE_NAME \"Cortex-M4\" #define SYSVIEW_OS_NAME \"NoOS\" The system clock : // SystemcoreClock is used in most CMSIS compatible projects. #define SYSVIEW_TIMESTAMP_FREQ (SystemCoreClock) #define SYSVIEW_CPU_FREQ (SystemCoreClock) Then set the RAM base address . Every variable\u2019s address will be subtracted to this base address to get an offset value which is later encoded in only 1 or 2 bytes. #define SYSVIEW_RAM_BASE (0x20000000) At beginning of the main function, SEGGER_SYSVIEW_Conf() is called to initialize the System View with System Clock Frequency (saved in SystemCoreClock variable) for timestamp resolution, and provide a _cbSendSystemDesc() callback function which will be executed when the host application requests to start monitoring. The function _cbSendSystemDesc() can be modified to provide more detail of the system: static void _cbSendSystemDesc ( void ) { SEGGER_SYSVIEW_SendSysDesc ( \"N=\" SYSVIEW_APP_NAME \",\" \"D=\" SYSVIEW_DEVICE_NAME \",\" \"C=\" SYSVIEW_CORE_NAME \",\" \"O=\" SYSVIEW_OS_NAME ); SEGGER_SYSVIEW_SendSysDesc ( \"I#15=SysTick\" ); SEGGER_SYSVIEW_SendSysDesc ( \"I#41=TIM1_UP_TIM10_IRQHandler\" ); SEGGER_SYSVIEW_SendSysDesc ( \"I#54=USART2_IRQHandler\" ); SEGGER_SYSVIEW_SendSysDesc ( \"I#56=EXTI15_10_IRQHandler\" ); } The SYSVIEW_OS_NAME also is used by System View Application to load useful descriptions for displaying analysed data. Read more in OS Description . The Interrupt number can be found in the g_pfnVectors table in the startup_stm32f411retx.s . Different cores have different interrupt mapping. Application should only send in-use interrupts to the host. g_pfnVectors: .word _estack .word Reset_Handler .word NMI_Handler .word HardFault_Handler .word MemManage_Handler .word BusFault_Handler .word UsageFault_Handler .word 0 .word 0 .word 0 .word 0 .word SVC_Handler .word DebugMon_Handler .word 0 .word PendSV_Handler .word SysTick_Handler /* External Interrupts */ .word WWDG_IRQHandler /* Window WatchDog */ ... .word TIM1_UP_TIM10_IRQHandler /* TIM1 Update and TIM10 */ ... .word USART2_IRQHandler /* USART2 */ .word 0 /* Reserved */ .word EXTI15_10_IRQHandler /* External Line [ 15 : 10 ] */ The final step is to help System View find the system timestamp which is used in all events for processing the timeline of recorded events. Cortex-M0 does not have Cycle Counter, therefore, it needs to be calculated manually based on the SysTick interrupt and the SysTick reload register. Other Cortex-M CPU has CPU Cycle Counter register to be used as system timestamp. Both of two methods provide 1-cycle resolution. #ifndef SEGGER_SYSVIEW_GET_TIMESTAMP #if defined (SEGGER_SYSVIEW_CORE) && (SEGGER_SYSVIEW_CORE == SEGGER_SYSVIEW_CORE_CM3) #define SEGGER_SYSVIEW_GET_TIMESTAMP() (*(U32 *)(0xE0001004)) #else #define SEGGER_SYSVIEW_GET_TIMESTAMP() SEGGER_SYSVIEW_X_GetTimestamp() #endif #endif Start the System View at the beginning of the main function: main.c #include \"SEGGER_SYSVIEW_Conf.h\" #include \"SEGGER_SYSVIEW.h\" int main () { SEGGER_SYSVIEW_Conf (); // initialize System View while ( 1 ) {...} } If there is no event is registered to be sent to host, System View is disabled by default.","title":"Configure System View"},{"location":"blog/stm32/segger-systemview/#print-messages-to-host","text":"To log the counter value to both the UART interface and the System View application, add the function call SEGGER_SYSVIEW_Print() which sends a string, or SEGGER_SYSVIEW_PrintfHost() which sends unformatted string to the host. while ( 1 ) { sprintf ( buffer , \"counter = %03d \\r\\n \" , counter ); HAL_UART_Transmit ( & huart2 , ( uint8_t * ) buffer , strlen ( buffer ), HAL_MAX_DELAY ); #if 0 SEGGER_SYSVIEW_Print(buffer); #else // better performance SEGGER_SYSVIEW_PrintfHost ( \"counter = %03d \\r\\n \" , counter ); #endif HAL_Delay ( 100 );","title":"Print messages to host"},{"location":"blog/stm32/segger-systemview/#run-the-system-view","text":"Connect any J-Link probe into the SWV interface of the target MCU. Then start the System View application on the host PC. J-Link Pro debugger J-Link SWV pins Convert ST-LINK to J-LINK SEGGER offers a firmware upgrading the ST-LINK on-board on the Nucleo and Discovery Boards to a J-LINK On-Board debugger. Start the System View for the first time, it will show a recorded example. Go to Tools \u2192 Preferences and uncheck the checkbox Load last data on start . When starting to record a new session, it is recommended to check and set the target device. Press Alt + Return to show the device selection: Select target device Press F5 or click on the start button to start recording. At the beginning step in this lab, the System View will display: Device information Messages of counter value System View with device info and some messages","title":"Run the System View"},{"location":"blog/stm32/segger-systemview/#record-interrupts","text":"In the file stm32f4xx_it.c , in each concerning interrupt handler, add a pair of ISR recording function SEGGER_SYSVIEW_RecordEnterISR() and SEGGER_SYSVIEW_RecordExitISR() to track the interrupts. It automatically retrieves the interrupt ID via a special register implemented in the SEGGER_SYSVIEW_GET_INTERRUPT_ID() function macro: stm32f4xx_it.c void SysTick_Handler ( void ) { SEGGER_SYSVIEW_RecordEnterISR (); HAL_IncTick (); SEGGER_SYSVIEW_RecordExitISR (); } void TIM1_UP_TIM10_IRQHandler ( void ) { SEGGER_SYSVIEW_RecordEnterISR (); HAL_TIM_IRQHandler ( & htim10 ); SEGGER_SYSVIEW_RecordExitISR (); } void EXTI15_10_IRQHandler ( void ) { SEGGER_SYSVIEW_RecordEnterISR (); HAL_GPIO_EXTI_IRQHandler ( BUTTON_Pin ); SEGGER_SYSVIEW_RecordExitISR (); } void USART2_IRQHandler ( void ) { SEGGER_SYSVIEW_RecordEnterISR (); HAL_UART_IRQHandler ( & huart2 ); SEGGER_SYSVIEW_RecordExitISR (); } This time, when recording with System View, there are many events captured. You will notice that between two log messages printed out, button interrupts are triggered twice. System View with Interrupt events","title":"Record interrupts"},{"location":"blog/stm32/segger-systemview/#record-functions","text":"The System View records to enter and the exit event of an interrupt, but it does not automatically record a user function. To do that, application must manually set the starting point of the function\u2019s entry with one of: SEGGER_SYSVIEW_RecordVoid(EventId) , or SEGGER_SYSVIEW_RecordU32(EventId, Param) , or SEGGER_SYSVIEW_RecordU32*(EventId, ...) , or SEGGER_SYSVIEW_RecordString(EventId, char*) and the ending point of that function with one of: SEGGER_SYSVIEW_RecordEndCall(EventId) , or SEGGER_SYSVIEW_RecordEndCallU32(EventId, Param) function. These functions need an ID to distinguish the different APIs. ID is 2 bytes, comparing to an API function name which usually is much more than 2 bytes, it is very short to save sending bandwidth. For example, to measure the main loop, and user callback functions, define some IDs starting from 32 as below: SEGGER_SYSVIEW_Conf.h #define APP_EVTID_MAIN_LOOP 32 #define APP_EVTID_HAL_TIM_PeriodElapsedCallback 33 #define APP_EVTID_HAL_GPIO_EXTI_Callback 34 #define APP_EVTID_HAL_UART_TxCpltCallback 35 void HAL_TIM_PeriodElapsedCallback ( TIM_HandleTypeDef * htim ) { SEGGER_SYSVIEW_RecordU32 ( APP_EVTID_HAL_TIM_PeriodElapsedCallback , ( U32 ) htim -> Instance ); if ( htim == & htim10 ) { HAL_GPIO_TogglePin ( LED_GPIO_Port , LED_Pin ); } SEGGER_SYSVIEW_RecordEndCall ( APP_EVTID_HAL_TIM_PeriodElapsedCallback ); } void HAL_GPIO_EXTI_Callback ( uint16_t GPIO_Pin ) { SEGGER_SYSVIEW_RecordU32 ( APP_EVTID_HAL_GPIO_EXTI_Callback , ( U32 ) GPIO_Pin ); if ( GPIO_Pin == GPIO_PIN_13 ) { counter ++ ; } SEGGER_SYSVIEW_RecordEndCall ( APP_EVTID_HAL_GPIO_EXTI_Callback ); } void HAL_UART_TxCpltCallback ( UART_HandleTypeDef * huart ) { SEGGER_SYSVIEW_RecordVoid ( APP_EVTID_HAL_UART_TxCpltCallback ); if ( huart == & huart2 ) {} SEGGER_SYSVIEW_RecordEndCall ( APP_EVTID_HAL_UART_TxCpltCallback ); } int main ( void ) { while ( 1 ) { SEGGER_SYSVIEW_RecordVoid ( APP_EVTID_MAIN_LOOP ); sprintf ( buffer , \"counter = %03d \\r\\n \" , counter ); HAL_UART_Transmit ( & huart1 , ( uint8_t * ) buffer , strlen ( buffer ), HAL_MAX_DELAY ); SEGGER_SYSVIEW_Print ( buffer ); HAL_Delay ( 100 ); SEGGER_SYSVIEW_RecordEndCall ( APP_EVTID_MAIN_LOOP ); } } After this step, there are recorded events for starting and ending of a function. However, there is just event ID, not a human-friendly readable API name. In the below image, the TIM10 IRQ handler took 81 us to run, in which the user callback function with ID #33 took 25 us. System View shows event ID for recorded functions","title":"Record functions"},{"location":"blog/stm32/segger-systemview/#os-description-file","text":"In order for System View to properly decode API calls it requires a description file to be present in the C:\\Program Files\\SEGGER\\SystemView\\Description directory of System View. The name of the file has to be SYSVIEW_<OSName>.txt where <OSName> is the name as sent in the system description. This lab use NoOS as the OS Name, therefore, it should be a SYSVIEW_NoOS.txt file in the description folder of System View. The user description folder is notified via System View log windows, e.g. C:\\Users\\<user>\\AppData\\Roaming\\SEGGER . System View can not find OS Description OS Description syntax A description file includes all API functions which can be recorded by the OS. Each line in the file is one function in the following format: <ID> <Name> <Parameters> | <ReturnValue> <Id> is the Id which is recorded for the API function. It can be in the range of 32 to 511. <Name> is the name of the API function, displayed in the Event column of System View. It may not contain spaces. <Parameters> and <ReturnValue> are the description string of the parameters which are recorded with the API functions. The ReturnValueDescription is optional. The parameter display can be configured by a set of modifiers: %b - Display parameter as binary. %B - Display parameter as hexadecimal string (e.g. 00 AA FF \u2026). %d - Display parameter as signed decimal integer. %D - Display parameter as time value. %I - Display parameter as a resource name if the resource id is known to System View. %p - Display parameter as 4 byte hexadecimal integer (e.g. 0xAABBCCDD). %s - Display parameter as string. %t - Display parameter as a task name if the task id is known to System View. %u - Display parameter as unsigned decimal integer. %x - Display parameter as hexadecimal integer. The following example shows a part of SYSVIEW_embOS.txt : 46 OS_CreateTask Task = %t Pri = %u Stack = %p Size = %u In addition to the default modifiers the description file can define NamedTypes to map numerical values to strings, which can for example be useful to display the textual value of enums or error codes. The special character * represents for all remaining unmapped values. NamedTypes have following format, can be used in the <Parameters> and the <ReturnValue> : NamedType <TypeName> <Key>=<Value> [<Key1>=<Value1> ...] The following example shows a part of SYSVIEW_embOS.txt : # Types for parameter formatters NamedType OSErr 0 = OS_ERR_NONE 10000 = OS_ERR_A # API Functions 34 OSFunc Param = %OSFlag | Returns %OSErr When a task pauses execution its state is recorded in the System View event. This task state can be converted to a textual representation in System View with the TaskState description. TaskState has following format: TaskState <Mask> <Key>=<Value>, [<Key1>=<Value1>, ...] For example: # Task States TaskState 0xFF 0 = Ready, 1 = Delayed or Timeout Always have an empty line in the OS description file to make the last line is parsed properly Write OS Description with Peripheral Info We will define a lookup table for TIMx instance. The record function sends the address of the being called Timer: SEGGER_SYSVIEW_RecordU32 ( APP_EVTID_HAL_TIM_PeriodElapsedCallback , ( U32 ) htim -> Instance ); Therefore, we can map the received address value with the instance name. Use the Table 1. STM32F411xC/E register boundary addresses in Reference Manual document to know the addresses. For the PIN number, we can need to call log2() function to get actual PIN in numeric order. SEGGER_SYSVIEW_RecordU32 ( APP_EVTID_HAL_GPIO_EXTI_Callback , ( U32 ) log2 ( GPIO_Pin ) ); Here is the sample OS Description for our project: SYSVIEW_NoOS.txt # Types NamedType TIMx * = %p 0x40010000 = TIM1 0x40014400 = TIM10 NamedType PINx * = %u NamedType UARTx * = %p 0x40011000 = USART1 0x40004400 = USART2 # API IDs 32 Main_Loop 33 HAL_TIM_PeriodElapsedCallback Instance = %TIMx 34 GPIO_EXTI_Callback GPIO_Pin = %Pinx 35 HAL_UART_TxCpltCallback Re-run the System Viewer, you now can see the function name, with more detail as described in the OS Description file: System View shows function name and its parameters","title":"OS Description file"},{"location":"blog/stm32/segger-systemview/#measure-performance","text":"To measure performance, System View uses Markers to calculate the execution time between a starting point and a corresponding ending point. The functions to measure performance is SEGGER_SYSVIEW_MarkStart() and SEGGER_SYSVIEW_MarkStop() , which need IDs to create pairs. Define the Marker IDs: SEGGER_SYSVIEW_Conf.h #define APP_MARKER_MAIN_LOOP 0 #define APP_MARKER_UART_TX_BLOCKING 1 #define APP_MARKER_UART_TX_INTERRUPT 2 Then send the marker names in the Device Information callback function: static void _cbSendSystemDesc ( void ) { SEGGER_SYSVIEW_SendSysDesc (...); SEGGER_SYSVIEW_NameMarker ( APP_MARKER_MAIN_LOOP , \"Main Loop\" ); SEGGER_SYSVIEW_NameMarker ( APP_MARKER_UART_TX_BLOCKING , \"UART_TX_Blocking\" ); SEGGER_SYSVIEW_NameMarker ( APP_MARKER_UART_TX_INTERRUPT , \"UART_TX_Interrupt\" ); } Compare Blocking and Non-Blocking Mode We will call to 2 methods of sending characters on USART: Blocking: function HAL_UART_Transmit() put on byte on TX line and wait for it to be sent, the put another bytes. CPU is kept to busy while waiting. Non-Blocking: function HAL_UART_Transmit_IT() set UART in interrupt mode: one byte is put on TX line the CPU does not wait for it to be sent, when a byte is sent, an interrupt is called to put next byte on TX again. CPU is free to run while a byte is being transmitted. while ( 1 ) { SEGGER_SYSVIEW_MarkStart ( APP_MARKER_MAIN_LOOP ); sprintf ( buffer , \"counter = %03d \\r\\n \" , counter ); #ifndef USE_UART_INTERRUPT // UART BLOCKING MODE SEGGER_SYSVIEW_MarkStart ( APP_MARKER_UART_TX_BLOCKING ); HAL_UART_Transmit ( & huart2 , ( uint8_t * ) buffer , strlen ( buffer ), HAL_MAX_DELAY ); SEGGER_SYSVIEW_MarkStop ( APP_MARKER_UART_TX_BLOCKING ); #else // UART INTERRUPT MODE SEGGER_SYSVIEW_MarkStart ( APP_MARKER_UART_TX_INTERRUPT ); HAL_UART_Transmit_IT ( & huart2 , ( uint8_t * ) buffer , strlen ( buffer ) ); #endif The result of measuring two performance points is as below: System View show a Blocking case System View show a Non-Blocking case Look at the above images, it\u2019s clear that in Non-Blocking case, the Main Loop has can finish a work faster as it can run while UART is transmitting a byte.","title":"Measure performance"},{"location":"blog/stm32/segger-systemview/#system-view-with-no-os-on-cortex-m0","text":"F051R8_SysView_NoOS.zip This section is a guide for F051R8 on STM32F0-DISCOVERY board. SEGGER_SYSVIEW_Config_NoOS_CM0.c #define SYSVIEW_APP_NAME \"Demo Application\" #define SYSVIEW_DEVICE_NAME \"STM32F051R8\" #define SYSVIEW_CORE_NAME \"Cortex-M0\" #define SYSVIEW_OS_NAME \"CM0-NoOS\" static void _cbSendSystemDesc ( void ) { SEGGER_SYSVIEW_SendSysDesc ( \"N=\" SYSVIEW_APP_NAME \",\" \"D=\" SYSVIEW_DEVICE_NAME \",\" \"C=\" SYSVIEW_CORE_NAME \",\" \"O=\" SYSVIEW_OS_NAME ); SEGGER_SYSVIEW_SendSysDesc ( \"I#15=SysTick\" ); } For Cortex-M0, it is needed to increase the variable SEGGER_SYSVIEW_TickCnt in the SysTick interrupt, as soon as that handler is executed. This variable is used in the function SEGGER_SYSVIEW_X_GetTimestamp() to correctly calculate the clock cycles. stm32f0xx_it.c void SysTick_Handler ( void ) { SEGGER_SYSVIEW_TickCnt ++ ; // must be at the beginning SEGGER_SYSVIEW_RecordEnterISR (); HAL_IncTick (); SEGGER_SYSVIEW_RecordExitISR (); } Done! Cortex-M0 now can provide precision timestamp for System View.","title":"System View with No OS on Cortex-M0"},{"location":"blog/stm32/segger-systemview/#system-view-on-rtos","text":"F411RE_SysView_RTOS.zip Using an RTOS makes system analysis more complicated. However, System View is designed to work with RTOS after some simple steps.","title":"System View on RTOS"},{"location":"blog/stm32/segger-systemview/#start-a-new-project_1","text":"Let\u2019s create a new project using FreeRTOS V10.3.1 using CMSIS-RTOS V2. Configure project to use RTOS Note: RTOS should use SysTick for its own OS delay function, while HAL function also needs a time-base to operate its own polling delay method.","title":"Start a new project"},{"location":"blog/stm32/segger-systemview/#import-system-view-files_1","text":"The core files of Segger System View is the same as they are used in the Non-OS firmware. The difference is the config files for RTOS, which are found in the target FreeRTOS version or any other RTOS such as embOS. FreeRTOSV10 \u2502 \u2502 SEGGER_SYSVIEW_FreeRTOS.c \u2502 SEGGER_SYSVIEW_FreeRTOS.h \u2502 \u251c\u2500\u2500\u2500Config \u2502 \u2514\u2500\u2500\u2500Cortex-M \u2502 SEGGER_SYSVIEW_Config_FreeRTOS.c \u2502 \u2514\u2500\u2500\u2500Patch FreeRTOSV10_Amazon_Core.patch FreeRTOSV10_Core.patch Copy all of those files to the project. Add System View files for RTOS","title":"Import System View files"},{"location":"blog/stm32/segger-systemview/#apply-patch","text":"The patch file may not be applied for newer FreeRTOS version, such as V10.3+. It easy to modify the patch to apply into a newer version, or download FreeRTOSV10.3.1_Core.patch . Apply System View patch to RTOS source","title":"Apply patch"},{"location":"blog/stm32/segger-systemview/#configure-system-view_1","text":"Include SEGGER_SYSVIEW_FreeRTOS.h at the end of the file FreeRTOSConfig.h to override some RTOS definitions of tracing functions. Finally, configure System View in the file SEGGER_SYSVIEW_Config_FreeRTOS.c which sends System Information, Interrupt ID & Name, Timers and Markers. #define SYSVIEW_APP_NAME \"Demo RTOS Application\" #define SYSVIEW_DEVICE_NAME \"STM32F411RE\" #define SYSVIEW_CORE_NAME \"Cortex-M4\" #define SYSVIEW_OS_NAME \"FreeRTOS\" #define SYSVIEW_RAM_BASE (0x20000000) static void _cbSendSystemDesc ( void ) { SEGGER_SYSVIEW_SendSysDesc ( \"N=\" SYSVIEW_APP_NAME \",\" \"D=\" SYSVIEW_DEVICE_NAME \",\" \"C=\" SYSVIEW_CORE_NAME \",\" \"O=\" SYSVIEW_OS_NAME ); SEGGER_SYSVIEW_SendSysDesc ( \"I#15=SysTick\" ); } Include SEGGER\u2019s headers and call to SEGGER_SYSVIEW_Conf() to initialize System View: #include \"SEGGER_SYSVIEW_Conf.h\" #include \"SEGGER_SYSVIEW.h\" int main () { SEGGER_SYSVIEW_Conf (); ... }","title":"Configure System View"},{"location":"blog/stm32/segger-systemview/#run-system-view","text":"Done! You can build and run System Viewer to see RTOS running with a Default Task and a Timer Service. System View shows RTOS running with a Default Task and a Timer Service","title":"Run System View"},{"location":"blog/stm32/semihosting/","tags":["arm","stm32","debug"],"text":"STM32-Tutorials F411RE_Semihosting.zip Semihosting setup Connect a debugger via SWD interface Include Semihosting library in GCC Linker: -l rdimon --specs=rdimon.specs . Exclude the default syscall.c implementation if needed Call initialise_monitor_handles() at the begining of the main function Run OpenOCD with command monitor arm semihosting enable Limitation Semihosting implementation in OpenOCD is designed so that every string must be terminated with the newline character \\n before the string appears on the OpenOCD console Semihosting only works during a debug session, and it\u2019s slow and affects the system performance CPU is halt when Semihosting is executing in host machine, therefore Semihosting is not suitable for realtime application Debugging # There are some debug techniques used to inspect the firmware running on ARM-based MCUs: Semihosting : built-in to every ARM chips, need adding additional library and running in debug mode. Console log : forward to a native UART port , a Virtual COM port through a USB port. Serial Wire View (SWV) : fast output over dedicated Single Wire Output (SWO) pin, but it\u2019s only available on Cortex-M3+, and this is uni-direction communication. Real Time Transfer (RTT) : extremely fast but only work with SEGGER Debugger, can have a real-time bi-direction communication. Ways to print debug Semihosting # ARM Semihosting is a distinctive feature of the ARM platform, that allows to use input and output functions on a host computer that get forwarded to the microcontrollers over a hardware debugger, by hooking into I/O functions, such as printf() and scanf() , or even fopen() . Semihosting is implemented by a set of defined software instructions, for example, SVC , that generate exceptions from program control. The application invokes the appropriate Semihosting call and the debugger then handles the exception by communicating with the debugging application on the host computer. ARM processors prior to ARMv7 use the SVC instructions, formerly known as SWI instructions, to make Semihosting calls. However, for an ARMv6-M or ARMv7-M, in a Cortex-M1 or Cortex-M3 processor, Semihosting is implemented using the BKPT instruction. Semihosting overview Hardware setup # Semihosting need to be run under a debug session to communicate with Semihosting-enabled debugger, such as OpenOCD. In STM32, debugging channel maybe ST-LINK debugger (onboard, or external) which connects to the MCU via SWCLK and SWDIO in the SWD interface. Linker options # To use Semihosting, it has to be set in the linker options, and initialized in the main program. Standard C libraries GNU ARM libraries use newlib to provide standard implementation of C libraries. To reduce the code size and make it independent to hardware, there is a lightweight version newlib-nano used in MCUs. However, newlib-nano does not provide an implementation of low-level system calls which are used by C standard libraries, such as print() or scan() . To make the application compilable, a new library named nosys should be added. This library just provide a simple implementation of low-level system calls which mostly return a by-pass value. The lib newlib-nano is enabled via linker options --specs=nano.specs , and nosys is enabled via linker option --specs=nosys.specs . These two libraries are included by default in GCC linker options in generated project, check it here . Rdimon library There is a rdimon library that implements interrupt for some special system calls, which pauses the processor and interacts with the host debugger to exchange data, such as SYS_WRITE (0x05) or SYS_READ (0x06) . This library provides low-level system calls to handling the newlib-nano specs. The lib rdimon is enabled via linker option -l rdimon --specs=rdimon.specs STM32CubeIDE automatically generates syscalls.c with a simple implementation for nosys.specs . However, it conflicts with the implementation in rdimon.specs . Exclude syscalls.c from the build to avoid compilation error of multiple definitions . Add Semihosting in GCC Linker Exclude syscalls.c Initialize Semihosting # The rdimon library has to be initialized before it can run properly. It exposes a function to do that, then use it: extern void initialise_monitor_handles ( void ); int main ( void ) { initialise_monitor_handles (); ... } After that, the application can use printf() , scanf() , or gets() . Debugger option # The final thing is to enable Semihosting on debugger that will handle the interruptions fired from MCUs. We can select ST-LINK (OpenOCD) to use OpenOCD through ST-Link debugger. To start Semihosting in the debugger process, add below command in the Startup commands option: monitor arm semihosting enable Enable Semihosting in debugger Debug with Semihosting # Run the project in debug mode and then interact with MCUs. Here are some lines of code to print a message, get a string, and write to a file on the host machine: #include <stdio.h> #include <string.h> extern void initialise_monitor_handles ( void ); char buffer [ 255 ]; int main ( void ) { initialise_monitor_handles (); printf ( \"Please enter your name: \\n \" ); gets ( buffer ); printf ( \" \\n Ah, I know you, %s! \\n \" , buffer ); // test.out will be created in the host machine FILE * fd = fopen ( \"D: \\\\ test.out\" , \"w+\" ); if ( fd ) { fwrite ( buffer , sizeof ( char ), strlen ( buffer ), fd ); fclose ( fd ); } uint8_t counter = 0 ; while ( 1 ) { printf ( \"counter = %d \\n \" , counter ++ ); } } Interact with Semihosting Using files When using fopen() , the file path is specified either as relative to the current directory of the host process (e.g. openocd.exe ), or absolute, using the path conventions of the host operating system. Read more in here .","title":"ARM Semihosting - native but slow Debugging"},{"location":"blog/stm32/semihosting/#debugging","text":"There are some debug techniques used to inspect the firmware running on ARM-based MCUs: Semihosting : built-in to every ARM chips, need adding additional library and running in debug mode. Console log : forward to a native UART port , a Virtual COM port through a USB port. Serial Wire View (SWV) : fast output over dedicated Single Wire Output (SWO) pin, but it\u2019s only available on Cortex-M3+, and this is uni-direction communication. Real Time Transfer (RTT) : extremely fast but only work with SEGGER Debugger, can have a real-time bi-direction communication. Ways to print debug","title":"Debugging"},{"location":"blog/stm32/semihosting/#semihosting","text":"ARM Semihosting is a distinctive feature of the ARM platform, that allows to use input and output functions on a host computer that get forwarded to the microcontrollers over a hardware debugger, by hooking into I/O functions, such as printf() and scanf() , or even fopen() . Semihosting is implemented by a set of defined software instructions, for example, SVC , that generate exceptions from program control. The application invokes the appropriate Semihosting call and the debugger then handles the exception by communicating with the debugging application on the host computer. ARM processors prior to ARMv7 use the SVC instructions, formerly known as SWI instructions, to make Semihosting calls. However, for an ARMv6-M or ARMv7-M, in a Cortex-M1 or Cortex-M3 processor, Semihosting is implemented using the BKPT instruction. Semihosting overview","title":"Semihosting"},{"location":"blog/stm32/semihosting/#hardware-setup","text":"Semihosting need to be run under a debug session to communicate with Semihosting-enabled debugger, such as OpenOCD. In STM32, debugging channel maybe ST-LINK debugger (onboard, or external) which connects to the MCU via SWCLK and SWDIO in the SWD interface.","title":"Hardware setup"},{"location":"blog/stm32/semihosting/#linker-options","text":"To use Semihosting, it has to be set in the linker options, and initialized in the main program. Standard C libraries GNU ARM libraries use newlib to provide standard implementation of C libraries. To reduce the code size and make it independent to hardware, there is a lightweight version newlib-nano used in MCUs. However, newlib-nano does not provide an implementation of low-level system calls which are used by C standard libraries, such as print() or scan() . To make the application compilable, a new library named nosys should be added. This library just provide a simple implementation of low-level system calls which mostly return a by-pass value. The lib newlib-nano is enabled via linker options --specs=nano.specs , and nosys is enabled via linker option --specs=nosys.specs . These two libraries are included by default in GCC linker options in generated project, check it here . Rdimon library There is a rdimon library that implements interrupt for some special system calls, which pauses the processor and interacts with the host debugger to exchange data, such as SYS_WRITE (0x05) or SYS_READ (0x06) . This library provides low-level system calls to handling the newlib-nano specs. The lib rdimon is enabled via linker option -l rdimon --specs=rdimon.specs STM32CubeIDE automatically generates syscalls.c with a simple implementation for nosys.specs . However, it conflicts with the implementation in rdimon.specs . Exclude syscalls.c from the build to avoid compilation error of multiple definitions . Add Semihosting in GCC Linker Exclude syscalls.c","title":"Linker options"},{"location":"blog/stm32/semihosting/#initialize-semihosting","text":"The rdimon library has to be initialized before it can run properly. It exposes a function to do that, then use it: extern void initialise_monitor_handles ( void ); int main ( void ) { initialise_monitor_handles (); ... } After that, the application can use printf() , scanf() , or gets() .","title":"Initialize Semihosting"},{"location":"blog/stm32/semihosting/#debugger-option","text":"The final thing is to enable Semihosting on debugger that will handle the interruptions fired from MCUs. We can select ST-LINK (OpenOCD) to use OpenOCD through ST-Link debugger. To start Semihosting in the debugger process, add below command in the Startup commands option: monitor arm semihosting enable Enable Semihosting in debugger","title":"Debugger option"},{"location":"blog/stm32/semihosting/#debug-with-semihosting","text":"Run the project in debug mode and then interact with MCUs. Here are some lines of code to print a message, get a string, and write to a file on the host machine: #include <stdio.h> #include <string.h> extern void initialise_monitor_handles ( void ); char buffer [ 255 ]; int main ( void ) { initialise_monitor_handles (); printf ( \"Please enter your name: \\n \" ); gets ( buffer ); printf ( \" \\n Ah, I know you, %s! \\n \" , buffer ); // test.out will be created in the host machine FILE * fd = fopen ( \"D: \\\\ test.out\" , \"w+\" ); if ( fd ) { fwrite ( buffer , sizeof ( char ), strlen ( buffer ), fd ); fclose ( fd ); } uint8_t counter = 0 ; while ( 1 ) { printf ( \"counter = %d \\n \" , counter ++ ); } } Interact with Semihosting Using files When using fopen() , the file path is specified either as relative to the current directory of the host process (e.g. openocd.exe ), or absolute, using the path conventions of the host operating system. Read more in here .","title":"Debug with Semihosting"},{"location":"blog/stm32/stack-memory/","tags":["arm","stm32"],"text":"STM32-Tutorials F411RE_Stack.zip Stack # Stack Memory is part of the main memory reserved for the temporary storage of data (transient data), mainly used in function call, interrupt/exception handling. Stack Memory is accessed in Last In First Out LIFO manner. The stack can be accessed using PUSH , POP or memory instructions such as LDR , STR . The stack is traced by the Stack Pointer (SP) , and is used to save below information: Temporary storage for processor register values Temporary storage for local variables of functions Save the context of the current executing code before moving to exception/ interrupt handing routine Stack Memory models Processor Stacks # The ARM Cortex-M processor uses a full descending stack . This means the stack pointer indicates the last stacked item on the stack memory. When the processor pushes a new item onto the stack, it decrements the stack pointer and then writes the item to the new memory location. The processor implements two stacks, the main stack and the process stack , with independent copies of the stack pointer. The Stack Pointer (SP) is register R13 . In Thread mode, bit[1] of the CONTROL register indicates the stack pointer to use: 0 : Main Stack Pointer (MSP) . This is the default after reset, used for all exception/ interrupt handler and also for code running in thread mode. 1 : Process Stack Pointer (PSP) . This alternative stack is only can be used in thread mode. It is usually used for application task in embedded systems and OS On reset, the processor loads the MSP with the value from address 0x00000000 . Processor mode Code execute Access level Stack used Thread Applications Privileged or unprivileged Main stack or process stack Handler Exception handlers Always privileged Main stack Stack placement # In ARM projects based on ARM CMSIS, the linker decides to place Stack at the end of RAM. Let check the linker file STM32F411RETX_FLASH.ld : /* Highest address of the user mode stack */ _estack = ORIGIN ( RAM ) + LENGTH ( RAM ); /* end of \"RAM\" Ram type memory */ _Min_Heap_Size = 0x200 ; /* required amount of heap */ _Min_Stack_Size = 0x400 ; /* required amount of stack */ /* Memories definition */ MEMORY { RAM ( xrw ) : ORIGIN = 0x20000000 , LENGTH = 128 K FLASH ( rx ) : ORIGIN = 0x8000000 , LENGTH = 512 K } On reset, the processor loads the MSP with the value from address 0x00000000 . At that initial address, the Interrupt Vector Table must be there. The startup code in startup_stm32f411retx.s defines the isr_vector as below: .section .isr_vector , \"a\" , %progbits .type g_pfnVectors , %object .size g_pfnVectors , .-g_pfnVectors g_pfnVectors: .word _estack .word Reset_Handler .word NMI_Handler ... with the value of _estack at the 0x00000000 which is declared in the linker script: /* Sections */ SECTIONS { /* The startup code into \"FLASH\" Rom type memory */ . isr_vector : { . = ALIGN ( 4 ); KEEP ( * (. isr_vector )) /* Startup code */ . = ALIGN ( 4 ); } > FLASH ... Stack placement for Full Descending Stack Prologue and Epilogue sequences # In assembly language programming, the function prologue is a few lines of code at the beginning of a function, which prepare the stack and registers for use within the function. Similarly, the function epilogue appears at the end of the function, and restores the stack and registers to the state they were in before the function was called. Prologue A function prologue typically does the following actions if the architecture has a base pointer (also known as frame pointer) and a stack pointer: Pushes current base pointer onto the stack, so it can be restored later. Value of base pointer is set to the address of stack pointer (which is pointed to the top of the stack) so that the base pointer will point to the top of the stack. Moves the stack pointer further by decreasing or increasing its value, depending on whether the stack grows down or up. On x86, the stack pointer is decreased to make room for the function\u2019s local variables. Example: push { r7 } ; Save frame pointer sub sp , #20 ; Reserve 20 bytes add r7 , sp , #0 ; Set frame pointer to new stack pointer str r0 , [ r7 , #12 ] ; Save params on R0-R3 to stack str r1 , [ r7 , #8 ] str r2 , [ r7 , #4 ] str r3 , [ r7 , #0 ] Epilogue Function epilogue reverses the actions of the function prologue and returns control to the calling function. It typically does the following actions (this procedure may differ from one architecture to another): Drop the stack pointer to the current base pointer, so room reserved in the prologue for local variables is freed. Pops the base pointer off the stack, so it is restored to its value before the prologue. Returns to the calling function, by popping the previous frame\u2019s program counter off the stack and jumping to it. Example: adds r7 , #20 ; Return back to last stack pointer mov sp , r7 ldr.w r7 , [ sp ], #4 ; Get last frame pointer bx lr ; Exit function by brach and execute saved instruction in LR Example # In this example, we will create 2 Stack Regions and assign them to MSP and PSP . Step 0: Create a new project You should create a bare-metal project which just has a few files including a linker and a main. Step 1: Define Stack Start Address The stack model is that Main Stack and Process Stack are a half of allocated stack space. By default, after reset, the processor uses the Main Stack, therefore, Main Stack is located at the start of Stack region. Main Stack and Process Stack In the linker script STM32F411RETX_FLASH.ld , define 2 new symbols _msp_stack and _psp_stack : /* Highest address of the user mode stack */ _estack = ORIGIN ( RAM ) + LENGTH ( RAM ); /* end of \"RAM\" Ram type memory */ _Min_Heap_Size = 0x200 ; /* required amount of heap */ _Min_Stack_Size = 0x400 ; /* required amount of stack */ _msp_stack = _estack ; _psp_stack = _estack - _Min_Stack_Size / 2 ; Step 2: Demo program to change Stack to PSP int add ( int a , int b , int c , int d ) { return a + b + c + d ; } void SVC_Handler () { // this function call uses MSP int sum = add ( 5 , 6 , 7 , 8 ); } __attribute__ (( naked )) void changeStackToPSP ( void ) { // change PSP __asm volatile ( \"LDR R0, =_psp_stack\" ); __asm volatile ( \"MSR PSP, R0\" ); // set SPSEL bit __asm volatile ( \"MRS R1, CONTROL\" ); __asm volatile ( \"ORR R1, R1, #2\" ); __asm volatile ( \"MSR CONTROL, R1\" ); // return __asm volatile ( \"BX LR\" ); } void callSVC () { __asm volatile ( \"SVC #0\" ); } int main ( void ) { changeStackToPSP (); // this function call uses PSP int sum = add ( 1 , 2 , 3 , 4 ); // trigger SVC will force to use MSP callSVC (); /* Loop forever */ for (;;); } Step 4: At reset You have to place a breakpoint right at the Reset_Handler function which is the first instruction loaded into PC. Right after CPU reset: The MSP register is loaded from the address 0x00000000 in System Memory (alias to 0x08000000 in Flash) which has _estack value. The PC register then is loaded with the value at the address 0x00000004 which is the address of Reset_Handler (added 1 to set the Thumb bit ). _estack and Reset_Handler are loaded to MSP and PC at reset Step 5: Application changes to use PSP To change to PSP stack, we have to write a special function that set a new value to PSP regsiter, and set a bit in CONTROL register. __attribute__((naked)) is used to tell compiler that this function is embedded assembly function and compiler does not generate prologue and epilogue sequences for it. The compiler only supports basic __asm statements in __attribute__((naked)) functions. Note that: The _psp_stack symbol is defined in the linker script. Manually return from a naked function (no epilogue) using assembly instruction BX LR __attribute__ (( naked )) void changeStackToPSP ( void ) { // change PSP __asm volatile ( \"LDR R0, =_psp_stack\" ); __asm volatile ( \"MSR PSP, R0\" ); // set SPSEL bit __asm volatile ( \"MRS R1, CONTROL\" ); __asm volatile ( \"ORR R1, R1, #2\" ); __asm volatile ( \"MSR CONTROL, R1\" ); // return __asm volatile ( \"BX LR\" ); } Change to Process Stack Application is using PSP Step 6: Exception Handler uses MSP When CPU sees an SVC call, it automatically changes to MSP Stack by setting SP to MSP . MSP is used in Exception Handler During an exception/ interrupt handler, MSP is used. Exception is using MSP If we do not clear the SPSEL in the CONTROL register, the SP register will be switch back to PSP after returning from the exception/ interrupt handler. Procedure Call Standard for Arm Architecture (AAPCS) # A Procedure Call Standard or Calling Convention defines how different compilation units, even when compiled by different compilers, can work together. It defines how parameters are passed from one function to another, which registers and other program states must be preserved by caller a callee and what might be altered by the callee. The procedure call standard is one in a set of standards, which define the application binary interface (ABI) a compilation unit has to respect. Parameters and Arguments A parameter is a variable name and type, which is part of the declaration of the function An argument, on the other side, is the actual value passed into a function Caller-saved and Callee-saved registers The general-purpose registers R0 - R3 are used to pass arguments to a function and also return values. They are not needed to be preserved by the callee, they are caller-saved. The registers R4 - R8 , R10 and R11 are used to hold local variables within a function. A caller can expect them to be unchanged, when the called function returns: They are callee-saved. Passing arguments The arguments are bound to registers, which is used to pass the argument to the function. When all caller-saved registers ( R0 to R3 ) are bound to arguments, the stack is used to pass all arguments left: int add ( int a , int b , int c , int d , int e ) { return a + b + c + d + e ; } int main () { int sum = add ( 1 , 2 , 3 , 4 , 5 ); } xxxxxxx < main > : 8000266: 2305 movs r3 , #5 ; 8000268: 9300 str r3 , [ sp , #0 ] ; save arg 5 to stack 800026 a: 2304 movs r3 , #4 ; save arg 4 to R3 800026 c: 2203 movs r2 , #3 ; save arg 3 to R2 800026 e: 2102 movs r1 , #2 ; save arg 2 to R1 8000270: 2001 movs r0 , #1 ; save arg 1 to R0 8000272: f7ff ffb1 bl 80001d8 < add > ; call to function ... 080001 d8 < add > : 80001 d8: b480 push { r7 } ; save frame pointer 80001 da: b085 sub sp , #20 ; reserve 20 bytes on stack 80001 dc: af00 add r7 , sp , #0 ; set new frame pointer 80001 de: 60 f8 str r0 , [ r7 , #12 ] ; save arg 1 to stack 80001 e0: 60 b9 str r1 , [ r7 , #8 ] ; save arg 2 to stack 80001 e2: 607 a str r2 , [ r7 , #4 ] ; save arg 3 to stack 80001 e4: 603 b str r3 , [ r7 , #0 ] ; save arg 4 to stack 80001 e6: 68 fa ldr r2 , [ r7 , #12 ] ; get arg 1 from stack 80001 e8: 68 bb ldr r3 , [ r7 , #8 ] ; get arg 2 from stack 80001 ea: 441 a add r2 , r3 ; sum += arg 1 + arg 2 80001 ec: 687 b ldr r3 , [ r7 , #4 ] ; get arg 3 from stack 80001 ee: 441 a add r2 , r3 ; sum += arg 3 80001 f0: 683 b ldr r3 , [ r7 , #0 ] ; get arg 4 from stack 80001 f2: 441 a add r2 , r3 ; sum += arg 4 80001 f4: 69 bb ldr r3 , [ r7 , #24 ] ; get arg 5 from stack 80001 f6: 4413 add r3 , r2 ; sum += arg 5 80001 f8: 4618 mov r0 , r3 ; save sum to r0 as return value 80001 fa: 3714 adds r7 , #20 ; restore frame pointer 80001 fc: 46 bd mov sp , r7 ; restore stack pointer 80001 fe: f85d 7 b04 ldr.w r7 , [ sp ], #4 ; get saved frame pointer, pop back stack pointer 8000202: 4770 bx lr ; return ... Arguments on stack during function call Context Saving on Stack # When application is running, if there is any exception/ interrupt raised, the processor will do a special procedure called \u201cContext Saving\u201d. Context saving allows the current executing application flow is saved and then restored because all registers would have the same values as when the interrupt started. This context saving also be used to switch tasks which is used in OS. Automatic context saving on stack When the processor takes an exception, unless the exception is a tail-chained or a late-arriving exception, the processor pushes information onto the current stack. This operation is referred as stacking and the structure of eight data words is referred as stack frame. When using floating-point routines, the Cortex-M4 processor automatically stacks the architected floating-point state on exception entry. Stack frame layout with Floating-point Unit or without it The stack frame includes the return address. This is the address of the next instruction in the interrupted program. This value is restored to the PC at exception return so that the interrupted program resumes.","title":"Stack Memory"},{"location":"blog/stm32/stack-memory/#stack","text":"Stack Memory is part of the main memory reserved for the temporary storage of data (transient data), mainly used in function call, interrupt/exception handling. Stack Memory is accessed in Last In First Out LIFO manner. The stack can be accessed using PUSH , POP or memory instructions such as LDR , STR . The stack is traced by the Stack Pointer (SP) , and is used to save below information: Temporary storage for processor register values Temporary storage for local variables of functions Save the context of the current executing code before moving to exception/ interrupt handing routine Stack Memory models","title":"Stack"},{"location":"blog/stm32/stack-memory/#processor-stacks","text":"The ARM Cortex-M processor uses a full descending stack . This means the stack pointer indicates the last stacked item on the stack memory. When the processor pushes a new item onto the stack, it decrements the stack pointer and then writes the item to the new memory location. The processor implements two stacks, the main stack and the process stack , with independent copies of the stack pointer. The Stack Pointer (SP) is register R13 . In Thread mode, bit[1] of the CONTROL register indicates the stack pointer to use: 0 : Main Stack Pointer (MSP) . This is the default after reset, used for all exception/ interrupt handler and also for code running in thread mode. 1 : Process Stack Pointer (PSP) . This alternative stack is only can be used in thread mode. It is usually used for application task in embedded systems and OS On reset, the processor loads the MSP with the value from address 0x00000000 . Processor mode Code execute Access level Stack used Thread Applications Privileged or unprivileged Main stack or process stack Handler Exception handlers Always privileged Main stack","title":"Processor Stacks"},{"location":"blog/stm32/stack-memory/#stack-placement","text":"In ARM projects based on ARM CMSIS, the linker decides to place Stack at the end of RAM. Let check the linker file STM32F411RETX_FLASH.ld : /* Highest address of the user mode stack */ _estack = ORIGIN ( RAM ) + LENGTH ( RAM ); /* end of \"RAM\" Ram type memory */ _Min_Heap_Size = 0x200 ; /* required amount of heap */ _Min_Stack_Size = 0x400 ; /* required amount of stack */ /* Memories definition */ MEMORY { RAM ( xrw ) : ORIGIN = 0x20000000 , LENGTH = 128 K FLASH ( rx ) : ORIGIN = 0x8000000 , LENGTH = 512 K } On reset, the processor loads the MSP with the value from address 0x00000000 . At that initial address, the Interrupt Vector Table must be there. The startup code in startup_stm32f411retx.s defines the isr_vector as below: .section .isr_vector , \"a\" , %progbits .type g_pfnVectors , %object .size g_pfnVectors , .-g_pfnVectors g_pfnVectors: .word _estack .word Reset_Handler .word NMI_Handler ... with the value of _estack at the 0x00000000 which is declared in the linker script: /* Sections */ SECTIONS { /* The startup code into \"FLASH\" Rom type memory */ . isr_vector : { . = ALIGN ( 4 ); KEEP ( * (. isr_vector )) /* Startup code */ . = ALIGN ( 4 ); } > FLASH ... Stack placement for Full Descending Stack","title":"Stack placement"},{"location":"blog/stm32/stack-memory/#prologue-and-epilogue-sequences","text":"In assembly language programming, the function prologue is a few lines of code at the beginning of a function, which prepare the stack and registers for use within the function. Similarly, the function epilogue appears at the end of the function, and restores the stack and registers to the state they were in before the function was called. Prologue A function prologue typically does the following actions if the architecture has a base pointer (also known as frame pointer) and a stack pointer: Pushes current base pointer onto the stack, so it can be restored later. Value of base pointer is set to the address of stack pointer (which is pointed to the top of the stack) so that the base pointer will point to the top of the stack. Moves the stack pointer further by decreasing or increasing its value, depending on whether the stack grows down or up. On x86, the stack pointer is decreased to make room for the function\u2019s local variables. Example: push { r7 } ; Save frame pointer sub sp , #20 ; Reserve 20 bytes add r7 , sp , #0 ; Set frame pointer to new stack pointer str r0 , [ r7 , #12 ] ; Save params on R0-R3 to stack str r1 , [ r7 , #8 ] str r2 , [ r7 , #4 ] str r3 , [ r7 , #0 ] Epilogue Function epilogue reverses the actions of the function prologue and returns control to the calling function. It typically does the following actions (this procedure may differ from one architecture to another): Drop the stack pointer to the current base pointer, so room reserved in the prologue for local variables is freed. Pops the base pointer off the stack, so it is restored to its value before the prologue. Returns to the calling function, by popping the previous frame\u2019s program counter off the stack and jumping to it. Example: adds r7 , #20 ; Return back to last stack pointer mov sp , r7 ldr.w r7 , [ sp ], #4 ; Get last frame pointer bx lr ; Exit function by brach and execute saved instruction in LR","title":"Prologue and Epilogue sequences"},{"location":"blog/stm32/stack-memory/#example","text":"In this example, we will create 2 Stack Regions and assign them to MSP and PSP . Step 0: Create a new project You should create a bare-metal project which just has a few files including a linker and a main. Step 1: Define Stack Start Address The stack model is that Main Stack and Process Stack are a half of allocated stack space. By default, after reset, the processor uses the Main Stack, therefore, Main Stack is located at the start of Stack region. Main Stack and Process Stack In the linker script STM32F411RETX_FLASH.ld , define 2 new symbols _msp_stack and _psp_stack : /* Highest address of the user mode stack */ _estack = ORIGIN ( RAM ) + LENGTH ( RAM ); /* end of \"RAM\" Ram type memory */ _Min_Heap_Size = 0x200 ; /* required amount of heap */ _Min_Stack_Size = 0x400 ; /* required amount of stack */ _msp_stack = _estack ; _psp_stack = _estack - _Min_Stack_Size / 2 ; Step 2: Demo program to change Stack to PSP int add ( int a , int b , int c , int d ) { return a + b + c + d ; } void SVC_Handler () { // this function call uses MSP int sum = add ( 5 , 6 , 7 , 8 ); } __attribute__ (( naked )) void changeStackToPSP ( void ) { // change PSP __asm volatile ( \"LDR R0, =_psp_stack\" ); __asm volatile ( \"MSR PSP, R0\" ); // set SPSEL bit __asm volatile ( \"MRS R1, CONTROL\" ); __asm volatile ( \"ORR R1, R1, #2\" ); __asm volatile ( \"MSR CONTROL, R1\" ); // return __asm volatile ( \"BX LR\" ); } void callSVC () { __asm volatile ( \"SVC #0\" ); } int main ( void ) { changeStackToPSP (); // this function call uses PSP int sum = add ( 1 , 2 , 3 , 4 ); // trigger SVC will force to use MSP callSVC (); /* Loop forever */ for (;;); } Step 4: At reset You have to place a breakpoint right at the Reset_Handler function which is the first instruction loaded into PC. Right after CPU reset: The MSP register is loaded from the address 0x00000000 in System Memory (alias to 0x08000000 in Flash) which has _estack value. The PC register then is loaded with the value at the address 0x00000004 which is the address of Reset_Handler (added 1 to set the Thumb bit ). _estack and Reset_Handler are loaded to MSP and PC at reset Step 5: Application changes to use PSP To change to PSP stack, we have to write a special function that set a new value to PSP regsiter, and set a bit in CONTROL register. __attribute__((naked)) is used to tell compiler that this function is embedded assembly function and compiler does not generate prologue and epilogue sequences for it. The compiler only supports basic __asm statements in __attribute__((naked)) functions. Note that: The _psp_stack symbol is defined in the linker script. Manually return from a naked function (no epilogue) using assembly instruction BX LR __attribute__ (( naked )) void changeStackToPSP ( void ) { // change PSP __asm volatile ( \"LDR R0, =_psp_stack\" ); __asm volatile ( \"MSR PSP, R0\" ); // set SPSEL bit __asm volatile ( \"MRS R1, CONTROL\" ); __asm volatile ( \"ORR R1, R1, #2\" ); __asm volatile ( \"MSR CONTROL, R1\" ); // return __asm volatile ( \"BX LR\" ); } Change to Process Stack Application is using PSP Step 6: Exception Handler uses MSP When CPU sees an SVC call, it automatically changes to MSP Stack by setting SP to MSP . MSP is used in Exception Handler During an exception/ interrupt handler, MSP is used. Exception is using MSP If we do not clear the SPSEL in the CONTROL register, the SP register will be switch back to PSP after returning from the exception/ interrupt handler.","title":"Example"},{"location":"blog/stm32/stack-memory/#procedure-call-standard-for-arm-architecture-aapcs","text":"A Procedure Call Standard or Calling Convention defines how different compilation units, even when compiled by different compilers, can work together. It defines how parameters are passed from one function to another, which registers and other program states must be preserved by caller a callee and what might be altered by the callee. The procedure call standard is one in a set of standards, which define the application binary interface (ABI) a compilation unit has to respect. Parameters and Arguments A parameter is a variable name and type, which is part of the declaration of the function An argument, on the other side, is the actual value passed into a function Caller-saved and Callee-saved registers The general-purpose registers R0 - R3 are used to pass arguments to a function and also return values. They are not needed to be preserved by the callee, they are caller-saved. The registers R4 - R8 , R10 and R11 are used to hold local variables within a function. A caller can expect them to be unchanged, when the called function returns: They are callee-saved. Passing arguments The arguments are bound to registers, which is used to pass the argument to the function. When all caller-saved registers ( R0 to R3 ) are bound to arguments, the stack is used to pass all arguments left: int add ( int a , int b , int c , int d , int e ) { return a + b + c + d + e ; } int main () { int sum = add ( 1 , 2 , 3 , 4 , 5 ); } xxxxxxx < main > : 8000266: 2305 movs r3 , #5 ; 8000268: 9300 str r3 , [ sp , #0 ] ; save arg 5 to stack 800026 a: 2304 movs r3 , #4 ; save arg 4 to R3 800026 c: 2203 movs r2 , #3 ; save arg 3 to R2 800026 e: 2102 movs r1 , #2 ; save arg 2 to R1 8000270: 2001 movs r0 , #1 ; save arg 1 to R0 8000272: f7ff ffb1 bl 80001d8 < add > ; call to function ... 080001 d8 < add > : 80001 d8: b480 push { r7 } ; save frame pointer 80001 da: b085 sub sp , #20 ; reserve 20 bytes on stack 80001 dc: af00 add r7 , sp , #0 ; set new frame pointer 80001 de: 60 f8 str r0 , [ r7 , #12 ] ; save arg 1 to stack 80001 e0: 60 b9 str r1 , [ r7 , #8 ] ; save arg 2 to stack 80001 e2: 607 a str r2 , [ r7 , #4 ] ; save arg 3 to stack 80001 e4: 603 b str r3 , [ r7 , #0 ] ; save arg 4 to stack 80001 e6: 68 fa ldr r2 , [ r7 , #12 ] ; get arg 1 from stack 80001 e8: 68 bb ldr r3 , [ r7 , #8 ] ; get arg 2 from stack 80001 ea: 441 a add r2 , r3 ; sum += arg 1 + arg 2 80001 ec: 687 b ldr r3 , [ r7 , #4 ] ; get arg 3 from stack 80001 ee: 441 a add r2 , r3 ; sum += arg 3 80001 f0: 683 b ldr r3 , [ r7 , #0 ] ; get arg 4 from stack 80001 f2: 441 a add r2 , r3 ; sum += arg 4 80001 f4: 69 bb ldr r3 , [ r7 , #24 ] ; get arg 5 from stack 80001 f6: 4413 add r3 , r2 ; sum += arg 5 80001 f8: 4618 mov r0 , r3 ; save sum to r0 as return value 80001 fa: 3714 adds r7 , #20 ; restore frame pointer 80001 fc: 46 bd mov sp , r7 ; restore stack pointer 80001 fe: f85d 7 b04 ldr.w r7 , [ sp ], #4 ; get saved frame pointer, pop back stack pointer 8000202: 4770 bx lr ; return ... Arguments on stack during function call","title":"Procedure Call Standard for Arm Architecture (AAPCS)"},{"location":"blog/stm32/stack-memory/#context-saving-on-stack","text":"When application is running, if there is any exception/ interrupt raised, the processor will do a special procedure called \u201cContext Saving\u201d. Context saving allows the current executing application flow is saved and then restored because all registers would have the same values as when the interrupt started. This context saving also be used to switch tasks which is used in OS. Automatic context saving on stack When the processor takes an exception, unless the exception is a tail-chained or a late-arriving exception, the processor pushes information onto the current stack. This operation is referred as stacking and the structure of eight data words is referred as stack frame. When using floating-point routines, the Cortex-M4 processor automatically stacks the architected floating-point state on exception entry. Stack frame layout with Floating-point Unit or without it The stack frame includes the return address. This is the address of the next instruction in the interrupted program. This value is restored to the PC at exception return so that the interrupted program resumes.","title":"Context Saving on Stack"},{"location":"blog/stm32/swv/","tags":["stm32","debug","swv"],"text":"STM32-Tutorials F411RE_SWV.zip SWV setup Connect a debugger via SWD + SWO interface Override _write() function in the main.c file: /* Debug Exception and Monitor Control Register base address */ #define DEMCR *((volatile uint32_t*) 0xE000EDFCu) /* ITM register addresses */ #define ITM_STIMULUS_PORT0 *((volatile uint32_t*) 0xE0000000u) #define ITM_TRACE_EN *((volatile uint32_t*) 0xE0000E00u) /* Send a char through ITM */ void ITM_SendChar ( uint8_t ch ) { // read FIFO status in bit [0]: while ( ! ( ITM_STIMULUS_PORT0 & 1 )); // write to ITM stimulus port0 ITM_STIMULUS_PORT0 = ch ; } /* Override low-level _write system call */ int _write ( int file , char * ptr , int len ) { int DataIdx ; for ( DataIdx = 0 ; DataIdx < len ; DataIdx ++ ) { ITM_SendChar ( * ptr ++ ); } return len ; } In main function, enable ITM Trace: // Enable TRCENA DEMCR |= ( 1 << 24 ); // Enable stimulus port 0 ITM_TRACE_EN |= ( 1 << 0 ); Use a debugger or a software that can show messages from SWO pin Debugging # There are some debug techniques used to inspect the firmware running on ARM-based MCUs: Semihosting : built-in to every ARM chips, need adding additional library and running in debug mode. Console log : forward to a native UART port , a Virtual COM port through a USB port. Serial Wire View (SWV) : fast output over dedicated Single Wire Output (SWO) pin, but it\u2019s only available on Cortex-M3+, and this is uni-direction communication. Real Time Transfer (RTT) : extremely fast but only work with SEGGER Debugger, can have a real-time bi-direction communication. Ways to print debug Serial Wire Viewer # Cortex-M based microcontrollers integrate some debugging and tracing technologies, including JTAG and SWD. Tracing allows exporting in real-time internal activities performed by the CPU. The Instrumentation Trace MacroCell (ITM) allows sending software-generated debug messages through a specific signal I/O named Serial Wire Output (SWO) . The ITM support is available in Cortex-M3/M4/M7 microcontrollers. The protocol used on the SWO pin to exchange data with the debugger probe is called Serial Wire Viewer (SWV) . Compared to other \u201cdebugging-alike\u201d peripherals like UART/VCOM redirection or the ARM Semihosting , Serial Wire Viewer is really fast. Its communication speed is proportional to the MCU speed. To properly decode the bytes sent over the SWO port, the host debugger needs to know the frequencies of the CPU and SWO port. SWV protocol defines 32 different stimulus ports: a port is a \u201ctag\u201d on the SWV message used to enable/disable messages selectively. These channels allow for separating the diagnostic data into different categories. For instance, ARM recommends channel 0 for text data (e.g., from printf ) and channel 31 for RTOS events, while the other channels can be used for any other purposes. SWV-Supported Debugger Any original ST\u2019s board has an integrated ST-LINK/V2 debugger which supports SWO to trace ITM outputs on Cortex-M3+. That debugger can be used to program and debug an external MCU on other board, or turn into an J-Link debugger. Many ST-LINK clones do not have SWO pin exposed. When open the clone board, the STM32F103 chip is found, which is the same as the chip used in the original ST-LINK. So, the problem of missing SWO can be solved by exporting the SWO pin. ITM Functions # The ITM stimulus registers are standardized by ARM and found on address 0xE0000000 (port 0) through 0xE000007C (port 31). To write data, enable ITM tracing and write data to the corresponding register. The CMSIS-Core package for Cortex-M3/M4/M7 cores provides necessary glue to handle SWV protocol. For example, the ITM_SendChar() routines allows to send a character using the SWO pin. core_cm4.h __STATIC_INLINE int32_t ITM_ReceiveChar ( void ) { int32_t ch = -1 ; /* no character available */ if ( ITM_RxBuffer != ITM_RXBUFFER_EMPTY ) { ch = ITM_RxBuffer ; ITM_RxBuffer = ITM_RXBUFFER_EMPTY ; /* ready for next character */ } return ( ch ); } __STATIC_INLINE uint32_t ITM_SendChar ( uint32_t ch ) { if ((( ITM -> TCR & ITM_TCR_ITMENA_Msk ) != 0UL ) && /* ITM enabled */ (( ITM -> TER & 1UL ) != 0UL )) { /* ITM Port #0 enabled */ while ( ITM -> PORT [ 0U ]. u32 == 0UL ) { __NOP (); } ITM -> PORT [ 0U ]. u8 = ( uint8_t ) ch ; } return ( ch ); } Setup project # Start a new project with STM32F411RE through CubeMX or just an empty project. Take note of the System Clock Frequency , such as 100 MHz , as we need to use it later Debug mode is set to Trace Asynchronous SW at reset, no need to configure this interface Pin map STM32F411RE Description PA13 SWDIO PA14 SWCLK PB3 SWO Override system calls # Standard C libraries GNU ARM libraries use newlib to provide standard implementation of C libraries. To reduce the code size and make it independent to hardware, there is a lightweight version newlib-nano used in MCUs. However, newlib-nano does not provide an implementation of low-level system calls which are used by C standard libraries, such as print() or scan() . To make the application compilable, a new library named nosys should be added. This library just provide a simple implementation of low-level system calls which mostly return a by-pass value. The lib newlib-nano is enabled via linker options --specs=nano.specs , and nosys is enabled via linker option --specs=nosys.specs . These two libraries are included by default in GCC linker options in generated project, check it here . Default system call There is a file syscalls.c containing implementation for standard input/output calls of the system, such as _write() function is used by printf() . That implementation is marked as weak , so we can override them. __attribute__ (( weak )) int _write ( int file , char * ptr , int len ) { int DataIdx ; for ( DataIdx = 0 ; DataIdx < len ; DataIdx ++ ) { __io_putchar ( * ptr ++ ); } return len ; } Redirect to ITM To redirect the output to the ITM, override the _write() function in main.c and replace the call to __io_putchar by ITM_SendChar : main.c #include <stm32f4xx.h> int _write ( int file , char * ptr , int len ) { int DataIdx ; for ( DataIdx = 0 ; DataIdx < len ; DataIdx ++ ) { ITM_SendChar ( * ptr ++ ); } return len ; } Print a counter variable Create a variable char counter = 0 ; and in the main while loop, increase it by 1 and print out its value using standard function printf() every second. char counter = 0 ; int delay ; int main ( void ) { while ( 1 ) { printf ( \"counter = %d \\n \" , counter ++ ); delay = 160000 ; while ( delay ){ delay -- ; } } } SWV Windows # Debugger Configuration : To enable the SWV function, in the Debugger Configuration screen, select below settings: Interface: SWD Serial Wire Viewer: Enable: true Core Clock: should match the real CPU clock in the setup step, such as 100 MHz Setup Debugger to use SWV SWV Windows : The next step is to add SWV Windows into the Debug perspective of IDE. Select Windows \u2192 Show View \u2192 SWV and select one of available windows type. For displaying ITM Print data, select the SWV ITM Data Console window. Add SWV windows Click on the Config icon in the SWV ITM Data Console tab, enable the ITM 0 and apply. Press on the Red button to start reading the SWV data. Configure ITM channel and start reading Resume the execution and observe the text appears on the ITM Data console: counter is printed in the ITM Data Console Inspect variables # The Debug IDE can inspect a variable in real-time using the Live Expression feature. For example, add uwTick to see the instant system time in milliseconds, add counter to show the instant value. Live Expression SWV also has a useful graph mode to monitor variables. Open the SWV Data Trace Timeline Graph and open its configuration to enable Comparator 0 to trace the counter variable. Enable tracing variable in SWV Press on the red button to start reading the SWV data. Resume the execution and observe the data being drawn on the graph: Variable counter is drawn on the graph Trace events # SWV can be used to trace different types of events as it can sample Program Counter (PC) register and access some special registers to calculate some statistics. Trace configuration for SWV Events # CPI \u2014 Cycles per instruction For each cycle beyond the first one that an instruction uses, an internal counter is increased with one. The counter (DWT CPI count) can count up to 256 and is then set to 0. Each time that happens, one of these packets are sent. This is one aspect of the processors performance and used to calculate instructions per seconds. The lower the value, the better the performance. SLEEP \u2014 Sleep cycles The number of cycles the CPU is in sleep mode. Counted in DWT Sleep count register. Each time the CPU has been in sleep mode for 256 cycles, one of these packets is sent. This is used when debugging for power consumption or waiting for external devices. FOLD \u2014 Folded instructions A counter for how many instructions are folded (removed). Every 256 instruction folded (taken zero cycles) will receive one of these events. Counted in DWT Fold count register. Branch folding is a technique where, on the prediction of most branches, the branch instruction is completely removed from the instruction stream presented to the execution pipeline. Branch folding can significantly improve the performance of branches, taking the CPI for branches below 1. EXC \u2014 Exception overhead The DWT Exception count register keeps track of the number of CPU cycles spent in exception overhead. This includes stack operations and returns but not the time spent processing the exception code. When the timer overflows, one of these events is sent. Used to calculate the actual exception handling cost to the program. LSU \u2014 Load Store Unit Cycles The DWT LSU count register counts the total number of cycles the processor is processing an LSU operation beyond the first cycle. When the timer overflows, one of these events is sent. With this measurement, it is possible to track the amount of time spent in memory operations. EXETRC \u2014 Trace Exceptions Whenever an exception occurs, exception entry, exception exit and exception return events are sent. These events can be monitored in the SWV Exception Trace Log view. From this view, it is possible to jump to the exception handler code for that exception. PC Sampling Enabling this starts sampling the Program Counter at some cycle interval. Since the SWO pin has a limited bandwidth, it is not advised to sample to fast. Experiment with the Resolution (cycles/ sample setting) to be able to sample often enough. The results from the sampling are used, among other things, for the SWV Statistical Profiling view. Statistical Profiling # When enable PC Sampling , the IDE can show the amount of execution time spent within various functions. This is useful when optimizing code. When pause the execution, the SWV Statistical Profiling view will display a table with calculated information. Clear the collected data to start a new profiling session. Statistical profiling of function execution Exception Trace # Every event sent when CPU handles an exception will be recorded and these data is used to calculate some information about exceptions. There are two tabs, but the useful information is in the statistic tab. Statistic of exception execution Receive data using scanf In above section, the _write function is overridden to redirect printf to ITM0 . The same method can be applied to override _read function to receive data for the function scanf . int _read ( int file , char * ptr , int len ) { for ( int DataIdx = 0 ; DataIdx < len ; DataIdx ++ ) { * ptr ++ = ITM_ReceiveChar (); } return len ; } However, when compile this code, an error will be raised due to undefined reference to the ITM_RxBuffer . This special variable is left to be defined by Debugger which support SWV input functions, such as Keil ARM. STM32CubeIDE does not support. There are ideas to use either Semihosting or SWD to write data into the ITM_RxBuffer as mentioned in here . SEGGER RTT is well done of utilizing the ARM Debug Access Port (DAP) and background memory access to provide bi-direction communication. Use SWV with other software STM32Cube Programmer Open the SWV tab to see the Viewer. This software also have color syntax to helps displaying log with debug/ warning/ error messages. Show SWV log in STM32Cube Programmer Segger J-Link SWO Viewer If you use J-Link debugger, you can see SWO log with this tool also. J-Link SWO Viewer Export SWO pin # Many ST-LINK clones do not have SWO pin exposed. When open the clone board, the STM32F103 chip is found, which is the same as the chip used in the original ST-LINK. So, the problem of missing SWO can be solved by exporting the SWO pin. ST-LINK/V2 Schematic # The original boards from ST always come with a schematic. Under the tab CAD Resources of the page for the Nucleo-F103 board on ST\u2019s site, the schematic is nucleo_64pins_sch.zip . In the schematic, it is clear that T_SWO line is connected to the pin PA10 (#31) on the STM32F103 chip. Original ST-LINK/V2 with the SWO pin Clone schematic # There is no way to see a schematic of a clone device. Clone hardware modules are marked with MX-LINK label. However, as the schematic for ST-LINK/V2 is public in the board document, it\u2019s expected that the clone uses the exactly same hardware with the original one. The firmware download works well on the clone, so it\u2019s supposed that the hardware is identical, at least in the I/O exporting. People also have found that some cloned devices use STM32F101 instead of STM32F103 , and the pinout maybe LQFP64, not LQFP48. However, thanks to the pin compatibility of STM32, PA10 will still have the same function on variant chips. Wire SWO Pin # One thing apparently clear at the moment is the PA10 (#31) pin can be exposed to the header. Just cut a 5 V pin, and wire the PA10 pin to it. It is better to make it go through a small resister (22 R or 100 R). Write the PA10 pin to the header on a LQFP64 STM32F101","title":"Serial Wire Viewer (SWD + SWO) - fast & native Debugging"},{"location":"blog/stm32/swv/#debugging","text":"There are some debug techniques used to inspect the firmware running on ARM-based MCUs: Semihosting : built-in to every ARM chips, need adding additional library and running in debug mode. Console log : forward to a native UART port , a Virtual COM port through a USB port. Serial Wire View (SWV) : fast output over dedicated Single Wire Output (SWO) pin, but it\u2019s only available on Cortex-M3+, and this is uni-direction communication. Real Time Transfer (RTT) : extremely fast but only work with SEGGER Debugger, can have a real-time bi-direction communication. Ways to print debug","title":"Debugging"},{"location":"blog/stm32/swv/#serial-wire-viewer","text":"Cortex-M based microcontrollers integrate some debugging and tracing technologies, including JTAG and SWD. Tracing allows exporting in real-time internal activities performed by the CPU. The Instrumentation Trace MacroCell (ITM) allows sending software-generated debug messages through a specific signal I/O named Serial Wire Output (SWO) . The ITM support is available in Cortex-M3/M4/M7 microcontrollers. The protocol used on the SWO pin to exchange data with the debugger probe is called Serial Wire Viewer (SWV) . Compared to other \u201cdebugging-alike\u201d peripherals like UART/VCOM redirection or the ARM Semihosting , Serial Wire Viewer is really fast. Its communication speed is proportional to the MCU speed. To properly decode the bytes sent over the SWO port, the host debugger needs to know the frequencies of the CPU and SWO port. SWV protocol defines 32 different stimulus ports: a port is a \u201ctag\u201d on the SWV message used to enable/disable messages selectively. These channels allow for separating the diagnostic data into different categories. For instance, ARM recommends channel 0 for text data (e.g., from printf ) and channel 31 for RTOS events, while the other channels can be used for any other purposes. SWV-Supported Debugger Any original ST\u2019s board has an integrated ST-LINK/V2 debugger which supports SWO to trace ITM outputs on Cortex-M3+. That debugger can be used to program and debug an external MCU on other board, or turn into an J-Link debugger. Many ST-LINK clones do not have SWO pin exposed. When open the clone board, the STM32F103 chip is found, which is the same as the chip used in the original ST-LINK. So, the problem of missing SWO can be solved by exporting the SWO pin.","title":"Serial Wire Viewer"},{"location":"blog/stm32/swv/#itm-functions","text":"The ITM stimulus registers are standardized by ARM and found on address 0xE0000000 (port 0) through 0xE000007C (port 31). To write data, enable ITM tracing and write data to the corresponding register. The CMSIS-Core package for Cortex-M3/M4/M7 cores provides necessary glue to handle SWV protocol. For example, the ITM_SendChar() routines allows to send a character using the SWO pin. core_cm4.h __STATIC_INLINE int32_t ITM_ReceiveChar ( void ) { int32_t ch = -1 ; /* no character available */ if ( ITM_RxBuffer != ITM_RXBUFFER_EMPTY ) { ch = ITM_RxBuffer ; ITM_RxBuffer = ITM_RXBUFFER_EMPTY ; /* ready for next character */ } return ( ch ); } __STATIC_INLINE uint32_t ITM_SendChar ( uint32_t ch ) { if ((( ITM -> TCR & ITM_TCR_ITMENA_Msk ) != 0UL ) && /* ITM enabled */ (( ITM -> TER & 1UL ) != 0UL )) { /* ITM Port #0 enabled */ while ( ITM -> PORT [ 0U ]. u32 == 0UL ) { __NOP (); } ITM -> PORT [ 0U ]. u8 = ( uint8_t ) ch ; } return ( ch ); }","title":"ITM Functions"},{"location":"blog/stm32/swv/#setup-project","text":"Start a new project with STM32F411RE through CubeMX or just an empty project. Take note of the System Clock Frequency , such as 100 MHz , as we need to use it later Debug mode is set to Trace Asynchronous SW at reset, no need to configure this interface Pin map STM32F411RE Description PA13 SWDIO PA14 SWCLK PB3 SWO","title":"Setup project"},{"location":"blog/stm32/swv/#override-system-calls","text":"Standard C libraries GNU ARM libraries use newlib to provide standard implementation of C libraries. To reduce the code size and make it independent to hardware, there is a lightweight version newlib-nano used in MCUs. However, newlib-nano does not provide an implementation of low-level system calls which are used by C standard libraries, such as print() or scan() . To make the application compilable, a new library named nosys should be added. This library just provide a simple implementation of low-level system calls which mostly return a by-pass value. The lib newlib-nano is enabled via linker options --specs=nano.specs , and nosys is enabled via linker option --specs=nosys.specs . These two libraries are included by default in GCC linker options in generated project, check it here . Default system call There is a file syscalls.c containing implementation for standard input/output calls of the system, such as _write() function is used by printf() . That implementation is marked as weak , so we can override them. __attribute__ (( weak )) int _write ( int file , char * ptr , int len ) { int DataIdx ; for ( DataIdx = 0 ; DataIdx < len ; DataIdx ++ ) { __io_putchar ( * ptr ++ ); } return len ; } Redirect to ITM To redirect the output to the ITM, override the _write() function in main.c and replace the call to __io_putchar by ITM_SendChar : main.c #include <stm32f4xx.h> int _write ( int file , char * ptr , int len ) { int DataIdx ; for ( DataIdx = 0 ; DataIdx < len ; DataIdx ++ ) { ITM_SendChar ( * ptr ++ ); } return len ; } Print a counter variable Create a variable char counter = 0 ; and in the main while loop, increase it by 1 and print out its value using standard function printf() every second. char counter = 0 ; int delay ; int main ( void ) { while ( 1 ) { printf ( \"counter = %d \\n \" , counter ++ ); delay = 160000 ; while ( delay ){ delay -- ; } } }","title":"Override system calls"},{"location":"blog/stm32/swv/#swv-windows","text":"Debugger Configuration : To enable the SWV function, in the Debugger Configuration screen, select below settings: Interface: SWD Serial Wire Viewer: Enable: true Core Clock: should match the real CPU clock in the setup step, such as 100 MHz Setup Debugger to use SWV SWV Windows : The next step is to add SWV Windows into the Debug perspective of IDE. Select Windows \u2192 Show View \u2192 SWV and select one of available windows type. For displaying ITM Print data, select the SWV ITM Data Console window. Add SWV windows Click on the Config icon in the SWV ITM Data Console tab, enable the ITM 0 and apply. Press on the Red button to start reading the SWV data. Configure ITM channel and start reading Resume the execution and observe the text appears on the ITM Data console: counter is printed in the ITM Data Console","title":"SWV Windows"},{"location":"blog/stm32/swv/#inspect-variables","text":"The Debug IDE can inspect a variable in real-time using the Live Expression feature. For example, add uwTick to see the instant system time in milliseconds, add counter to show the instant value. Live Expression SWV also has a useful graph mode to monitor variables. Open the SWV Data Trace Timeline Graph and open its configuration to enable Comparator 0 to trace the counter variable. Enable tracing variable in SWV Press on the red button to start reading the SWV data. Resume the execution and observe the data being drawn on the graph: Variable counter is drawn on the graph","title":"Inspect variables"},{"location":"blog/stm32/swv/#trace-events","text":"SWV can be used to trace different types of events as it can sample Program Counter (PC) register and access some special registers to calculate some statistics. Trace configuration for SWV","title":"Trace events"},{"location":"blog/stm32/swv/#events","text":"CPI \u2014 Cycles per instruction For each cycle beyond the first one that an instruction uses, an internal counter is increased with one. The counter (DWT CPI count) can count up to 256 and is then set to 0. Each time that happens, one of these packets are sent. This is one aspect of the processors performance and used to calculate instructions per seconds. The lower the value, the better the performance. SLEEP \u2014 Sleep cycles The number of cycles the CPU is in sleep mode. Counted in DWT Sleep count register. Each time the CPU has been in sleep mode for 256 cycles, one of these packets is sent. This is used when debugging for power consumption or waiting for external devices. FOLD \u2014 Folded instructions A counter for how many instructions are folded (removed). Every 256 instruction folded (taken zero cycles) will receive one of these events. Counted in DWT Fold count register. Branch folding is a technique where, on the prediction of most branches, the branch instruction is completely removed from the instruction stream presented to the execution pipeline. Branch folding can significantly improve the performance of branches, taking the CPI for branches below 1. EXC \u2014 Exception overhead The DWT Exception count register keeps track of the number of CPU cycles spent in exception overhead. This includes stack operations and returns but not the time spent processing the exception code. When the timer overflows, one of these events is sent. Used to calculate the actual exception handling cost to the program. LSU \u2014 Load Store Unit Cycles The DWT LSU count register counts the total number of cycles the processor is processing an LSU operation beyond the first cycle. When the timer overflows, one of these events is sent. With this measurement, it is possible to track the amount of time spent in memory operations. EXETRC \u2014 Trace Exceptions Whenever an exception occurs, exception entry, exception exit and exception return events are sent. These events can be monitored in the SWV Exception Trace Log view. From this view, it is possible to jump to the exception handler code for that exception. PC Sampling Enabling this starts sampling the Program Counter at some cycle interval. Since the SWO pin has a limited bandwidth, it is not advised to sample to fast. Experiment with the Resolution (cycles/ sample setting) to be able to sample often enough. The results from the sampling are used, among other things, for the SWV Statistical Profiling view.","title":"Events"},{"location":"blog/stm32/swv/#statistical-profiling","text":"When enable PC Sampling , the IDE can show the amount of execution time spent within various functions. This is useful when optimizing code. When pause the execution, the SWV Statistical Profiling view will display a table with calculated information. Clear the collected data to start a new profiling session. Statistical profiling of function execution","title":"Statistical Profiling"},{"location":"blog/stm32/swv/#exception-trace","text":"Every event sent when CPU handles an exception will be recorded and these data is used to calculate some information about exceptions. There are two tabs, but the useful information is in the statistic tab. Statistic of exception execution Receive data using scanf In above section, the _write function is overridden to redirect printf to ITM0 . The same method can be applied to override _read function to receive data for the function scanf . int _read ( int file , char * ptr , int len ) { for ( int DataIdx = 0 ; DataIdx < len ; DataIdx ++ ) { * ptr ++ = ITM_ReceiveChar (); } return len ; } However, when compile this code, an error will be raised due to undefined reference to the ITM_RxBuffer . This special variable is left to be defined by Debugger which support SWV input functions, such as Keil ARM. STM32CubeIDE does not support. There are ideas to use either Semihosting or SWD to write data into the ITM_RxBuffer as mentioned in here . SEGGER RTT is well done of utilizing the ARM Debug Access Port (DAP) and background memory access to provide bi-direction communication. Use SWV with other software STM32Cube Programmer Open the SWV tab to see the Viewer. This software also have color syntax to helps displaying log with debug/ warning/ error messages. Show SWV log in STM32Cube Programmer Segger J-Link SWO Viewer If you use J-Link debugger, you can see SWO log with this tool also. J-Link SWO Viewer","title":"Exception Trace"},{"location":"blog/stm32/swv/#export-swo-pin","text":"Many ST-LINK clones do not have SWO pin exposed. When open the clone board, the STM32F103 chip is found, which is the same as the chip used in the original ST-LINK. So, the problem of missing SWO can be solved by exporting the SWO pin.","title":"Export SWO pin"},{"location":"blog/stm32/swv/#st-linkv2-schematic","text":"The original boards from ST always come with a schematic. Under the tab CAD Resources of the page for the Nucleo-F103 board on ST\u2019s site, the schematic is nucleo_64pins_sch.zip . In the schematic, it is clear that T_SWO line is connected to the pin PA10 (#31) on the STM32F103 chip. Original ST-LINK/V2 with the SWO pin","title":"ST-LINK/V2 Schematic"},{"location":"blog/stm32/swv/#clone-schematic","text":"There is no way to see a schematic of a clone device. Clone hardware modules are marked with MX-LINK label. However, as the schematic for ST-LINK/V2 is public in the board document, it\u2019s expected that the clone uses the exactly same hardware with the original one. The firmware download works well on the clone, so it\u2019s supposed that the hardware is identical, at least in the I/O exporting. People also have found that some cloned devices use STM32F101 instead of STM32F103 , and the pinout maybe LQFP64, not LQFP48. However, thanks to the pin compatibility of STM32, PA10 will still have the same function on variant chips.","title":"Clone schematic"},{"location":"blog/stm32/swv/#wire-swo-pin","text":"One thing apparently clear at the moment is the PA10 (#31) pin can be exposed to the header. Just cut a 5 V pin, and wire the PA10 pin to it. It is better to make it go through a small resister (22 R or 100 R). Write the PA10 pin to the header on a LQFP64 STM32F101","title":"Wire SWO Pin"},{"location":"blog/stm32/system-call-exception/","tags":["arm","stm32","asm"],"text":"STM32-Tutorials F411RE_SVC_Handler.zip System-level Services # On an Operating System, tasks are work that can be handler in parallel. User Tasks usually are assigned to run in Unprivileged level, while System Tasks are running in Privileged level. Many resources are protected by OS Kernel (by Memory Management/Protection Unit), and Unprivileged tasks can not access them. Supervisor Call (SVC) exception allows User Task to request Privileged operations or access to system resource Pendable Service Call (PendSV) exception allows Operating System to carry out Context Switching between tasks when no other exceptions are active Exception Number IRQ Number Exception Type Priority Function 11 -5 SVCall Configurable System Service Call when call SVC instruction 12 Debug Configurable Debug monitor (via SWD) 13 Reserved \u2014 Reserved 14 -2 PendSV Configurable For context switching in an OS 15 -1 SysTick Configurable System Timer Supervisor Call (SVC) # The SVC Handler executes right after the SVC instruction is executed, unless there is a higher priority exception arrives at the same time. SVC instruction is always used along with a number, which can be used to identify the request type. __asm volatile ( \"SVC #0\" ); // call SVC 0 The OS will have a lookup table of SVC numbers and call to the corresponding handler of the request number. Example of using Supervisor Call to access to a protected memory Extract the SVC Number # The declaration of void SVC_Handler(void) does not accept any parameter, however, SVC Handler needs to know its SVC number. In the SVC Handler, we have to fetch the opcode of the SVC instruction and extract the SVC number. To fetch the opcode, we need to know the address of that instruction. When an exception occurs, processor automatically saves the Stack Frame which has the address of next instruction of the SVC instruction in PC slot. We can go back that address, and get the opcode easily. A normal function call always has Prologue and Epilogue sequences added by compiler. In the Prologue, some line of code is added to prepare the stack for the function. However, that action will change the Stack Pointer value. Therefore, a naked function should be used to keep the Stack Pointer value. SVC Call in Main Stack Example code to analyze the Stack Frame and find Opcode: __attribute__ (( naked )) void SVC_Handler ( void ) { __asm volatile ( \"MRS R0, MSP\" ); } int main ( void ) { __asm volatile ( \"SVC #6\" ); /* Loop forever */ for (;;); } We find out the MSP is at 0x2001ffd8 which stores the R0 register, go back 6 stack slots, we have the PC with value 0x080001E4 which is the next instruction at 0x080001E2: SVC 6 with the opcode 06df . To extract the opcode, we can do use a pointer type of byte as below: __attribute__ (( naked )) void SVC_Handler ( void ) { __asm volatile ( \"MRS R0, MSP\" ); // save MSP stack pointer value __asm volatile ( \"B SVC_Handler_main\" ); // pass R0 as the argument } void SVC_Handler_main ( uint32_t * pMSP ) { // get the address of the instruction saved in PC uint8_t * pInstruction = ( uint8_t * )( pMSP [ 6 ]); // go back 2 bytes (16-bit opcode) pInstruction -= 2 ; // get the opcode, in little endian uint8_t svc_num = * pInstruction ; switch ( svc_num ) { default : break ; } } SVC Call in Process Stack When Process Stack is used for user code, the Stack Frame is saved to Process Stack, then the processor will automatically switch to Main Stack. On an ARM Cortex M series device, the link register ( LR or R14 ) is a core register that stores the return address, such as when making a function call. In the case of an exception, the return address is pushed onto the stack by hardware and the LR is set to EXC_RETURN ( 0xFFFFFFF1 , 0xFFFFFFF9 , or 0xFFFFFFFD ). When debugging exceptions such as hard faults, reading the LR is necessary to determine which stack pointer was used when the exception occurred. We will test the bit[2] of the LR value to see if it is 1 then PSP is used. EXC_RETURN Description 0xFFFFFFF1 Return to Handler mode. Exception return gets state from the main stack. Execution uses MSP after return. 0xFFFFFFF9 Return to Thread mode. Exception Return get state from the main stack. Execution uses MSP after return. 0xFFFFFFFD Return to Thread mode. Exception return gets state from the process stack. Execution uses PSP after return. All other values Reserved. Example code to analyze the Stack Frame and find Opcode: *.ld ENTRY ( Reset_Handler ) _estack = ORIGIN ( RAM ) + LENGTH ( RAM ); /* end of \"RAM\" Ram type memory */ _Min_Heap_Size = 0x200 ; /* required amount of heap */ _Min_Stack_Size = 0x400 ; /* required amount of stack */ _psp_stack = _estack - _Min_Stack_Size / 2 ; __attribute__ (( naked )) void changeStackToPSP ( void ) { // change PSP __asm volatile ( \"LDR R0, =_psp_stack\" ); __asm volatile ( \"MSR PSP, R0\" ); // set SPSEL bit __asm volatile ( \"MRS R1, CONTROL\" ); __asm volatile ( \"ORR R1, R1, #2\" ); __asm volatile ( \"MSR CONTROL, R1\" ); // return __asm volatile ( \"BX LR\" ); } __attribute__ (( naked )) void SVC_Handler ( void ) { __asm volatile ( \"MRS R0, MSP\" ); __asm volatile ( \"MRS R1, PSP\" ); } int main ( void ) { changeStackToPSP (); __asm volatile ( \"SVC #6\" ); /* Loop forever */ for (;;); } In case of using Process Stack, the LR value is 0xFFFFFFFD , we will use PSP to trace back to the SVC Opcode. Complete code of extracting SVC number __attribute__ (( naked )) void SVC_Handler ( void ) { __asm volatile ( \"TST LR, 4\" ); // check LR to know which stack is used __asm volatile ( \"ITE EQ\" ); // 2 next instructions are conditional __asm volatile ( \"MRSEQ R0, MSP\" ); // save MSP if bit 2 is 0 __asm volatile ( \"MRSNE R0, PSP\" ); // save PSP if bit 2 is 1 __asm volatile ( \"B SVC_Handler_main\" ); // pass R0 as the argument } void SVC_Handler_main ( uint32_t * SP ) { // get the address of the instruction saved in PC uint8_t * pInstruction = ( uint8_t * )( SP [ 6 ]); // go back 2 bytes (16-bit opcode) pInstruction -= 2 ; // get the opcode, in little endian uint8_t svc_num = * pInstruction ; switch ( svc_num ) { } } Return value from SVC # The Procedure Call Standard for Arm Architecture has defined that: The general-purpose registers R0 - R3 are used to pass arguments to a function and also return values . Those registers are pushed on the stack when function enters, and then popped back to registers when function exits. We have the Stack Frame pointer, so we can read or write to the stack slot of those registers. int main ( void ) { int x = add ( 20 , 10 ); // save 20 and 10 to R0, R1 } int32_t add ( int32_t x , int32_t y ) { int32_t result ; // call SVC __asm volatile ( \"SVC #0\" ); // R0, R1 are saved into stack // copy returned value from R0 to variable __asm volatile ( \"MOV %0, R0\" : \"=r\" ( result )); // return return result ; } void SVC_Handler_main ( uint32_t * SP ) { ... switch ( svc_num ) { case 0 : // add { int32_t x = SP [ 0 ]; // Argument 0 at R0 saved at MSP int32_t y = SP [ 1 ]; // Argument 1 at R1 saved at MSP+1 int32_t z = x + y ; SP [ 0 ] = z ; // Return value saved back to R0 at MSP } ... Example # In this example, we will create 4 system calls: add , sub , mul and div . The user application run in unprivileged level will call to SVC 0 to SVC 3 to execute the corresponding system call and get the result. The below code runs the application in Thread Mode using Process Stack with Unprivileged Access. SVC Handler will run in Handler Mode using Main Stack with Privileged Access. #include <stdint.h> #include <stdio.h> /* ITM register addresses */ #define ITM_STIMULUS_PORT0 *((volatile uint32_t*) 0xE0000000 ) /* Send a char through ITM */ void ITM_SendChar ( uint8_t ch ) { // read FIFO status in bit [0]: while ( ! ( ITM_STIMULUS_PORT0 & 1 )); //Write to ITM stimulus port0 ITM_STIMULUS_PORT0 = ch ; } /* Override low-level _write system call */ int _write ( int file , char * ptr , int len ) { int DataIdx ; for ( DataIdx = 0 ; DataIdx < len ; DataIdx ++ ) { ITM_SendChar ( * ptr ++ ); } return len ; } __attribute__ (( naked )) void changeStackToPSP ( void ) { // change PSP __asm volatile ( \"LDR R0, =_psp_stack\" ); __asm volatile ( \"MSR PSP, R0\" ); // set SPSEL bit __asm volatile ( \"MRS R1, CONTROL\" ); __asm volatile ( \"ORR R1, R1, #2\" ); __asm volatile ( \"MSR CONTROL, R1\" ); // return __asm volatile ( \"BX LR\" ); } __attribute__ (( naked )) void changeAccessToUnprivileged ( void ) { // set nPRIV bit __asm volatile ( \"MRS R0, CONTROL\" ); __asm volatile ( \"ORR R0, R0, #1\" ); __asm volatile ( \"MSR CONTROL, r0\" ); // return __asm volatile ( \"BX LR\" ); } /* SVC Number Table * 0: Add * 1: Sub * 2: Mul * 3: Div */ int32_t add ( int32_t x , int32_t y ) { int32_t result ; // call SVC __asm volatile ( \"SVC #0\" ); // copy returned value from R0 to variable __asm volatile ( \"MOV %0, R0\" : \"=r\" ( result )); // return return result ; } int32_t sub ( int32_t x , int32_t y ) { int32_t result ; __asm volatile ( \"SVC #1\" ); __asm volatile ( \"MOV %0, R0\" : \"=r\" ( result )); return result ; } int32_t mul ( int32_t x , int32_t y ) { int32_t result ; __asm volatile ( \"SVC #2\" ); __asm volatile ( \"MOV %0, R0\" : \"=r\" ( result )); return result ; } int32_t div ( int32_t x , int32_t y ) { int32_t result ; __asm volatile ( \"SVC #3\" ); __asm volatile ( \"MOV %0, R0\" : \"=r\" ( result )); return result ; } __attribute__ (( naked )) void SVC_Handler ( void ) { __asm volatile ( \"TST LR, 4\" ); // check LR to know which stack is used __asm volatile ( \"ITE EQ\" ); // 2 next instructions are conditional __asm volatile ( \"MRSEQ R0, MSP\" ); // save MSP if bit 2 is 0 __asm volatile ( \"MRSNE R0, PSP\" ); // save PSP if bit 2 is 1 __asm volatile ( \"B SVC_Handler_main\" ); // pass R0 as the argument } void SVC_Handler_main ( uint32_t * SP ) { // get the address of the instruction saved in PC uint8_t * pInstruction = ( uint8_t * )( SP [ 6 ]); // go back 2 bytes (16-bit opcode) pInstruction -= 2 ; // get the opcode, in little endian uint8_t svc_num = * pInstruction ; switch ( svc_num ) { case 0 : // add { int32_t x = SP [ 0 ]; // Argument 0 at R0 saved at SP int32_t y = SP [ 1 ]; // Argument 1 at R1 saved at SP+1 int32_t z = x + y ; SP [ 0 ] = z ; // Return value saved back to R0 at SP } break ; case 1 : // sub SP [ 0 ] = SP [ 0 ] - SP [ 1 ]; break ; case 2 : // mul SP [ 0 ] = SP [ 0 ] * SP [ 1 ]; break ; case 3 : // div SP [ 0 ] = SP [ 0 ] / SP [ 1 ]; break ; default : printf ( \"Invalid SVC number: %d!!! \\n \" , svc_num ); break ; } } int main ( void ) { changeStackToPSP (); changeAccessToUnprivileged (); int32_t x ; x = add ( 20 , 10 ); printf ( \"20 + 10 = %ld \\n \" , x ); x = sub ( 20 , 10 ); printf ( \"20 - 10 = %ld \\n \" , x ); x = mul ( 20 , 10 ); printf ( \"20 * 10 = %ld \\n \" , x ); x = div ( 20 , 10 ); printf ( \"20 / 10 = %ld \\n \" , x ); __asm volatile ( \"SVC #6\" ); /* Loop forever */ for (;;); } Run with SWV enabled to see the output: Example of using SVC System Calls in a Restricted Application SysTick # SysTick is simply a timer present inside ARM based microcontrollers. Basic purpose is to generate accurate periodical interrupts. In non-OS environment, SysTick is used in delay function, or to do some tasks periodically (like toggling LED, generating PWM). In OS environment, SysTick triggers the Scheduler to switch to other tasks. Each task is allowed to run in a time-slice. When the time slot is expired, the Scheduler is called to switch a next task. There is a case that an interrupt handler is executing, but the Scheduler switches to new task, the operation mode of processor is changed from Handler mode to Thread mode. This causes Usage Fault exception. Context Switching without PendSV may cause Usage Fault Pendable Service Call (PendSV) # This PendSV exception is triggered by setting its pending status in the Interrupt Control and State Register of the processor. This exception is a way of invoking the preemptive kernel to carry out the context switching in an Operating System. In OS, PendSV is set to the lowest priority level, therefore, all IRQ are executed before a scheduled context can run. SysTick handler only runs the Scheduler to select the next task which will be run, then turns on PendSV pending bit. Therefore, the Context Switching will be done in PendSV Handler after there is no Interrupt handler in active state. Context Switching with PendSV ensures ISRs can complete The PendSV can be used to offloading a heavy ISR. For example, ISR0 can be divided to 2 parts: The first part handles critical actions, then sets PendSV to handle the second part which consumes much more time. By this way, the first part is handled immediately, and the second part still allows other IRQs get served. That means, the ISR0 does not block other IRQs. Offloading a heavy ISR","title":"Exceptions for System-level Services"},{"location":"blog/stm32/system-call-exception/#system-level-services","text":"On an Operating System, tasks are work that can be handler in parallel. User Tasks usually are assigned to run in Unprivileged level, while System Tasks are running in Privileged level. Many resources are protected by OS Kernel (by Memory Management/Protection Unit), and Unprivileged tasks can not access them. Supervisor Call (SVC) exception allows User Task to request Privileged operations or access to system resource Pendable Service Call (PendSV) exception allows Operating System to carry out Context Switching between tasks when no other exceptions are active Exception Number IRQ Number Exception Type Priority Function 11 -5 SVCall Configurable System Service Call when call SVC instruction 12 Debug Configurable Debug monitor (via SWD) 13 Reserved \u2014 Reserved 14 -2 PendSV Configurable For context switching in an OS 15 -1 SysTick Configurable System Timer","title":"System-level Services"},{"location":"blog/stm32/system-call-exception/#supervisor-call-svc","text":"The SVC Handler executes right after the SVC instruction is executed, unless there is a higher priority exception arrives at the same time. SVC instruction is always used along with a number, which can be used to identify the request type. __asm volatile ( \"SVC #0\" ); // call SVC 0 The OS will have a lookup table of SVC numbers and call to the corresponding handler of the request number. Example of using Supervisor Call to access to a protected memory","title":"Supervisor Call (SVC)"},{"location":"blog/stm32/system-call-exception/#extract-the-svc-number","text":"The declaration of void SVC_Handler(void) does not accept any parameter, however, SVC Handler needs to know its SVC number. In the SVC Handler, we have to fetch the opcode of the SVC instruction and extract the SVC number. To fetch the opcode, we need to know the address of that instruction. When an exception occurs, processor automatically saves the Stack Frame which has the address of next instruction of the SVC instruction in PC slot. We can go back that address, and get the opcode easily. A normal function call always has Prologue and Epilogue sequences added by compiler. In the Prologue, some line of code is added to prepare the stack for the function. However, that action will change the Stack Pointer value. Therefore, a naked function should be used to keep the Stack Pointer value. SVC Call in Main Stack Example code to analyze the Stack Frame and find Opcode: __attribute__ (( naked )) void SVC_Handler ( void ) { __asm volatile ( \"MRS R0, MSP\" ); } int main ( void ) { __asm volatile ( \"SVC #6\" ); /* Loop forever */ for (;;); } We find out the MSP is at 0x2001ffd8 which stores the R0 register, go back 6 stack slots, we have the PC with value 0x080001E4 which is the next instruction at 0x080001E2: SVC 6 with the opcode 06df . To extract the opcode, we can do use a pointer type of byte as below: __attribute__ (( naked )) void SVC_Handler ( void ) { __asm volatile ( \"MRS R0, MSP\" ); // save MSP stack pointer value __asm volatile ( \"B SVC_Handler_main\" ); // pass R0 as the argument } void SVC_Handler_main ( uint32_t * pMSP ) { // get the address of the instruction saved in PC uint8_t * pInstruction = ( uint8_t * )( pMSP [ 6 ]); // go back 2 bytes (16-bit opcode) pInstruction -= 2 ; // get the opcode, in little endian uint8_t svc_num = * pInstruction ; switch ( svc_num ) { default : break ; } } SVC Call in Process Stack When Process Stack is used for user code, the Stack Frame is saved to Process Stack, then the processor will automatically switch to Main Stack. On an ARM Cortex M series device, the link register ( LR or R14 ) is a core register that stores the return address, such as when making a function call. In the case of an exception, the return address is pushed onto the stack by hardware and the LR is set to EXC_RETURN ( 0xFFFFFFF1 , 0xFFFFFFF9 , or 0xFFFFFFFD ). When debugging exceptions such as hard faults, reading the LR is necessary to determine which stack pointer was used when the exception occurred. We will test the bit[2] of the LR value to see if it is 1 then PSP is used. EXC_RETURN Description 0xFFFFFFF1 Return to Handler mode. Exception return gets state from the main stack. Execution uses MSP after return. 0xFFFFFFF9 Return to Thread mode. Exception Return get state from the main stack. Execution uses MSP after return. 0xFFFFFFFD Return to Thread mode. Exception return gets state from the process stack. Execution uses PSP after return. All other values Reserved. Example code to analyze the Stack Frame and find Opcode: *.ld ENTRY ( Reset_Handler ) _estack = ORIGIN ( RAM ) + LENGTH ( RAM ); /* end of \"RAM\" Ram type memory */ _Min_Heap_Size = 0x200 ; /* required amount of heap */ _Min_Stack_Size = 0x400 ; /* required amount of stack */ _psp_stack = _estack - _Min_Stack_Size / 2 ; __attribute__ (( naked )) void changeStackToPSP ( void ) { // change PSP __asm volatile ( \"LDR R0, =_psp_stack\" ); __asm volatile ( \"MSR PSP, R0\" ); // set SPSEL bit __asm volatile ( \"MRS R1, CONTROL\" ); __asm volatile ( \"ORR R1, R1, #2\" ); __asm volatile ( \"MSR CONTROL, R1\" ); // return __asm volatile ( \"BX LR\" ); } __attribute__ (( naked )) void SVC_Handler ( void ) { __asm volatile ( \"MRS R0, MSP\" ); __asm volatile ( \"MRS R1, PSP\" ); } int main ( void ) { changeStackToPSP (); __asm volatile ( \"SVC #6\" ); /* Loop forever */ for (;;); } In case of using Process Stack, the LR value is 0xFFFFFFFD , we will use PSP to trace back to the SVC Opcode. Complete code of extracting SVC number __attribute__ (( naked )) void SVC_Handler ( void ) { __asm volatile ( \"TST LR, 4\" ); // check LR to know which stack is used __asm volatile ( \"ITE EQ\" ); // 2 next instructions are conditional __asm volatile ( \"MRSEQ R0, MSP\" ); // save MSP if bit 2 is 0 __asm volatile ( \"MRSNE R0, PSP\" ); // save PSP if bit 2 is 1 __asm volatile ( \"B SVC_Handler_main\" ); // pass R0 as the argument } void SVC_Handler_main ( uint32_t * SP ) { // get the address of the instruction saved in PC uint8_t * pInstruction = ( uint8_t * )( SP [ 6 ]); // go back 2 bytes (16-bit opcode) pInstruction -= 2 ; // get the opcode, in little endian uint8_t svc_num = * pInstruction ; switch ( svc_num ) { } }","title":"Extract the SVC Number"},{"location":"blog/stm32/system-call-exception/#return-value-from-svc","text":"The Procedure Call Standard for Arm Architecture has defined that: The general-purpose registers R0 - R3 are used to pass arguments to a function and also return values . Those registers are pushed on the stack when function enters, and then popped back to registers when function exits. We have the Stack Frame pointer, so we can read or write to the stack slot of those registers. int main ( void ) { int x = add ( 20 , 10 ); // save 20 and 10 to R0, R1 } int32_t add ( int32_t x , int32_t y ) { int32_t result ; // call SVC __asm volatile ( \"SVC #0\" ); // R0, R1 are saved into stack // copy returned value from R0 to variable __asm volatile ( \"MOV %0, R0\" : \"=r\" ( result )); // return return result ; } void SVC_Handler_main ( uint32_t * SP ) { ... switch ( svc_num ) { case 0 : // add { int32_t x = SP [ 0 ]; // Argument 0 at R0 saved at MSP int32_t y = SP [ 1 ]; // Argument 1 at R1 saved at MSP+1 int32_t z = x + y ; SP [ 0 ] = z ; // Return value saved back to R0 at MSP } ...","title":"Return value from SVC"},{"location":"blog/stm32/system-call-exception/#example","text":"In this example, we will create 4 system calls: add , sub , mul and div . The user application run in unprivileged level will call to SVC 0 to SVC 3 to execute the corresponding system call and get the result. The below code runs the application in Thread Mode using Process Stack with Unprivileged Access. SVC Handler will run in Handler Mode using Main Stack with Privileged Access. #include <stdint.h> #include <stdio.h> /* ITM register addresses */ #define ITM_STIMULUS_PORT0 *((volatile uint32_t*) 0xE0000000 ) /* Send a char through ITM */ void ITM_SendChar ( uint8_t ch ) { // read FIFO status in bit [0]: while ( ! ( ITM_STIMULUS_PORT0 & 1 )); //Write to ITM stimulus port0 ITM_STIMULUS_PORT0 = ch ; } /* Override low-level _write system call */ int _write ( int file , char * ptr , int len ) { int DataIdx ; for ( DataIdx = 0 ; DataIdx < len ; DataIdx ++ ) { ITM_SendChar ( * ptr ++ ); } return len ; } __attribute__ (( naked )) void changeStackToPSP ( void ) { // change PSP __asm volatile ( \"LDR R0, =_psp_stack\" ); __asm volatile ( \"MSR PSP, R0\" ); // set SPSEL bit __asm volatile ( \"MRS R1, CONTROL\" ); __asm volatile ( \"ORR R1, R1, #2\" ); __asm volatile ( \"MSR CONTROL, R1\" ); // return __asm volatile ( \"BX LR\" ); } __attribute__ (( naked )) void changeAccessToUnprivileged ( void ) { // set nPRIV bit __asm volatile ( \"MRS R0, CONTROL\" ); __asm volatile ( \"ORR R0, R0, #1\" ); __asm volatile ( \"MSR CONTROL, r0\" ); // return __asm volatile ( \"BX LR\" ); } /* SVC Number Table * 0: Add * 1: Sub * 2: Mul * 3: Div */ int32_t add ( int32_t x , int32_t y ) { int32_t result ; // call SVC __asm volatile ( \"SVC #0\" ); // copy returned value from R0 to variable __asm volatile ( \"MOV %0, R0\" : \"=r\" ( result )); // return return result ; } int32_t sub ( int32_t x , int32_t y ) { int32_t result ; __asm volatile ( \"SVC #1\" ); __asm volatile ( \"MOV %0, R0\" : \"=r\" ( result )); return result ; } int32_t mul ( int32_t x , int32_t y ) { int32_t result ; __asm volatile ( \"SVC #2\" ); __asm volatile ( \"MOV %0, R0\" : \"=r\" ( result )); return result ; } int32_t div ( int32_t x , int32_t y ) { int32_t result ; __asm volatile ( \"SVC #3\" ); __asm volatile ( \"MOV %0, R0\" : \"=r\" ( result )); return result ; } __attribute__ (( naked )) void SVC_Handler ( void ) { __asm volatile ( \"TST LR, 4\" ); // check LR to know which stack is used __asm volatile ( \"ITE EQ\" ); // 2 next instructions are conditional __asm volatile ( \"MRSEQ R0, MSP\" ); // save MSP if bit 2 is 0 __asm volatile ( \"MRSNE R0, PSP\" ); // save PSP if bit 2 is 1 __asm volatile ( \"B SVC_Handler_main\" ); // pass R0 as the argument } void SVC_Handler_main ( uint32_t * SP ) { // get the address of the instruction saved in PC uint8_t * pInstruction = ( uint8_t * )( SP [ 6 ]); // go back 2 bytes (16-bit opcode) pInstruction -= 2 ; // get the opcode, in little endian uint8_t svc_num = * pInstruction ; switch ( svc_num ) { case 0 : // add { int32_t x = SP [ 0 ]; // Argument 0 at R0 saved at SP int32_t y = SP [ 1 ]; // Argument 1 at R1 saved at SP+1 int32_t z = x + y ; SP [ 0 ] = z ; // Return value saved back to R0 at SP } break ; case 1 : // sub SP [ 0 ] = SP [ 0 ] - SP [ 1 ]; break ; case 2 : // mul SP [ 0 ] = SP [ 0 ] * SP [ 1 ]; break ; case 3 : // div SP [ 0 ] = SP [ 0 ] / SP [ 1 ]; break ; default : printf ( \"Invalid SVC number: %d!!! \\n \" , svc_num ); break ; } } int main ( void ) { changeStackToPSP (); changeAccessToUnprivileged (); int32_t x ; x = add ( 20 , 10 ); printf ( \"20 + 10 = %ld \\n \" , x ); x = sub ( 20 , 10 ); printf ( \"20 - 10 = %ld \\n \" , x ); x = mul ( 20 , 10 ); printf ( \"20 * 10 = %ld \\n \" , x ); x = div ( 20 , 10 ); printf ( \"20 / 10 = %ld \\n \" , x ); __asm volatile ( \"SVC #6\" ); /* Loop forever */ for (;;); } Run with SWV enabled to see the output: Example of using SVC System Calls in a Restricted Application","title":"Example"},{"location":"blog/stm32/system-call-exception/#systick","text":"SysTick is simply a timer present inside ARM based microcontrollers. Basic purpose is to generate accurate periodical interrupts. In non-OS environment, SysTick is used in delay function, or to do some tasks periodically (like toggling LED, generating PWM). In OS environment, SysTick triggers the Scheduler to switch to other tasks. Each task is allowed to run in a time-slice. When the time slot is expired, the Scheduler is called to switch a next task. There is a case that an interrupt handler is executing, but the Scheduler switches to new task, the operation mode of processor is changed from Handler mode to Thread mode. This causes Usage Fault exception. Context Switching without PendSV may cause Usage Fault","title":"SysTick"},{"location":"blog/stm32/system-call-exception/#pendable-service-call-pendsv","text":"This PendSV exception is triggered by setting its pending status in the Interrupt Control and State Register of the processor. This exception is a way of invoking the preemptive kernel to carry out the context switching in an Operating System. In OS, PendSV is set to the lowest priority level, therefore, all IRQ are executed before a scheduled context can run. SysTick handler only runs the Scheduler to select the next task which will be run, then turns on PendSV pending bit. Therefore, the Context Switching will be done in PendSV Handler after there is no Interrupt handler in active state. Context Switching with PendSV ensures ISRs can complete The PendSV can be used to offloading a heavy ISR. For example, ISR0 can be divided to 2 parts: The first part handles critical actions, then sets PendSV to handle the second part which consumes much more time. By this way, the first part is handled immediately, and the second part still allows other IRQs get served. That means, the ISR0 does not block other IRQs. Offloading a heavy ISR","title":"Pendable Service Call (PendSV)"},{"location":"blog/stm32/task-scheduler/","tags":["arm","stm32","asm"],"text":"STM32-Tutorials F411RE_Task_Scheduler.zip F411RE_Task_Scheduler_PendSV.zip Task # A Task is a piece of code, or a function, that does a specific job when it is allowed to run. A Task has its own Stack to create its local variables. Its stack can be used to store addition information which is needed to save or restore the task from running state. Usually, a task is an infinite loop which can repeatedly do multiple steps. void task_main ( void * param ) { // init task ... // main loop while ( 1 ) { // do things over and over } } Scheduler # Round-Robin scheduling method is the time slices assigned to each task are equal , and all tasks are done in a circular order . The time slice is defined by a special timer - SysTick which is a free-run timer to produce a periodical interrupt. In the SysTick Handler , we will to the context switching to move to a next task. There are some others steps to initialize a scheduler: Steps to run a Scheduler Task Table # Task Table is the place to store information of all tasks. Because each task should have its own stack to save its local variable, the task table must include the PSP values which point to the current stack pointer of each task. The scheduler also needs to know which task is currently running to do save/ restore stack to the corresponding task. Here is a minimal Task Table implementation, without using struct: #define TASK_NUMBER_MAX (16) uint32_t __uCurrentTaskIdx = 0 ; uint32_t __puTasksPSP [ TASK_NUMBER_MAX ] = { 0 }; The helper functions to access to the Task Table: // return PSP value stored in slot at __uCurrentTaskIdx index uint32_t get_current_psp () { return __puTasksPSP [ __uCurrentTaskIdx ]; } // save PSP value to the slot at __uCurrentTaskIdx index void save_current_psp ( uint32_t psp ) { __puTasksPSP [ __uCurrentTaskIdx ] = psp ; } Add a Task # We need to set how much RAM is reserved for a Task Stack. Let say 1 KB. The RAM space for Tasks should not overlap the Main Stack because Handler mode always use the Main Stack. #define RAM_START (0x20000000u) #define RAM_SIZE (128 * 1024) // 128 KB #define MAIN_STACK (RAM_START + RAM_SIZE) #define TASK_STACK_SIZE (1024u) For the i -th task, the beginning Stack address should be: uint32_t * psp = ( uint32_t * )( MAIN_STACK - ( i + 1 ) * TASK_STACK_SIZE ); Structure of Scheduler and Task Stack Set Task Stack # When adding a task, we initialize the PSP value of the new task at the start address of new 1 KB RAM. We reserve 1 KB for Main Stack, then every 1 KB for a new task. The Task Table will be filled a new slot when a new task is added. void init_task ( void ( * handler )) { int i = 0 ; // find an empty slot for (; i < TASK_NUMBER_MAX ; i ++ ) { if ( __puTasksPSP [ i ] == 0 ) break ; } if ( i >= TASK_NUMBER_MAX ) { printf ( \"Can not register a new task anymore! \\n \" ); return ; } else { printf ( \"Register a task %p at slot %i \\n \" , handler , i ); } // calculate new PSP uint32_t * psp = ( uint32_t * )( MAIN_STACK - ( i + 1 ) * TASK_STACK_SIZE ); // fill stack frame ... Fill Stack Frame # When a task is switched in (load and run), the CPU will use PSP pointer to find below information: Last CPU status \u2192 Load xPSR register Next instruction to be executed \u2192 Load PC register Return mode \u2192 Load LR register Last execution status \u2192 Load all R0 to R12 registers As we use the SysTick exception to trigger Context Switching, the below registers are automatically saved at exception: xPSR , PC , LR , R12 , R3 to R0 , in fixed order Therefore, we will prepare additional registers in the order R11 to R4 . What are the value of those registers??? xPSR = 0x01000000 : no special status should be set at initial stage of a task, except the Thumb State bit must be set PC = task\u2019 handler function: should be the address of the task\u2019s function LR = 0xFFFFFFFD : when exception occurs, LR contains the EXC_RETURN value to control exception exit. This should make exception returns Thread mode, non-floating-point state from PSP R12 to R0 = any dummy data: can use a pattern for debugging void init_task ( void ( * handler )) { ... // fill dummy stack frame * ( -- psp ) = 0x01000000u ; // Dummy xPSR, just enable Thumb State bit; * ( -- psp ) = ( uint32_t ) handler ; // PC * ( -- psp ) = 0xFFFFFFFDu ; // LR with EXC_RETURN to return to Thread using PSP * ( -- psp ) = 0x12121212u ; // Dummy R12 * ( -- psp ) = 0x03030303u ; // Dummy R3 * ( -- psp ) = 0x02020202u ; // Dummy R2 * ( -- psp ) = 0x01010101u ; // Dummy R1 * ( -- psp ) = 0x00000000u ; // Dummy R0 * ( -- psp ) = 0x11111111u ; // Dummy R11 * ( -- psp ) = 0x10101010u ; // Dummy R10 * ( -- psp ) = 0x09090909u ; // Dummy R9 * ( -- psp ) = 0x08080808u ; // Dummy R8 * ( -- psp ) = 0x07070707u ; // Dummy R7 * ( -- psp ) = 0x06060606u ; // Dummy R6 * ( -- psp ) = 0x05050505u ; // Dummy R5 * ( -- psp ) = 0x04040404u ; // Dummy R4 // save PSP __puTasksPSP [ i ] = ( uint32_t ) psp ; Start scheduling # The scheduler has to do some extra steps before it can run the first task. Enable PSP # Task must use its own stack, therefore, we have to enable Process Stack mode. The initial PSP value should be the PSP of the first task. To access PSP and CONTROL register, we have to use inline assembly code . void start_scheduler () { printf ( \"Start Scheduler! \\n \" ); // start with the first task __uCurrentTaskIdx = 0 ; // prepare PSP of the first task __asm volatile ( \"BL get_current_psp\" ); // return PSP in R0 __asm volatile ( \"MSR PSP, R0\" ); // set PSP // change to use PSP __asm volatile ( \"MRS R0, CONTROL\" ); __asm volatile ( \"ORR R0, R0, #2\" ); // set bit[1] SPSEL __asm volatile ( \"MSR CONTROL, R0\" ); ... } Start SysTick # We need to configure the SysTick to trigger every 1 ms. The application is still have Privileged Access level, therefore, we can start a timer at this point. /* SysTick register address */ #define SCSR *((volatile uint32_t*) 0xE000E010u) #define SRVR *((volatile uint32_t*) 0xE000E014u) void start_scheduler () { ... // clear and set the period SRVR &= ~ 0xFFFFFFFF ; SRVR |= 16000-1 ; // 1000 Hz ~ 1 ms // enable SysTick SCSR |= ( 1 << 1 ); // enable SysTick Exception request SCSR |= ( 1 << 2 ); // select system clock ... } Set Access Level (optional) # This is an optional step to move the user task to Unprivileged Access level. If user tasks are set to Unprivileged, they are limited to access system memory, then you have to implement System Call through SVC exception. void start_scheduler () { ... // Move to Unprivileged level __asm volatile ( \"MRS R0, CONTROL\" ); __asm volatile ( \"ORR R0, R0, #1\" ); // Set bit[0] nPRIV __asm volatile ( \"MSR CONTROL, R0\" ); ... } Run the first task # Finally, we run the first task. Note the PC value we have pushed to the task\u2019s Stack Frame. void start_scheduler () { ... // get the handler of the first task by tracing back from PSP which is at R4 slot void ( * handler )() = ( void ( * ))(( uint32_t * ) __puTasksPSP [ __uCurrentTaskIdx ])[ 14 ]; // execute the handler handler (); } The SysTick will be triggered to do Context Switching. Context Switching # The Context Switching is implemented in the SysTick_Handler() as it is triggered periodically. Note 1: The xPSR , PC , LR , R12 , R3 to R0 registers are automatically saved to Task\u2019s PSP stack when an exception occurs. They are also restored automatically when the exception exits. Context Switching on Registers Note 2: The processor use Fill Descending Stack, therefore, when pushing registers to stack, the PSP is decreased, while popping register from stack, the PSP is increased. Therefore, we can use STMDB (Store memory using Decrement Before) to save registers at PSP. Note to use the exclamation to update the changed address (new PSP value). __asm volatile ( \"STMDB R0!, {R4-R11}\" ); // R0 is updated after decrement The same note is applied for LDMIA (Load memory using Increment After) to pop registers from stack. Note 3: To note change the PSP stack of the current task, SysTick_Handler() must be a naked function to remove prologue and epilogue sequence of a function. Note 4: The scheduler will decode which task is run next. A Round-Robin, it is easy to make a circular index. void select_next_task () { /* Round-Robin scheduler */ __uCurrentTaskIdx ++ ; // check if a task is register at current slot if ( __uCurrentTaskIdx >= TASK_NUMBER_MAX || __puTasksPSP [ __uCurrentTaskIdx ] == 0 ) { __uCurrentTaskIdx = 0 ; } } The implementation of Context Switching: __attribute__ (( naked )) void SysTick_Handler () { // save LR back to main, must do this firstly __asm volatile ( \"PUSH {LR}\" ); printf ( \"**** \\n \" ); /* Save the context of current task */ // get current PSP __asm volatile ( \"MRS R0, PSP\" ); // save R4 to R11 to PSP Frame Stack __asm volatile ( \"STMDB R0!, {R4-R11}\" ); // R0 is updated after decrement // save current value of PSP __asm volatile ( \"BL save_current_psp\" ); // R0 is first argument /* Do scheduling */ // select next task __asm volatile ( \"BL select_next_task\" ); /* Retrieve the context of next task */ // get its past PSP value __asm volatile ( \"BL get_current_psp\" ); // return PSP is in R0 // retrieve R4-R11 from PSP Fram Stack __asm volatile ( \"LDMIA R0!, {R4-R11}\" ); // R0 is updated after increment // update PSP __asm volatile ( \"MSR PSP, R0\" ); // exit __asm volatile ( \"POP {LR}\" ); __asm volatile ( \"BX LR\" ); } Main function # In the main, we just need to do: Declare Tasks\u2019 main function Add tasks into the Scheduler Start the scheduler int main () { // some initialization ... // add tasks init_task ( task1_main ); init_task ( task2_main ); init_task ( task3_main ); init_task ( task4_main ); // start start_scheduler (); // should never go here for (;;); **** } Debug and Run # Set a breakpoint before the scheduler starts: Check the Stack values Check the dummy Stack Frame The Stack Frame is filled Run the scheduler, and open the output of the system, such as SWV to see the log. All tasks should be running! All tasks are running There is no gurantee that the messages in output stream are completed. You mostly see the messages are interrupted into piecese because different tasks will try to use one sharing output. You will learn to synchronize output to avoid interruption later. Scheduler with PendSV # The delay problem Let say task A has to delay 1 ms in its execution, how long does it wait actually? If there are N tasks running in above scheduler, task A will have to wait N ms, not 1 ms. Extended delay in of blocking tasks System Ticks # System keeps tracking the number of ticks using a global counter, and increases it by 1 at every SysTick exception. As discussed in Pendable Service Call , SysTick Handler only needs to trigger the Context Switching by setting up the pending bit for PendSV. Note that, reschedule() is called from an Exception which is in Handler mode with Privileged access level. uint32_t __gSysTicks = 0 ; void SysTick_Handler ( void ) { printf ( \"**** \\n \" ); __gSysTicks ++ ; reschedule ( 1 ); // privileged } Context Switching in PendSV # We move the Context Switching from SysTick Handler to the PendSV Handler. The sequence is kept as the same as before: Save the context of current task Select next task Retrieve the context of next task Resume next task execution __attribute__ (( naked )) void PendSV_Handler ( void ) { // save LR back to main, must do this firstly __asm volatile ( \"PUSH {LR}\" ); /* Save the context of current task */ // get current PSP __asm volatile ( \"MRS R0, PSP\" ); // save R4 to R11 to PSP Frame Stack __asm volatile ( \"STMDB R0!, {R4-R11}\" ); // R0 is updated after decrement // save current value of PSP __asm volatile ( \"BL save_current_psp\" ); // R0 is first argument /* Do scheduling */ // select next task __asm volatile ( \"BL select_next_task\" ); /* Retrieve the context of next task */ // get its past PSP value __asm volatile ( \"BL get_current_psp\" ); // return PSP is in R0 // retrieve R4-R11 from PSP Fram Stack __asm volatile ( \"LDMIA R0!, {R4-R11}\" ); // R0 is updated after increment // update PSP __asm volatile ( \"MSR PSP, R0\" ); // exit __asm volatile ( \"POP {LR}\" ); __asm volatile ( \"BX LR\" ); } Task state # When a task has got nothing to do, it should go to the Blocked State in which it actually does nothing instead of consuming CPU to do a meaningless loop. To make it simple, a task has 2 states: RUNNING and BLOCKED . The scheduler should schedule only RUNNING tasks, and unblock BLOCKED tasks if their blocking period is over. typedef enum { RUNNING , BLOCKED } TaskState_t ; Task Control Block # There is a structure called Task Control Block to group all information related to a task: Handler : the main function of the task PSP : the current process stack pointer State : task is running or blocked WaitToTick : task is blocked until the system ticks meet this value typedef struct { void ( * handler )( void ); uint32_t psp ; TaskState_t state ; uint32_t waitToTick ; } TCB_t ; uint32_t __uCurrentTaskIdx = 0 ; TCB_t __pTasks [ TASK_NUMBER_MAX ] = { 0 }; uint32_t get_current_psp () { return __pTasks [ __uCurrentTaskIdx ]. psp ; } void save_current_psp ( uint32_t psp ) { __pTasks [ __uCurrentTaskIdx ]. psp = psp ; } Blocked Task # A task_delay() function will set the current task to BLOCKED state, and set its waitToTick value. When a task is blocked, it should tell scheduler to run a next task. Note that, reschedule() is called from a user task which is in Thread mode with Unprivileged access level. void task_delay ( uint32_t ticks ) { if ( __uCurrentTaskIdx ) { __pTasks [ __uCurrentTaskIdx ]. state = BLOCKED ; __pTasks [ __uCurrentTaskIdx ]. waitToTick = __gSysTicks + ticks ; reschedule ( 0 ); // unprivileged } } Idle Task # This is the default and the first task of the scheduler. In case all user tasks are blocked, the Idle task will be run. As soon as a user task is unblocked, that task is scheduled to run on next SysTick exception. void idle_main ( void ) { while ( 1 ) { __asm volatile ( \"NOP\" ); } } The idle_main is hidden to user, when a user tasks is added, scheduler will try to add the idle_main at the first slot: void init_task ( void ( * handler )) { // init idle if it is not found if ( handler != idle_main ) { if ( __pTasks [ 0 ]. handler != idle_main ) { init_task ( idle_main ); } } // find an empty slot int i = 0 ; for (; i < TASK_NUMBER_MAX ; i ++ ) { if ( __pTasks [ i ]. psp == 0 ) break ; } if ( i >= TASK_NUMBER_MAX ) { printf ( \"Can not register a new task anymore! \\n \" ); return ; } else { printf ( \"Register a task %p at slot %i \\n \" , handler , i ); } // calculate new PSP uint32_t * psp = ( uint32_t * )( MAIN_STACK - ( i + 1 ) * TASK_STACK_SIZE ); // fill dummy stack frame * ( -- psp ) = 0x01000000u ; // Dummy xPSR, just enable Thumb State bit; * ( -- psp ) = ( uint32_t ) handler ; // PC * ( -- psp ) = 0xFFFFFFFDu ; // LR with EXC_RETURN to return to Thread using PSP * ( -- psp ) = 0x12121212u ; // Dummy R12 * ( -- psp ) = 0x03030303u ; // Dummy R3 * ( -- psp ) = 0x02020202u ; // Dummy R2 * ( -- psp ) = 0x01010101u ; // Dummy R1 * ( -- psp ) = 0x00000000u ; // Dummy R0 * ( -- psp ) = 0x11111111u ; // Dummy R11 * ( -- psp ) = 0x10101010u ; // Dummy R10 * ( -- psp ) = 0x09090909u ; // Dummy R9 * ( -- psp ) = 0x08080808u ; // Dummy R8 * ( -- psp ) = 0x07070707u ; // Dummy R7 * ( -- psp ) = 0x06060606u ; // Dummy R6 * ( -- psp ) = 0x05050505u ; // Dummy R5 * ( -- psp ) = 0x04040404u ; // Dummy R4 // save PSP __pTasks [ i ]. psp = ( uint32_t ) psp ; // initial state __pTasks [ i ]. state = RUNNING ; __pTasks [ i ]. handler = handler ; } Select next task # At every context switching request, a task is selected to be run only when it is in RUNNING state All tasks will be checked to unblock if its waitToTick meets the global tick void select_next_task () { /* Check all task state */ for ( int i = 0 ; i < TASK_NUMBER_MAX ; i ++ ) { if ( __pTasks [ i ]. state == BLOCKED ) { if ( __gSysTicks >= __pTasks [ i ]. waitToTick ) { __pTasks [ i ]. state = RUNNING ; } } } /* Round-Robin scheduler */ while ( 1 ) { __uCurrentTaskIdx ++ ; // check if a task is register at current slot if ( __uCurrentTaskIdx >= TASK_NUMBER_MAX || __pTasks [ __uCurrentTaskIdx ]. psp == 0 ) { __uCurrentTaskIdx = 0 ; } if ( __pTasks [ __uCurrentTaskIdx ]. state == RUNNING ) break ; } } Reschedule the task # From above, we know that there are 2 moments that requests to reschedule the tasks: In SysTick Handler: call from Handler mode with Privileged access level We can directly access the Interrupt Control and State Register to set the pending bit for PendSV In Delay Task: call from Thread mode with Unprivileged access level We have limited access to the Interrupt Control and State Register, therefore, we have to request a Supervisor Call SVC Fault Exception Calling SVC in an SysTick handler causes Hard Fault (FORCED) Direct access ICSR register in Thread Mode with unprivileged access causes Bus Fault (PRECISERR) void reschedule ( uint32_t priv ) { if ( priv ) { // trigger PendSV directly ICSR |= ( 1 << 28 ); } else { // call Supervior exception to get Privileged access __asm volatile ( \"SVC #255\" ); } } To call to SVC exception, refer to Supervisor Call (SVC) : __attribute__ (( naked )) void SVC_Handler ( void ) { __asm volatile ( \"TST LR, 4\" ); // check LR to know which stack is used __asm volatile ( \"ITE EQ\" ); // 2 next instructions are conditional __asm volatile ( \"MRSEQ R0, MSP\" ); // save MSP if bit 2 is 0 __asm volatile ( \"MRSNE R0, PSP\" ); // save PSP if bit 2 is 1 __asm volatile ( \"B SVC_Handler_main\" ); // pass R0 as the argument } void SVC_Handler_main ( uint32_t * SP ) { // get the address of the instruction saved in PC uint8_t * pInstruction = ( uint8_t * )( SP [ 6 ]); // go back 2 bytes (16-bit opcode) pInstruction -= 2 ; // get the opcode, in little endian uint8_t svc_num = * pInstruction ; switch ( svc_num ) { case 0xFF : // trigger PendSV ICSR |= ( 1 << 28 ); break ; default : break ; } } User Tasks and Main function # Here is the time we use task_delay() to delay a task in non-blocking way. The expected result is: print 1111 after 16 ticks, print 2222 after 8 ticks, and so on. /* Tasks */ void task1_main ( void ) { while ( 1 ) { printf ( \"1111 \\n \" ); task_delay ( 16 ); } } void task2_main ( void ) { while ( 1 ) { printf ( \"2222 \\n \" ); task_delay ( 8 ); } } void task3_main ( void ) { while ( 1 ) { printf ( \"3333 \\n \" ); task_delay ( 4 ); } } void task4_main ( void ) { while ( 1 ) { printf ( \"4444 \\n \" ); task_delay ( 2 ); } } int main ( void ) { // some initialization ... // add tasks init_task ( task1_main ); init_task ( task2_main ); init_task ( task3_main ); init_task ( task4_main ); // start start_scheduler (); // should never go here for (;;); } Debug and Run # Run the scheduler, and open the output of the system, such as SWV to see the log. All tasks should be running! You can count the number of ticks **** to see how many ticks are passed before a task prints out again. Tasks are running and have correct delays","title":"A simple implementation of a Task Scheduler"},{"location":"blog/stm32/task-scheduler/#task","text":"A Task is a piece of code, or a function, that does a specific job when it is allowed to run. A Task has its own Stack to create its local variables. Its stack can be used to store addition information which is needed to save or restore the task from running state. Usually, a task is an infinite loop which can repeatedly do multiple steps. void task_main ( void * param ) { // init task ... // main loop while ( 1 ) { // do things over and over } }","title":"Task"},{"location":"blog/stm32/task-scheduler/#scheduler","text":"Round-Robin scheduling method is the time slices assigned to each task are equal , and all tasks are done in a circular order . The time slice is defined by a special timer - SysTick which is a free-run timer to produce a periodical interrupt. In the SysTick Handler , we will to the context switching to move to a next task. There are some others steps to initialize a scheduler: Steps to run a Scheduler","title":"Scheduler"},{"location":"blog/stm32/task-scheduler/#task-table","text":"Task Table is the place to store information of all tasks. Because each task should have its own stack to save its local variable, the task table must include the PSP values which point to the current stack pointer of each task. The scheduler also needs to know which task is currently running to do save/ restore stack to the corresponding task. Here is a minimal Task Table implementation, without using struct: #define TASK_NUMBER_MAX (16) uint32_t __uCurrentTaskIdx = 0 ; uint32_t __puTasksPSP [ TASK_NUMBER_MAX ] = { 0 }; The helper functions to access to the Task Table: // return PSP value stored in slot at __uCurrentTaskIdx index uint32_t get_current_psp () { return __puTasksPSP [ __uCurrentTaskIdx ]; } // save PSP value to the slot at __uCurrentTaskIdx index void save_current_psp ( uint32_t psp ) { __puTasksPSP [ __uCurrentTaskIdx ] = psp ; }","title":"Task Table"},{"location":"blog/stm32/task-scheduler/#add-a-task","text":"We need to set how much RAM is reserved for a Task Stack. Let say 1 KB. The RAM space for Tasks should not overlap the Main Stack because Handler mode always use the Main Stack. #define RAM_START (0x20000000u) #define RAM_SIZE (128 * 1024) // 128 KB #define MAIN_STACK (RAM_START + RAM_SIZE) #define TASK_STACK_SIZE (1024u) For the i -th task, the beginning Stack address should be: uint32_t * psp = ( uint32_t * )( MAIN_STACK - ( i + 1 ) * TASK_STACK_SIZE ); Structure of Scheduler and Task Stack","title":"Add a Task"},{"location":"blog/stm32/task-scheduler/#set-task-stack","text":"When adding a task, we initialize the PSP value of the new task at the start address of new 1 KB RAM. We reserve 1 KB for Main Stack, then every 1 KB for a new task. The Task Table will be filled a new slot when a new task is added. void init_task ( void ( * handler )) { int i = 0 ; // find an empty slot for (; i < TASK_NUMBER_MAX ; i ++ ) { if ( __puTasksPSP [ i ] == 0 ) break ; } if ( i >= TASK_NUMBER_MAX ) { printf ( \"Can not register a new task anymore! \\n \" ); return ; } else { printf ( \"Register a task %p at slot %i \\n \" , handler , i ); } // calculate new PSP uint32_t * psp = ( uint32_t * )( MAIN_STACK - ( i + 1 ) * TASK_STACK_SIZE ); // fill stack frame ...","title":"Set Task Stack"},{"location":"blog/stm32/task-scheduler/#fill-stack-frame","text":"When a task is switched in (load and run), the CPU will use PSP pointer to find below information: Last CPU status \u2192 Load xPSR register Next instruction to be executed \u2192 Load PC register Return mode \u2192 Load LR register Last execution status \u2192 Load all R0 to R12 registers As we use the SysTick exception to trigger Context Switching, the below registers are automatically saved at exception: xPSR , PC , LR , R12 , R3 to R0 , in fixed order Therefore, we will prepare additional registers in the order R11 to R4 . What are the value of those registers??? xPSR = 0x01000000 : no special status should be set at initial stage of a task, except the Thumb State bit must be set PC = task\u2019 handler function: should be the address of the task\u2019s function LR = 0xFFFFFFFD : when exception occurs, LR contains the EXC_RETURN value to control exception exit. This should make exception returns Thread mode, non-floating-point state from PSP R12 to R0 = any dummy data: can use a pattern for debugging void init_task ( void ( * handler )) { ... // fill dummy stack frame * ( -- psp ) = 0x01000000u ; // Dummy xPSR, just enable Thumb State bit; * ( -- psp ) = ( uint32_t ) handler ; // PC * ( -- psp ) = 0xFFFFFFFDu ; // LR with EXC_RETURN to return to Thread using PSP * ( -- psp ) = 0x12121212u ; // Dummy R12 * ( -- psp ) = 0x03030303u ; // Dummy R3 * ( -- psp ) = 0x02020202u ; // Dummy R2 * ( -- psp ) = 0x01010101u ; // Dummy R1 * ( -- psp ) = 0x00000000u ; // Dummy R0 * ( -- psp ) = 0x11111111u ; // Dummy R11 * ( -- psp ) = 0x10101010u ; // Dummy R10 * ( -- psp ) = 0x09090909u ; // Dummy R9 * ( -- psp ) = 0x08080808u ; // Dummy R8 * ( -- psp ) = 0x07070707u ; // Dummy R7 * ( -- psp ) = 0x06060606u ; // Dummy R6 * ( -- psp ) = 0x05050505u ; // Dummy R5 * ( -- psp ) = 0x04040404u ; // Dummy R4 // save PSP __puTasksPSP [ i ] = ( uint32_t ) psp ;","title":"Fill Stack Frame"},{"location":"blog/stm32/task-scheduler/#start-scheduling","text":"The scheduler has to do some extra steps before it can run the first task.","title":"Start scheduling"},{"location":"blog/stm32/task-scheduler/#enable-psp","text":"Task must use its own stack, therefore, we have to enable Process Stack mode. The initial PSP value should be the PSP of the first task. To access PSP and CONTROL register, we have to use inline assembly code . void start_scheduler () { printf ( \"Start Scheduler! \\n \" ); // start with the first task __uCurrentTaskIdx = 0 ; // prepare PSP of the first task __asm volatile ( \"BL get_current_psp\" ); // return PSP in R0 __asm volatile ( \"MSR PSP, R0\" ); // set PSP // change to use PSP __asm volatile ( \"MRS R0, CONTROL\" ); __asm volatile ( \"ORR R0, R0, #2\" ); // set bit[1] SPSEL __asm volatile ( \"MSR CONTROL, R0\" ); ... }","title":"Enable PSP"},{"location":"blog/stm32/task-scheduler/#start-systick","text":"We need to configure the SysTick to trigger every 1 ms. The application is still have Privileged Access level, therefore, we can start a timer at this point. /* SysTick register address */ #define SCSR *((volatile uint32_t*) 0xE000E010u) #define SRVR *((volatile uint32_t*) 0xE000E014u) void start_scheduler () { ... // clear and set the period SRVR &= ~ 0xFFFFFFFF ; SRVR |= 16000-1 ; // 1000 Hz ~ 1 ms // enable SysTick SCSR |= ( 1 << 1 ); // enable SysTick Exception request SCSR |= ( 1 << 2 ); // select system clock ... }","title":"Start SysTick"},{"location":"blog/stm32/task-scheduler/#set-access-level-optional","text":"This is an optional step to move the user task to Unprivileged Access level. If user tasks are set to Unprivileged, they are limited to access system memory, then you have to implement System Call through SVC exception. void start_scheduler () { ... // Move to Unprivileged level __asm volatile ( \"MRS R0, CONTROL\" ); __asm volatile ( \"ORR R0, R0, #1\" ); // Set bit[0] nPRIV __asm volatile ( \"MSR CONTROL, R0\" ); ... }","title":"Set Access Level (optional)"},{"location":"blog/stm32/task-scheduler/#run-the-first-task","text":"Finally, we run the first task. Note the PC value we have pushed to the task\u2019s Stack Frame. void start_scheduler () { ... // get the handler of the first task by tracing back from PSP which is at R4 slot void ( * handler )() = ( void ( * ))(( uint32_t * ) __puTasksPSP [ __uCurrentTaskIdx ])[ 14 ]; // execute the handler handler (); } The SysTick will be triggered to do Context Switching.","title":"Run the first task"},{"location":"blog/stm32/task-scheduler/#context-switching","text":"The Context Switching is implemented in the SysTick_Handler() as it is triggered periodically. Note 1: The xPSR , PC , LR , R12 , R3 to R0 registers are automatically saved to Task\u2019s PSP stack when an exception occurs. They are also restored automatically when the exception exits. Context Switching on Registers Note 2: The processor use Fill Descending Stack, therefore, when pushing registers to stack, the PSP is decreased, while popping register from stack, the PSP is increased. Therefore, we can use STMDB (Store memory using Decrement Before) to save registers at PSP. Note to use the exclamation to update the changed address (new PSP value). __asm volatile ( \"STMDB R0!, {R4-R11}\" ); // R0 is updated after decrement The same note is applied for LDMIA (Load memory using Increment After) to pop registers from stack. Note 3: To note change the PSP stack of the current task, SysTick_Handler() must be a naked function to remove prologue and epilogue sequence of a function. Note 4: The scheduler will decode which task is run next. A Round-Robin, it is easy to make a circular index. void select_next_task () { /* Round-Robin scheduler */ __uCurrentTaskIdx ++ ; // check if a task is register at current slot if ( __uCurrentTaskIdx >= TASK_NUMBER_MAX || __puTasksPSP [ __uCurrentTaskIdx ] == 0 ) { __uCurrentTaskIdx = 0 ; } } The implementation of Context Switching: __attribute__ (( naked )) void SysTick_Handler () { // save LR back to main, must do this firstly __asm volatile ( \"PUSH {LR}\" ); printf ( \"**** \\n \" ); /* Save the context of current task */ // get current PSP __asm volatile ( \"MRS R0, PSP\" ); // save R4 to R11 to PSP Frame Stack __asm volatile ( \"STMDB R0!, {R4-R11}\" ); // R0 is updated after decrement // save current value of PSP __asm volatile ( \"BL save_current_psp\" ); // R0 is first argument /* Do scheduling */ // select next task __asm volatile ( \"BL select_next_task\" ); /* Retrieve the context of next task */ // get its past PSP value __asm volatile ( \"BL get_current_psp\" ); // return PSP is in R0 // retrieve R4-R11 from PSP Fram Stack __asm volatile ( \"LDMIA R0!, {R4-R11}\" ); // R0 is updated after increment // update PSP __asm volatile ( \"MSR PSP, R0\" ); // exit __asm volatile ( \"POP {LR}\" ); __asm volatile ( \"BX LR\" ); }","title":"Context Switching"},{"location":"blog/stm32/task-scheduler/#main-function","text":"In the main, we just need to do: Declare Tasks\u2019 main function Add tasks into the Scheduler Start the scheduler int main () { // some initialization ... // add tasks init_task ( task1_main ); init_task ( task2_main ); init_task ( task3_main ); init_task ( task4_main ); // start start_scheduler (); // should never go here for (;;); **** }","title":"Main function"},{"location":"blog/stm32/task-scheduler/#debug-and-run","text":"Set a breakpoint before the scheduler starts: Check the Stack values Check the dummy Stack Frame The Stack Frame is filled Run the scheduler, and open the output of the system, such as SWV to see the log. All tasks should be running! All tasks are running There is no gurantee that the messages in output stream are completed. You mostly see the messages are interrupted into piecese because different tasks will try to use one sharing output. You will learn to synchronize output to avoid interruption later.","title":"Debug and Run"},{"location":"blog/stm32/task-scheduler/#scheduler-with-pendsv","text":"The delay problem Let say task A has to delay 1 ms in its execution, how long does it wait actually? If there are N tasks running in above scheduler, task A will have to wait N ms, not 1 ms. Extended delay in of blocking tasks","title":"Scheduler with PendSV"},{"location":"blog/stm32/task-scheduler/#system-ticks","text":"System keeps tracking the number of ticks using a global counter, and increases it by 1 at every SysTick exception. As discussed in Pendable Service Call , SysTick Handler only needs to trigger the Context Switching by setting up the pending bit for PendSV. Note that, reschedule() is called from an Exception which is in Handler mode with Privileged access level. uint32_t __gSysTicks = 0 ; void SysTick_Handler ( void ) { printf ( \"**** \\n \" ); __gSysTicks ++ ; reschedule ( 1 ); // privileged }","title":"System Ticks"},{"location":"blog/stm32/task-scheduler/#context-switching-in-pendsv","text":"We move the Context Switching from SysTick Handler to the PendSV Handler. The sequence is kept as the same as before: Save the context of current task Select next task Retrieve the context of next task Resume next task execution __attribute__ (( naked )) void PendSV_Handler ( void ) { // save LR back to main, must do this firstly __asm volatile ( \"PUSH {LR}\" ); /* Save the context of current task */ // get current PSP __asm volatile ( \"MRS R0, PSP\" ); // save R4 to R11 to PSP Frame Stack __asm volatile ( \"STMDB R0!, {R4-R11}\" ); // R0 is updated after decrement // save current value of PSP __asm volatile ( \"BL save_current_psp\" ); // R0 is first argument /* Do scheduling */ // select next task __asm volatile ( \"BL select_next_task\" ); /* Retrieve the context of next task */ // get its past PSP value __asm volatile ( \"BL get_current_psp\" ); // return PSP is in R0 // retrieve R4-R11 from PSP Fram Stack __asm volatile ( \"LDMIA R0!, {R4-R11}\" ); // R0 is updated after increment // update PSP __asm volatile ( \"MSR PSP, R0\" ); // exit __asm volatile ( \"POP {LR}\" ); __asm volatile ( \"BX LR\" ); }","title":"Context Switching in PendSV"},{"location":"blog/stm32/task-scheduler/#task-state","text":"When a task has got nothing to do, it should go to the Blocked State in which it actually does nothing instead of consuming CPU to do a meaningless loop. To make it simple, a task has 2 states: RUNNING and BLOCKED . The scheduler should schedule only RUNNING tasks, and unblock BLOCKED tasks if their blocking period is over. typedef enum { RUNNING , BLOCKED } TaskState_t ;","title":"Task state"},{"location":"blog/stm32/task-scheduler/#task-control-block","text":"There is a structure called Task Control Block to group all information related to a task: Handler : the main function of the task PSP : the current process stack pointer State : task is running or blocked WaitToTick : task is blocked until the system ticks meet this value typedef struct { void ( * handler )( void ); uint32_t psp ; TaskState_t state ; uint32_t waitToTick ; } TCB_t ; uint32_t __uCurrentTaskIdx = 0 ; TCB_t __pTasks [ TASK_NUMBER_MAX ] = { 0 }; uint32_t get_current_psp () { return __pTasks [ __uCurrentTaskIdx ]. psp ; } void save_current_psp ( uint32_t psp ) { __pTasks [ __uCurrentTaskIdx ]. psp = psp ; }","title":"Task Control Block"},{"location":"blog/stm32/task-scheduler/#blocked-task","text":"A task_delay() function will set the current task to BLOCKED state, and set its waitToTick value. When a task is blocked, it should tell scheduler to run a next task. Note that, reschedule() is called from a user task which is in Thread mode with Unprivileged access level. void task_delay ( uint32_t ticks ) { if ( __uCurrentTaskIdx ) { __pTasks [ __uCurrentTaskIdx ]. state = BLOCKED ; __pTasks [ __uCurrentTaskIdx ]. waitToTick = __gSysTicks + ticks ; reschedule ( 0 ); // unprivileged } }","title":"Blocked Task"},{"location":"blog/stm32/task-scheduler/#idle-task","text":"This is the default and the first task of the scheduler. In case all user tasks are blocked, the Idle task will be run. As soon as a user task is unblocked, that task is scheduled to run on next SysTick exception. void idle_main ( void ) { while ( 1 ) { __asm volatile ( \"NOP\" ); } } The idle_main is hidden to user, when a user tasks is added, scheduler will try to add the idle_main at the first slot: void init_task ( void ( * handler )) { // init idle if it is not found if ( handler != idle_main ) { if ( __pTasks [ 0 ]. handler != idle_main ) { init_task ( idle_main ); } } // find an empty slot int i = 0 ; for (; i < TASK_NUMBER_MAX ; i ++ ) { if ( __pTasks [ i ]. psp == 0 ) break ; } if ( i >= TASK_NUMBER_MAX ) { printf ( \"Can not register a new task anymore! \\n \" ); return ; } else { printf ( \"Register a task %p at slot %i \\n \" , handler , i ); } // calculate new PSP uint32_t * psp = ( uint32_t * )( MAIN_STACK - ( i + 1 ) * TASK_STACK_SIZE ); // fill dummy stack frame * ( -- psp ) = 0x01000000u ; // Dummy xPSR, just enable Thumb State bit; * ( -- psp ) = ( uint32_t ) handler ; // PC * ( -- psp ) = 0xFFFFFFFDu ; // LR with EXC_RETURN to return to Thread using PSP * ( -- psp ) = 0x12121212u ; // Dummy R12 * ( -- psp ) = 0x03030303u ; // Dummy R3 * ( -- psp ) = 0x02020202u ; // Dummy R2 * ( -- psp ) = 0x01010101u ; // Dummy R1 * ( -- psp ) = 0x00000000u ; // Dummy R0 * ( -- psp ) = 0x11111111u ; // Dummy R11 * ( -- psp ) = 0x10101010u ; // Dummy R10 * ( -- psp ) = 0x09090909u ; // Dummy R9 * ( -- psp ) = 0x08080808u ; // Dummy R8 * ( -- psp ) = 0x07070707u ; // Dummy R7 * ( -- psp ) = 0x06060606u ; // Dummy R6 * ( -- psp ) = 0x05050505u ; // Dummy R5 * ( -- psp ) = 0x04040404u ; // Dummy R4 // save PSP __pTasks [ i ]. psp = ( uint32_t ) psp ; // initial state __pTasks [ i ]. state = RUNNING ; __pTasks [ i ]. handler = handler ; }","title":"Idle Task"},{"location":"blog/stm32/task-scheduler/#select-next-task","text":"At every context switching request, a task is selected to be run only when it is in RUNNING state All tasks will be checked to unblock if its waitToTick meets the global tick void select_next_task () { /* Check all task state */ for ( int i = 0 ; i < TASK_NUMBER_MAX ; i ++ ) { if ( __pTasks [ i ]. state == BLOCKED ) { if ( __gSysTicks >= __pTasks [ i ]. waitToTick ) { __pTasks [ i ]. state = RUNNING ; } } } /* Round-Robin scheduler */ while ( 1 ) { __uCurrentTaskIdx ++ ; // check if a task is register at current slot if ( __uCurrentTaskIdx >= TASK_NUMBER_MAX || __pTasks [ __uCurrentTaskIdx ]. psp == 0 ) { __uCurrentTaskIdx = 0 ; } if ( __pTasks [ __uCurrentTaskIdx ]. state == RUNNING ) break ; } }","title":"Select next task"},{"location":"blog/stm32/task-scheduler/#reschedule-the-task","text":"From above, we know that there are 2 moments that requests to reschedule the tasks: In SysTick Handler: call from Handler mode with Privileged access level We can directly access the Interrupt Control and State Register to set the pending bit for PendSV In Delay Task: call from Thread mode with Unprivileged access level We have limited access to the Interrupt Control and State Register, therefore, we have to request a Supervisor Call SVC Fault Exception Calling SVC in an SysTick handler causes Hard Fault (FORCED) Direct access ICSR register in Thread Mode with unprivileged access causes Bus Fault (PRECISERR) void reschedule ( uint32_t priv ) { if ( priv ) { // trigger PendSV directly ICSR |= ( 1 << 28 ); } else { // call Supervior exception to get Privileged access __asm volatile ( \"SVC #255\" ); } } To call to SVC exception, refer to Supervisor Call (SVC) : __attribute__ (( naked )) void SVC_Handler ( void ) { __asm volatile ( \"TST LR, 4\" ); // check LR to know which stack is used __asm volatile ( \"ITE EQ\" ); // 2 next instructions are conditional __asm volatile ( \"MRSEQ R0, MSP\" ); // save MSP if bit 2 is 0 __asm volatile ( \"MRSNE R0, PSP\" ); // save PSP if bit 2 is 1 __asm volatile ( \"B SVC_Handler_main\" ); // pass R0 as the argument } void SVC_Handler_main ( uint32_t * SP ) { // get the address of the instruction saved in PC uint8_t * pInstruction = ( uint8_t * )( SP [ 6 ]); // go back 2 bytes (16-bit opcode) pInstruction -= 2 ; // get the opcode, in little endian uint8_t svc_num = * pInstruction ; switch ( svc_num ) { case 0xFF : // trigger PendSV ICSR |= ( 1 << 28 ); break ; default : break ; } }","title":"Reschedule the task"},{"location":"blog/stm32/task-scheduler/#user-tasks-and-main-function","text":"Here is the time we use task_delay() to delay a task in non-blocking way. The expected result is: print 1111 after 16 ticks, print 2222 after 8 ticks, and so on. /* Tasks */ void task1_main ( void ) { while ( 1 ) { printf ( \"1111 \\n \" ); task_delay ( 16 ); } } void task2_main ( void ) { while ( 1 ) { printf ( \"2222 \\n \" ); task_delay ( 8 ); } } void task3_main ( void ) { while ( 1 ) { printf ( \"3333 \\n \" ); task_delay ( 4 ); } } void task4_main ( void ) { while ( 1 ) { printf ( \"4444 \\n \" ); task_delay ( 2 ); } } int main ( void ) { // some initialization ... // add tasks init_task ( task1_main ); init_task ( task2_main ); init_task ( task3_main ); init_task ( task4_main ); // start start_scheduler (); // should never go here for (;;); }","title":"User Tasks and Main function"},{"location":"blog/stm32/task-scheduler/#debug-and-run_1","text":"Run the scheduler, and open the output of the system, such as SWV to see the log. All tasks should be running! You can count the number of ticks **** to see how many ticks are passed before a task prints out again. Tasks are running and have correct delays","title":"Debug and Run"},{"location":"blog/stm32/tools/","tags":["arm","stm32"],"text":"There are many developement environemts to work with STM32 MCUs, such as the official STM32 IDE , ARM Keil , PlatformIO , Mbed , Arduino , etc. STM32 Ecosystem # A tool-chain is a set of programming tools that allow developers to: Configure the settings on the target MCU Write code and navigate inside source files of the project Inspect the code to show additional information about variables, function definitions, etc. Compile the source code to an executable application Program the target MCU Debug the application running on the target MCU Monitor the application on the target MCU The STM32Cube ecosystem is a complete software solution for STM32 microcontrollers and microprocessors. It has a complete tool chain and extended packages to well support developers on STM32 MCUs. STM32 Ecosystem STM32CubeMX , a configuration tool for any STM32 device. This easy-to-use graphical user interface generates initialization C code for Cortex-M cores and generates the Linux device tree source for Cortex-A cores. STM32CubeIDE , an Integrated Development Environment. Based on open-source solutions like Eclipse or the GNU C/C++ tool chain, this IDE includes compilation reporting features and advanced debug features. It also integrates additional features present in other tools from the ecosystem, such as the HW and SW initialization and code generation from STM32CubeMX. This software includes: Eclipse IDE \u2014 an open source code editor and manager which supports many plugins such as C/C++ Development Platform, GCC Cross-Compiler, GDB Hardware Debugger, Make and build scripts. GNU ARM Cross-compiler with ST patch for STM32 MCUs \u2014 a compiler that converts code to executable and linkable file (.elf) or binary file (.bin, .hex). GDB for inspecting, debugging the target application. STM32CubeProgrammer , a programming tool. It provides an easy-to-use and efficient environment for reading, writing and verifying devices and external memories via a wide variety of available communication media (JTAG, SWD, UART, USB DFU, I2C, SPI, CAN, etc.). STM32CubeMonitor , a monitoring tool. Powerful monitoring tools that help developers fine-tune the behavior and performance of their applications in real time. STM32Cube MCU and MPU packages , dedicated to each STM32 series. Packages offer all the required to be embedded software bricks to operate the available set of STM32 peripherals. They include drivers (HAL, low-layer, etc.), middleware, and lots of example code used in a wide variety of real-world use cases. STM32Cube expansion packages , for application-oriented solutions. Complementing and expanding the STM32Cube MCU Package offer with additional embedded software bricks, STM32 expansion packages come either from ST or approved partners to create an extensive and scalable embedded software offer around the STM32. 4 steps of an interactive development process STM32CubeIDE # STM32CubeIDE is an advanced C/C++ development platform with peripheral configuration, code generation, code compilation, and debug features for STM32 microcontrollers and microprocessors. It is based on the Eclipse\u00ae/CDT framework and GCC tool chain for the development, and GDB for the debugging. It allows the integration of the hundreds of existing plugins that complete the features of the Eclipse\u00ae IDE. This tool includes the STM32CubeMX for code generation. At any time during the development, the user can return to the initialization and configuration of the peripherals or middleware and regenerate the initialization code with no impact on the user code written in the user blocks. STM32CubeIDE includes build and stack analyzers that provide the user with useful information about project status and memory requirements. STM32CubeIDE also includes standard and advanced debugging features including views of CPU core registers, memories, and peripheral registers, as well as live variable watch, Serial Wire Viewer interface, or fault analyzer. Other IDEs that support ARM Cortex: ARM\u00ae, Atollic TrueSTUDIO\u00ae: was bought by ST, included in STM32CubeIDE Keil\u2122, MDK-ARM\u2122: only free for STM32F0 and STM32L0 processes Altium\u00ae, TASKING\u2122 VX-toolset: paid license IAR\u2122, EWARM (IAR Embedded Workbench\u00ae): paid license Installation # Download STM32CubeIDE STM32CubeIDE User Manual During the installation, please be sure to install ST-LINK and SEGGER J-Link drivers. Create a workspace # When start the program, it will ask to select a directory as a workspace \u2014 the location to save projects. Consider to make new workspaces for different big projects. Select a workspace Workspace settings Each workspace has its own settings configured in the Windows \u2192 Preferences menu. General \u2192 Editor \u2192 Text Editor Due to the generated code from STM32CubeMX is 2-space tab width, it is better to configure the Text Editor to adapt with the tab width behavior: Displayed tab width: 2 Insert spaces for tabs: Checked Remove multiple spaces on backspace/delete: Checked C/C++ \u2192 Build \u2192 Code Analysis There are some options for under the. I recommended to enable some check for Potential Programming Problems : Assignment in condition: if ( a = b ){} Assignment to itself: var = var ; No return in a function which is declared to return a value: int func (){} Return without value: int func (){ return ;} Return the address of a local variable: int * func (){ int a ; return & a ;} Virtual method call in constructor/ destructor C/C++ \u2192 Code Style \u2192 Formatter Next is the formatting style: Create a new profile from K&R In the Indentation : Change Tab Policy to Space Only; then set Indentation size and Tab size both to 2. Indent is activated for all cases except empty lines In the Control Statement : Insert new line for all control statements Terminal Finally, it should increase the buffer for terminals in Terminal option to 1000 or more. Create a project # F411RE_Intro.zip When start a new STM32 project, IDE shows up the Device Finder screen first. There are options to select the target MCU/MPU by name , board , example , and cross-reference . Select the target MCU by name After selecting the microprocessor, it\u2019s time to name the project, and then select the targeted project type: STM32Cube : CubeMX will help you to configure the projects, and it also generates source code for all settings you choose. Refer to the Blink project using LL or HAL . In this option, you can choose the STM32Cube MCU packages version for the selected target. For example, it is STM32Cube FW_F4 V1.27.0 for the STM32F4 MCUs. Empty : you will start with minimal source code, and you have to configure the target chip manually. Refer to the Blink project using Register-based or CMSIS . Set name and select firmware package for a new project Press on Finish then IDE will run a screen named Device Configuration Tool from the STM32CubeMX tool, in there, it\u2019s easy to enable any supported features in graphical mode. If the selected target is a development board, this tool will ask to use a default system config for the target board \u2014 usually including ST-Link pins, on-board buttons, LEDs, USB connect. STM32CubeMX # STM32CubeMX User Manual STM32CubeMX is a graphical tool that allows a very easy configuration of STM32 microcontrollers and microprocessors, as well as the generation of the corresponding initialization C code for the Arm\u00ae Cortex\u00ae-M cores. STM32CubeMX allows the user to create, save and load previously saved projects. MCU configuration .ioc file is saved in the project folder, and user can open it in the STM32CubeMX for editing. Pinout Configuration # This tab shows available Components in categories or in A-Z list. Select on a component will show its Configuration screen. The large Pinout view shows a graphic representation of the pin assignment. Left-click to select the function, and Right-click to do extra actions such as assigning a custom name. The Pinout config screen Clock Configuration # This tab provides a schematic overview of the clock paths, clock sources, dividers, and multipliers. Drop-down menus and buttons can be used to modify the actual clock tree configuration, to meet the application requirements. IDE has ability to automatically calculate multipliers and dividers to provide requested frequency, user can set a desired frequency in the clock node, and press enter, then IDE will re-configure the PLL, prescaler. The frequency on each node can be locked via the right-click menu. The Clock config screen Project Manager # This tab provides information about general project setting: to specify the project name, location, tool chain, and firmware version. It also has configs for code generation options such as the location of peripheral initialization code, library copy/link options, and to select templates for customized code. The Project config view Extra Tools # There are some provided tools which can be used to analyze or estimate the power consumption. You can see the RUN/ SLEEP modes with different clock frequency, peripheral status, and duration. It has a chart to visualize the power consumption profile for better understanding. The Tools config view Code generation # Generate code or Write your own code? High-level or Low-Level programming? There are many topics on the internet discussing about how to learn MCU though generated code or through self-written bare-metal/register-based code. Here is my opinion to learn MCU which I\u2019ve followed to get better understanding: First, start with bare-metal/ register-based programming This step requires you to read document carefully, to understand every bit of the hardware configurations and how they will work. At this step, you should work on small application only, on simple peripherals first. Second, work with Low-level Library (CMSIS, LL) At this step, you should use an abstraction layer to reduce your own code. This also makes your code portable, reusable, and usually more coverage rate. Low-Level Lib also uses register-based programming. You can use LL as reference for the first step. Cortex Microcontroller Software Interface Standard (CMSIS) can be used at this stage. ST also provides LL Library for this purpose. ST LL can be integrated in Code generation. Third, work with High-level Library (HAL) In more complicated projects, Hardware-Abstraction Layer (HAL) is used for a quick development. HAL is preferred to use in production as it is built and test in long time, and of course, it reduces time-to-market. However, HAL is big, and make your application slower. It\u2019s also hard to debug due to overriding or function pointers. ST provides HAL Lib, and this lib is integrated with Code generation. Another open source HAL for STM32 is libopencm3 . Refer to the Blink project to get the overview of what you have to do in either registered-based code or generated code. After configuring pins, save the settings first and then start generating code. Manually request to generate code by pressing Alt + K or choosing menu Project \u2192 Generate Code . The tool will create sub-folders and add necessary files into project. The general file structure is: Structure of generated code When chosen to use a Firmware Library in the project, IDE automatically uses ST Hardware Abstract Layer (HAL) library as the main way of controlling the processor and peripherals. HAL also makes use of Cortex Microcontroller Software Interface Standard (CMSIS) library to access processor\u2019s registers. In the Project Manager tab, it can change to use Low-Level (LL) library instead of HAL . Code dependency starts from the main.h source file. This file includes HAL files which eventually includes CMSIS files. The main function is called from the startup file startup_*.s . Code dependency A HAL driver includes the following set of files: File Description stm32f4xx_hal.h/.c This file is used for HAL initialization and contains DBGMCU, Remap and Time Delay based on SysTick APIs. This also include stm32f4xx_hal_def.h . stm32f4xx_hal_def.h Common HAL resources such as common define statements, enumerations, structures and macros. This includes CMSIS headers. stm32f4xx_hal_ppp.h/.c Main peripheral/module driver file. It includes the APIs that are common to all STM32 devices, example: stm32f4xx_hal_adc.c , stm32f4xx_hal_irda.c stm32f4xx_hal_ppp_ex.h/.c Extension file of a peripheral/module driver. It includes the specific APIs for a given part number or family, as well as the newly defined APIs that overwrite the default generic APIs if the internal process is implemented in different way, for example: stm32f4xx_hal_adc_ex.c , stm32f4xx_hal_flash_ex.c . The minimum files required to build an application using the HAL are listed in the table below: File Description startup_stm32f4xx.s Tool chain specific file that contains reset handler and exception vectors. For some tool chains, it allows adapting the stack/heap size to fit the application requirements system_stm32f4xx.c This file contains SystemInit() which is called at startup just after reset and before branching to the main program. It does not configure the system clock at startup (contrary to the standard library). This is to be done using the HAL APIs in the user files. It allows relocating the vector table in internal SRAM. stm32f4xx_hal_conf.h This file allows the user to customize the HAL drivers for a specific application. It is not mandatory to modify this configuration. The application can use the default configuration without any modification. This call to STM32F0 HAL headers. stm32f4xx_hal_msp.c This file contains the MSP initialization and de-initialization (main routine and callbacks) of the peripheral used in the user application. stm32f4xx_it.h/.c This file contains the exceptions handler and peripherals interrupt service routine, and calls HAL_IncTick() at regular time intervals to increment a local variable (declared in stm32f0xx_hal.c ) used as HAL time base. By default, this function is called each 1ms in SysTick ISR. The PPP_IRQHandler() routine must call HAL_PPP_IRQHandler() if an interrupt based process is used within the application. main.h/.c This file contains the main program routine, mainly: \u2022 call to HAL_Init() \u2022 set system clock configuration declare peripheral HAL initialization user application code. Add user code # User code sections are marked with a pair of phrases /* USER CODE BEGIN x */ and /* USER CODE END x */ . User code inside those marks are kept remaining during code generation. I am going to add a variable counter with type of char , then inside the main while loop in the main() function, increase it by 1 after 100ms. Don\u2019t mind the HAL function at this time. /* USER CODE BEGIN PV */ char counter = 0 ; /* USER CODE END PV */ int main ( void ) { /* other setup function */ /* USER CODE BEGIN WHILE */ while ( 1 ) { counter ++ ; HAL_Delay ( 100 ); /* USER CODE END WHILE */ /* USER CODE BEGIN 3 */ } /* USER CODE END 3 */ } Compiler options # Project has options for the compiler under its properties. Right-click on the project name in the right panel, then select Properties menu. The default included folders are all the folders created in the project by the STM32CubeMX tool. There are also some symbols created for the project build, such DEBUG mode, the MCU name STM32F411xE , and the macro USE_HAL_DRIVER if the project is generated with HAL firmware. The including paths and symbols Then in the Build Options, there are options to be used by GCC compiler, GNU Linker, GNU Assembler. For details, you can refer to the Blink project. Build options Build Project # Build the application by pressing Ctrl + B , or in menu Project \u2192 Build All . There are some reports about the resource usage to check after the compilation. The first thing it reports is the memory usage, in terms of RAM and FLASH free space. Build analyzer with memory usage report Setup debugger # Before Run or Debug on the target chip, it is needed to configure the programming/ debugging interface. By default, the application code can be programmed through the debugger interface, therefore, in Run Config or Debug Config, there is a tab named Debugger to select: Debug Probe: ST-LINK GDB, ST-LINK OpenOCD, SEGGER J-LINK, or other available probes Interface: SWD or JTAG. If there are multiple boards connected, use debugger board Serial Number to choose the correct target Advanced features: Serial Wire Viewer: read data from MCU in a dedicated SWO pin, available on Cortext-M3 and above Live Expression: read out the value at a memory address without halting the CPU Setup Debugger Run Mode # In the Run Mode, IDE flashes the firmware via the Debugging interface, and then disconnect the debugger to make the target board run freely. Just use the menu Run \u2192 Run . Debug Mode # Putting the target under the Debug Mode is to control its execution, step by step. Breakpoint is where the CPU will be halted and debugger will inspect its current status: registers, memory values. By default, the first breakpoint is right after entering the main function. The start address and the first break point can be set in the Startup tab in Debug Configurations. Startup option for debug When CPU is halted at a breakpoint, user can control the execution step by step, through the commands or buttons: Debug controls STM32CubeProgrammer # Download STM32CubeProgrammer STM32CubeProgrammer User Manual STM32CubeProgrammer (previous name was ST-Link Utility) provides an easy-to-use and efficient environment for reading, writing and verifying device memory through both the debug interface (JTAG and SWD) and the bootloader interface (UART, USB DFU, I2C, SPI, and CAN). STM32CubeProgrammer offers a wide range of features to program STM32 internal memories (such as Flash, RAM, and OTP) as well as external memories. STM32 Programmer Target connection # On the original development boards, please select ST-LINK interface, and then select either SWD or JTAG port. If the custom board has a USB port with Device Firmware Update mode, it can be connected on the USB interface. Before pressing Connect on the software, find on the board to press and hold the Boot button (Boot0 or Boot1) and press Reset button (NRST) to make device run into DFU mode. Different connections Erase and Program # Once connected to a target, the memory sectors are displayed in the right-hand panel showing the start address and the size of each sector. To erase one or more sectors, select them in the first column and then click on the Erase selected sectors button. To download firmware to the target chip, select the Erasing & Programming tab. Click on the browse button and select the file to be programmed. The file format supported are binary files ( .bin ), ELF files ( .elf , .axf , .out ), Intel hex files ( .hex ) and Motorola S-record files ( .srec ). In case of programming a binary file, the address must be set. Other features # Other advanced features will be covered in other posts. Here is the list of those features: Option Bytes CPU Instruction debug Serial Wire View Fault Analyzer External Flash programming Program a binary file STM32CubeMonitor # Download STM32CubeMonitor STM32CubeMonitor Guide The STM32CubeMonitor helps to fine-tune and diagnose STM32 applications at run-time by reading and visualizing their variables in real-time. It provides a flow-based graphical editor to build custom dashboards simply, and quickly add widgets such as gauges, bar graphs and plots. With non-intrusive monitoring, STM32CubeMonitor preserves the real-time behavior of applications, and perfectly complements traditional debugging tools to perform application profiling. This tool use SWD/JTAG interface to access the memory addresses and read their value. The block editor When start the tool, there is a basic flow created with: Start/ Stop/ Clear buttons myVariables block holds the addresses under monitoring myProbe_Out block has configs to connect to the target device through debug interface myProbe_In block has script to read the value of the addresses listed in the myVariables block myVariables processing block read the captured value and process it myChart displays the dashboard which visualizes the processed data To configure a block, double-click on it, and follow the guide. The steps go through file selection, variable list, connect probe, and assign probe. To demonstrate how it works, we will visualize the counter variable which is defined as a global variable in the main.c file. This variable is creased every 100 ms in the main while loop. Select variable Double click on the myVariables node, and add the .elf file, select counter variable. Configure the variable block Select probe Connect the target board via ST-LINK or other SWD/ JTAG compatible debugger. The debugger will be shown as a probe in the myProble_Out node. You can choose the same proble for the myProbe_In node. Configure the probe block The chart can be drawn in line or bar chart. At this time, just use a default one. Deploy and run the Dashboard Finally, press on Deploy to configure the probes, and then click on Dashboard to show the graphical interface. Start button will send start message to the probe and variable processing block. The captured data will be drawn on the chart. The interactive dashboard Other tools # There are many other tools that work on ARM cores. I will have other posts to share about those tools such as Cross-Compiler, Config File, Make File, or System View.","title":"Tools for developing, programming and debugging"},{"location":"blog/stm32/tools/#stm32-ecosystem","text":"A tool-chain is a set of programming tools that allow developers to: Configure the settings on the target MCU Write code and navigate inside source files of the project Inspect the code to show additional information about variables, function definitions, etc. Compile the source code to an executable application Program the target MCU Debug the application running on the target MCU Monitor the application on the target MCU The STM32Cube ecosystem is a complete software solution for STM32 microcontrollers and microprocessors. It has a complete tool chain and extended packages to well support developers on STM32 MCUs. STM32 Ecosystem STM32CubeMX , a configuration tool for any STM32 device. This easy-to-use graphical user interface generates initialization C code for Cortex-M cores and generates the Linux device tree source for Cortex-A cores. STM32CubeIDE , an Integrated Development Environment. Based on open-source solutions like Eclipse or the GNU C/C++ tool chain, this IDE includes compilation reporting features and advanced debug features. It also integrates additional features present in other tools from the ecosystem, such as the HW and SW initialization and code generation from STM32CubeMX. This software includes: Eclipse IDE \u2014 an open source code editor and manager which supports many plugins such as C/C++ Development Platform, GCC Cross-Compiler, GDB Hardware Debugger, Make and build scripts. GNU ARM Cross-compiler with ST patch for STM32 MCUs \u2014 a compiler that converts code to executable and linkable file (.elf) or binary file (.bin, .hex). GDB for inspecting, debugging the target application. STM32CubeProgrammer , a programming tool. It provides an easy-to-use and efficient environment for reading, writing and verifying devices and external memories via a wide variety of available communication media (JTAG, SWD, UART, USB DFU, I2C, SPI, CAN, etc.). STM32CubeMonitor , a monitoring tool. Powerful monitoring tools that help developers fine-tune the behavior and performance of their applications in real time. STM32Cube MCU and MPU packages , dedicated to each STM32 series. Packages offer all the required to be embedded software bricks to operate the available set of STM32 peripherals. They include drivers (HAL, low-layer, etc.), middleware, and lots of example code used in a wide variety of real-world use cases. STM32Cube expansion packages , for application-oriented solutions. Complementing and expanding the STM32Cube MCU Package offer with additional embedded software bricks, STM32 expansion packages come either from ST or approved partners to create an extensive and scalable embedded software offer around the STM32. 4 steps of an interactive development process","title":"STM32 Ecosystem"},{"location":"blog/stm32/tools/#stm32cubeide","text":"STM32CubeIDE is an advanced C/C++ development platform with peripheral configuration, code generation, code compilation, and debug features for STM32 microcontrollers and microprocessors. It is based on the Eclipse\u00ae/CDT framework and GCC tool chain for the development, and GDB for the debugging. It allows the integration of the hundreds of existing plugins that complete the features of the Eclipse\u00ae IDE. This tool includes the STM32CubeMX for code generation. At any time during the development, the user can return to the initialization and configuration of the peripherals or middleware and regenerate the initialization code with no impact on the user code written in the user blocks. STM32CubeIDE includes build and stack analyzers that provide the user with useful information about project status and memory requirements. STM32CubeIDE also includes standard and advanced debugging features including views of CPU core registers, memories, and peripheral registers, as well as live variable watch, Serial Wire Viewer interface, or fault analyzer. Other IDEs that support ARM Cortex: ARM\u00ae, Atollic TrueSTUDIO\u00ae: was bought by ST, included in STM32CubeIDE Keil\u2122, MDK-ARM\u2122: only free for STM32F0 and STM32L0 processes Altium\u00ae, TASKING\u2122 VX-toolset: paid license IAR\u2122, EWARM (IAR Embedded Workbench\u00ae): paid license","title":"STM32CubeIDE"},{"location":"blog/stm32/tools/#installation","text":"Download STM32CubeIDE STM32CubeIDE User Manual During the installation, please be sure to install ST-LINK and SEGGER J-Link drivers.","title":"Installation"},{"location":"blog/stm32/tools/#create-a-workspace","text":"When start the program, it will ask to select a directory as a workspace \u2014 the location to save projects. Consider to make new workspaces for different big projects. Select a workspace Workspace settings Each workspace has its own settings configured in the Windows \u2192 Preferences menu. General \u2192 Editor \u2192 Text Editor Due to the generated code from STM32CubeMX is 2-space tab width, it is better to configure the Text Editor to adapt with the tab width behavior: Displayed tab width: 2 Insert spaces for tabs: Checked Remove multiple spaces on backspace/delete: Checked C/C++ \u2192 Build \u2192 Code Analysis There are some options for under the. I recommended to enable some check for Potential Programming Problems : Assignment in condition: if ( a = b ){} Assignment to itself: var = var ; No return in a function which is declared to return a value: int func (){} Return without value: int func (){ return ;} Return the address of a local variable: int * func (){ int a ; return & a ;} Virtual method call in constructor/ destructor C/C++ \u2192 Code Style \u2192 Formatter Next is the formatting style: Create a new profile from K&R In the Indentation : Change Tab Policy to Space Only; then set Indentation size and Tab size both to 2. Indent is activated for all cases except empty lines In the Control Statement : Insert new line for all control statements Terminal Finally, it should increase the buffer for terminals in Terminal option to 1000 or more.","title":"Create a workspace"},{"location":"blog/stm32/tools/#create-a-project","text":"F411RE_Intro.zip When start a new STM32 project, IDE shows up the Device Finder screen first. There are options to select the target MCU/MPU by name , board , example , and cross-reference . Select the target MCU by name After selecting the microprocessor, it\u2019s time to name the project, and then select the targeted project type: STM32Cube : CubeMX will help you to configure the projects, and it also generates source code for all settings you choose. Refer to the Blink project using LL or HAL . In this option, you can choose the STM32Cube MCU packages version for the selected target. For example, it is STM32Cube FW_F4 V1.27.0 for the STM32F4 MCUs. Empty : you will start with minimal source code, and you have to configure the target chip manually. Refer to the Blink project using Register-based or CMSIS . Set name and select firmware package for a new project Press on Finish then IDE will run a screen named Device Configuration Tool from the STM32CubeMX tool, in there, it\u2019s easy to enable any supported features in graphical mode. If the selected target is a development board, this tool will ask to use a default system config for the target board \u2014 usually including ST-Link pins, on-board buttons, LEDs, USB connect.","title":"Create a project"},{"location":"blog/stm32/tools/#stm32cubemx","text":"STM32CubeMX User Manual STM32CubeMX is a graphical tool that allows a very easy configuration of STM32 microcontrollers and microprocessors, as well as the generation of the corresponding initialization C code for the Arm\u00ae Cortex\u00ae-M cores. STM32CubeMX allows the user to create, save and load previously saved projects. MCU configuration .ioc file is saved in the project folder, and user can open it in the STM32CubeMX for editing.","title":"STM32CubeMX"},{"location":"blog/stm32/tools/#pinout-configuration","text":"This tab shows available Components in categories or in A-Z list. Select on a component will show its Configuration screen. The large Pinout view shows a graphic representation of the pin assignment. Left-click to select the function, and Right-click to do extra actions such as assigning a custom name. The Pinout config screen","title":"Pinout Configuration"},{"location":"blog/stm32/tools/#clock-configuration","text":"This tab provides a schematic overview of the clock paths, clock sources, dividers, and multipliers. Drop-down menus and buttons can be used to modify the actual clock tree configuration, to meet the application requirements. IDE has ability to automatically calculate multipliers and dividers to provide requested frequency, user can set a desired frequency in the clock node, and press enter, then IDE will re-configure the PLL, prescaler. The frequency on each node can be locked via the right-click menu. The Clock config screen","title":"Clock Configuration"},{"location":"blog/stm32/tools/#project-manager","text":"This tab provides information about general project setting: to specify the project name, location, tool chain, and firmware version. It also has configs for code generation options such as the location of peripheral initialization code, library copy/link options, and to select templates for customized code. The Project config view","title":"Project Manager"},{"location":"blog/stm32/tools/#extra-tools","text":"There are some provided tools which can be used to analyze or estimate the power consumption. You can see the RUN/ SLEEP modes with different clock frequency, peripheral status, and duration. It has a chart to visualize the power consumption profile for better understanding. The Tools config view","title":"Extra Tools"},{"location":"blog/stm32/tools/#code-generation","text":"Generate code or Write your own code? High-level or Low-Level programming? There are many topics on the internet discussing about how to learn MCU though generated code or through self-written bare-metal/register-based code. Here is my opinion to learn MCU which I\u2019ve followed to get better understanding: First, start with bare-metal/ register-based programming This step requires you to read document carefully, to understand every bit of the hardware configurations and how they will work. At this step, you should work on small application only, on simple peripherals first. Second, work with Low-level Library (CMSIS, LL) At this step, you should use an abstraction layer to reduce your own code. This also makes your code portable, reusable, and usually more coverage rate. Low-Level Lib also uses register-based programming. You can use LL as reference for the first step. Cortex Microcontroller Software Interface Standard (CMSIS) can be used at this stage. ST also provides LL Library for this purpose. ST LL can be integrated in Code generation. Third, work with High-level Library (HAL) In more complicated projects, Hardware-Abstraction Layer (HAL) is used for a quick development. HAL is preferred to use in production as it is built and test in long time, and of course, it reduces time-to-market. However, HAL is big, and make your application slower. It\u2019s also hard to debug due to overriding or function pointers. ST provides HAL Lib, and this lib is integrated with Code generation. Another open source HAL for STM32 is libopencm3 . Refer to the Blink project to get the overview of what you have to do in either registered-based code or generated code. After configuring pins, save the settings first and then start generating code. Manually request to generate code by pressing Alt + K or choosing menu Project \u2192 Generate Code . The tool will create sub-folders and add necessary files into project. The general file structure is: Structure of generated code When chosen to use a Firmware Library in the project, IDE automatically uses ST Hardware Abstract Layer (HAL) library as the main way of controlling the processor and peripherals. HAL also makes use of Cortex Microcontroller Software Interface Standard (CMSIS) library to access processor\u2019s registers. In the Project Manager tab, it can change to use Low-Level (LL) library instead of HAL . Code dependency starts from the main.h source file. This file includes HAL files which eventually includes CMSIS files. The main function is called from the startup file startup_*.s . Code dependency A HAL driver includes the following set of files: File Description stm32f4xx_hal.h/.c This file is used for HAL initialization and contains DBGMCU, Remap and Time Delay based on SysTick APIs. This also include stm32f4xx_hal_def.h . stm32f4xx_hal_def.h Common HAL resources such as common define statements, enumerations, structures and macros. This includes CMSIS headers. stm32f4xx_hal_ppp.h/.c Main peripheral/module driver file. It includes the APIs that are common to all STM32 devices, example: stm32f4xx_hal_adc.c , stm32f4xx_hal_irda.c stm32f4xx_hal_ppp_ex.h/.c Extension file of a peripheral/module driver. It includes the specific APIs for a given part number or family, as well as the newly defined APIs that overwrite the default generic APIs if the internal process is implemented in different way, for example: stm32f4xx_hal_adc_ex.c , stm32f4xx_hal_flash_ex.c . The minimum files required to build an application using the HAL are listed in the table below: File Description startup_stm32f4xx.s Tool chain specific file that contains reset handler and exception vectors. For some tool chains, it allows adapting the stack/heap size to fit the application requirements system_stm32f4xx.c This file contains SystemInit() which is called at startup just after reset and before branching to the main program. It does not configure the system clock at startup (contrary to the standard library). This is to be done using the HAL APIs in the user files. It allows relocating the vector table in internal SRAM. stm32f4xx_hal_conf.h This file allows the user to customize the HAL drivers for a specific application. It is not mandatory to modify this configuration. The application can use the default configuration without any modification. This call to STM32F0 HAL headers. stm32f4xx_hal_msp.c This file contains the MSP initialization and de-initialization (main routine and callbacks) of the peripheral used in the user application. stm32f4xx_it.h/.c This file contains the exceptions handler and peripherals interrupt service routine, and calls HAL_IncTick() at regular time intervals to increment a local variable (declared in stm32f0xx_hal.c ) used as HAL time base. By default, this function is called each 1ms in SysTick ISR. The PPP_IRQHandler() routine must call HAL_PPP_IRQHandler() if an interrupt based process is used within the application. main.h/.c This file contains the main program routine, mainly: \u2022 call to HAL_Init() \u2022 set system clock configuration declare peripheral HAL initialization user application code.","title":"Code generation"},{"location":"blog/stm32/tools/#add-user-code","text":"User code sections are marked with a pair of phrases /* USER CODE BEGIN x */ and /* USER CODE END x */ . User code inside those marks are kept remaining during code generation. I am going to add a variable counter with type of char , then inside the main while loop in the main() function, increase it by 1 after 100ms. Don\u2019t mind the HAL function at this time. /* USER CODE BEGIN PV */ char counter = 0 ; /* USER CODE END PV */ int main ( void ) { /* other setup function */ /* USER CODE BEGIN WHILE */ while ( 1 ) { counter ++ ; HAL_Delay ( 100 ); /* USER CODE END WHILE */ /* USER CODE BEGIN 3 */ } /* USER CODE END 3 */ }","title":"Add user code"},{"location":"blog/stm32/tools/#compiler-options","text":"Project has options for the compiler under its properties. Right-click on the project name in the right panel, then select Properties menu. The default included folders are all the folders created in the project by the STM32CubeMX tool. There are also some symbols created for the project build, such DEBUG mode, the MCU name STM32F411xE , and the macro USE_HAL_DRIVER if the project is generated with HAL firmware. The including paths and symbols Then in the Build Options, there are options to be used by GCC compiler, GNU Linker, GNU Assembler. For details, you can refer to the Blink project. Build options","title":"Compiler options"},{"location":"blog/stm32/tools/#build-project","text":"Build the application by pressing Ctrl + B , or in menu Project \u2192 Build All . There are some reports about the resource usage to check after the compilation. The first thing it reports is the memory usage, in terms of RAM and FLASH free space. Build analyzer with memory usage report","title":"Build Project"},{"location":"blog/stm32/tools/#setup-debugger","text":"Before Run or Debug on the target chip, it is needed to configure the programming/ debugging interface. By default, the application code can be programmed through the debugger interface, therefore, in Run Config or Debug Config, there is a tab named Debugger to select: Debug Probe: ST-LINK GDB, ST-LINK OpenOCD, SEGGER J-LINK, or other available probes Interface: SWD or JTAG. If there are multiple boards connected, use debugger board Serial Number to choose the correct target Advanced features: Serial Wire Viewer: read data from MCU in a dedicated SWO pin, available on Cortext-M3 and above Live Expression: read out the value at a memory address without halting the CPU Setup Debugger","title":"Setup debugger"},{"location":"blog/stm32/tools/#run-mode","text":"In the Run Mode, IDE flashes the firmware via the Debugging interface, and then disconnect the debugger to make the target board run freely. Just use the menu Run \u2192 Run .","title":"Run Mode"},{"location":"blog/stm32/tools/#debug-mode","text":"Putting the target under the Debug Mode is to control its execution, step by step. Breakpoint is where the CPU will be halted and debugger will inspect its current status: registers, memory values. By default, the first breakpoint is right after entering the main function. The start address and the first break point can be set in the Startup tab in Debug Configurations. Startup option for debug When CPU is halted at a breakpoint, user can control the execution step by step, through the commands or buttons: Debug controls","title":"Debug Mode"},{"location":"blog/stm32/tools/#stm32cubeprogrammer","text":"Download STM32CubeProgrammer STM32CubeProgrammer User Manual STM32CubeProgrammer (previous name was ST-Link Utility) provides an easy-to-use and efficient environment for reading, writing and verifying device memory through both the debug interface (JTAG and SWD) and the bootloader interface (UART, USB DFU, I2C, SPI, and CAN). STM32CubeProgrammer offers a wide range of features to program STM32 internal memories (such as Flash, RAM, and OTP) as well as external memories. STM32 Programmer","title":"STM32CubeProgrammer"},{"location":"blog/stm32/tools/#target-connection","text":"On the original development boards, please select ST-LINK interface, and then select either SWD or JTAG port. If the custom board has a USB port with Device Firmware Update mode, it can be connected on the USB interface. Before pressing Connect on the software, find on the board to press and hold the Boot button (Boot0 or Boot1) and press Reset button (NRST) to make device run into DFU mode. Different connections","title":"Target connection"},{"location":"blog/stm32/tools/#erase-and-program","text":"Once connected to a target, the memory sectors are displayed in the right-hand panel showing the start address and the size of each sector. To erase one or more sectors, select them in the first column and then click on the Erase selected sectors button. To download firmware to the target chip, select the Erasing & Programming tab. Click on the browse button and select the file to be programmed. The file format supported are binary files ( .bin ), ELF files ( .elf , .axf , .out ), Intel hex files ( .hex ) and Motorola S-record files ( .srec ). In case of programming a binary file, the address must be set.","title":"Erase and Program"},{"location":"blog/stm32/tools/#other-features","text":"Other advanced features will be covered in other posts. Here is the list of those features: Option Bytes CPU Instruction debug Serial Wire View Fault Analyzer External Flash programming Program a binary file","title":"Other features"},{"location":"blog/stm32/tools/#stm32cubemonitor","text":"Download STM32CubeMonitor STM32CubeMonitor Guide The STM32CubeMonitor helps to fine-tune and diagnose STM32 applications at run-time by reading and visualizing their variables in real-time. It provides a flow-based graphical editor to build custom dashboards simply, and quickly add widgets such as gauges, bar graphs and plots. With non-intrusive monitoring, STM32CubeMonitor preserves the real-time behavior of applications, and perfectly complements traditional debugging tools to perform application profiling. This tool use SWD/JTAG interface to access the memory addresses and read their value. The block editor When start the tool, there is a basic flow created with: Start/ Stop/ Clear buttons myVariables block holds the addresses under monitoring myProbe_Out block has configs to connect to the target device through debug interface myProbe_In block has script to read the value of the addresses listed in the myVariables block myVariables processing block read the captured value and process it myChart displays the dashboard which visualizes the processed data To configure a block, double-click on it, and follow the guide. The steps go through file selection, variable list, connect probe, and assign probe. To demonstrate how it works, we will visualize the counter variable which is defined as a global variable in the main.c file. This variable is creased every 100 ms in the main while loop. Select variable Double click on the myVariables node, and add the .elf file, select counter variable. Configure the variable block Select probe Connect the target board via ST-LINK or other SWD/ JTAG compatible debugger. The debugger will be shown as a probe in the myProble_Out node. You can choose the same proble for the myProbe_In node. Configure the probe block The chart can be drawn in line or bar chart. At this time, just use a default one. Deploy and run the Dashboard Finally, press on Deploy to configure the probes, and then click on Dashboard to show the graphical interface. Start button will send start message to the probe and variable processing block. The captured data will be drawn on the chart. The interactive dashboard","title":"STM32CubeMonitor"},{"location":"blog/stm32/tools/#other-tools","text":"There are many other tools that work on ARM cores. I will have other posts to share about those tools such as Cross-Compiler, Config File, Make File, or System View.","title":"Other tools"},{"location":"blog/virtual-machine/","text":"","title":"Virtual Machine"},{"location":"blog/virtual-machine/docker/","tags":["virtual-machine","docker"],"text":"Docker gained so much popularity and adoption in the DevOps community in a short time because of the way it\u2019s developed for portability and designed for modern microservice architecture. Linux container # The concept of containers started way back in the 2000s. In fact, the roots go back to 1979 where chroot was introduced \u2014 it\u2019s a concept of changing the root directory of a process. In a typical virtualized environment, one or more virtual machines run on top of a physical server using a hypervisor like Hyper-V. Containers, on the other hand, run on top of operating systems\u2019 kernel \u2014 so called OS-level virtualization. A container is a Process When a process is started, it runs in a self-contained virtual space. However, it still interacts with external environment. If a process is isolated with all of its files, configurations to make it run and operate, it needs to be in a container, and a container actually do that. A container is basically a process with enough isolation of user-space components so that it gives a feeling of a separate operating system. A process and A container Docker # Docker evolved on Linux. A container is considered \u201cnative\u201d, if it can run directly on the host operating system. Therefore, Docker runs on Linux is a native docker container. To run a container on Windows, Docker has to create a Linux Virtual Machine using virtualization to emulate a Linux environment. This virtualization can be: VirtualBox (Docker Toolbox) Hyper-V backend or WSL2 backend (Docker Desktop) Install Docker on Windows On Windows, there are Windows (Server) Containers: Windows applications that run in isolated Windows environment. Windows Hyper-V can be used to run even native Windows containers, which is generally a source of confusion: Process Isolation: This is the \u201ctraditional\u201d isolation mode for containers. It is approximately the same as how Linux containers run on Linux Hyper-V isolation: This isolation mode offers enhanced security and broader compatibility between host and container versions. How Docker works # When Docker starts at the first time, Docker will create a Virtual Machine which runs a Linux OS. Open the Hyper-V Manager to see the configuration of that VM. Docker Desktop Virtual Machine This virtual machine is initialized from an ISO disk image located in C:\\Program Files\\Docker\\Docker\\resources\\docker-desktop.iso . Let\u2019s inspect the virtual machine by connecting it and access into its terminal: uname -a Linux 6a7ab2c7921c 5 .10.25-linuxkit #1 SMP Tue Mar 23 09:27:39 UTC 2021 x86_64 x86_64 x86_64 GNU/Linux It shows a Linux kernel version 5.10 in linuxkit repo! What is the linuxkit repo? linuxkit is a special kernel under development of Linux Kit team which provides a toolkit for building custom minimal, immutable Linux distributions. Read more in linuxkit . Docker Desktop Kernel Base components # Docker takes advantage of several features of the Linux kernel to deliver its functionality. Namespaces Docker makes use of kernel namespaces to provide the isolated workspace called the container . When container runs, Docker creates a set of namespaces for that container. These namespaces provide a layer of isolation. Each aspect of a container runs in a separate namespace and its access is limited to that namespace. Docker Engine uses the following namespaces on Linux: PID namespace for process isolation. NET namespace for managing network interfaces. IPC namespace for managing access to IPC resources. MNT namespace for managing file system mount points. UTS namespace for isolating kernel and version identifiers. Cgroups Docker also makes use of kernel control groups for resource allocation and isolation. A cgroup limits an application to a specific set of resources. Control groups allow Docker Engine to share available hardware resources to containers and optionally enforce limits and constraints. Docker Engine uses the following cgroups: Memory cgroup for managing accounting, limits and notifications. HugeTBL cgroup for accounting usage of huge pages by process group. CPU cgroup for managing user / system CPU time and usage. CPUSet cgroup for binding a group to specific CPU. Useful for real time applications and NUMA systems with localized memory per CPU. BlkIO cgroup for measuring & limiting amount of blckIO by group. net_cls and net_prio cgroup for tagging the traffic control. Devices cgroup for reading / writing access devices. Freezer cgroup for freezing a group. Useful for cluster batch scheduling, process migration and debugging without affecting prtrace . Union File Systems Union file systems operate by creating layers, making them very lightweight and fast. Docker Engine uses UnionFS to provide the building blocks for containers. Docker Engine can use multiple UnionFS variants, including AUFS, btrfs, vfs, and device mapper. Container Format Docker Engine combines the namespaces, control groups and UnionFS into a wrapper called a container format. The default container format is libcontainer . Here are main points about container: Containers share the host kernel Containers use the kernel ability to group processes for resource control Containers ensure isolation through namespaces Containers feel like lightweight VMs (lower footprint, faster), but are not Virtual Machines! When a container runs, it basically extracts the container image content then add its layers using UnionFS into the host kernel, in an isolated namespace, under a control group, and finally expose to user that isolated live running container. Inspect an image # To get an image, pull it from Docker Hub . Let get the latest Ubuntu image from https://hub.docker.com/_/ubuntu using image name ubuntu and the tag name latest : docker pull ubuntu:latest To export the downloaded image to a file, use save command as below: docker image save ubuntu > ubuntu.tar Extract the ubuntu.tar file to get its content: \u2502 repositories \u2502 manifest.json \u2502 X.json \u2502 \u2514\u2500\u2500\u2500X Y.json layer.tar VERSION The repositories has the SHA ID X of the image: repositories { \"ubuntu\" : { \"latest\" : \"X\" } } Then the manifest.json has information about the image configuration Y.json and its layers [\"X/layer.tar\"] . manifest.json [ { Config : \"Y.json\" , RepoTags : [ \"ubuntu:latest\" ], Layers : [ \"X/layer.tar\" ], }, ]; In the configure file Y.json , there are some more information that can be seen in clear text: Environment PATH Build Command Layers { \"architecture\" : \"amd64\" , \"config\" : { ... \"Env\" : [ \"PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\" ], \"Cmd\" : [ \"bash\" ], \"Image\" : \"sha256:Z\" , ... }, \"container\" : \"A\" , \"container_config\" : { ... \"Env\" : [ \"PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\" ], \"Cmd\" : [ \"/bin/sh\" , \"-c\" , \"#(nop) \" , \"CMD [\\\"bash\\\"]\" ], \"Image\" : \"sha256:Z\" , ... }, \"created\" : \"2021-06-17T23:31:29.779641053Z\" , \"docker_version\" : \"19.03.12\" , \"history\" : [ { \"created\" : \"2021-06-17T23:31:29.39657203Z\" , \"created_by\" : \"/bin/sh -c #(nop) ADD file:B in / \" }, { \"created\" : \"2021-06-17T23:31:29.779641053Z\" , \"created_by\" : \"/bin/sh -c #(nop) CMD [\\\"bash\\\"]\" , \"empty_layer\" : true } ], \"os\" : \"linux\" , \"rootfs\" : { \"type\" : \"layers\" , \"diff_ids\" : [ \"sha256:C\" ] } } And zipped files X\\layer.tar contain file system of each layer, which will be populated into the host kernel in an isolated namespace. File system in a layer That\u2019s how container works. Reference # https://medium.com/@BeNitinAgarwal/understanding-the-docker-internals-7ccb052ce9fe http://docker-saigon.github.io/post/Docker-Internals/","title":"Docker - Platform of Runnable Containers"},{"location":"blog/virtual-machine/docker/#linux-container","text":"The concept of containers started way back in the 2000s. In fact, the roots go back to 1979 where chroot was introduced \u2014 it\u2019s a concept of changing the root directory of a process. In a typical virtualized environment, one or more virtual machines run on top of a physical server using a hypervisor like Hyper-V. Containers, on the other hand, run on top of operating systems\u2019 kernel \u2014 so called OS-level virtualization. A container is a Process When a process is started, it runs in a self-contained virtual space. However, it still interacts with external environment. If a process is isolated with all of its files, configurations to make it run and operate, it needs to be in a container, and a container actually do that. A container is basically a process with enough isolation of user-space components so that it gives a feeling of a separate operating system. A process and A container","title":"Linux container"},{"location":"blog/virtual-machine/docker/#docker","text":"Docker evolved on Linux. A container is considered \u201cnative\u201d, if it can run directly on the host operating system. Therefore, Docker runs on Linux is a native docker container. To run a container on Windows, Docker has to create a Linux Virtual Machine using virtualization to emulate a Linux environment. This virtualization can be: VirtualBox (Docker Toolbox) Hyper-V backend or WSL2 backend (Docker Desktop) Install Docker on Windows On Windows, there are Windows (Server) Containers: Windows applications that run in isolated Windows environment. Windows Hyper-V can be used to run even native Windows containers, which is generally a source of confusion: Process Isolation: This is the \u201ctraditional\u201d isolation mode for containers. It is approximately the same as how Linux containers run on Linux Hyper-V isolation: This isolation mode offers enhanced security and broader compatibility between host and container versions.","title":"Docker"},{"location":"blog/virtual-machine/docker/#how-docker-works","text":"When Docker starts at the first time, Docker will create a Virtual Machine which runs a Linux OS. Open the Hyper-V Manager to see the configuration of that VM. Docker Desktop Virtual Machine This virtual machine is initialized from an ISO disk image located in C:\\Program Files\\Docker\\Docker\\resources\\docker-desktop.iso . Let\u2019s inspect the virtual machine by connecting it and access into its terminal: uname -a Linux 6a7ab2c7921c 5 .10.25-linuxkit #1 SMP Tue Mar 23 09:27:39 UTC 2021 x86_64 x86_64 x86_64 GNU/Linux It shows a Linux kernel version 5.10 in linuxkit repo! What is the linuxkit repo? linuxkit is a special kernel under development of Linux Kit team which provides a toolkit for building custom minimal, immutable Linux distributions. Read more in linuxkit . Docker Desktop Kernel","title":"How Docker works"},{"location":"blog/virtual-machine/docker/#base-components","text":"Docker takes advantage of several features of the Linux kernel to deliver its functionality. Namespaces Docker makes use of kernel namespaces to provide the isolated workspace called the container . When container runs, Docker creates a set of namespaces for that container. These namespaces provide a layer of isolation. Each aspect of a container runs in a separate namespace and its access is limited to that namespace. Docker Engine uses the following namespaces on Linux: PID namespace for process isolation. NET namespace for managing network interfaces. IPC namespace for managing access to IPC resources. MNT namespace for managing file system mount points. UTS namespace for isolating kernel and version identifiers. Cgroups Docker also makes use of kernel control groups for resource allocation and isolation. A cgroup limits an application to a specific set of resources. Control groups allow Docker Engine to share available hardware resources to containers and optionally enforce limits and constraints. Docker Engine uses the following cgroups: Memory cgroup for managing accounting, limits and notifications. HugeTBL cgroup for accounting usage of huge pages by process group. CPU cgroup for managing user / system CPU time and usage. CPUSet cgroup for binding a group to specific CPU. Useful for real time applications and NUMA systems with localized memory per CPU. BlkIO cgroup for measuring & limiting amount of blckIO by group. net_cls and net_prio cgroup for tagging the traffic control. Devices cgroup for reading / writing access devices. Freezer cgroup for freezing a group. Useful for cluster batch scheduling, process migration and debugging without affecting prtrace . Union File Systems Union file systems operate by creating layers, making them very lightweight and fast. Docker Engine uses UnionFS to provide the building blocks for containers. Docker Engine can use multiple UnionFS variants, including AUFS, btrfs, vfs, and device mapper. Container Format Docker Engine combines the namespaces, control groups and UnionFS into a wrapper called a container format. The default container format is libcontainer . Here are main points about container: Containers share the host kernel Containers use the kernel ability to group processes for resource control Containers ensure isolation through namespaces Containers feel like lightweight VMs (lower footprint, faster), but are not Virtual Machines! When a container runs, it basically extracts the container image content then add its layers using UnionFS into the host kernel, in an isolated namespace, under a control group, and finally expose to user that isolated live running container.","title":"Base components"},{"location":"blog/virtual-machine/docker/#inspect-an-image","text":"To get an image, pull it from Docker Hub . Let get the latest Ubuntu image from https://hub.docker.com/_/ubuntu using image name ubuntu and the tag name latest : docker pull ubuntu:latest To export the downloaded image to a file, use save command as below: docker image save ubuntu > ubuntu.tar Extract the ubuntu.tar file to get its content: \u2502 repositories \u2502 manifest.json \u2502 X.json \u2502 \u2514\u2500\u2500\u2500X Y.json layer.tar VERSION The repositories has the SHA ID X of the image: repositories { \"ubuntu\" : { \"latest\" : \"X\" } } Then the manifest.json has information about the image configuration Y.json and its layers [\"X/layer.tar\"] . manifest.json [ { Config : \"Y.json\" , RepoTags : [ \"ubuntu:latest\" ], Layers : [ \"X/layer.tar\" ], }, ]; In the configure file Y.json , there are some more information that can be seen in clear text: Environment PATH Build Command Layers { \"architecture\" : \"amd64\" , \"config\" : { ... \"Env\" : [ \"PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\" ], \"Cmd\" : [ \"bash\" ], \"Image\" : \"sha256:Z\" , ... }, \"container\" : \"A\" , \"container_config\" : { ... \"Env\" : [ \"PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\" ], \"Cmd\" : [ \"/bin/sh\" , \"-c\" , \"#(nop) \" , \"CMD [\\\"bash\\\"]\" ], \"Image\" : \"sha256:Z\" , ... }, \"created\" : \"2021-06-17T23:31:29.779641053Z\" , \"docker_version\" : \"19.03.12\" , \"history\" : [ { \"created\" : \"2021-06-17T23:31:29.39657203Z\" , \"created_by\" : \"/bin/sh -c #(nop) ADD file:B in / \" }, { \"created\" : \"2021-06-17T23:31:29.779641053Z\" , \"created_by\" : \"/bin/sh -c #(nop) CMD [\\\"bash\\\"]\" , \"empty_layer\" : true } ], \"os\" : \"linux\" , \"rootfs\" : { \"type\" : \"layers\" , \"diff_ids\" : [ \"sha256:C\" ] } } And zipped files X\\layer.tar contain file system of each layer, which will be populated into the host kernel in an isolated namespace. File system in a layer That\u2019s how container works.","title":"Inspect an image"},{"location":"blog/virtual-machine/docker/#reference","text":"https://medium.com/@BeNitinAgarwal/understanding-the-docker-internals-7ccb052ce9fe http://docker-saigon.github.io/post/Docker-Internals/","title":"Reference"},{"location":"blog/virtual-machine/hyper-v/","tags":["virtual-machine","hyper-v"],"text":"Virtualization # Virtualization allows to: Run software that requires an older version of Windows or non-Windows operating systems. Experiment with other operating systems. Hyper-V makes it very easy to create and remove different operating systems. Test software on multiple operating systems using multiple virtual machines. Hyper-V feature When enabling the Hyper-V feature on Windows OS, it actually makes modifications to the kernel allowing virtual machines to run alongside the rest of windows (type 1) similar to how Kernel-based Virtual Machine (KVM) works, as it is a kernel module on Linux. VirtualBox runs atop the guest kernel not alongside it (type 2) which is what separates the two types of hypervisors. Limitations # Programs that depend on specific hardware will not work well in a virtual machine, such as applications that require processing with GPUs, a music mixing applications that require sub-10ms timers. In addition, if Hyper-V enabled, those latency-sensitive, high-precision applications may also have issues running in the host. This is because with virtualization enabled, the host OS also runs on top of the Hyper-V virtualization layer, just as guest operating systems do . However, unlike guests, the host OS is special in that it has direct access to all the hardware, which means that applications with special hardware requirements can still run without issues in the host OS. Hypervisor types Hyper-V # Using the Hyper-V is mandatory to run Docker , but it reduces the Windows performance a bit. Older version of VMWare and VirtualBox can not run when Hyper-V is enabled. Newer versions can run along with Hyper-V, but performance is impacted. . Some sites say to use Add/Remove Features to turn the Hyper-V support off, but that seems like a big deal to do what should be a small thing. Windows has config in Boot up settings to load/ unload Hyper-V. If the current boot-up session of Windows has Hyper-V enabled, then make new boot ID by duplicating the current ID: bcdedit /copy { current } /d \"Hyper-V\" Then disable the Hyper-V in current boot ID: bcdedit /set { current } hypervisorlaunchtype off By that way, default boot-up will not load Hyper-V, but booting through \u201cHyper-V\u201d ID will get it enabled. To switch between boot ID, hold down the Shift key while clicking on the Restart menu. If Intel HAXM check tool is available, it can be used to check if Hyper-V is totally disabled: C:\\Program Files\\Intel\\HAXM>checktool.exe -v CPU vendor * GenuineIntel Intel64 supported * Yes VMX supported * Yes VMX enabled * Yes EPT supported * Yes NX supported * Yes NX enabled * Yes Hyper-V disabled * Yes OS version * Windows 10.0.17763 OS architecture * x86_64 Guest unoccupied * Yes. 0 guest(s) When Hyper-V disabled = No , some functions also are reported to not supported, such as VMX supported because VMX (Virtual Machine) can not be enabled on the Hypervisor layer. Reference # https://www.nakivo.com/blog/hyper-v-virtualbox-one-choose-infrastructure/","title":"Hyper-V on Windows"},{"location":"blog/virtual-machine/hyper-v/#virtualization","text":"Virtualization allows to: Run software that requires an older version of Windows or non-Windows operating systems. Experiment with other operating systems. Hyper-V makes it very easy to create and remove different operating systems. Test software on multiple operating systems using multiple virtual machines. Hyper-V feature When enabling the Hyper-V feature on Windows OS, it actually makes modifications to the kernel allowing virtual machines to run alongside the rest of windows (type 1) similar to how Kernel-based Virtual Machine (KVM) works, as it is a kernel module on Linux. VirtualBox runs atop the guest kernel not alongside it (type 2) which is what separates the two types of hypervisors.","title":"Virtualization"},{"location":"blog/virtual-machine/hyper-v/#limitations","text":"Programs that depend on specific hardware will not work well in a virtual machine, such as applications that require processing with GPUs, a music mixing applications that require sub-10ms timers. In addition, if Hyper-V enabled, those latency-sensitive, high-precision applications may also have issues running in the host. This is because with virtualization enabled, the host OS also runs on top of the Hyper-V virtualization layer, just as guest operating systems do . However, unlike guests, the host OS is special in that it has direct access to all the hardware, which means that applications with special hardware requirements can still run without issues in the host OS. Hypervisor types","title":"Limitations"},{"location":"blog/virtual-machine/hyper-v/#hyper-v","text":"Using the Hyper-V is mandatory to run Docker , but it reduces the Windows performance a bit. Older version of VMWare and VirtualBox can not run when Hyper-V is enabled. Newer versions can run along with Hyper-V, but performance is impacted. . Some sites say to use Add/Remove Features to turn the Hyper-V support off, but that seems like a big deal to do what should be a small thing. Windows has config in Boot up settings to load/ unload Hyper-V. If the current boot-up session of Windows has Hyper-V enabled, then make new boot ID by duplicating the current ID: bcdedit /copy { current } /d \"Hyper-V\" Then disable the Hyper-V in current boot ID: bcdedit /set { current } hypervisorlaunchtype off By that way, default boot-up will not load Hyper-V, but booting through \u201cHyper-V\u201d ID will get it enabled. To switch between boot ID, hold down the Shift key while clicking on the Restart menu. If Intel HAXM check tool is available, it can be used to check if Hyper-V is totally disabled: C:\\Program Files\\Intel\\HAXM>checktool.exe -v CPU vendor * GenuineIntel Intel64 supported * Yes VMX supported * Yes VMX enabled * Yes EPT supported * Yes NX supported * Yes NX enabled * Yes Hyper-V disabled * Yes OS version * Windows 10.0.17763 OS architecture * x86_64 Guest unoccupied * Yes. 0 guest(s) When Hyper-V disabled = No , some functions also are reported to not supported, such as VMX supported because VMX (Virtual Machine) can not be enabled on the Hypervisor layer.","title":"Hyper-V"},{"location":"blog/virtual-machine/hyper-v/#reference","text":"https://www.nakivo.com/blog/hyper-v-virtualbox-one-choose-infrastructure/","title":"Reference"},{"location":"blog/virtual-machine/notes/","tags":["virtual-machine","notes"],"text":"Automount VMWare shared folder # Unlike Virtual Box, VMWare does not automatically mount shared folders. Here are steps to make it work at system startup: Make sure the mounting target folder exists. If not: sudo mkdir /mnt/hgfs Edit /etc/fstab and add: vmhgfs-fuse /mnt/hgfs fuse defaults,allow_other 0 0 Then remount: sudo mount -a A faster way, but be carefull of the redirection syntax: must use >> to append a new line : sudo mkdir -p /mnt/hgfs && \\ sudo bash -c 'echo \\ \"vmhgfs-fuse /mnt/hgfs fuse defaults,allow_other 0 0\" \\ >> /etc/fstab' Mount shared network folder in Ubuntu # This is for mounting Samba shared-folder in Linux. Install necessary packages: sudo apt install -y \\ smbclient \\ cifs-utils Then use smbclient to probe sharing points: smbclient -L //<ip> Create a mount point: sudo mkdir -p /media/SharedFolder Then mount: sudo mount -t cifs \\ -o user = <username>,pass = <password>,uid = <uid>,gid = <gid> \\ //<ip>/<share_point> \\ <mount_point> Run id to see ID of user and groups of the current user. Install VirtualBox Guest Additions CD Image from Terminal # Install build kernel modules: sudo apt install -y dkms build-essential linux-headers-generic linux-headers- $( uname -r ) Insert Guest Additions CD Images and mount it: sudo mkdir - /media/cdrom sudo mount /dev/cdrom /media/cdrom Change to the sudo account and run the build script: ./VBoxLinuxAdditions.run VirtualBox Guest Additions functions only works in GUI desktop! Compact Virtual Disk # Install zerofree in the virtual machine Boot into Recovery mode Press ESC while boot up to see Grub menu. Select Advanced options \u2192 (recovery mode) \u2192 root . Press Enter afterwards when Press Enter for maintenance appears on your screen. You\u2019ll be given a terminal prompt. Run zerofree on the target disk, such as /dev/sda2 : zerofree -v /dev/sda2 Error: filesystem is mounted rw Remount system in ro mode, and run zerofree again: echo \"u\" > /proc/sysrq-trigger zerofree -v /dev/sda2 Shutdown the machine poweroff Compress the disk file VBoxManage modifyhd --compact /path/to/VDI/VM.vdi","title":"Notes for Virtual Machines"},{"location":"blog/virtual-machine/notes/#automount-vmware-shared-folder","text":"Unlike Virtual Box, VMWare does not automatically mount shared folders. Here are steps to make it work at system startup: Make sure the mounting target folder exists. If not: sudo mkdir /mnt/hgfs Edit /etc/fstab and add: vmhgfs-fuse /mnt/hgfs fuse defaults,allow_other 0 0 Then remount: sudo mount -a A faster way, but be carefull of the redirection syntax: must use >> to append a new line : sudo mkdir -p /mnt/hgfs && \\ sudo bash -c 'echo \\ \"vmhgfs-fuse /mnt/hgfs fuse defaults,allow_other 0 0\" \\ >> /etc/fstab'","title":"Automount VMWare shared folder"},{"location":"blog/virtual-machine/notes/#mount-shared-network-folder-in-ubuntu","text":"This is for mounting Samba shared-folder in Linux. Install necessary packages: sudo apt install -y \\ smbclient \\ cifs-utils Then use smbclient to probe sharing points: smbclient -L //<ip> Create a mount point: sudo mkdir -p /media/SharedFolder Then mount: sudo mount -t cifs \\ -o user = <username>,pass = <password>,uid = <uid>,gid = <gid> \\ //<ip>/<share_point> \\ <mount_point> Run id to see ID of user and groups of the current user.","title":"Mount shared network folder in Ubuntu"},{"location":"blog/virtual-machine/notes/#install-virtualbox-guest-additions-cd-image-from-terminal","text":"Install build kernel modules: sudo apt install -y dkms build-essential linux-headers-generic linux-headers- $( uname -r ) Insert Guest Additions CD Images and mount it: sudo mkdir - /media/cdrom sudo mount /dev/cdrom /media/cdrom Change to the sudo account and run the build script: ./VBoxLinuxAdditions.run VirtualBox Guest Additions functions only works in GUI desktop!","title":"Install VirtualBox Guest Additions CD Image from Terminal"},{"location":"blog/virtual-machine/notes/#compact-virtual-disk","text":"Install zerofree in the virtual machine Boot into Recovery mode Press ESC while boot up to see Grub menu. Select Advanced options \u2192 (recovery mode) \u2192 root . Press Enter afterwards when Press Enter for maintenance appears on your screen. You\u2019ll be given a terminal prompt. Run zerofree on the target disk, such as /dev/sda2 : zerofree -v /dev/sda2 Error: filesystem is mounted rw Remount system in ro mode, and run zerofree again: echo \"u\" > /proc/sysrq-trigger zerofree -v /dev/sda2 Shutdown the machine poweroff Compress the disk file VBoxManage modifyhd --compact /path/to/VDI/VM.vdi","title":"Compact Virtual Disk"},{"location":"blog/virtual-machine/serial-ports/","tags":["virtual-machine","serial"],"text":"Serial Connection # There are many cases that a guest machine need to communicate with an external device or host application through a Serial COM port. Since USB-to-COM devices can be connected to the guest machine directly, other real native COM devices must be connected to the host machine first. Virtual machines have bridges which connect to serial port and forward data to guest machines. However, if virtual machine has connected to a port, host machine can not access it anymore. A virtual pair of ports will allow a host application to send data to a guest application as show in below diagram of connection methods. Serial port connections Bridge ports # Virtual Machines have a setting screen for Serial Ports. It does not create a new COM port to connect to. It, actually, works as a bridge between a COM port on the host machine and a COM port on the guest machine. Virtual Box serial settings VMware serial settings Windows provides legacy names only for COM ports #1 through to #9. For all other COM ports, the full device naming convention under Windows must be used. So starting from COM10, the field Path/Address has to be filled with \\\\.\\COM10 . There are also some other modes: Pipe File TCP Virtual COM port # A pair of virtual COM ports can be used to feed data to a COM port on a virtual machine. The Null-modem emulator is an open source kernel-mode virtual serial port driver for Windows, available freely under GPL license. Download com0com emulator and run its setup to add pairs of COM ports, such as COM15-COM16. Then, you can connect to the COM15, to feed data to the COM1 of the virtual machine. Some pairs of virtual COM ports Virtual Serial Port Driver # Paid product, with trial time This software is far better than the null-modem Virtual COM port, because it adds many advanced features: Splitting port (1-to-N) Joining ports (N-to-1) Port bundles (hub) Port merging (bi-direction) Virtual Serial Port Driver","title":"Use Serial Ports on Virtual Machines"},{"location":"blog/virtual-machine/serial-ports/#serial-connection","text":"There are many cases that a guest machine need to communicate with an external device or host application through a Serial COM port. Since USB-to-COM devices can be connected to the guest machine directly, other real native COM devices must be connected to the host machine first. Virtual machines have bridges which connect to serial port and forward data to guest machines. However, if virtual machine has connected to a port, host machine can not access it anymore. A virtual pair of ports will allow a host application to send data to a guest application as show in below diagram of connection methods. Serial port connections","title":"Serial Connection"},{"location":"blog/virtual-machine/serial-ports/#bridge-ports","text":"Virtual Machines have a setting screen for Serial Ports. It does not create a new COM port to connect to. It, actually, works as a bridge between a COM port on the host machine and a COM port on the guest machine. Virtual Box serial settings VMware serial settings Windows provides legacy names only for COM ports #1 through to #9. For all other COM ports, the full device naming convention under Windows must be used. So starting from COM10, the field Path/Address has to be filled with \\\\.\\COM10 . There are also some other modes: Pipe File TCP","title":"Bridge ports"},{"location":"blog/virtual-machine/serial-ports/#virtual-com-port","text":"A pair of virtual COM ports can be used to feed data to a COM port on a virtual machine. The Null-modem emulator is an open source kernel-mode virtual serial port driver for Windows, available freely under GPL license. Download com0com emulator and run its setup to add pairs of COM ports, such as COM15-COM16. Then, you can connect to the COM15, to feed data to the COM1 of the virtual machine. Some pairs of virtual COM ports","title":"Virtual COM port"},{"location":"blog/virtual-machine/serial-ports/#virtual-serial-port-driver","text":"Paid product, with trial time This software is far better than the null-modem Virtual COM port, because it adds many advanced features: Splitting port (1-to-N) Joining ports (N-to-1) Port bundles (hub) Port merging (bi-direction) Virtual Serial Port Driver","title":"Virtual Serial Port Driver"},{"location":"blog/yocto/concepts/","tags":["yocto"],"text":".op { font-size: 1.2em !important; color: red !important; background-color: lightyellow !important; } Operator # Hard Assignment = Occur immediately as the statement is parsed. VARIABLE = \"value\" VARIABLE = 'value with \" in it' Soft (Default) Assignment ?= Define a variable if it is undefined when the statement is parsed. If the variable is defined, the soft assignment is lost. If multiple soft assignments get parsed, the first one is used. VARIABLE ? = \"default value\" VARIABLE = \"set value\" VARIABLE ? = \"default value\" # this does nothing Weak (Default) Assignment ??= Delay the assignment at the end of parsing process rather than immediately. If multiple weak assignments get parsed, the last one is used. VARIABLE ? = \"value 1\" # this wins VARIABLE ? = \"value 2\" VARIABLE ?? = \"value 1\" VARIABLE ?? = \"value 2\" # this wins VARIABLE ? = \"value 1\" # this wins VARIABLE ?? = \"value 2\" VARIABLE ?? = \"value 1\" VARIABLE ? = \"value 2\" # this wins VARIABLE ?? = \"value 1\" VARIABLE = \"value 3\" # this always wins VARIABLE ? = \"value 2\" Variable expansion ${} Refer to the value of a variable. The = operator does not immediately expand the variable reference. The expansion is deferred until the variable is used. The := immediately expand the variable reference when is parsed. A = \" ${ B } hello\" # A = linux world hello B = \" ${ C } world\" # B = world C = \"linux\" A : = \" ${ B } hello\" # A = ${B} hello B : = \" ${ C } world\" # B = ${C} world C = \"linux\" A = \"11\" B = \" ${ A } \" # B = 22 when B is used A = \"22\" C = \" ${ A } \" # C = 22 when C is used A = \"11\" B : = \" ${ A } \" # B = 11 immediately A = \"22\" C = \" ${ A } \" # C = 22 when C is used Appending += , .= , _append= Append values with or without a space. += automatically adds a space, but .= and _append= do not do that. A = \"hello\" A += \"my\" # A = hello my A . = \"sunny\" # A = hello mysunny A_append = \"world\" # A = hello mysunnyworld Prepending =+ , =. , _prepend= Prepend values with or without a space. =+ automatically adds a space, but =. and _prepend= do not do that. A = \"hello\" A = + \"my\" # A = my hello A = . \"sunny\" # A = sunnymy hello A_prepend = \"world\" # A = worldsunnymy hello Removal _remove= Remove all occurrences of a value in a list. A = \"123 456 123 789 123\" A_remove = \"123\" # A = \" 456 789 \", note the spaces Overriding syntax _append= , _prepend= , _remove= Provide guaranteed operations, as compared to += , =+ . 1st parsed A += \"world\" # does not work, A is undefined 2nd parsed A = \"hello\" # A = hello when A is used However, using overriding syntax give a good result: 1st parsed A_append = \" world\" # keep this action when A is used 2nd parsed A = \"hello\" # A = hello world when A is used Check the value After all configurations are parsed: bitbake <target/recipe> -e | grep ^VARIABLE = Layer # A layer is a logical collection of related recipes. Layer name should start with meta- to follow Yocto\u2019s naming convention. Each layer has a priority, which is used by bitbake to decide which layer takes precedence if there are recipe files with the same name in multiple layers. A higher numeric value represents a higher priority. Despite most of the customization can be done with the local.conf configuration file, it is not possible to: * Store recipes for your own software projects * Create your own images * Consolidate patches/modifications to other people\u2019s recipes * Add a new custom kernel * Add a new machine Depending on the type of layer, add the content: If the layer is adding support for a machine, add the machine configuration in conf/machine/ If the layer is adding distro policy, add the distro configuration in conf/distro/ If the layer introduces new recipes, put the recipes you need in recipes-* subdirectories of the layer directory. Recipes are divided into categories {\u00bbbut hard to decide\u00bb} Create new layer There are two ways to create your own layer. Manually mkdir meta-my-layer cp meta-my-layer Copy poky/meta-skeleton/conf/layer.conf to new layer: mkdir conf && cd conf cp ../../poky/meta-skeleton/conf/layer.conf . Using script bitbake-layers create-layer meta-my-layer The tool automates layer creation by setting up a subdirectory with a layer.conf configuration file, a recipes-example subdirectory that contains an example.bb recipe, a licensing file, and a README. Default priority of the layer is 6 . meta-my-layer/ \u251c\u2500\u2500 conf \u2502 \u2514\u2500\u2500 layer.conf \u251c\u2500\u2500 COPYING.MIT \u251c\u2500\u2500 README \u2514\u2500\u2500 recipes-example \u2514\u2500\u2500 example \u2514\u2500\u2500 example_0.1.bb To check layer compatibility, run yocto-check-layer : yocto-check-layer meta-my-layer Layer configs Note the BBFILE_PRIORITY_ meta-my-layer/conf/layer.conf # We have a conf and classes directory, add to BBPATH BBPATH . = \": ${ LAYERDIR } \" # We have recipes-* directories, add to BBFILES BBFILES += \" ${ LAYERDIR } /recipes-*/*/*.bb ${ LAYERDIR } /recipes-*/*/*.bbappend\" BBFILE_COLLECTIONS += \"my-layer\" BBFILE_PATTERN_my-layer = \"^ ${ LAYERDIR } /\" BBFILE_PRIORITY_my-layer = \"6\" # This should only be incremented on significant changes that will # cause compatibility issues with other layers LAYERVERSION_my-layer = \"1\" LAYERDEPENDS_my-layer = \"core\" LAYERSERIES_COMPAT_my-layer = \"dunfell\" Image # Image is a top level recipe. It inherits the image.bbclass . Create new Image # You often need to create your own Image recipe in order to add new packages or functionality. There are 2 ways: Create an image from scratch The simplest way is to inherit the core-image bbclass, as it provides a set of image features that can be used very easily. Create an image directory mkdir -p recipes-examples/images Create the image recipe nano recipes-examples/images/lwl-image.bb lwl-image.bb SUMMARY = \"A small boot image for LWL learners\" LICENSE = \"MIT\" # start from core-image inherit core-image # core files for basic console boot IMAGE_INSTALL = \"packagegroup-core-boot\" # add our needed applications #IMAGE_INSTALL += \"userprog\" Extend an existing recipe (preferable) When an image mostly fits our needs, and we need to do minor adjustments on it, it is very convenient to reuse its code. This makes code maintenance easier and highlights the functional differences. nano recipes-examples/images/lwl-image-reuse.bb lwl-image.bb # select base image require recipes-core/images/core-image-minimal.bb # append our needed packages, use overriding syntax #IMAGE_INSTALL_append = \" userprog\" Package group # A package group is a set of packages that can be included on any image. Using a package group name in IMAGE_INSTALL variable install all the packages defined by the package group into the root file system of your target image. There are many package groups. There are present in subdirectories named packagegroups . They are recipe files(.bb) and starts with packagegroup- . For example, packagegroup-core-boot : Provides the minimum set of packages necessary to create a bootable image with console. ls poky/meta/recipes-core/packagegroups/ nativesdk-packagegroup-sdk-host.bb packagegroup-core-standalone-sdk-target.bb packagegroup-base.bb packagegroup-core-tools-debug.bb packagegroup-core-boot.bb packagegroup-core-tools-profile.bb packagegroup-core-buildessential.bb packagegroup-core-tools-testapps.bb packagegroup-core-eclipse-debug.bb packagegroup-cross-canadian.bb packagegroup-core-nfs.bb packagegroup-go-cross-canadian.bb packagegroup-core-sdk.bb packagegroup-go-sdk-target.bb packagegroup-core-ssh-dropbear.bb packagegroup-self-hosted.bb packagegroup-core-ssh-openssh.bb Image features # Another method for customizing your image is to enable or disable high-level image features by using the IMAGE_FEATURES and EXTRA_IMAGE_FEATURES variables. Image features is the map of features to package groups. IMAGE_FEATURES / EXTRA_IMAGE_FEATURES is made to enable special features for your image, such as empty password for root, debug image, special packages, x11, splash, ssh-server. Best practice is to: Use IMAGE_FEATURES from a recipe Use EXTRA_IMAGE_FEATURES from local.conf For example: meta/classes/core-image.bbclass FEATURE_PACKAGES_x11 = \"packagegroup-core-x11\" FEATURE_PACKAGES_x11-base = \"packagegroup-core-x11-base\" FEATURE_PACKAGES_x11-sato = \"packagegroup-core-x11-sato\" FEATURE_PACKAGES_tools-debug = \"packagegroup-core-tools-debug\" FEATURE_PACKAGES_eclipse-debug = \"packagegroup-core-eclipse-debug\" FEATURE_PACKAGES_tools-profile = \"packagegroup-core-tools-profile\" FEATURE_PACKAGES_tools-testapps = \"packagegroup-core-tools-testapps\" FEATURE_PACKAGES_tools-sdk = \"packagegroup-core-sdk packagegroup-core-standalone-sdk-target\" FEATURE_PACKAGES_nfs-server = \"packagegroup-core-nfs-server\" FEATURE_PACKAGES_nfs-client = \"packagegroup-core-nfs-client\" FEATURE_PACKAGES_ssh-server-dropbear = \"packagegroup-core-ssh-dropbear\" FEATURE_PACKAGES_ssh-server-openssh = \"packagegroup-core-ssh-openssh\" FEATURE_PACKAGES_hwcodecs = \" ${ MACHINE_HWCODECS } \" poky/meta/recipes-sato/images/core-image-sato.bb IMAGE_FEATURES += \"splash package-management x11-base x11-sato ssh-server-dropbear hwcodecs\" inherit core-image build/conf/local.conf EXTRA_IMAGE_FEATURES ? = \"debug-tweaks\" Some Features debug-tweaks Debug tweaks enables password-less login for the root user. You must remove the debug-tweaks feature from production image. read-only-rootfs Read-only RootFS helps to reduce wear on flash memory, and to eliminate system file corruption. splash Boot splash screen tools-debug Installs debugging tools such as strace and gdb. tools-sdk Installs a full SDK that runs on the device. Image options # Some other options also control the image content. IMAGE_FSTYPES Determines the root filesystem image type. If more than one format is specified, one image per format will be generated. Image formats instructions are delivered in Poky: meta/classes/image_types.bbclass If you have a particular layout on your storage (for example bootloader location on an SD card), you may want to create your own image type. This is done through a class that inherits from image_types . It has to define a function named IMAGE_CMD_<type> . Example: sdcard_image-rpi.bbclass in meta-raspberrypi IMAGE_NAME The name of the output image files minus the extension. For example: IMAGE_NAME = \"${IMAGE_BASENAME}-${MACHINE}-${DATETIME}\" IMAGE_MANIFEST This file lists all the installed packages that make up the image. IMAGE_LINGUAS Specifies the list of locales to install into the image during the root filesystem construction process. For example: IMAGE_LINGUAS = \"en-us\" Recipe # Recipes are fundamental components in the Yocto Project environment. A Yocto/OpenEmbedded recipe is a text file with file extension .bb . Each software component built by the OpenEmbedded build system requires a recipe to define the component. A recipe contains information about single piece of software. Information such as: Location from which to download the unaltered source Any patches to be applied to that source (if needed) Special configuration options to apply How to compile the source files and How to package the compiled output Poky includes several classes that abstract the process for the most common development tools as projects based on Autotools, CMake, and QMake. File Format: <base_name>_<version>.bb Use lower-cased characters and do not include the reserved suffixes -native , -cross , -initial , or -dev . List all recipes: bitbake-layers show-recipes Find a recipe in added layers: bitbake-layers show-recipes <recipe> Bitbake # Yocto/OpenEmbedded\u2019s build tool bitbake parses a recipe and generates list of tasks that it can execute to perform the build steps: do_fetch : Fetches the source code do_unpack : Unpacks the source code into a working directory do_patch : Locates patch files and applies them to the source code do_configure : Configures the source by enabling and disabling any build-time and configuration options for the software being built do_compile : Compiles the source in the compilation directory do_install : Copies files from the compilation directory to a holding area do_package : Analyzes the content of the holding area and splits it into subsets based on available packages and files do_package_write_rpm : Creates the actual RPM packages and places them in the Package Feed area Generally, the only tasks that the user needs to specify in a recipe are do_configure , do_compile and do_install ones. The remaining tasks are automatically defined by the YP build system The above task list is in the correct dependency order. They are executed from top to bottom. You can use the -c argument to execute the specific task of a recipe. bitbake -c compile <recipe> Stage 1: Fetching Code (do_fetch) Fetching is controlled mainly through the SRC_URI variable. Bitbake supports fetching source code from git, svn, https, ftp, etc. URI scheme syntax: scheme://url;param1;param2 Example: SRC_URI = \"https://busybox.net/downloads/busybox-${PV}.tar.bz2\" Stage 2: Unpacking (do_unpack) All local files found in SRC_URI are copied into the recipe\u2019s working directory, in $BUILDDIR/tmp/work/ . When extracting a tarball, BitBake expects to find the extracted files in a directory named <application>-<version> . This is controlled by the S variable. Stage 3: Patching Code (do_patch) Sometimes it is necessary to patch code after it has been fetched. Any files mentioned in SRC_URI whose names end in .patch or .diff or compressed versions of these suffixes (e.g. diff.gz ) are treated as patches. The do_patch task automatically applies these patches. The build system should be able to apply patches with the -p1 option (i.e. one directory level in the path will be stripped off). If your patch needs to have more directory levels stripped off, specify the number of levels using the striplevel option in the SRC_URI entry for the patch. Stage 4: Configuration (do_configure) Most software provides some means of setting build-time configuration options before compilation. Typically, setting these options is accomplished by running a configured script with options, or by modifying a build configuration file. Autotools: If your source files have a configure.ac file, then your software is built using Autotools. CMake: If your source files have a CMakeLists.txt file, then your software is built using CMake If your source files do not have a configure.ac or CMakeLists.txt file, you normally need to provide a do_configure task in your recipe unless there is nothing to configure. Stage 5: Compilation (do_compile) do_compile task happens after source is fetched, unpacked, and configured. No package output Check the do_compile in Bitbake file to make sure the compiling commands are correct, including the value of expanded variables. Check the targets and dependencies in Makefile also. Stage 6: Installation (do_install) After compilation completes, BitBake executes the do_install task. During do_install, the task copies the built files along with their hierarchy to locations that would mirror their locations on the target device. install keyword install not only copies files but also changes its ownership and permissions and optionally removes debugging symbols from executables. It combines cp with chown , chmod and strip . Not installed package When a required package is not installed, do_rootfs will fail with errors. The most happened error is Could not invoke dnf or No match for argument: , which is caused by do_install was not run, or by do_compile did not produce any output. Check the do_compile and do_install in Bitbake file to make sure it call to oe-runmake if Makefile is used. Check the targets and dependencies in Makefile also. Stage 7: Packaging (do_package) The do_package task splits the files produced by the recipe into logical components. Even software that produces a single binary might still have debug symbols, documentation, and other logical components that should be split out. The do_package task ensures that files are split up and packaged correctly. Bitbake Variables S : Contains the unpacked source files for a given recipe D : The destination directory (root directory of where the files are installed, before creating the image) WORKDIR : The location where the OpenEmbedded build system builds a recipe (i.e. does the work to create the package). PN : The name of the recipe used to build the package PV : The version of the recipe used to build the package PR : The revision of the recipe used to build the package. Example 1: Add userprog recipe Create userprog recipe by adding its folder and bb file: recipes-example \u2514\u2500\u2500 userprog \u251c\u2500\u2500 files \u2502 \u251c\u2500\u2500 COPYING.MIT \u2502 \u2514\u2500\u2500 userprog.c \u2514\u2500\u2500 userprog_0.1.bb Add code to userprog.c : #include <stdio.h> int main () { printf ( \"Hello World from \" ); printf ( \"meta-my-layer/recipes-example/userprog \\n \" ); return 0 ; } Declare the recipe in userprog_0.1.bb : Run md5hash files/COPYING.MIT to get MD5 Checksum userprog_0.1.bb SUMMARY = \"Example userprog recipe which prints out a message\" DESCRIPTION = \"Example userprog in the meta-my-layer/recipe-example/userprog\" LICENSE = \"MIT\" LIC_FILES_CHKSUM = \"file://COPYING.MIT;md5=3da9cfbcb788c80a0384361b4de20420\" # source file SRC_URI = \"file://userprog.c\" SRC_URI += \"file://COPYING.MIT\" # after fetching, set the source dir in build S = \" ${ WORKDIR } \" # call cross-compiler do_compile () { ${ CC } userprog.c ${ LDFLAGS } -o userprog } # create directoty and install binary with permission 0755 do_install () { install -d ${ D }${ bindir } install -m 0755 userprog ${ D }${ bindir } } # python do_before_build () { bb.plain ( \"* USERPROG: before build *\" ) ; } addtask before_build before do_build python do_before_compile () { bb.plain ( \"* USERPROG: before compile *\" ) ; } addtask before_compile before do_compile Build the recipe bitbake userprog Recipe sysroot will be built if it is not ready yet. This contains needed headers and libraries for generating binaries that run on the target architecture. Add the recipe to rootfs Use either: CORE_IMAGE_EXTRA_INSTALL_append = \" userprog\" or IMAGE_INSTALL_append = \" userprog\" Example 2: Use Makefile in userprog2 recipe This example use Makefile to compile the source code. oe-runmake oe-runmake will look for Makefile and can automatically call to primary target all or clean . If Makefile has install target, Bitbake have to call oe-runmake install in do_install() function. Directory tree: userprog2 \u251c\u2500\u2500 files \u2502 \u251c\u2500\u2500 COPYING.MIT \u2502 \u251c\u2500\u2500 Makefile \u2502 \u2514\u2500\u2500 userprog2.c \u2514\u2500\u2500 userprog2_0.1.bb Source code of the program, which uses USE_SYSCALL variable passed from make: userprog2.c #include <stdio.h> int main () { #ifdef USE_SYSCALL write ( 1 , \"USE_SYSCALL \\n \" , 12 ); write ( 1 , \"Hello World from \\n \" , 17 ); write ( 1 , \"meta-my-layer/recipes-example/userprog2 \\n \" , 40 ); #else printf ( \"Hello World from \\n \" ); printf ( \"meta-my-layer/recipes-example/userprog2 \\n \" ); #endif return 0 ; } Makefile which declares all , install , and clean . Makefile # compiler flags: # -g adds debugging information to the executable file # -Wall turns on most, but not all, compiler warnings CFLAGS = -g -Wall -DUSE_SYSCALL # the name to use for both the target source file, and the output file: TARGET = userprog2 all : $( TARGET ) $(TARGET) : $( TARGET ) . c ${ CC } $( CFLAGS ) -o $( TARGET ) $( TARGET ) .c $( LDFLAGS ) install : install -d $( DESTDIR ) install -m 0755 $( TARGET ) $( DESTDIR ) clean : rm -f $( TARGET ) The bitbake file have to send DESTDIR variable to make: userprog2.bb SUMMARY = \"Example userprog2 recipe which prints out a message\" DESCRIPTION = \"Example userprog2 in the meta-my-layer/recipe-example/userprog2\" LICENSE = \"MIT\" LIC_FILES_CHKSUM = \"file://COPYING.MIT;md5=3da9cfbcb788c80a0384361b4de20420\" # source file SRC_URI = \"file://userprog2.c \\ file://Makefile \\ file://COPYING.MIT \\ \" # after fetching, set the source dir in build S = \" ${ WORKDIR } \" do_install () { oe_runmake install 'DESTDIR=${D}${bindir}' } Remote Recipe # Yocto supports the ability to pull code from online git repositories as part of the build process. The SRC_URI should point to a repository, with extra paramters if needed: branch : The master branch by default, or set a branch in branch parameter protocol : Set the protocol to https , file , or ssh . tag : Select a tag revision on a branch The SRCREV is used to set the revision, it can be ${AUTOREV} to pull the latest source revision, or the SHA1 Hash of a revision. If the tag parameter is used, SRCREV is not needed anymore. .bb SRC_URI = \"git://git@github.com/group_name/repo_name.git;protocol=ssh\" SRCREV = \" ${ AUTOREV } \" S = ${ WORKDIR } /git Working with Git source code The git source code is downloaded into ${WORKDIR}/git directory, in which, you can easily update your code and commit back to the upstream. However, there are somethings to mind: Run bitbake -c clean will wipe the git directory, you will loose editted code Run bitbake -c compile -f to force re-compile the source code with changes. Use patch files if you can not commit to the upstream Example 3: Use git and apply patch userprog3 \u251c\u2500\u2500 files \u2502 \u2514\u2500\u2500 001 -increase-version.patch \u2514\u2500\u2500 userprog3_0.1.bb diff --git a/userprog3.c b/userprog3.c index 08aee7b..d593622 100755 --- a/userprog3.c +++ b/userprog3.c @@ -2,13 +2,14 @@ int main() { + printf(\"Patch applied!!!\\n\"); #ifdef USE_SYSCALL write(1, \"USE_SYSCALL\\n\", 12); write(1, \"Hello World from\\n\", 17); - write(1, \"meta-my-layer/recipes-example/userprog2\\n\", 40); + write(1, \"meta-my-layer/recipes-example/userprog3\\n\", 40); #else printf(\"Hello World from\\n\"); - printf(\"meta-my-layer/recipes-example/userprog2\\n\"); + printf(\"meta-my-layer/recipes-example/userprog3\\n\"); #endif return 0; } userprog3_0.1.bb SUMMARY = \"Example userprog3 recipe which prints out a message\" DESCRIPTION = \"Example userprog3 in the meta-my-layer/recipe-example/userprog3\" LICENSE = \"MIT\" LIC_FILES_CHKSUM = \"file://COPYING.MIT;md5=3da9cfbcb788c80a0384361b4de20420\" # source file SRC_URI = \"git:/// ${ HOME } /local-userprog-repo;protocol=file \\ file://001-increase-version.patch \\ \" SRCREV = \" ${ AUTOREV } \" # after fetching, set the source dir in build S = \" ${ WORKDIR } /git\" do_install () { oe_runmake install 'DESTDIR=${D}${bindir}' } Package files # The do_package task splits the files produced by the recipe during do_install into logical components which are normal binary , debug binary , documents_, etc. These different files will be used in different image types. Variables controls splitting: PACKAGES List all the packages to be produced. The default value: ${PN} ${PN}-dbg ${PN}-staticdev ${PN}-dev ${PN}-doc ${PN}-locale ${PACKAGE_BEFORE_PN} FILES Specify which files to include in each package by using an override to specify the package. To use the FILES variable, provide a package name override that identifies the resulting package. E.g.: FILES_${PN} specifies the files to go into the main package. FILES_${PN} += \"${bindir}/mydir1 ${bindir}/mydir2/myfile\" use ${sysconfdir} rather than /etc , or ${bindir} rather than /usr/bin","title":"Yocto Project Concepts"},{"location":"blog/yocto/concepts/#operator","text":"Hard Assignment = Occur immediately as the statement is parsed. VARIABLE = \"value\" VARIABLE = 'value with \" in it' Soft (Default) Assignment ?= Define a variable if it is undefined when the statement is parsed. If the variable is defined, the soft assignment is lost. If multiple soft assignments get parsed, the first one is used. VARIABLE ? = \"default value\" VARIABLE = \"set value\" VARIABLE ? = \"default value\" # this does nothing Weak (Default) Assignment ??= Delay the assignment at the end of parsing process rather than immediately. If multiple weak assignments get parsed, the last one is used. VARIABLE ? = \"value 1\" # this wins VARIABLE ? = \"value 2\" VARIABLE ?? = \"value 1\" VARIABLE ?? = \"value 2\" # this wins VARIABLE ? = \"value 1\" # this wins VARIABLE ?? = \"value 2\" VARIABLE ?? = \"value 1\" VARIABLE ? = \"value 2\" # this wins VARIABLE ?? = \"value 1\" VARIABLE = \"value 3\" # this always wins VARIABLE ? = \"value 2\" Variable expansion ${} Refer to the value of a variable. The = operator does not immediately expand the variable reference. The expansion is deferred until the variable is used. The := immediately expand the variable reference when is parsed. A = \" ${ B } hello\" # A = linux world hello B = \" ${ C } world\" # B = world C = \"linux\" A : = \" ${ B } hello\" # A = ${B} hello B : = \" ${ C } world\" # B = ${C} world C = \"linux\" A = \"11\" B = \" ${ A } \" # B = 22 when B is used A = \"22\" C = \" ${ A } \" # C = 22 when C is used A = \"11\" B : = \" ${ A } \" # B = 11 immediately A = \"22\" C = \" ${ A } \" # C = 22 when C is used Appending += , .= , _append= Append values with or without a space. += automatically adds a space, but .= and _append= do not do that. A = \"hello\" A += \"my\" # A = hello my A . = \"sunny\" # A = hello mysunny A_append = \"world\" # A = hello mysunnyworld Prepending =+ , =. , _prepend= Prepend values with or without a space. =+ automatically adds a space, but =. and _prepend= do not do that. A = \"hello\" A = + \"my\" # A = my hello A = . \"sunny\" # A = sunnymy hello A_prepend = \"world\" # A = worldsunnymy hello Removal _remove= Remove all occurrences of a value in a list. A = \"123 456 123 789 123\" A_remove = \"123\" # A = \" 456 789 \", note the spaces Overriding syntax _append= , _prepend= , _remove= Provide guaranteed operations, as compared to += , =+ . 1st parsed A += \"world\" # does not work, A is undefined 2nd parsed A = \"hello\" # A = hello when A is used However, using overriding syntax give a good result: 1st parsed A_append = \" world\" # keep this action when A is used 2nd parsed A = \"hello\" # A = hello world when A is used Check the value After all configurations are parsed: bitbake <target/recipe> -e | grep ^VARIABLE =","title":"Operator"},{"location":"blog/yocto/concepts/#layer","text":"A layer is a logical collection of related recipes. Layer name should start with meta- to follow Yocto\u2019s naming convention. Each layer has a priority, which is used by bitbake to decide which layer takes precedence if there are recipe files with the same name in multiple layers. A higher numeric value represents a higher priority. Despite most of the customization can be done with the local.conf configuration file, it is not possible to: * Store recipes for your own software projects * Create your own images * Consolidate patches/modifications to other people\u2019s recipes * Add a new custom kernel * Add a new machine Depending on the type of layer, add the content: If the layer is adding support for a machine, add the machine configuration in conf/machine/ If the layer is adding distro policy, add the distro configuration in conf/distro/ If the layer introduces new recipes, put the recipes you need in recipes-* subdirectories of the layer directory. Recipes are divided into categories {\u00bbbut hard to decide\u00bb} Create new layer There are two ways to create your own layer. Manually mkdir meta-my-layer cp meta-my-layer Copy poky/meta-skeleton/conf/layer.conf to new layer: mkdir conf && cd conf cp ../../poky/meta-skeleton/conf/layer.conf . Using script bitbake-layers create-layer meta-my-layer The tool automates layer creation by setting up a subdirectory with a layer.conf configuration file, a recipes-example subdirectory that contains an example.bb recipe, a licensing file, and a README. Default priority of the layer is 6 . meta-my-layer/ \u251c\u2500\u2500 conf \u2502 \u2514\u2500\u2500 layer.conf \u251c\u2500\u2500 COPYING.MIT \u251c\u2500\u2500 README \u2514\u2500\u2500 recipes-example \u2514\u2500\u2500 example \u2514\u2500\u2500 example_0.1.bb To check layer compatibility, run yocto-check-layer : yocto-check-layer meta-my-layer Layer configs Note the BBFILE_PRIORITY_ meta-my-layer/conf/layer.conf # We have a conf and classes directory, add to BBPATH BBPATH . = \": ${ LAYERDIR } \" # We have recipes-* directories, add to BBFILES BBFILES += \" ${ LAYERDIR } /recipes-*/*/*.bb ${ LAYERDIR } /recipes-*/*/*.bbappend\" BBFILE_COLLECTIONS += \"my-layer\" BBFILE_PATTERN_my-layer = \"^ ${ LAYERDIR } /\" BBFILE_PRIORITY_my-layer = \"6\" # This should only be incremented on significant changes that will # cause compatibility issues with other layers LAYERVERSION_my-layer = \"1\" LAYERDEPENDS_my-layer = \"core\" LAYERSERIES_COMPAT_my-layer = \"dunfell\"","title":"Layer"},{"location":"blog/yocto/concepts/#image","text":"Image is a top level recipe. It inherits the image.bbclass .","title":"Image"},{"location":"blog/yocto/concepts/#create-new-image","text":"You often need to create your own Image recipe in order to add new packages or functionality. There are 2 ways: Create an image from scratch The simplest way is to inherit the core-image bbclass, as it provides a set of image features that can be used very easily. Create an image directory mkdir -p recipes-examples/images Create the image recipe nano recipes-examples/images/lwl-image.bb lwl-image.bb SUMMARY = \"A small boot image for LWL learners\" LICENSE = \"MIT\" # start from core-image inherit core-image # core files for basic console boot IMAGE_INSTALL = \"packagegroup-core-boot\" # add our needed applications #IMAGE_INSTALL += \"userprog\" Extend an existing recipe (preferable) When an image mostly fits our needs, and we need to do minor adjustments on it, it is very convenient to reuse its code. This makes code maintenance easier and highlights the functional differences. nano recipes-examples/images/lwl-image-reuse.bb lwl-image.bb # select base image require recipes-core/images/core-image-minimal.bb # append our needed packages, use overriding syntax #IMAGE_INSTALL_append = \" userprog\"","title":"Create new Image"},{"location":"blog/yocto/concepts/#package-group","text":"A package group is a set of packages that can be included on any image. Using a package group name in IMAGE_INSTALL variable install all the packages defined by the package group into the root file system of your target image. There are many package groups. There are present in subdirectories named packagegroups . They are recipe files(.bb) and starts with packagegroup- . For example, packagegroup-core-boot : Provides the minimum set of packages necessary to create a bootable image with console. ls poky/meta/recipes-core/packagegroups/ nativesdk-packagegroup-sdk-host.bb packagegroup-core-standalone-sdk-target.bb packagegroup-base.bb packagegroup-core-tools-debug.bb packagegroup-core-boot.bb packagegroup-core-tools-profile.bb packagegroup-core-buildessential.bb packagegroup-core-tools-testapps.bb packagegroup-core-eclipse-debug.bb packagegroup-cross-canadian.bb packagegroup-core-nfs.bb packagegroup-go-cross-canadian.bb packagegroup-core-sdk.bb packagegroup-go-sdk-target.bb packagegroup-core-ssh-dropbear.bb packagegroup-self-hosted.bb packagegroup-core-ssh-openssh.bb","title":"Package group"},{"location":"blog/yocto/concepts/#image-features","text":"Another method for customizing your image is to enable or disable high-level image features by using the IMAGE_FEATURES and EXTRA_IMAGE_FEATURES variables. Image features is the map of features to package groups. IMAGE_FEATURES / EXTRA_IMAGE_FEATURES is made to enable special features for your image, such as empty password for root, debug image, special packages, x11, splash, ssh-server. Best practice is to: Use IMAGE_FEATURES from a recipe Use EXTRA_IMAGE_FEATURES from local.conf For example: meta/classes/core-image.bbclass FEATURE_PACKAGES_x11 = \"packagegroup-core-x11\" FEATURE_PACKAGES_x11-base = \"packagegroup-core-x11-base\" FEATURE_PACKAGES_x11-sato = \"packagegroup-core-x11-sato\" FEATURE_PACKAGES_tools-debug = \"packagegroup-core-tools-debug\" FEATURE_PACKAGES_eclipse-debug = \"packagegroup-core-eclipse-debug\" FEATURE_PACKAGES_tools-profile = \"packagegroup-core-tools-profile\" FEATURE_PACKAGES_tools-testapps = \"packagegroup-core-tools-testapps\" FEATURE_PACKAGES_tools-sdk = \"packagegroup-core-sdk packagegroup-core-standalone-sdk-target\" FEATURE_PACKAGES_nfs-server = \"packagegroup-core-nfs-server\" FEATURE_PACKAGES_nfs-client = \"packagegroup-core-nfs-client\" FEATURE_PACKAGES_ssh-server-dropbear = \"packagegroup-core-ssh-dropbear\" FEATURE_PACKAGES_ssh-server-openssh = \"packagegroup-core-ssh-openssh\" FEATURE_PACKAGES_hwcodecs = \" ${ MACHINE_HWCODECS } \" poky/meta/recipes-sato/images/core-image-sato.bb IMAGE_FEATURES += \"splash package-management x11-base x11-sato ssh-server-dropbear hwcodecs\" inherit core-image build/conf/local.conf EXTRA_IMAGE_FEATURES ? = \"debug-tweaks\" Some Features debug-tweaks Debug tweaks enables password-less login for the root user. You must remove the debug-tweaks feature from production image. read-only-rootfs Read-only RootFS helps to reduce wear on flash memory, and to eliminate system file corruption. splash Boot splash screen tools-debug Installs debugging tools such as strace and gdb. tools-sdk Installs a full SDK that runs on the device.","title":"Image features"},{"location":"blog/yocto/concepts/#image-options","text":"Some other options also control the image content. IMAGE_FSTYPES Determines the root filesystem image type. If more than one format is specified, one image per format will be generated. Image formats instructions are delivered in Poky: meta/classes/image_types.bbclass If you have a particular layout on your storage (for example bootloader location on an SD card), you may want to create your own image type. This is done through a class that inherits from image_types . It has to define a function named IMAGE_CMD_<type> . Example: sdcard_image-rpi.bbclass in meta-raspberrypi IMAGE_NAME The name of the output image files minus the extension. For example: IMAGE_NAME = \"${IMAGE_BASENAME}-${MACHINE}-${DATETIME}\" IMAGE_MANIFEST This file lists all the installed packages that make up the image. IMAGE_LINGUAS Specifies the list of locales to install into the image during the root filesystem construction process. For example: IMAGE_LINGUAS = \"en-us\"","title":"Image options"},{"location":"blog/yocto/concepts/#recipe","text":"Recipes are fundamental components in the Yocto Project environment. A Yocto/OpenEmbedded recipe is a text file with file extension .bb . Each software component built by the OpenEmbedded build system requires a recipe to define the component. A recipe contains information about single piece of software. Information such as: Location from which to download the unaltered source Any patches to be applied to that source (if needed) Special configuration options to apply How to compile the source files and How to package the compiled output Poky includes several classes that abstract the process for the most common development tools as projects based on Autotools, CMake, and QMake. File Format: <base_name>_<version>.bb Use lower-cased characters and do not include the reserved suffixes -native , -cross , -initial , or -dev . List all recipes: bitbake-layers show-recipes Find a recipe in added layers: bitbake-layers show-recipes <recipe>","title":"Recipe"},{"location":"blog/yocto/concepts/#bitbake","text":"Yocto/OpenEmbedded\u2019s build tool bitbake parses a recipe and generates list of tasks that it can execute to perform the build steps: do_fetch : Fetches the source code do_unpack : Unpacks the source code into a working directory do_patch : Locates patch files and applies them to the source code do_configure : Configures the source by enabling and disabling any build-time and configuration options for the software being built do_compile : Compiles the source in the compilation directory do_install : Copies files from the compilation directory to a holding area do_package : Analyzes the content of the holding area and splits it into subsets based on available packages and files do_package_write_rpm : Creates the actual RPM packages and places them in the Package Feed area Generally, the only tasks that the user needs to specify in a recipe are do_configure , do_compile and do_install ones. The remaining tasks are automatically defined by the YP build system The above task list is in the correct dependency order. They are executed from top to bottom. You can use the -c argument to execute the specific task of a recipe. bitbake -c compile <recipe> Stage 1: Fetching Code (do_fetch) Fetching is controlled mainly through the SRC_URI variable. Bitbake supports fetching source code from git, svn, https, ftp, etc. URI scheme syntax: scheme://url;param1;param2 Example: SRC_URI = \"https://busybox.net/downloads/busybox-${PV}.tar.bz2\" Stage 2: Unpacking (do_unpack) All local files found in SRC_URI are copied into the recipe\u2019s working directory, in $BUILDDIR/tmp/work/ . When extracting a tarball, BitBake expects to find the extracted files in a directory named <application>-<version> . This is controlled by the S variable. Stage 3: Patching Code (do_patch) Sometimes it is necessary to patch code after it has been fetched. Any files mentioned in SRC_URI whose names end in .patch or .diff or compressed versions of these suffixes (e.g. diff.gz ) are treated as patches. The do_patch task automatically applies these patches. The build system should be able to apply patches with the -p1 option (i.e. one directory level in the path will be stripped off). If your patch needs to have more directory levels stripped off, specify the number of levels using the striplevel option in the SRC_URI entry for the patch. Stage 4: Configuration (do_configure) Most software provides some means of setting build-time configuration options before compilation. Typically, setting these options is accomplished by running a configured script with options, or by modifying a build configuration file. Autotools: If your source files have a configure.ac file, then your software is built using Autotools. CMake: If your source files have a CMakeLists.txt file, then your software is built using CMake If your source files do not have a configure.ac or CMakeLists.txt file, you normally need to provide a do_configure task in your recipe unless there is nothing to configure. Stage 5: Compilation (do_compile) do_compile task happens after source is fetched, unpacked, and configured. No package output Check the do_compile in Bitbake file to make sure the compiling commands are correct, including the value of expanded variables. Check the targets and dependencies in Makefile also. Stage 6: Installation (do_install) After compilation completes, BitBake executes the do_install task. During do_install, the task copies the built files along with their hierarchy to locations that would mirror their locations on the target device. install keyword install not only copies files but also changes its ownership and permissions and optionally removes debugging symbols from executables. It combines cp with chown , chmod and strip . Not installed package When a required package is not installed, do_rootfs will fail with errors. The most happened error is Could not invoke dnf or No match for argument: , which is caused by do_install was not run, or by do_compile did not produce any output. Check the do_compile and do_install in Bitbake file to make sure it call to oe-runmake if Makefile is used. Check the targets and dependencies in Makefile also. Stage 7: Packaging (do_package) The do_package task splits the files produced by the recipe into logical components. Even software that produces a single binary might still have debug symbols, documentation, and other logical components that should be split out. The do_package task ensures that files are split up and packaged correctly. Bitbake Variables S : Contains the unpacked source files for a given recipe D : The destination directory (root directory of where the files are installed, before creating the image) WORKDIR : The location where the OpenEmbedded build system builds a recipe (i.e. does the work to create the package). PN : The name of the recipe used to build the package PV : The version of the recipe used to build the package PR : The revision of the recipe used to build the package. Example 1: Add userprog recipe Create userprog recipe by adding its folder and bb file: recipes-example \u2514\u2500\u2500 userprog \u251c\u2500\u2500 files \u2502 \u251c\u2500\u2500 COPYING.MIT \u2502 \u2514\u2500\u2500 userprog.c \u2514\u2500\u2500 userprog_0.1.bb Add code to userprog.c : #include <stdio.h> int main () { printf ( \"Hello World from \" ); printf ( \"meta-my-layer/recipes-example/userprog \\n \" ); return 0 ; } Declare the recipe in userprog_0.1.bb : Run md5hash files/COPYING.MIT to get MD5 Checksum userprog_0.1.bb SUMMARY = \"Example userprog recipe which prints out a message\" DESCRIPTION = \"Example userprog in the meta-my-layer/recipe-example/userprog\" LICENSE = \"MIT\" LIC_FILES_CHKSUM = \"file://COPYING.MIT;md5=3da9cfbcb788c80a0384361b4de20420\" # source file SRC_URI = \"file://userprog.c\" SRC_URI += \"file://COPYING.MIT\" # after fetching, set the source dir in build S = \" ${ WORKDIR } \" # call cross-compiler do_compile () { ${ CC } userprog.c ${ LDFLAGS } -o userprog } # create directoty and install binary with permission 0755 do_install () { install -d ${ D }${ bindir } install -m 0755 userprog ${ D }${ bindir } } # python do_before_build () { bb.plain ( \"* USERPROG: before build *\" ) ; } addtask before_build before do_build python do_before_compile () { bb.plain ( \"* USERPROG: before compile *\" ) ; } addtask before_compile before do_compile Build the recipe bitbake userprog Recipe sysroot will be built if it is not ready yet. This contains needed headers and libraries for generating binaries that run on the target architecture. Add the recipe to rootfs Use either: CORE_IMAGE_EXTRA_INSTALL_append = \" userprog\" or IMAGE_INSTALL_append = \" userprog\" Example 2: Use Makefile in userprog2 recipe This example use Makefile to compile the source code. oe-runmake oe-runmake will look for Makefile and can automatically call to primary target all or clean . If Makefile has install target, Bitbake have to call oe-runmake install in do_install() function. Directory tree: userprog2 \u251c\u2500\u2500 files \u2502 \u251c\u2500\u2500 COPYING.MIT \u2502 \u251c\u2500\u2500 Makefile \u2502 \u2514\u2500\u2500 userprog2.c \u2514\u2500\u2500 userprog2_0.1.bb Source code of the program, which uses USE_SYSCALL variable passed from make: userprog2.c #include <stdio.h> int main () { #ifdef USE_SYSCALL write ( 1 , \"USE_SYSCALL \\n \" , 12 ); write ( 1 , \"Hello World from \\n \" , 17 ); write ( 1 , \"meta-my-layer/recipes-example/userprog2 \\n \" , 40 ); #else printf ( \"Hello World from \\n \" ); printf ( \"meta-my-layer/recipes-example/userprog2 \\n \" ); #endif return 0 ; } Makefile which declares all , install , and clean . Makefile # compiler flags: # -g adds debugging information to the executable file # -Wall turns on most, but not all, compiler warnings CFLAGS = -g -Wall -DUSE_SYSCALL # the name to use for both the target source file, and the output file: TARGET = userprog2 all : $( TARGET ) $(TARGET) : $( TARGET ) . c ${ CC } $( CFLAGS ) -o $( TARGET ) $( TARGET ) .c $( LDFLAGS ) install : install -d $( DESTDIR ) install -m 0755 $( TARGET ) $( DESTDIR ) clean : rm -f $( TARGET ) The bitbake file have to send DESTDIR variable to make: userprog2.bb SUMMARY = \"Example userprog2 recipe which prints out a message\" DESCRIPTION = \"Example userprog2 in the meta-my-layer/recipe-example/userprog2\" LICENSE = \"MIT\" LIC_FILES_CHKSUM = \"file://COPYING.MIT;md5=3da9cfbcb788c80a0384361b4de20420\" # source file SRC_URI = \"file://userprog2.c \\ file://Makefile \\ file://COPYING.MIT \\ \" # after fetching, set the source dir in build S = \" ${ WORKDIR } \" do_install () { oe_runmake install 'DESTDIR=${D}${bindir}' }","title":"Bitbake"},{"location":"blog/yocto/concepts/#remote-recipe","text":"Yocto supports the ability to pull code from online git repositories as part of the build process. The SRC_URI should point to a repository, with extra paramters if needed: branch : The master branch by default, or set a branch in branch parameter protocol : Set the protocol to https , file , or ssh . tag : Select a tag revision on a branch The SRCREV is used to set the revision, it can be ${AUTOREV} to pull the latest source revision, or the SHA1 Hash of a revision. If the tag parameter is used, SRCREV is not needed anymore. .bb SRC_URI = \"git://git@github.com/group_name/repo_name.git;protocol=ssh\" SRCREV = \" ${ AUTOREV } \" S = ${ WORKDIR } /git Working with Git source code The git source code is downloaded into ${WORKDIR}/git directory, in which, you can easily update your code and commit back to the upstream. However, there are somethings to mind: Run bitbake -c clean will wipe the git directory, you will loose editted code Run bitbake -c compile -f to force re-compile the source code with changes. Use patch files if you can not commit to the upstream Example 3: Use git and apply patch userprog3 \u251c\u2500\u2500 files \u2502 \u2514\u2500\u2500 001 -increase-version.patch \u2514\u2500\u2500 userprog3_0.1.bb diff --git a/userprog3.c b/userprog3.c index 08aee7b..d593622 100755 --- a/userprog3.c +++ b/userprog3.c @@ -2,13 +2,14 @@ int main() { + printf(\"Patch applied!!!\\n\"); #ifdef USE_SYSCALL write(1, \"USE_SYSCALL\\n\", 12); write(1, \"Hello World from\\n\", 17); - write(1, \"meta-my-layer/recipes-example/userprog2\\n\", 40); + write(1, \"meta-my-layer/recipes-example/userprog3\\n\", 40); #else printf(\"Hello World from\\n\"); - printf(\"meta-my-layer/recipes-example/userprog2\\n\"); + printf(\"meta-my-layer/recipes-example/userprog3\\n\"); #endif return 0; } userprog3_0.1.bb SUMMARY = \"Example userprog3 recipe which prints out a message\" DESCRIPTION = \"Example userprog3 in the meta-my-layer/recipe-example/userprog3\" LICENSE = \"MIT\" LIC_FILES_CHKSUM = \"file://COPYING.MIT;md5=3da9cfbcb788c80a0384361b4de20420\" # source file SRC_URI = \"git:/// ${ HOME } /local-userprog-repo;protocol=file \\ file://001-increase-version.patch \\ \" SRCREV = \" ${ AUTOREV } \" # after fetching, set the source dir in build S = \" ${ WORKDIR } /git\" do_install () { oe_runmake install 'DESTDIR=${D}${bindir}' }","title":"Remote Recipe"},{"location":"blog/yocto/concepts/#package-files","text":"The do_package task splits the files produced by the recipe during do_install into logical components which are normal binary , debug binary , documents_, etc. These different files will be used in different image types. Variables controls splitting: PACKAGES List all the packages to be produced. The default value: ${PN} ${PN}-dbg ${PN}-staticdev ${PN}-dev ${PN}-doc ${PN}-locale ${PACKAGE_BEFORE_PN} FILES Specify which files to include in each package by using an override to specify the package. To use the FILES variable, provide a package name override that identifies the resulting package. E.g.: FILES_${PN} specifies the files to go into the main package. FILES_${PN} += \"${bindir}/mydir1 ${bindir}/mydir2/myfile\" use ${sysconfdir} rather than /etc , or ${bindir} rather than /usr/bin","title":"Package files"},{"location":"blog/yocto/introduction/","tags":["yocto"],"text":"Embedded System # An embedded system running with an OS need 4 main parts: Toolchain : The compiler and other tools needed to create a system or an application on your target system. Bootloader : The program that initializes the board and loads the Kernel. Kernel : This is the heart of the system, managing system resources and interfacing with hardware. Root filesystem : Contains the libraries and programs that are run once the kernel has completed its initialization. Yocto Project # The Yocto Project (YP) is an open source collaboration project that helps developers create custom Linux-based systems regardless of the hardware architecture. The project provides a flexible set of tools, definitions and configurations (called stacks), and steps to build a customized Linux images. Refer to a full version of Yocto Documents to learn more. Input Set of data that describes what we want, that is our specification, including Kernel Configuration, Hardware Name, Packages/Binaries to be installed Output Linux Based Embedded Product, such as Linux Kernel, Root File System, Bootloader, Device Tree, Toolchain Advantages of Yocto Project : Widely Adopted Across the Industry: Support multiple architectures: from Intel, ARM, MIPS, PPC, etc., Chip vendors create and supply BSPs that support their hardware Images and Code Transfer Easily: just update configuration, and keep all other stacks Flexibility: Through customization and layering, a project group can leverage the base Linux distribution to create a distribution that works for their product needs. Poky Repo # Poky is a reference distribution of the Yocto Project\u00ae. It contains the OpenEmbedded Build System (Bitbake and OpenEmbedded Core) as well as a set of metadata to get you started building your own distro. To use the Yocto Project tools, you can download Poky and use it to bootstrap your own distribution. Note that Poky does not contain binary files \u2013 it is a working example of how to build your own custom Linux distribution from source. OpenEmbedded Core # OpenEmbedded offers a best-in-class cross-compile environment. It allows developers to create a complete Linux Distribution for embedded systems. The Yocto Project and OpenEmbedded share a core collection of metadata called OpenEmbedded-Core( oe-core ). The Yocto Project focuses on providing powerful, easy-to-use, interoperable, well-tested tools, metadata, and board support packages (BSPs) for a core set of architectures and specific boards. OpenEmbedded only provides a comprehensive set of metadata for a wide variety of architectures, features, and applications Open Embedded in Poky Repo using Yocto Project Terminology # Metadata # Metadata is collection of: Recipes (.bb and .bbappend) Configuration files (.conf) Classes (.bbclass) Includes (.inc) Recipes # A recipe is a set of instructions that is read and processed by the bitbake. Extension: .bb A recipe describes: where you get source code which patches to apply Configuration options Compile options (library dependencies) Install License Configuration Files # They tell the build system what to build and put into the image to support a particular platform Extension: .conf Files which hold : global definition of variables user defined variables and hardware configuration information Types : Machine Configuration Options Distribution Configuration Options Compiler tuning options General Common Configuration Options User Configuration Options (local.conf) Classes # Class files are used to abstract common functionality and share it amongst multiple recipe (.bb) files. To use a class, add inherit <classname> in the recipe file. Extension: .bbclass Layers # A collection of related recipes. Typical naming convention: meta-<layername> . Layers provide a mechanism to isolate metadata according to functionality, for instance BSPs, distribution configuration, etc. BBLAYERS variable present in build/conf/bblayers.conf file list the layers Bitbake tries to find. If bblayers.conf is not present when you start the build, the OpenEmbedded build system creates it from bblayers.conf.sample when you source the oe-init-build-env script. Command to find out which layers are present: bitbake-layers show-layers Where to get other layers: Yocto Project Compatible Layers: https://www.yoctoproject.org/software-overview/layers/ OpenEmbedded Layers: https://layers.openembedded.org/layerindex/branch/master/layers/ . Packages # A package is a binary file with name .rpm, .deb, or *.ipkg. A single recipe may produce many packages. All packages that a recipe generated are listed in the recipe variable. Image # An image is the top level recipe, it has a description, a license and inherits the core-image class. Image is architecture agnostic and defines how the root filesystem is built, with what packages. Command to check the list of available image recipes: ls meta*/recipes*/images/*.bb Prerequisites # Host Linux machine Use a native Linux machine for better performance. A virtual machine can be used also. Install Ubuntu Server running in VirtualBox Virtual Machine settings: At least 4GB RAM, 128 GB HDD (Fixed Disk for better performance) Use more processors Disable Network to speed up installation Use Ubuntu Live Server image to install Enable OpenSSH server for remote access After installation: Enable Network for NAT + Host-only in Virtual machine settings Disable Journal features Boot into Recovery Mode on Ubuntu Grub menu (press ESC at boot), then select root termninal. echo \"u\" > /proc/sysrq-trigger tune2fs -O ^has_journal /dev/sda2 Change mounting option, and use tmpfs for /tmp sudo nano /etc/fstab UUID=/dev/sda2 / ext4 noatime,barrier=0,commit=6000,errors=remount-ro 0 1 tmpfs /tmp tmpfs rw,noatime,nosuid,nodev 0 0 /swap.img none swap sw 0 0 Set up system: Add current user to the sudoers: sudo bash -c \"echo ' $USER ALL=(ALL) NOPASSWD: ALL' > /etc/sudoers.d/ $USER \" Disable unattended upgrades sudo dpkg-reconfigure unattended-upgrades Use ip a to show availabe interface, such as enp0s3 and enp0s8 Configure Network through Netplan: sudo nano /etc/netplan/99_config.yaml network : version : 2 ethernets : enp0s3 : dhcp4 : true enp0s8 : dhcp4 : true sudo netplan apply Install Samba for file sharing Yocto build packages such as for Ubuntu sudo apt install \\ gawk wget git diffstat unzip texinfo gcc build-essential chrpath \\ socat cpio python3 python3-pip python3-pexpect xz-utils debianutils \\ iputils-ping python3-git python3-jinja2 libegl1-mesa libsdl1.2-dev \\ pylint3 xterm python3-subunit mesa-common-dev zstd liblz4-tool Workflow of Yocto Project # The general workflow Checkout the branch of Poky to use Check the Release table to see the version and tags. Note to select the latest branch supported by all layers. For example, on the writing date (Arp 7 th 2022), the latest version is Honister (3.4.3) , but the latest LTS version is Dunfell (3.1.15) which was released in Arp 2020. So, it is reasonable to use Dunfell for better compatibility. git clone -b dunfell \\ git://git.yoctoproject.org/poky.git tree pocky -L 1 pocky \u251c\u2500\u2500 bitbake \u251c\u2500\u2500 contrib \u251c\u2500\u2500 documentation \u251c\u2500\u2500 LICENSE \u251c\u2500\u2500 LICENSE.GPL-2.0-only \u251c\u2500\u2500 LICENSE.MIT \u251c\u2500\u2500 MEMORIAM \u251c\u2500\u2500 meta \u251c\u2500\u2500 meta-poky \u251c\u2500\u2500 meta-selftest \u251c\u2500\u2500 meta-skeleton \u251c\u2500\u2500 meta-yocto-bsp \u251c\u2500\u2500 oe-init-build-env \u251c\u2500\u2500 README.hardware -> meta-yocto-bsp/README.hardware \u251c\u2500\u2500 README.OE-Core \u251c\u2500\u2500 README.poky -> meta-poky/README.poky \u251c\u2500\u2500 README.qemu \u2514\u2500\u2500 scripts Prepare the build environment Poky provides you a script oe-init-build-env , which should be used to set up the build environment. You can pass a build_directory argument for the name of the directory where the environment is set. In case it is not given, it defaults to build . The above script will move you in a build folder and create two files ( local.conf , bblayers.conf ) inside conf folder. The defaults are set to build for a qemux86-64 . source poky/oe-init-build-env # ## Shell environment set up for builds. ### You can now run 'bitbake <target>' Common targets are: core-image-minimal core-image-sato meta-toolchain meta-ide-support You can also run generated qemu images with a command like 'runqemu qemux86' Other commonly useful commands are: - 'devtool' and 'recipetool' handle common recipe tasks - 'bitbake-layers' handles common layer tasks - 'oe-pkgdata-util' handles common target package tasks The config files: tree conf conf \u251c\u2500\u2500 bblayers.conf \u251c\u2500\u2500 local.conf \u2514\u2500\u2500 templateconf.cfg Check the Metadata and layers Refer to Bitbake User Manual for more infomation. Check the build configs: bitbake <target> -n Build Configuration: BB_VERSION = \"1.46.0\" BUILD_SYS = \"x86_64-linux\" NATIVELSBSTRING = \"ubuntu-18.04\" TARGET_SYS = \"x86_64-poky-linux\" MACHINE = \"qemux86-64\" DISTRO = \"poky\" DISTRO_VERSION = \"3.1.15\" TUNE_FEATURES = \"m64 core2\" TARGET_FPU = \"\" meta meta-poky meta-yocto-bsp = \"dunfell:ab03f130e449fdb24de79b119c73f0969f1bd801\" Build the target image Run bitbake with the target image name: bitbake <target> for example: core-image-minimal : the smallest image allowing a device to boot to check bootloader and kernel core-image-sato : an X11 Window-system-based image with a SATO theme and a GNOME mobile desktop environment bitbake core-image-minimal The first build will take quite long time to complete. Yocto will download source code and compile all components needed to make the target. Try to run the image: runqemu core-image-minimal adding nographic to run without the graphic window Configurations # local.conf # Contains local user settings for almost aspects of the build system, is generated from meta-pocky/conf/local.conf.sample . local.conf file is a very convenient way to override several default configurations over all the Yocto Project\u2019s tools, but local.conf file is not tracked by source code manager. In general, everything in your local.conf should be moved to your own distro configuration. Finally, you should only set DISTRO to your own distro in local.conf . MACHINE : The target machine is being built for. E.g.: MACHINE = \"qemux86-64\" IMAGE_FSTYPES : Output image formats are list of different image formats. These images can be used for different purpose, such as rootfs, raw disk, MTD partition. E.g.: IMAGE_FSTYPES += \"tar.bz2 jffs2 wic\" CORE_IMAGE_EXTRA_INSTALL add extra packages to an image This is a convenience variable that enables you to add extra packages to an image based on the core-image class. E.g.: CORE_IMAGE_EXTRA_INSTALL += \"openssh\" IMAGE_INSTALL : This is the variable that controls what is included in any image. Use IMAGE_INSTALL_append only!\\ E.g.: IMAGE_INSTALL_append = \" openssh\" note the space Use IMAGE_INSTALL += will override the CORE_IMAGE_EXTRA_INSTALL that can lead to missing packages. DL_DIR : Where to place downloads During a first build the system will download many source code tarballs, from various upstream projects. These are all stored in DL_DIR . The default is a downloads directory under TOPDIR which is the build directory. This download folder can be shared between builds. It also can create tarball files using BB_GENERATE_MIRROR_TARBALLS = \"1\" option. You can also pre-fetch source code without running any compilation with --runonly=fetch option in bitbake. Example to create sharing downloaded package folder: DL_DIR ? = \" ${ HOME } /yocto-downloads\" bitbake <target> --runonly = fetch TMP_DIR : Where to place the build output This option specifies where the bulk of the building work should be done and where Bitbake should place its temporary files(source extraction, compilation) and output. BB_NUMBER_THREADS : Determine the number of tasks that Bitbake will perform in parallel Note: These tasks are related to bitbake and nothing related to compiling. Defaults to the number of CPUs on the system. PARALLEL_MAKE : Specify the number of processes that GNU make can run in parallel This specifies the number of processes that GNU make can run in parallel on a compilation task. Defaults to the number of CPUs on the system. Corresponds to the -j make option. rm_work : Remove source code and imtermediate files Yocto Build System can take a lot of disk space during build. But bitbake provides options to preserve disk space. You can tell bitbake to delete all the source code, build files after building a particular recipe by adding the following line in local.conf file: INHERIT += \"rm_work\" Disadvantage: Difficult to debug while build fails of any recipe. If you want to exclude bitbake deleting source code of a particular package, you can add it in RM_WORK_EXCLUDE variable, for example: RM_WORK_EXCLUDE += \"core-image-minimal\" Query a configuration For example, get BB_NUMBER_THREADS setting of the target core-image-minimal : bitbake -e core-image-minimal | grep ^BB_NUMBER_THREADS = bblayers.conf # The bblayers.conf file tells Bitbake what layers you want considered during the build. By default, the layers listed in this file include layers minimally needed by the build system. However, you must manually add any custom layers you have created. BBLAYERS = \"\\ /home/vqtrong/poky/meta \\ /home/vqtrong/poky/meta-poky \\ /home/vqtrong/poky/meta-yocto-bsp \\ \" To add/remove a layer, you can use bitbake-layers command, for example: bitbake-layers add-layer ../meta-openembedded/meta-oe To show all layers: bitbake-layers show-layers Absolute paths in Config files When you copy project to another path, two files need modified: build/conf/bblayers.conf build/tmp/saved_tmpdir Generated Images # Top-level image targets : There are some top-level image targets defined for different purposes, such as: core-image-minimal : A small image just capable of allowing a device to boot. core-image-base : A console-only image that fully supports the target device hardware. core-image-sato : An image with Sato support, a mobile environment and visual style that works well with mobile devices. The image supports X11 with a Sato theme and applications such as a terminal, editor, file manager, media player, and so forth. core-image-weston : A very basic Wayland image with a terminal. This image provides the Wayland protocol libraries and the reference Weston compositor. core-image-x11 : A very basic X11 image with a terminal. Component images : The build process writes component images out to the Build Directory inside the tmp/deploy/images/machine/ folder: kernel-image : A kernel binary file. The KERNEL_IMAGETYPE variable determines the naming scheme for the kernel image file. root-filesystem-image : Root filesystem for the target device (e.g. .ext3 or .bz2 files). The IMAGE_FSTYPES variable determines the root filesystem image type kernel-modules : Tarballs that contain all the modules built for the kernel. bootloaders : If applicable to the target machine, bootloaders supporting the image. Image formats : Yocto can generate different image formats, e.g. tar file: extract into formatted partition partition image (e.g. ext4 , jffs2 ): raw copy to disk or MTD partition disk image (wic): raw copy to disk","title":"Introduction of Yocto Project"},{"location":"blog/yocto/introduction/#embedded-system","text":"An embedded system running with an OS need 4 main parts: Toolchain : The compiler and other tools needed to create a system or an application on your target system. Bootloader : The program that initializes the board and loads the Kernel. Kernel : This is the heart of the system, managing system resources and interfacing with hardware. Root filesystem : Contains the libraries and programs that are run once the kernel has completed its initialization.","title":"Embedded System"},{"location":"blog/yocto/introduction/#yocto-project","text":"The Yocto Project (YP) is an open source collaboration project that helps developers create custom Linux-based systems regardless of the hardware architecture. The project provides a flexible set of tools, definitions and configurations (called stacks), and steps to build a customized Linux images. Refer to a full version of Yocto Documents to learn more. Input Set of data that describes what we want, that is our specification, including Kernel Configuration, Hardware Name, Packages/Binaries to be installed Output Linux Based Embedded Product, such as Linux Kernel, Root File System, Bootloader, Device Tree, Toolchain Advantages of Yocto Project : Widely Adopted Across the Industry: Support multiple architectures: from Intel, ARM, MIPS, PPC, etc., Chip vendors create and supply BSPs that support their hardware Images and Code Transfer Easily: just update configuration, and keep all other stacks Flexibility: Through customization and layering, a project group can leverage the base Linux distribution to create a distribution that works for their product needs.","title":"Yocto Project"},{"location":"blog/yocto/introduction/#poky-repo","text":"Poky is a reference distribution of the Yocto Project\u00ae. It contains the OpenEmbedded Build System (Bitbake and OpenEmbedded Core) as well as a set of metadata to get you started building your own distro. To use the Yocto Project tools, you can download Poky and use it to bootstrap your own distribution. Note that Poky does not contain binary files \u2013 it is a working example of how to build your own custom Linux distribution from source.","title":"Poky Repo"},{"location":"blog/yocto/introduction/#openembedded-core","text":"OpenEmbedded offers a best-in-class cross-compile environment. It allows developers to create a complete Linux Distribution for embedded systems. The Yocto Project and OpenEmbedded share a core collection of metadata called OpenEmbedded-Core( oe-core ). The Yocto Project focuses on providing powerful, easy-to-use, interoperable, well-tested tools, metadata, and board support packages (BSPs) for a core set of architectures and specific boards. OpenEmbedded only provides a comprehensive set of metadata for a wide variety of architectures, features, and applications Open Embedded in Poky Repo using Yocto Project","title":"OpenEmbedded Core"},{"location":"blog/yocto/introduction/#terminology","text":"","title":"Terminology"},{"location":"blog/yocto/introduction/#metadata","text":"Metadata is collection of: Recipes (.bb and .bbappend) Configuration files (.conf) Classes (.bbclass) Includes (.inc)","title":"Metadata"},{"location":"blog/yocto/introduction/#recipes","text":"A recipe is a set of instructions that is read and processed by the bitbake. Extension: .bb A recipe describes: where you get source code which patches to apply Configuration options Compile options (library dependencies) Install License","title":"Recipes"},{"location":"blog/yocto/introduction/#configuration-files","text":"They tell the build system what to build and put into the image to support a particular platform Extension: .conf Files which hold : global definition of variables user defined variables and hardware configuration information Types : Machine Configuration Options Distribution Configuration Options Compiler tuning options General Common Configuration Options User Configuration Options (local.conf)","title":"Configuration Files"},{"location":"blog/yocto/introduction/#classes","text":"Class files are used to abstract common functionality and share it amongst multiple recipe (.bb) files. To use a class, add inherit <classname> in the recipe file. Extension: .bbclass","title":"Classes"},{"location":"blog/yocto/introduction/#layers","text":"A collection of related recipes. Typical naming convention: meta-<layername> . Layers provide a mechanism to isolate metadata according to functionality, for instance BSPs, distribution configuration, etc. BBLAYERS variable present in build/conf/bblayers.conf file list the layers Bitbake tries to find. If bblayers.conf is not present when you start the build, the OpenEmbedded build system creates it from bblayers.conf.sample when you source the oe-init-build-env script. Command to find out which layers are present: bitbake-layers show-layers Where to get other layers: Yocto Project Compatible Layers: https://www.yoctoproject.org/software-overview/layers/ OpenEmbedded Layers: https://layers.openembedded.org/layerindex/branch/master/layers/ .","title":"Layers"},{"location":"blog/yocto/introduction/#packages","text":"A package is a binary file with name .rpm, .deb, or *.ipkg. A single recipe may produce many packages. All packages that a recipe generated are listed in the recipe variable.","title":"Packages"},{"location":"blog/yocto/introduction/#image","text":"An image is the top level recipe, it has a description, a license and inherits the core-image class. Image is architecture agnostic and defines how the root filesystem is built, with what packages. Command to check the list of available image recipes: ls meta*/recipes*/images/*.bb","title":"Image"},{"location":"blog/yocto/introduction/#prerequisites","text":"Host Linux machine Use a native Linux machine for better performance. A virtual machine can be used also. Install Ubuntu Server running in VirtualBox Virtual Machine settings: At least 4GB RAM, 128 GB HDD (Fixed Disk for better performance) Use more processors Disable Network to speed up installation Use Ubuntu Live Server image to install Enable OpenSSH server for remote access After installation: Enable Network for NAT + Host-only in Virtual machine settings Disable Journal features Boot into Recovery Mode on Ubuntu Grub menu (press ESC at boot), then select root termninal. echo \"u\" > /proc/sysrq-trigger tune2fs -O ^has_journal /dev/sda2 Change mounting option, and use tmpfs for /tmp sudo nano /etc/fstab UUID=/dev/sda2 / ext4 noatime,barrier=0,commit=6000,errors=remount-ro 0 1 tmpfs /tmp tmpfs rw,noatime,nosuid,nodev 0 0 /swap.img none swap sw 0 0 Set up system: Add current user to the sudoers: sudo bash -c \"echo ' $USER ALL=(ALL) NOPASSWD: ALL' > /etc/sudoers.d/ $USER \" Disable unattended upgrades sudo dpkg-reconfigure unattended-upgrades Use ip a to show availabe interface, such as enp0s3 and enp0s8 Configure Network through Netplan: sudo nano /etc/netplan/99_config.yaml network : version : 2 ethernets : enp0s3 : dhcp4 : true enp0s8 : dhcp4 : true sudo netplan apply Install Samba for file sharing Yocto build packages such as for Ubuntu sudo apt install \\ gawk wget git diffstat unzip texinfo gcc build-essential chrpath \\ socat cpio python3 python3-pip python3-pexpect xz-utils debianutils \\ iputils-ping python3-git python3-jinja2 libegl1-mesa libsdl1.2-dev \\ pylint3 xterm python3-subunit mesa-common-dev zstd liblz4-tool","title":"Prerequisites"},{"location":"blog/yocto/introduction/#workflow-of-yocto-project","text":"The general workflow Checkout the branch of Poky to use Check the Release table to see the version and tags. Note to select the latest branch supported by all layers. For example, on the writing date (Arp 7 th 2022), the latest version is Honister (3.4.3) , but the latest LTS version is Dunfell (3.1.15) which was released in Arp 2020. So, it is reasonable to use Dunfell for better compatibility. git clone -b dunfell \\ git://git.yoctoproject.org/poky.git tree pocky -L 1 pocky \u251c\u2500\u2500 bitbake \u251c\u2500\u2500 contrib \u251c\u2500\u2500 documentation \u251c\u2500\u2500 LICENSE \u251c\u2500\u2500 LICENSE.GPL-2.0-only \u251c\u2500\u2500 LICENSE.MIT \u251c\u2500\u2500 MEMORIAM \u251c\u2500\u2500 meta \u251c\u2500\u2500 meta-poky \u251c\u2500\u2500 meta-selftest \u251c\u2500\u2500 meta-skeleton \u251c\u2500\u2500 meta-yocto-bsp \u251c\u2500\u2500 oe-init-build-env \u251c\u2500\u2500 README.hardware -> meta-yocto-bsp/README.hardware \u251c\u2500\u2500 README.OE-Core \u251c\u2500\u2500 README.poky -> meta-poky/README.poky \u251c\u2500\u2500 README.qemu \u2514\u2500\u2500 scripts Prepare the build environment Poky provides you a script oe-init-build-env , which should be used to set up the build environment. You can pass a build_directory argument for the name of the directory where the environment is set. In case it is not given, it defaults to build . The above script will move you in a build folder and create two files ( local.conf , bblayers.conf ) inside conf folder. The defaults are set to build for a qemux86-64 . source poky/oe-init-build-env # ## Shell environment set up for builds. ### You can now run 'bitbake <target>' Common targets are: core-image-minimal core-image-sato meta-toolchain meta-ide-support You can also run generated qemu images with a command like 'runqemu qemux86' Other commonly useful commands are: - 'devtool' and 'recipetool' handle common recipe tasks - 'bitbake-layers' handles common layer tasks - 'oe-pkgdata-util' handles common target package tasks The config files: tree conf conf \u251c\u2500\u2500 bblayers.conf \u251c\u2500\u2500 local.conf \u2514\u2500\u2500 templateconf.cfg Check the Metadata and layers Refer to Bitbake User Manual for more infomation. Check the build configs: bitbake <target> -n Build Configuration: BB_VERSION = \"1.46.0\" BUILD_SYS = \"x86_64-linux\" NATIVELSBSTRING = \"ubuntu-18.04\" TARGET_SYS = \"x86_64-poky-linux\" MACHINE = \"qemux86-64\" DISTRO = \"poky\" DISTRO_VERSION = \"3.1.15\" TUNE_FEATURES = \"m64 core2\" TARGET_FPU = \"\" meta meta-poky meta-yocto-bsp = \"dunfell:ab03f130e449fdb24de79b119c73f0969f1bd801\" Build the target image Run bitbake with the target image name: bitbake <target> for example: core-image-minimal : the smallest image allowing a device to boot to check bootloader and kernel core-image-sato : an X11 Window-system-based image with a SATO theme and a GNOME mobile desktop environment bitbake core-image-minimal The first build will take quite long time to complete. Yocto will download source code and compile all components needed to make the target. Try to run the image: runqemu core-image-minimal adding nographic to run without the graphic window","title":"Workflow of Yocto Project"},{"location":"blog/yocto/introduction/#configurations","text":"","title":"Configurations"},{"location":"blog/yocto/introduction/#localconf","text":"Contains local user settings for almost aspects of the build system, is generated from meta-pocky/conf/local.conf.sample . local.conf file is a very convenient way to override several default configurations over all the Yocto Project\u2019s tools, but local.conf file is not tracked by source code manager. In general, everything in your local.conf should be moved to your own distro configuration. Finally, you should only set DISTRO to your own distro in local.conf . MACHINE : The target machine is being built for. E.g.: MACHINE = \"qemux86-64\" IMAGE_FSTYPES : Output image formats are list of different image formats. These images can be used for different purpose, such as rootfs, raw disk, MTD partition. E.g.: IMAGE_FSTYPES += \"tar.bz2 jffs2 wic\" CORE_IMAGE_EXTRA_INSTALL add extra packages to an image This is a convenience variable that enables you to add extra packages to an image based on the core-image class. E.g.: CORE_IMAGE_EXTRA_INSTALL += \"openssh\" IMAGE_INSTALL : This is the variable that controls what is included in any image. Use IMAGE_INSTALL_append only!\\ E.g.: IMAGE_INSTALL_append = \" openssh\" note the space Use IMAGE_INSTALL += will override the CORE_IMAGE_EXTRA_INSTALL that can lead to missing packages. DL_DIR : Where to place downloads During a first build the system will download many source code tarballs, from various upstream projects. These are all stored in DL_DIR . The default is a downloads directory under TOPDIR which is the build directory. This download folder can be shared between builds. It also can create tarball files using BB_GENERATE_MIRROR_TARBALLS = \"1\" option. You can also pre-fetch source code without running any compilation with --runonly=fetch option in bitbake. Example to create sharing downloaded package folder: DL_DIR ? = \" ${ HOME } /yocto-downloads\" bitbake <target> --runonly = fetch TMP_DIR : Where to place the build output This option specifies where the bulk of the building work should be done and where Bitbake should place its temporary files(source extraction, compilation) and output. BB_NUMBER_THREADS : Determine the number of tasks that Bitbake will perform in parallel Note: These tasks are related to bitbake and nothing related to compiling. Defaults to the number of CPUs on the system. PARALLEL_MAKE : Specify the number of processes that GNU make can run in parallel This specifies the number of processes that GNU make can run in parallel on a compilation task. Defaults to the number of CPUs on the system. Corresponds to the -j make option. rm_work : Remove source code and imtermediate files Yocto Build System can take a lot of disk space during build. But bitbake provides options to preserve disk space. You can tell bitbake to delete all the source code, build files after building a particular recipe by adding the following line in local.conf file: INHERIT += \"rm_work\" Disadvantage: Difficult to debug while build fails of any recipe. If you want to exclude bitbake deleting source code of a particular package, you can add it in RM_WORK_EXCLUDE variable, for example: RM_WORK_EXCLUDE += \"core-image-minimal\" Query a configuration For example, get BB_NUMBER_THREADS setting of the target core-image-minimal : bitbake -e core-image-minimal | grep ^BB_NUMBER_THREADS =","title":"local.conf"},{"location":"blog/yocto/introduction/#bblayersconf","text":"The bblayers.conf file tells Bitbake what layers you want considered during the build. By default, the layers listed in this file include layers minimally needed by the build system. However, you must manually add any custom layers you have created. BBLAYERS = \"\\ /home/vqtrong/poky/meta \\ /home/vqtrong/poky/meta-poky \\ /home/vqtrong/poky/meta-yocto-bsp \\ \" To add/remove a layer, you can use bitbake-layers command, for example: bitbake-layers add-layer ../meta-openembedded/meta-oe To show all layers: bitbake-layers show-layers Absolute paths in Config files When you copy project to another path, two files need modified: build/conf/bblayers.conf build/tmp/saved_tmpdir","title":"bblayers.conf"},{"location":"blog/yocto/introduction/#generated-images","text":"Top-level image targets : There are some top-level image targets defined for different purposes, such as: core-image-minimal : A small image just capable of allowing a device to boot. core-image-base : A console-only image that fully supports the target device hardware. core-image-sato : An image with Sato support, a mobile environment and visual style that works well with mobile devices. The image supports X11 with a Sato theme and applications such as a terminal, editor, file manager, media player, and so forth. core-image-weston : A very basic Wayland image with a terminal. This image provides the Wayland protocol libraries and the reference Weston compositor. core-image-x11 : A very basic X11 image with a terminal. Component images : The build process writes component images out to the Build Directory inside the tmp/deploy/images/machine/ folder: kernel-image : A kernel binary file. The KERNEL_IMAGETYPE variable determines the naming scheme for the kernel image file. root-filesystem-image : Root filesystem for the target device (e.g. .ext3 or .bz2 files). The IMAGE_FSTYPES variable determines the root filesystem image type kernel-modules : Tarballs that contain all the modules built for the kernel. bootloaders : If applicable to the target machine, bootloaders supporting the image. Image formats : Yocto can generate different image formats, e.g. tar file: extract into formatted partition partition image (e.g. ext4 , jffs2 ): raw copy to disk or MTD partition disk image (wic): raw copy to disk","title":"Generated Images"},{"location":"blog/yocto/raspberry-pi/","tags":["yocto","raspberry-pi"],"text":"This article use Yocto on Dulfell version Check the Release table to see the version and tags. Note to select the latest branch supported by all layers. For example, on the writing date (Arp 7 th 2022), the latest version is Honister (3.4.3), but the latest LTS version is Dunfell (3.1.15) which was released in Arp 2020. So, it is reasonable to use Dunfell for better compatibility. Raspberry Pi Layer # Go to OpenEmbedded Layers to search for layers raspberrypi in branch dunfell : https://layers.openembedded.org/layerindex/branch/dunfell/layer/meta-raspberrypi/ Read the overview manual to get some main points: Repo git://git.yoctoproject.org/meta-raspberrypi Branch: dunfell Readme: https://git.yoctoproject.org/meta-raspberrypi/tree/README.md?h=dunfell Dependencies : git://git.yoctoproject.org/poky Branch: dunfell git://git.openembedded.org/meta-openembedded Branch: dunfell Layers: meta-oe , meta-python , meta-multimedia , meta-networking Supported Machines : raspberrypi raspberrypi0 raspberrypi0-wifi raspberrypi2 raspberrypi3 raspberrypi3-64 (64-bit kernel & userspace) raspberrypi4 raspberrypi4-64 (64-bit kernel & userspace) raspberrypi-cm (dummy alias for raspberrypi) raspberrypi-cm3 can be checked using ls ../meta-raspberrypi/conf/machine/ Images core-image-base rpi-test-image can be checked using ls ../meta-raspberrypi/recipes-core/images/ Download and Setup # Go to project folder: cd $HOME Download poky and metadata layers # git clone -b dunfell \\ git://git.yoctoproject.org/poky.git git clone -b dunfell \\ git://git.yoctoproject.org/meta-raspberrypi.git git clone -b dunfell \\ git://git.openembedded.org/meta-openembedded Create build folder # source poky/oe-init-build-env Add layers # ~/build bitbake-layers add-layer ../meta-openembedded/meta-oe bitbake-layers add-layer ../meta-openembedded/meta-python bitbake-layers add-layer ../meta-openembedded/meta-multimedia bitbake-layers add-layer ../meta-openembedded/meta-networking bitbake-layers add-layer ../meta-raspberrypi bitbake-layers show-layers layer path priority ========================================================================== meta /home/vqtrong/poky/meta 5 meta-poky /home/vqtrong/poky/meta-poky 5 meta-yocto-bsp /home/vqtrong/poky/meta-yocto-bsp 5 meta-oe /home/vqtrong/meta-openembedded/meta-oe 6 meta-python /home/vqtrong/meta-openembedded/meta-python 7 meta-multimedia /home/vqtrong/meta-openembedded/meta-multimedia 6 meta-networking /home/vqtrong/meta-openembedded/meta-networking 5 meta-raspberrypi /home/vqtrong/meta-raspberrypi 9 Set build configs # build/conf/local.conf # target MACHINE ? = \"raspberrypi3-64\" # download folder DL_DIR ? = \" ${ HOME } /yocto-downloads\" # shared state folder SSTATE_DIR ? = \" ${ HOME } /yocto-sstate-cache\" # Dunfell (3.1.15), see more in <http://sstate.yoctoproject.org/> SSTATE_MIRRORS ? = \"file://.* http://sstate.yoctoproject.org/3.1.15/PATH;downloadfilename=PATH \\n \" # add a feature EXTRA_IMAGE_FEATURES_append = \" ssh-server-dropbear\" # add a recipe CORE_IMAGE_EXTRA_INSTALL_append = \" nano\" Check build configuration: bitbake core-image-base -n Build Configuration: BB_VERSION = \"1.46.0\" BUILD_SYS = \"x86_64-linux\" NATIVELSBSTRING = \"universal\" TARGET_SYS = \"aarch64-poky-linux\" MACHINE = \"raspberrypi3-64\" DISTRO = \"poky\" DISTRO_VERSION = \"3.1.15\" TUNE_FEATURES = \"aarch64 cortexa53 crc\" TARGET_FPU = \"\" meta meta-poky meta-yocto-bsp = \"dunfell:ab03f130e449fdb24de79b119c73f0969f1bd801\" meta-oe meta-python meta-multimedia meta-networking = \"dunfell:86b864a4d8c28185a4a464583fb86f73aa22847a\" meta-raspberrypi = \"dunfell:934064a01903b2ba9a82be93b3f0efdb4543a0e8\" Download packages # bitbake core-image-base --runonly = fetch Build and Run # Build the image # core-image-base is a console-only image that fully supports the target device hardware. bitbake core-image-base Image file The raw disk image is core-image-base-raspberrypi3-64.wic.bz2 , located in tmp/deploy/images/raspberrypi3-64/ . The WIC file can be directly flash to SD Card or eMMC: Extract the WIC file: cd tmp/deploy/images/raspberrypi3-64 bzip2 -d -f core-image-base-raspberrypi3-64.wic.bz2 Dump image to the SD Card at /dev/sdb sudo dd bs = 4M if = core-image-base-raspberrypi3-64.wic of = /dev/sdb status = progress conv = fsync Or use Raspberry Pi Imager or balenaEtcher to flash it. Run on Hardware # Plug the flashed SD Card to a Raspberry Pi 3 B+ board, and power it on. With a HMDI monitor attached to the board, you will finally see the console terminal as below. System console of Raspberry Pi base image By default, the username is root with an empty password. To turn it off, run poweroff command. Connect to Network Show available interface: ip a If Ethernet port is connected to a router, Pi will get an IP address automatically through udhcpd service. For the WiFi network, Pi includes all packages necessary for Wireless connection, however, the WiFi interface and configuration are not ready by default. Here are steps to use WiFi: Add WiFi credential: wpa_passphrase \u201c<SSID>\u201d \u201c<Password>\u201d >> /etc/wpa_supplicant.conf Bring up the interface: ifup wlan0 The system will run wpa_supplicant and udhcpc to connect to the selected WiFi network. Verify the assigned IP with: ifconfig wlan0","title":"Build minial image for Raspberry Pi"},{"location":"blog/yocto/raspberry-pi/#raspberry-pi-layer","text":"Go to OpenEmbedded Layers to search for layers raspberrypi in branch dunfell : https://layers.openembedded.org/layerindex/branch/dunfell/layer/meta-raspberrypi/ Read the overview manual to get some main points: Repo git://git.yoctoproject.org/meta-raspberrypi Branch: dunfell Readme: https://git.yoctoproject.org/meta-raspberrypi/tree/README.md?h=dunfell Dependencies : git://git.yoctoproject.org/poky Branch: dunfell git://git.openembedded.org/meta-openembedded Branch: dunfell Layers: meta-oe , meta-python , meta-multimedia , meta-networking Supported Machines : raspberrypi raspberrypi0 raspberrypi0-wifi raspberrypi2 raspberrypi3 raspberrypi3-64 (64-bit kernel & userspace) raspberrypi4 raspberrypi4-64 (64-bit kernel & userspace) raspberrypi-cm (dummy alias for raspberrypi) raspberrypi-cm3 can be checked using ls ../meta-raspberrypi/conf/machine/ Images core-image-base rpi-test-image can be checked using ls ../meta-raspberrypi/recipes-core/images/","title":"Raspberry Pi Layer"},{"location":"blog/yocto/raspberry-pi/#download-and-setup","text":"Go to project folder: cd $HOME","title":"Download and Setup"},{"location":"blog/yocto/raspberry-pi/#download-poky-and-metadata-layers","text":"git clone -b dunfell \\ git://git.yoctoproject.org/poky.git git clone -b dunfell \\ git://git.yoctoproject.org/meta-raspberrypi.git git clone -b dunfell \\ git://git.openembedded.org/meta-openembedded","title":"Download poky and metadata layers"},{"location":"blog/yocto/raspberry-pi/#create-build-folder","text":"source poky/oe-init-build-env","title":"Create build folder"},{"location":"blog/yocto/raspberry-pi/#add-layers","text":"~/build bitbake-layers add-layer ../meta-openembedded/meta-oe bitbake-layers add-layer ../meta-openembedded/meta-python bitbake-layers add-layer ../meta-openembedded/meta-multimedia bitbake-layers add-layer ../meta-openembedded/meta-networking bitbake-layers add-layer ../meta-raspberrypi bitbake-layers show-layers layer path priority ========================================================================== meta /home/vqtrong/poky/meta 5 meta-poky /home/vqtrong/poky/meta-poky 5 meta-yocto-bsp /home/vqtrong/poky/meta-yocto-bsp 5 meta-oe /home/vqtrong/meta-openembedded/meta-oe 6 meta-python /home/vqtrong/meta-openembedded/meta-python 7 meta-multimedia /home/vqtrong/meta-openembedded/meta-multimedia 6 meta-networking /home/vqtrong/meta-openembedded/meta-networking 5 meta-raspberrypi /home/vqtrong/meta-raspberrypi 9","title":"Add layers"},{"location":"blog/yocto/raspberry-pi/#set-build-configs","text":"build/conf/local.conf # target MACHINE ? = \"raspberrypi3-64\" # download folder DL_DIR ? = \" ${ HOME } /yocto-downloads\" # shared state folder SSTATE_DIR ? = \" ${ HOME } /yocto-sstate-cache\" # Dunfell (3.1.15), see more in <http://sstate.yoctoproject.org/> SSTATE_MIRRORS ? = \"file://.* http://sstate.yoctoproject.org/3.1.15/PATH;downloadfilename=PATH \\n \" # add a feature EXTRA_IMAGE_FEATURES_append = \" ssh-server-dropbear\" # add a recipe CORE_IMAGE_EXTRA_INSTALL_append = \" nano\" Check build configuration: bitbake core-image-base -n Build Configuration: BB_VERSION = \"1.46.0\" BUILD_SYS = \"x86_64-linux\" NATIVELSBSTRING = \"universal\" TARGET_SYS = \"aarch64-poky-linux\" MACHINE = \"raspberrypi3-64\" DISTRO = \"poky\" DISTRO_VERSION = \"3.1.15\" TUNE_FEATURES = \"aarch64 cortexa53 crc\" TARGET_FPU = \"\" meta meta-poky meta-yocto-bsp = \"dunfell:ab03f130e449fdb24de79b119c73f0969f1bd801\" meta-oe meta-python meta-multimedia meta-networking = \"dunfell:86b864a4d8c28185a4a464583fb86f73aa22847a\" meta-raspberrypi = \"dunfell:934064a01903b2ba9a82be93b3f0efdb4543a0e8\"","title":"Set build configs"},{"location":"blog/yocto/raspberry-pi/#download-packages","text":"bitbake core-image-base --runonly = fetch","title":"Download packages"},{"location":"blog/yocto/raspberry-pi/#build-and-run","text":"","title":"Build and Run"},{"location":"blog/yocto/raspberry-pi/#build-the-image","text":"core-image-base is a console-only image that fully supports the target device hardware. bitbake core-image-base Image file The raw disk image is core-image-base-raspberrypi3-64.wic.bz2 , located in tmp/deploy/images/raspberrypi3-64/ . The WIC file can be directly flash to SD Card or eMMC: Extract the WIC file: cd tmp/deploy/images/raspberrypi3-64 bzip2 -d -f core-image-base-raspberrypi3-64.wic.bz2 Dump image to the SD Card at /dev/sdb sudo dd bs = 4M if = core-image-base-raspberrypi3-64.wic of = /dev/sdb status = progress conv = fsync Or use Raspberry Pi Imager or balenaEtcher to flash it.","title":"Build the image"},{"location":"blog/yocto/raspberry-pi/#run-on-hardware","text":"Plug the flashed SD Card to a Raspberry Pi 3 B+ board, and power it on. With a HMDI monitor attached to the board, you will finally see the console terminal as below. System console of Raspberry Pi base image By default, the username is root with an empty password. To turn it off, run poweroff command. Connect to Network Show available interface: ip a If Ethernet port is connected to a router, Pi will get an IP address automatically through udhcpd service. For the WiFi network, Pi includes all packages necessary for Wireless connection, however, the WiFi interface and configuration are not ready by default. Here are steps to use WiFi: Add WiFi credential: wpa_passphrase \u201c<SSID>\u201d \u201c<Password>\u201d >> /etc/wpa_supplicant.conf Bring up the interface: ifup wlan0 The system will run wpa_supplicant and udhcpc to connect to the selected WiFi network. Verify the assigned IP with: ifconfig wlan0","title":"Run on Hardware"},{"location":"projects/","text":"I have published some of my personal projects on my GitHub at vuquangtrong . If you are interested, feel free to ask me for more details. Any feedback or comment is welcomed. .card { padding: 0.5em 1em; background-color: whitesmoke; margin: 0.5em 0; } dt { margin-top: 0 !important; } STM32 Tutorials at STM32-Tutorials I made this series of tutorials as a training courses in my company. I\u2019d like to share it here to help others who also start learning about ARM Cortex-M microcontrollers. Lidar Mapping (PoC) This is a personal project aiming to make a high precision Lidar Mapping system using GNSS and IMU. It is good for me to learn to design and implement an embedded system in a new area. MkDocs Material Blog theme at mkdocs-material-blog The Material for MkDocs theme hasn\u2019t supported blog yet, therefore I\u2019ve added some new components such as tags , tag cloud , and list of blog posts . Some features have recently appeared in Material for MkDocs Insider version. Simplify Pelican Theme at simplify-theme I used Pelican static site generator quite long time ago. At that time, I made a theme for this blog using Bootstrap and Jinja template. Pelican, same as MkDocs, is based on Python, and it is easy to be modified. VA-Camera at vacamera This is a small project that uses Accord framework and FFmpeg engine to record video streams from 2 cameras and write combined videos with some overlay text to mp4 files. Because the application runs in a very low performance machine, I\u2019ve had to add some optimizations on the image buffer. Tiva C TM4C123G Launchpad at tiva-c I practiced on ARM Cortex-M4F which was the first ARM core I learned. That repo contains my self-learning projects, including Bring Up, Sensors, LCD, Bootloader and Firmware Update. SMS Web Hub at smswebhub This project uses a mobile phone to process commands from a website on the internet (e.g. hosted on a VPS) via websocket , include sending SMS, checking balance, calling a phone number, and forwarding messages. Other Proof of Concept (PoC) projects at PoC This repo has prototypes for freelance projects I have done. As their source code are not allowed to be published by contracts, I just show some demonstrations with a few features somehow related to the projects.","title":"Projects"},{"location":"projects/gnss-base/","tags":["gnss"],"text":"Install an Operating System # A quick method using the official Raspberry Pi tool: Download, install and run Raspberry Pi Imager . Select Operating System: Raspberry Pi OS (other) \u2192 Raspberry Pi OS Lite . Press ctrl-shift-x to show Advanced Options: Set Hostname, e.g. raspberrypi.local Enable SSH after setting up an account, e.g. user: pi / cccc Select the target microSD Card and write the image. Boot the Raspberry Pi board after inserting the microSD Card. Use an SSH client to connect to raspberrypi.local with username pi and password cccc . Some tweaks can be applied after login : To use some list commands, run: nano ~/.bashrc and enable alias for ls commands. Set Wifi Settings Run sudo raspi-config , select System Options , then select Wireless LAN , set the Country Code to US . Set priority for Wifi by adding below config at the end of the /etc/dhcpcd.conf file: sudo nano /etc/dhcpcd.conf /etc/dhcpcd.conf interface wlan0 metric 100 Update repos: sudo apt update Install build tools: sudo apt install git cmake Create Wifi Access Point # Follow the guide Setting up a Routed Wireless Access Point : Install packages: sudo DEBIAN_FRONTEND = noninteractive apt install -y \\ hostapd \\ dnsmasq \\ netfilter-persistent \\ iptables-persistent Set the static IP for the gateway by going to the end of the /etc/dhcpcd.conf file and add the following: sudo nano /etc/dhcpcd.conf /etc/dhcpcd.conf interface wlan0 static ip_address=192.168.4.1/24 nohook wpa_supplicant Configure the DHCP and DNS services: sudo mv /etc/dnsmasq.conf /etc/dnsmasq.conf.orig sudo nano /etc/dnsmasq.conf Add the following to the file and save it: /etc/dnsmasq.conf # Listening interface interface=wlan0 # Pool of IP addresses served via DHCP dhcp-range=192.168.4.2,192.168.4.20,255.255.255.0,24h # Local wireless DNS domain domain=wlan # Alias for this router address=/gw.wlan/192.168.4.1 Unblock Wifi: sudo rfkill unblock wlan Create the hostapd configuration file: sudo nano /etc/hostapd/hostapd.conf Add configs as below, note the SSID, and PassPhrase: /etc/hostapd/hostapd.conf country_code=US interface=wlan0 ssid=RPI_BASE hw_mode=g channel=7 macaddr_acl=0 auth_algs=1 ignore_broadcast_ssid=0 wpa=2 wpa_passphrase=TestTestTest wpa_key_mgmt=WPA-PSK wpa_pairwise=TKIP rsn_pairwise=CCMP Start the hostapd service: sudo systemctl unmask hostapd sudo systemctl enable hostapd Reboot if needed and recheck the wlan0 interface. iw wlan0 info Interface wlan0 ifindex 3 wdev 0x1 addr b8:27:eb:a9:f5:fc ssid RPI_BASE type AP wiphy 0 channel 7 (2442 MHz), width: 20 MHz, center1: 2442 MHz txpower 31.00 dBm To see devices connected to the Pi Access point: iw dev wlan0 station dump Switching between Access Point and Client mode Disable Access Point : sudo systemctl disable hostapd dnsmasq Comment the static ip config in /etc/dhcpcd.conf : sudo nano /etc/dhcpcd.conf /etc/dhcpcd.conf #interface wlan0 # static ip_address=192.168.4.1/24 # nohook wpa_supplicant Restart: sudo reboot Enable Access Point : sudo systemctl enable hostapd dnsmasq Uncomment the static IP config in /etc/dhcpcd.conf : sudo nano /etc/dhcpcd.conf /etc/dhcpcd.conf interface wlan0 static ip_address=192.168.4.1/24 nohook wpa_supplicant Restart: sudo reboot Peripheral Configuration # Need to enable SPI , I2C , and UART . Run sudo raspi-config and select Interface Options : Select SPI , and choose Yes to enable SPI Select I2C , and choose Yes to enable I2C Select Serial , and choose No to disable shell, then in next screen, choose Yes to enable Hardware Serial port Run: groups to check if the current user is added into groups gpio , spi , i2c and dialout . If not, run: sudo usermod -a -G gpio,spi,i2c,dialout $USER to add the current user to necessary groups. Reboot and list all enabled interfaces by run: ll /dev/i2c* ll /dev/spi* ll /dev/serial* for example: crw-rw---- 1 root i2c 89, 1 Dec 19 17:10 /dev/i2c-1 crw-rw---- 1 root i2c 89, 2 Dec 19 17:10 /dev/i2c-2 crw-rw---- 1 root spi 153, 0 Dec 19 17:10 /dev/spidev0.0 crw-rw---- 1 root spi 153, 1 Dec 19 17:10 /dev/spidev0.1 lrwxrwxrwx 1 root root 5 Dec 19 17:10 /dev/serial0 -> ttyS0 lrwxrwxrwx 1 root root 7 Dec 19 17:10 /dev/serial1 -> ttyAMA0 Check Serial with GNSS module Install COM app: sudo apt install -y picocom Then try to talk to the GNSS module connected to the mini UART1 : picocom /dev/ttyS0 -b 115200 To send versiona\\r\\n , type: versiona , enter , ctrl-j . The GNSS module should reply: $ command,versiona,response: OK*45 # VERSIONA,98,GPS,FINE,2189,51932000,0,0,18,722 ; \"UB4B0M\" , \"R3.00Build21213\" , \"B123G125R12E15a5bS1Z125-HRBMDFS0011N1-S20-P20-A3L:2120/Jan/6\" , \"2330304000024-HV4001210403092\" , \"2101327772076\" , \"2020/Mar/19\" *bb111567 To enable echo: ctrl-a , ctr-c . To exit: ctrl-a , ctrl-x . If the supplying power is not sufficient, COM port on GNSS module will not work. Check the dropping voltage on the power input. Check SPI with nRF24 Download RF24 library: git clone https://github.com/vuquangtrong/RF24 && \\ cd RF24 && \\ ./configure --driver = SPIDEV && \\ make && \\ sudo make install && \\ cd .. Make new file: nano rf24_tx.cpp rf24_tx.cpp #include <iostream> // cin, cout, endl #include <RF24/RF24.h> // create RF24 instance RF24 radio ( 24 /* CE = sys_gpio_24 */ , 0 /* CSN = 0 means spidev0.0 */ /* default speed is 10 Mbps */ ); // max payload of RF24 is 32 bytes uint8_t payload [ 32 ]; int main ( int argc , char ** argv ) { // perform hardware check if ( ! radio . begin ()) { std :: cout << \"radio hardware is not responding!!\" << std :: endl ; return 0 ; // quit now } radio . setPayloadSize ( 32 ); radio . setChannel ( 100 ); // 2400 + 100 = 2500 MHz, out of WiFi band // address, defaut length is 5 uint8_t tx_address [ 6 ] = \"1Addr\" ; // write to radio . openWritingPipe ( tx_address ); // always uses pipe 0 // For debugging info radio . printDetails (); // (smaller) function that prints raw register values radio . printPrettyDetails (); // (larger) function that prints human readable data // Start std :: cout << \"Start TX\" << std :: endl ; radio . stopListening (); // put radio in TX mode while ( true ) { radio . write ( & payload , 32 ); // transmit } } Compile: g++ -Ofast -Wall -pthread rf24_tx.cpp -lrf24 -o rf24_tx Run and check the log: ================ SPI Configuration ================ CSN Pin = /dev/spidev0.0 CE Pin = Custom GPIO24 SPI Speedz = 10 Mhz ================ NRF Configuration ================ STATUS = 0x0e RX_DR=0 TX_DS=0 MAX_RT=0 RX_P_NO=7 TX_FULL=0 RX_ADDR_P0-1 = 0x7264644131 0x65646f4e31 RX_ADDR_P2-5 = 0xc3 0xc4 0xc5 0xc6 TX_ADDR = 0x7264644131 RX_PW_P0-6 = 0x20 0x20 0x20 0x20 0x20 0x20 EN_AA = 0x3f EN_RXADDR = 0x03 RF_CH = 0x64 RF_SETUP = 0x03 CONFIG = 0x0e DYNPD/FEATURE = 0x00 0x00 Data Rate = 1 MBPS Model = nRF24L01+ CRC Length = 16 bits PA Power = PA_LOW ARC = 0 ================ SPI Configuration ================ CSN Pin = /dev/spidev0.0 CE Pin = Custom GPIO24 SPI Frequency = 10 Mhz ================ NRF Configuration ================ Channel = 100 (~ 2500 MHz) RF Data Rate = 1 MBPS RF Power Amplifier = PA_LOW RF Low Noise Amplifier = Enabled CRC Length = 16 bits Address Length = 5 bytes Static Payload Length = 32 bytes Auto Retry Delay = 1500 microseconds Auto Retry Attempts = 15 maximum Packets lost on current channel = 0 Retry attempts made for last transmission = 0 Multicast = Disabled Custom ACK Payload = Disabled Dynamic Payloads = Disabled Auto Acknowledgment = Enabled Primary Mode = TX TX address = 0x7264644131 pipe 0 ( open ) bound = 0x7264644131 pipe 1 ( open ) bound = 0x65646f4e31 pipe 2 (closed) bound = 0xc3 pipe 3 (closed) bound = 0xc4 pipe 4 (closed) bound = 0xc5 pipe 5 (closed) bound = 0xc6 Start TX Check I2C with OLED Install i2c dev tools: sudo apt install i2c-tools Detect devices on I2C bus 1 /dev/i2c-1 : sudo i2cdetect -y 1 Check if 0x3c is shown in the scanned address when an OLED 0.91in is connected. Download SSD1306 Library: git clone https://github.com/vuquangtrong/OLED_SSD1306_I2C_Linux.git && \\ cd OLED_SSD1306_I2C_Linux && \\ make && \\ sudo make install && \\ cd .. Write a small program: nano oled_progres_bar.c oled_progres_bar.c #include <string.h> #include <unistd.h> #include <SSD1306/ssd1306.h> int main () { char counter = 0 ; char buffer [ 4 ]; SSD1306_Init ( \"/dev/i2c-1\" ); while ( 1 ) { sprintf ( buffer , \"%d\" , counter ++ ); SSD1306_Clear (); SSD1306_WriteString ( 0 , 0 , \"counter:\" , & Font_7x10 , SSD1306_WHITE , SSD1306_OVERRIDE ); SSD1306_WriteString ( 0 , 10 , buffer , & Font_11x18 , SSD1306_WHITE , SSD1306_OVERRIDE ); SSD1306_DrawRectangle ( 0 , 28 , 128 , 4 , SSD1306_WHITE ); SSD1306_DrawFilledRectangle ( 0 , 28 , counter * 128 / 256 , 4 , SSD1306_WHITE ); SSD1306_Screen_Update (); sleep ( 0.2 ); } return 0 ; } Compile: gcc oled_progress_bar.c -lssd1306 -o oled_progress_bar Run and see the screen updated. Compile RTKLib # Download source code of the RTKLib 2.4.3 (beta): git clone https://github.com/tomojitakasu/RTKLIB.git -b rtklib_2.4.3 Build str2str app: cd RTKLIB/app/consapp/str2str/gcc && \\ make Build all Build dependent libs if using rnx2rtkp : sudo apt install gfortran && \\ cd RTKLIB/lib/iers/gcc && \\ make Build all apps: cd RTKLIB/app/consapp && \\ make Compile NTRIP Caster # Install build tool: sudo apt install cmake sudo apt install libev-dev Download source code: git clone https://github.com/tisyang/ntripcaster.git && \\ cd ntripcaster && \\ git submodule update --init Build app: mkdir build && \\ cd build && \\ cmake .. && \\ make Local test # Copy ntripcaster and RTKLib str2str to a new folder. Create a new ntripcaster.json to set up the caster, see the parameters as below: Parameters max_client and max_source is the number of connected agents, value of 0 means unlimitted. tokens_client sets policy for clients in the format: \"username:password\": \"mountpoint\" , value of * means any mountpoint. tokens_source sets policy for sources in the format: \"password\": \"mountpoint\" , value of * means any mountpoint. { \"listen_addr\" : \"0.0.0.0\" , \"listen_port\" : 2101 , \"max_client\" : 0 , \"max_source\" : 0 , \"max_pending\" : 10 , \"tokens_client\" : { \"test:test\" : \"*\" }, \"tokens_source\" : { \"test\" : \"*\" } } Run the NTRIP Caster: ./ntripcaster Configure GNSS module via shell: stty -F /dev/ttyS0 115200 mode base time 60 1 .0 2 .0 Check the position: echo \"gngga 1\" >> /dev/ttyS0 When the type of processed position is 7 , meaning base is fixed, then we can get RTCM messages: gnss.cmd unlog rtcm1006 10 rtcm1033 10 rtcm1074 1 rtcm1124 1 rtcm1084 1 rtcm1094 1 Stream RTCM messages to a local NTRIP Caster at localhost using username test at the mount point UB4B0M : ./str2str \\ -in serial://ttyS0:115200 \\ -out ntrips://:test@localhost:2101/UB4B0M \\ -c gnss.cmd Stream RTCM messages to a remote NTRIP Caster at 103.166.182.209 using username oegalaxy at the mount point UB4B0M : ./str2str \\ -in serial://ttyS0:115200 \\ -out ntrips://:oegalaxy@103.166.182.209:2101/UB4B0M \\ -c gnss.cmd A sample script to configure GNSS module and run NTRIP streamer: #!/bin/bash # converter function ddmm2dec () { d = $( bc <<< \" $1 /100\" ) m = $( bc <<< \" $1 - $d *100\" ) m = $( bc <<< \"scale=6; $m /60\" ) echo $d$m } # set up COM port stty -F /dev/ttyS0 115200 # request base mode echo \"unlog\" >> /dev/ttyS0 echo \"mode base time 60 1.0 2.0\" >> /dev/ttyS0 echo \"gngga 1\" >> /dev/ttyS0 # check the log lat = '' lon = '' alt = '' while read -r line < /dev/ttyS0 ; do echo $line fix = $( echo $line | awk -F ',' '{print $7}' ) # gps position mode is fixed, then exit the loop if [[ $fix == '7' ]] ; then lat = $( echo $line | awk -F ',' '{print $3}' ) lat = $( ddmm2dec $lat ) lon = $( echo $line | awk -F ',' '{print $5}' ) lon = $( ddmm2dec $lon ) alt = $( echo $line | awk -F ',' '{print $10}' ) break fi done echo $lat $lon $alt # clear output echo \"unlog\" >> /dev/ttyS0 # request streamer # from ttyS0, to localhost:2101 using test account at the test mountpoint ./str2str \\ -in serial://ttyS0:115200 \\ -out ntrips://:test@localhost:2101/test \\ -c gnss.cmd Create System Services # NTRIP Service # Run at startup, listen to Local RTK messages and broadcast to clients ntripcaster.service [Unit] Description = NTRIP Server After = multi-user.target [Service] Type = simple User = pi Group = pi ExecStart = /home/pi/base/ntripcaster /home/pi/base/ntripcaster.json Restart = on-abort [Install] WantedBy = multi-user.target ntripcaster.json { \"listen_addr\" : \"0.0.0.0\" , \"listen_port\" : 2101 , \"max_client\" : 0 , \"max_source\" : 0 , \"max_pending\" : 10 , \"tokens_client\" : { \"test:test\" : \"*\" }, \"tokens_source\" : { \"test\" : \"*\" } } Install the service: sudo cp ntripcaster.service /usr/lib/systemd sudo systemctl enable ntripcaster.service Button Service # Run at startup, show a welcome message Handle the User button: hold more than 3 seconds to restart Local RTK service button.py #!/usr/bin/python import RPi.GPIO as GPIO import time , subprocess , signal , os # first message subprocess . Popen ( '/home/pi/base/start' ) # use BCM mode, see low level pin number GPIO . setmode ( GPIO . BCM ) # BCM 24 = BOARD 18 # Pull down to make it GND by default GPIO . setup ( 24 , GPIO . IN , pull_up_down = GPIO . PUD_DOWN ) count = 0 try : while True : time . sleep ( 1 ) button = GPIO . input ( 24 ) print ( \"Button: \" , button ) if button == 1 : count += 1 if count == 3 : p = subprocess . Popen ([ 'ps' , '-A' ], stdout = subprocess . PIPE ) out , err = p . communicate () for line in out . splitlines (): #print(line) if ( b 'local_rtk' in line ) or ( b 'str2str' in line ): pid = int ( line . split ( None , 1 )[ 0 ]) os . kill ( pid , signal . SIGKILL ) # run new time . sleep ( 1 ) subprocess . Popen ( '/home/pi/base/local_rtk' ) else : count = 0 except KeyboardInterrupt : print ( \"Exit\" ) GPIO . cleanup () button.service [Unit] Description = Button After = multi-user.target [Service] Type = simple User = pi Group = pi ExecStart = /usr/bin/python /home/pi/base/button.py Restart = on-abort [Install] WantedBy = multi-user.target Install the service: sudo cp ntripcaster.service /usr/lib/systemd sudo systemctl enable ntripcaster.service Local RTK application # Called by Button service when user presses and holds more 3 seconds Handle the sequence to control GNSS module via serial Run local streaming server #include <iostream> #include <string> #include <iomanip> #include <vector> #include <signal.h> #include <stdlib.h> #include <unistd.h> #include <serial/SerialPort.h> #include \"oled.h\" #include \"fonts.h\" using namespace std ; SerialPort gnss ; I2C i2c1 ( 1 ); Oled lcd ( & i2c1 ); double lat ; double lon ; double alt ; int fix_mode ; int timeout ; char msg [ 32 ] = { 0 }; char buffer [ 1024 ] = { 0 }; void handle_Ctrl_C ( int s ) { try { cout << \"Terminating...\" << endl ; gnss . writeString ( \"unlog \\r\\n \" ); gnss . closeDevice (); } catch (...) { cout << \"error while closing...\" << endl ; } exit ( 0 ); } vector < string > stringSplit ( const string & s , const char delimiter ) { vector < string > tokens ; string token ; istringstream tokenStream ( s ); while ( getline ( tokenStream , token , delimiter )) { tokens . push_back ( token ); } return tokens ; } template < class Type > Type stringToNum ( const string & str ) { istringstream iss ( str ); Type num ; iss >> num ; return num ; } double convertNmeaToDouble ( const std :: string & val , const std :: string & dir ) { int dot = val . find ( '.' ); std :: string degree = val . substr ( 0 , dot -2 ); std :: string minute = val . substr ( dot -2 ); double ret = stringToNum < double > ( degree ) + stringToNum < double > ( minute ) / 60 ; if ( dir == \"S\" || dir == \"W\" ) { ret = - ret ; } return ret ; } void Oled_msg ( char * msg ) { lcd . clear (); lcd . text ( 0 , 26 , msg , Oled :: DOUBLE_SIZE ); lcd . display (); } void Oled_pos ( double & lat , double & lon , double & alt , int & fix_mode ) { lcd . clear (); snprintf ( msg , 32 , \"%10.6f\" , lat ); lcd . text ( 8 , 4 , msg /*, Oled::DOUBLE_SIZE*/ ); snprintf ( msg , 32 , \"%10.6f\" , lon ); lcd . text ( 8 , 4 + 12 , msg /*, Oled::DOUBLE_SIZE*/ ); snprintf ( msg , 32 , \"%10.6f\" , alt ); lcd . text ( 8 , 4 + 24 , msg /*, Oled::DOUBLE_SIZE */ ); switch ( fix_mode ) { case 0 : snprintf ( msg , 32 , \"%s\" , \"INVALID\" ); break ; case 1 : snprintf ( msg , 32 , \"%s\" , \"SINGLE \" ); break ; case 2 : snprintf ( msg , 32 , \"%s\" , \"DIFFPOS\" ); break ; case 4 : snprintf ( msg , 32 , \"%s\" , \"RTK-FIX\" ); break ; case 5 : snprintf ( msg , 32 , \"%s\" , \"RTK-FLT\" ); break ; case 6 : snprintf ( msg , 32 , \"%s\" , \"INSPOS \" ); break ; case 7 : snprintf ( msg , 32 , \"%s\" , \"BASEFIX\" ); break ; default : snprintf ( msg , 32 , \"%s\" , \"-------\" ); break ; } lcd . text ( 4 , 8 + 36 , msg , Oled :: DOUBLE_SIZE ); if ( fix_mode != 7 ) { snprintf ( msg , 32 , \"%3d\" , timeout ); lcd . text ( 8 * 12 , 8 + 36 , msg /*, Oled::DOUBLE_SIZE */ ); } lcd . display (); } int main ( /*int argc, char *argv[]*/ ) { // register handler struct sigaction sigHandler ; sigHandler . sa_handler = handle_Ctrl_C ; sigemptyset ( & sigHandler . sa_mask ); sigHandler . sa_flags = 0 ; sigaction ( SIGINT , & sigHandler , NULL ); // start OLED lcd . init (); lcd . text ( 0 , 26 , \"Initializing...\" ); lcd . display (); // talk to GNSS module if ( gnss . openDevice ( \"/dev/ttyS0\" , 115200 ) != 1 ) { snprintf ( msg , 32 , \"%s\" , \"ERROR!\" ); Oled_msg ( msg ); return -1 ; } snprintf ( msg , 32 , \"%s\" , \"GNSS OK!\" ); Oled_msg ( msg ); RESTART : timeout = 120 ; // request base mode gnss . writeString ( \"unlog \\r\\n \" ); gnss . writeString ( \"mode base time 60 \\r\\n \" ); gnss . writeString ( \"gngga 1 \\r\\n \" ); gnss . flushReceiver (); while ( 1 ) { int n = gnss . readString ( buffer , '\\n' , 1024 ); if ( n > 0 ) { string line = string ( buffer , n ); cout << line ; // $GNGGA,090031.00,2057.59811809,N,10546.17292292,E,1,18,2.2,16.4378,M,-28.2478,M,,*64 vector < string > message = stringSplit ( line , ',' ); if ( message [ 0 ] == \"$GNGGA\" && message [ 2 ] != \"\" ) { lat = convertNmeaToDouble ( message [ 2 ], message [ 3 ]); lon = convertNmeaToDouble ( message [ 4 ], message [ 5 ]); alt = stringToNum < double > ( message [ 9 ]); fix_mode = stringToNum < int > ( message [ 6 ]); Oled_pos ( lat , lon , alt , fix_mode ); if ( fix_mode == 7 ) { cout << \"Base fixed at \" << lat << \", \" << lon << \", \" << alt << endl ; break ; } } else { snprintf ( msg , 32 , \"WAIT %d\" , timeout ); Oled_msg ( msg ); } timeout -- ; if ( timeout == 0 ) { goto RESTART ; } } } gnss . writeString ( \"unlog \\r\\n \" ); // Stream RTCM3 to local ntripcaster // password = test // mountpoint = test char cmd [ 1024 ] = \"/home/pi/base/str2str \" \"-in serial://ttyS0:115200 \" \"-out ntrips://:test@localhost:2101/test \" \"-c /home/pi/base/gnss.cmd \" ; cout << \"Run:\" << endl ; cout << cmd << endl ; system ( cmd ); // Close the serial device cout << \"Closing...\" << endl ; gnss . writeString ( \"unlog \\r\\n \" ); gnss . closeDevice (); return 0 ; } unlog rtcm1006 com1 10 rtcm1033 com1 10 rtcm1074 com1 1 rtcm1124 com1 1 rtcm1084 com1 1 rtcm1094 com1 1 References # https://www.petig.eu/rtk/ https://github.com/eringerli/RpiNtripBase https://github.com/tisyang/ntripcaster https://github.com/vbulat2003/ntripcaster2 http://www.hiddenvision.co.uk/ez/","title":"Create a GNSS Base Station"},{"location":"projects/gnss-base/#install-an-operating-system","text":"A quick method using the official Raspberry Pi tool: Download, install and run Raspberry Pi Imager . Select Operating System: Raspberry Pi OS (other) \u2192 Raspberry Pi OS Lite . Press ctrl-shift-x to show Advanced Options: Set Hostname, e.g. raspberrypi.local Enable SSH after setting up an account, e.g. user: pi / cccc Select the target microSD Card and write the image. Boot the Raspberry Pi board after inserting the microSD Card. Use an SSH client to connect to raspberrypi.local with username pi and password cccc . Some tweaks can be applied after login : To use some list commands, run: nano ~/.bashrc and enable alias for ls commands. Set Wifi Settings Run sudo raspi-config , select System Options , then select Wireless LAN , set the Country Code to US . Set priority for Wifi by adding below config at the end of the /etc/dhcpcd.conf file: sudo nano /etc/dhcpcd.conf /etc/dhcpcd.conf interface wlan0 metric 100 Update repos: sudo apt update Install build tools: sudo apt install git cmake","title":"Install an Operating System"},{"location":"projects/gnss-base/#create-wifi-access-point","text":"Follow the guide Setting up a Routed Wireless Access Point : Install packages: sudo DEBIAN_FRONTEND = noninteractive apt install -y \\ hostapd \\ dnsmasq \\ netfilter-persistent \\ iptables-persistent Set the static IP for the gateway by going to the end of the /etc/dhcpcd.conf file and add the following: sudo nano /etc/dhcpcd.conf /etc/dhcpcd.conf interface wlan0 static ip_address=192.168.4.1/24 nohook wpa_supplicant Configure the DHCP and DNS services: sudo mv /etc/dnsmasq.conf /etc/dnsmasq.conf.orig sudo nano /etc/dnsmasq.conf Add the following to the file and save it: /etc/dnsmasq.conf # Listening interface interface=wlan0 # Pool of IP addresses served via DHCP dhcp-range=192.168.4.2,192.168.4.20,255.255.255.0,24h # Local wireless DNS domain domain=wlan # Alias for this router address=/gw.wlan/192.168.4.1 Unblock Wifi: sudo rfkill unblock wlan Create the hostapd configuration file: sudo nano /etc/hostapd/hostapd.conf Add configs as below, note the SSID, and PassPhrase: /etc/hostapd/hostapd.conf country_code=US interface=wlan0 ssid=RPI_BASE hw_mode=g channel=7 macaddr_acl=0 auth_algs=1 ignore_broadcast_ssid=0 wpa=2 wpa_passphrase=TestTestTest wpa_key_mgmt=WPA-PSK wpa_pairwise=TKIP rsn_pairwise=CCMP Start the hostapd service: sudo systemctl unmask hostapd sudo systemctl enable hostapd Reboot if needed and recheck the wlan0 interface. iw wlan0 info Interface wlan0 ifindex 3 wdev 0x1 addr b8:27:eb:a9:f5:fc ssid RPI_BASE type AP wiphy 0 channel 7 (2442 MHz), width: 20 MHz, center1: 2442 MHz txpower 31.00 dBm To see devices connected to the Pi Access point: iw dev wlan0 station dump Switching between Access Point and Client mode Disable Access Point : sudo systemctl disable hostapd dnsmasq Comment the static ip config in /etc/dhcpcd.conf : sudo nano /etc/dhcpcd.conf /etc/dhcpcd.conf #interface wlan0 # static ip_address=192.168.4.1/24 # nohook wpa_supplicant Restart: sudo reboot Enable Access Point : sudo systemctl enable hostapd dnsmasq Uncomment the static IP config in /etc/dhcpcd.conf : sudo nano /etc/dhcpcd.conf /etc/dhcpcd.conf interface wlan0 static ip_address=192.168.4.1/24 nohook wpa_supplicant Restart: sudo reboot","title":"Create Wifi Access Point"},{"location":"projects/gnss-base/#peripheral-configuration","text":"Need to enable SPI , I2C , and UART . Run sudo raspi-config and select Interface Options : Select SPI , and choose Yes to enable SPI Select I2C , and choose Yes to enable I2C Select Serial , and choose No to disable shell, then in next screen, choose Yes to enable Hardware Serial port Run: groups to check if the current user is added into groups gpio , spi , i2c and dialout . If not, run: sudo usermod -a -G gpio,spi,i2c,dialout $USER to add the current user to necessary groups. Reboot and list all enabled interfaces by run: ll /dev/i2c* ll /dev/spi* ll /dev/serial* for example: crw-rw---- 1 root i2c 89, 1 Dec 19 17:10 /dev/i2c-1 crw-rw---- 1 root i2c 89, 2 Dec 19 17:10 /dev/i2c-2 crw-rw---- 1 root spi 153, 0 Dec 19 17:10 /dev/spidev0.0 crw-rw---- 1 root spi 153, 1 Dec 19 17:10 /dev/spidev0.1 lrwxrwxrwx 1 root root 5 Dec 19 17:10 /dev/serial0 -> ttyS0 lrwxrwxrwx 1 root root 7 Dec 19 17:10 /dev/serial1 -> ttyAMA0 Check Serial with GNSS module Install COM app: sudo apt install -y picocom Then try to talk to the GNSS module connected to the mini UART1 : picocom /dev/ttyS0 -b 115200 To send versiona\\r\\n , type: versiona , enter , ctrl-j . The GNSS module should reply: $ command,versiona,response: OK*45 # VERSIONA,98,GPS,FINE,2189,51932000,0,0,18,722 ; \"UB4B0M\" , \"R3.00Build21213\" , \"B123G125R12E15a5bS1Z125-HRBMDFS0011N1-S20-P20-A3L:2120/Jan/6\" , \"2330304000024-HV4001210403092\" , \"2101327772076\" , \"2020/Mar/19\" *bb111567 To enable echo: ctrl-a , ctr-c . To exit: ctrl-a , ctrl-x . If the supplying power is not sufficient, COM port on GNSS module will not work. Check the dropping voltage on the power input. Check SPI with nRF24 Download RF24 library: git clone https://github.com/vuquangtrong/RF24 && \\ cd RF24 && \\ ./configure --driver = SPIDEV && \\ make && \\ sudo make install && \\ cd .. Make new file: nano rf24_tx.cpp rf24_tx.cpp #include <iostream> // cin, cout, endl #include <RF24/RF24.h> // create RF24 instance RF24 radio ( 24 /* CE = sys_gpio_24 */ , 0 /* CSN = 0 means spidev0.0 */ /* default speed is 10 Mbps */ ); // max payload of RF24 is 32 bytes uint8_t payload [ 32 ]; int main ( int argc , char ** argv ) { // perform hardware check if ( ! radio . begin ()) { std :: cout << \"radio hardware is not responding!!\" << std :: endl ; return 0 ; // quit now } radio . setPayloadSize ( 32 ); radio . setChannel ( 100 ); // 2400 + 100 = 2500 MHz, out of WiFi band // address, defaut length is 5 uint8_t tx_address [ 6 ] = \"1Addr\" ; // write to radio . openWritingPipe ( tx_address ); // always uses pipe 0 // For debugging info radio . printDetails (); // (smaller) function that prints raw register values radio . printPrettyDetails (); // (larger) function that prints human readable data // Start std :: cout << \"Start TX\" << std :: endl ; radio . stopListening (); // put radio in TX mode while ( true ) { radio . write ( & payload , 32 ); // transmit } } Compile: g++ -Ofast -Wall -pthread rf24_tx.cpp -lrf24 -o rf24_tx Run and check the log: ================ SPI Configuration ================ CSN Pin = /dev/spidev0.0 CE Pin = Custom GPIO24 SPI Speedz = 10 Mhz ================ NRF Configuration ================ STATUS = 0x0e RX_DR=0 TX_DS=0 MAX_RT=0 RX_P_NO=7 TX_FULL=0 RX_ADDR_P0-1 = 0x7264644131 0x65646f4e31 RX_ADDR_P2-5 = 0xc3 0xc4 0xc5 0xc6 TX_ADDR = 0x7264644131 RX_PW_P0-6 = 0x20 0x20 0x20 0x20 0x20 0x20 EN_AA = 0x3f EN_RXADDR = 0x03 RF_CH = 0x64 RF_SETUP = 0x03 CONFIG = 0x0e DYNPD/FEATURE = 0x00 0x00 Data Rate = 1 MBPS Model = nRF24L01+ CRC Length = 16 bits PA Power = PA_LOW ARC = 0 ================ SPI Configuration ================ CSN Pin = /dev/spidev0.0 CE Pin = Custom GPIO24 SPI Frequency = 10 Mhz ================ NRF Configuration ================ Channel = 100 (~ 2500 MHz) RF Data Rate = 1 MBPS RF Power Amplifier = PA_LOW RF Low Noise Amplifier = Enabled CRC Length = 16 bits Address Length = 5 bytes Static Payload Length = 32 bytes Auto Retry Delay = 1500 microseconds Auto Retry Attempts = 15 maximum Packets lost on current channel = 0 Retry attempts made for last transmission = 0 Multicast = Disabled Custom ACK Payload = Disabled Dynamic Payloads = Disabled Auto Acknowledgment = Enabled Primary Mode = TX TX address = 0x7264644131 pipe 0 ( open ) bound = 0x7264644131 pipe 1 ( open ) bound = 0x65646f4e31 pipe 2 (closed) bound = 0xc3 pipe 3 (closed) bound = 0xc4 pipe 4 (closed) bound = 0xc5 pipe 5 (closed) bound = 0xc6 Start TX Check I2C with OLED Install i2c dev tools: sudo apt install i2c-tools Detect devices on I2C bus 1 /dev/i2c-1 : sudo i2cdetect -y 1 Check if 0x3c is shown in the scanned address when an OLED 0.91in is connected. Download SSD1306 Library: git clone https://github.com/vuquangtrong/OLED_SSD1306_I2C_Linux.git && \\ cd OLED_SSD1306_I2C_Linux && \\ make && \\ sudo make install && \\ cd .. Write a small program: nano oled_progres_bar.c oled_progres_bar.c #include <string.h> #include <unistd.h> #include <SSD1306/ssd1306.h> int main () { char counter = 0 ; char buffer [ 4 ]; SSD1306_Init ( \"/dev/i2c-1\" ); while ( 1 ) { sprintf ( buffer , \"%d\" , counter ++ ); SSD1306_Clear (); SSD1306_WriteString ( 0 , 0 , \"counter:\" , & Font_7x10 , SSD1306_WHITE , SSD1306_OVERRIDE ); SSD1306_WriteString ( 0 , 10 , buffer , & Font_11x18 , SSD1306_WHITE , SSD1306_OVERRIDE ); SSD1306_DrawRectangle ( 0 , 28 , 128 , 4 , SSD1306_WHITE ); SSD1306_DrawFilledRectangle ( 0 , 28 , counter * 128 / 256 , 4 , SSD1306_WHITE ); SSD1306_Screen_Update (); sleep ( 0.2 ); } return 0 ; } Compile: gcc oled_progress_bar.c -lssd1306 -o oled_progress_bar Run and see the screen updated.","title":"Peripheral Configuration"},{"location":"projects/gnss-base/#compile-rtklib","text":"Download source code of the RTKLib 2.4.3 (beta): git clone https://github.com/tomojitakasu/RTKLIB.git -b rtklib_2.4.3 Build str2str app: cd RTKLIB/app/consapp/str2str/gcc && \\ make Build all Build dependent libs if using rnx2rtkp : sudo apt install gfortran && \\ cd RTKLIB/lib/iers/gcc && \\ make Build all apps: cd RTKLIB/app/consapp && \\ make","title":"Compile RTKLib"},{"location":"projects/gnss-base/#compile-ntrip-caster","text":"Install build tool: sudo apt install cmake sudo apt install libev-dev Download source code: git clone https://github.com/tisyang/ntripcaster.git && \\ cd ntripcaster && \\ git submodule update --init Build app: mkdir build && \\ cd build && \\ cmake .. && \\ make","title":"Compile NTRIP Caster"},{"location":"projects/gnss-base/#local-test","text":"Copy ntripcaster and RTKLib str2str to a new folder. Create a new ntripcaster.json to set up the caster, see the parameters as below: Parameters max_client and max_source is the number of connected agents, value of 0 means unlimitted. tokens_client sets policy for clients in the format: \"username:password\": \"mountpoint\" , value of * means any mountpoint. tokens_source sets policy for sources in the format: \"password\": \"mountpoint\" , value of * means any mountpoint. { \"listen_addr\" : \"0.0.0.0\" , \"listen_port\" : 2101 , \"max_client\" : 0 , \"max_source\" : 0 , \"max_pending\" : 10 , \"tokens_client\" : { \"test:test\" : \"*\" }, \"tokens_source\" : { \"test\" : \"*\" } } Run the NTRIP Caster: ./ntripcaster Configure GNSS module via shell: stty -F /dev/ttyS0 115200 mode base time 60 1 .0 2 .0 Check the position: echo \"gngga 1\" >> /dev/ttyS0 When the type of processed position is 7 , meaning base is fixed, then we can get RTCM messages: gnss.cmd unlog rtcm1006 10 rtcm1033 10 rtcm1074 1 rtcm1124 1 rtcm1084 1 rtcm1094 1 Stream RTCM messages to a local NTRIP Caster at localhost using username test at the mount point UB4B0M : ./str2str \\ -in serial://ttyS0:115200 \\ -out ntrips://:test@localhost:2101/UB4B0M \\ -c gnss.cmd Stream RTCM messages to a remote NTRIP Caster at 103.166.182.209 using username oegalaxy at the mount point UB4B0M : ./str2str \\ -in serial://ttyS0:115200 \\ -out ntrips://:oegalaxy@103.166.182.209:2101/UB4B0M \\ -c gnss.cmd A sample script to configure GNSS module and run NTRIP streamer: #!/bin/bash # converter function ddmm2dec () { d = $( bc <<< \" $1 /100\" ) m = $( bc <<< \" $1 - $d *100\" ) m = $( bc <<< \"scale=6; $m /60\" ) echo $d$m } # set up COM port stty -F /dev/ttyS0 115200 # request base mode echo \"unlog\" >> /dev/ttyS0 echo \"mode base time 60 1.0 2.0\" >> /dev/ttyS0 echo \"gngga 1\" >> /dev/ttyS0 # check the log lat = '' lon = '' alt = '' while read -r line < /dev/ttyS0 ; do echo $line fix = $( echo $line | awk -F ',' '{print $7}' ) # gps position mode is fixed, then exit the loop if [[ $fix == '7' ]] ; then lat = $( echo $line | awk -F ',' '{print $3}' ) lat = $( ddmm2dec $lat ) lon = $( echo $line | awk -F ',' '{print $5}' ) lon = $( ddmm2dec $lon ) alt = $( echo $line | awk -F ',' '{print $10}' ) break fi done echo $lat $lon $alt # clear output echo \"unlog\" >> /dev/ttyS0 # request streamer # from ttyS0, to localhost:2101 using test account at the test mountpoint ./str2str \\ -in serial://ttyS0:115200 \\ -out ntrips://:test@localhost:2101/test \\ -c gnss.cmd","title":"Local test"},{"location":"projects/gnss-base/#create-system-services","text":"","title":"Create System Services"},{"location":"projects/gnss-base/#ntrip-service","text":"Run at startup, listen to Local RTK messages and broadcast to clients ntripcaster.service [Unit] Description = NTRIP Server After = multi-user.target [Service] Type = simple User = pi Group = pi ExecStart = /home/pi/base/ntripcaster /home/pi/base/ntripcaster.json Restart = on-abort [Install] WantedBy = multi-user.target ntripcaster.json { \"listen_addr\" : \"0.0.0.0\" , \"listen_port\" : 2101 , \"max_client\" : 0 , \"max_source\" : 0 , \"max_pending\" : 10 , \"tokens_client\" : { \"test:test\" : \"*\" }, \"tokens_source\" : { \"test\" : \"*\" } } Install the service: sudo cp ntripcaster.service /usr/lib/systemd sudo systemctl enable ntripcaster.service","title":"NTRIP Service"},{"location":"projects/gnss-base/#button-service","text":"Run at startup, show a welcome message Handle the User button: hold more than 3 seconds to restart Local RTK service button.py #!/usr/bin/python import RPi.GPIO as GPIO import time , subprocess , signal , os # first message subprocess . Popen ( '/home/pi/base/start' ) # use BCM mode, see low level pin number GPIO . setmode ( GPIO . BCM ) # BCM 24 = BOARD 18 # Pull down to make it GND by default GPIO . setup ( 24 , GPIO . IN , pull_up_down = GPIO . PUD_DOWN ) count = 0 try : while True : time . sleep ( 1 ) button = GPIO . input ( 24 ) print ( \"Button: \" , button ) if button == 1 : count += 1 if count == 3 : p = subprocess . Popen ([ 'ps' , '-A' ], stdout = subprocess . PIPE ) out , err = p . communicate () for line in out . splitlines (): #print(line) if ( b 'local_rtk' in line ) or ( b 'str2str' in line ): pid = int ( line . split ( None , 1 )[ 0 ]) os . kill ( pid , signal . SIGKILL ) # run new time . sleep ( 1 ) subprocess . Popen ( '/home/pi/base/local_rtk' ) else : count = 0 except KeyboardInterrupt : print ( \"Exit\" ) GPIO . cleanup () button.service [Unit] Description = Button After = multi-user.target [Service] Type = simple User = pi Group = pi ExecStart = /usr/bin/python /home/pi/base/button.py Restart = on-abort [Install] WantedBy = multi-user.target Install the service: sudo cp ntripcaster.service /usr/lib/systemd sudo systemctl enable ntripcaster.service","title":"Button Service"},{"location":"projects/gnss-base/#local-rtk-application","text":"Called by Button service when user presses and holds more 3 seconds Handle the sequence to control GNSS module via serial Run local streaming server #include <iostream> #include <string> #include <iomanip> #include <vector> #include <signal.h> #include <stdlib.h> #include <unistd.h> #include <serial/SerialPort.h> #include \"oled.h\" #include \"fonts.h\" using namespace std ; SerialPort gnss ; I2C i2c1 ( 1 ); Oled lcd ( & i2c1 ); double lat ; double lon ; double alt ; int fix_mode ; int timeout ; char msg [ 32 ] = { 0 }; char buffer [ 1024 ] = { 0 }; void handle_Ctrl_C ( int s ) { try { cout << \"Terminating...\" << endl ; gnss . writeString ( \"unlog \\r\\n \" ); gnss . closeDevice (); } catch (...) { cout << \"error while closing...\" << endl ; } exit ( 0 ); } vector < string > stringSplit ( const string & s , const char delimiter ) { vector < string > tokens ; string token ; istringstream tokenStream ( s ); while ( getline ( tokenStream , token , delimiter )) { tokens . push_back ( token ); } return tokens ; } template < class Type > Type stringToNum ( const string & str ) { istringstream iss ( str ); Type num ; iss >> num ; return num ; } double convertNmeaToDouble ( const std :: string & val , const std :: string & dir ) { int dot = val . find ( '.' ); std :: string degree = val . substr ( 0 , dot -2 ); std :: string minute = val . substr ( dot -2 ); double ret = stringToNum < double > ( degree ) + stringToNum < double > ( minute ) / 60 ; if ( dir == \"S\" || dir == \"W\" ) { ret = - ret ; } return ret ; } void Oled_msg ( char * msg ) { lcd . clear (); lcd . text ( 0 , 26 , msg , Oled :: DOUBLE_SIZE ); lcd . display (); } void Oled_pos ( double & lat , double & lon , double & alt , int & fix_mode ) { lcd . clear (); snprintf ( msg , 32 , \"%10.6f\" , lat ); lcd . text ( 8 , 4 , msg /*, Oled::DOUBLE_SIZE*/ ); snprintf ( msg , 32 , \"%10.6f\" , lon ); lcd . text ( 8 , 4 + 12 , msg /*, Oled::DOUBLE_SIZE*/ ); snprintf ( msg , 32 , \"%10.6f\" , alt ); lcd . text ( 8 , 4 + 24 , msg /*, Oled::DOUBLE_SIZE */ ); switch ( fix_mode ) { case 0 : snprintf ( msg , 32 , \"%s\" , \"INVALID\" ); break ; case 1 : snprintf ( msg , 32 , \"%s\" , \"SINGLE \" ); break ; case 2 : snprintf ( msg , 32 , \"%s\" , \"DIFFPOS\" ); break ; case 4 : snprintf ( msg , 32 , \"%s\" , \"RTK-FIX\" ); break ; case 5 : snprintf ( msg , 32 , \"%s\" , \"RTK-FLT\" ); break ; case 6 : snprintf ( msg , 32 , \"%s\" , \"INSPOS \" ); break ; case 7 : snprintf ( msg , 32 , \"%s\" , \"BASEFIX\" ); break ; default : snprintf ( msg , 32 , \"%s\" , \"-------\" ); break ; } lcd . text ( 4 , 8 + 36 , msg , Oled :: DOUBLE_SIZE ); if ( fix_mode != 7 ) { snprintf ( msg , 32 , \"%3d\" , timeout ); lcd . text ( 8 * 12 , 8 + 36 , msg /*, Oled::DOUBLE_SIZE */ ); } lcd . display (); } int main ( /*int argc, char *argv[]*/ ) { // register handler struct sigaction sigHandler ; sigHandler . sa_handler = handle_Ctrl_C ; sigemptyset ( & sigHandler . sa_mask ); sigHandler . sa_flags = 0 ; sigaction ( SIGINT , & sigHandler , NULL ); // start OLED lcd . init (); lcd . text ( 0 , 26 , \"Initializing...\" ); lcd . display (); // talk to GNSS module if ( gnss . openDevice ( \"/dev/ttyS0\" , 115200 ) != 1 ) { snprintf ( msg , 32 , \"%s\" , \"ERROR!\" ); Oled_msg ( msg ); return -1 ; } snprintf ( msg , 32 , \"%s\" , \"GNSS OK!\" ); Oled_msg ( msg ); RESTART : timeout = 120 ; // request base mode gnss . writeString ( \"unlog \\r\\n \" ); gnss . writeString ( \"mode base time 60 \\r\\n \" ); gnss . writeString ( \"gngga 1 \\r\\n \" ); gnss . flushReceiver (); while ( 1 ) { int n = gnss . readString ( buffer , '\\n' , 1024 ); if ( n > 0 ) { string line = string ( buffer , n ); cout << line ; // $GNGGA,090031.00,2057.59811809,N,10546.17292292,E,1,18,2.2,16.4378,M,-28.2478,M,,*64 vector < string > message = stringSplit ( line , ',' ); if ( message [ 0 ] == \"$GNGGA\" && message [ 2 ] != \"\" ) { lat = convertNmeaToDouble ( message [ 2 ], message [ 3 ]); lon = convertNmeaToDouble ( message [ 4 ], message [ 5 ]); alt = stringToNum < double > ( message [ 9 ]); fix_mode = stringToNum < int > ( message [ 6 ]); Oled_pos ( lat , lon , alt , fix_mode ); if ( fix_mode == 7 ) { cout << \"Base fixed at \" << lat << \", \" << lon << \", \" << alt << endl ; break ; } } else { snprintf ( msg , 32 , \"WAIT %d\" , timeout ); Oled_msg ( msg ); } timeout -- ; if ( timeout == 0 ) { goto RESTART ; } } } gnss . writeString ( \"unlog \\r\\n \" ); // Stream RTCM3 to local ntripcaster // password = test // mountpoint = test char cmd [ 1024 ] = \"/home/pi/base/str2str \" \"-in serial://ttyS0:115200 \" \"-out ntrips://:test@localhost:2101/test \" \"-c /home/pi/base/gnss.cmd \" ; cout << \"Run:\" << endl ; cout << cmd << endl ; system ( cmd ); // Close the serial device cout << \"Closing...\" << endl ; gnss . writeString ( \"unlog \\r\\n \" ); gnss . closeDevice (); return 0 ; } unlog rtcm1006 com1 10 rtcm1033 com1 10 rtcm1074 com1 1 rtcm1124 com1 1 rtcm1084 com1 1 rtcm1094 com1 1","title":"Local RTK application"},{"location":"projects/gnss-base/#references","text":"https://www.petig.eu/rtk/ https://github.com/eringerli/RpiNtripBase https://github.com/tisyang/ntripcaster https://github.com/vbulat2003/ntripcaster2 http://www.hiddenvision.co.uk/ez/","title":"References"},{"location":"projects/lidar-base/","tags":["lidar","ros"],"text":"Components # Livox Lidar Livox Mid-40 provides SDK for Linux native C++ APIs and ROS driver . Livox only provides Livox Viewer 0.10.0 for 64-bit Ubuntu 16.04 (Xenial), no source code published. Raspberry Pi 4 B Official Raspberry Pi OS does not have 64-bit version until 20.04 (Bullseye). Ubuntu has provided 64-bit OS version for Raspberry Pi 4 from 18.04 (Bionic). ROS Livox ROS driver supports 64-bit Ubuntu 18.04, and ROS Melodic also fully supports Ubuntu 18.04. Install OS # Flash Image Download Ubuntu 18.04.5 arm64 raspi3 and use Etcher to flash image to an SD Card. After flashing, there are 2 partitions on the SD Card: system-boot : startup files and bootloader configs writeable : root path of system By default, Ubuntu image enables the primary mini UART port, and also enables the Linux system console on that port. Connect a USB to TTL serial converter to GPIO 14 (PIN8) and GPIO 15 (PIN 10) to access Pi through the UART port. To access Pi through network, follow below instructions. Refer Ubuntu on Raspberry Pi for more information. Configure HDMI LCD (optional) This section is for WaveShare 7-inch HDMI LCD . In the system-boot partition, add below lines to the end of the file usercfg.txt : hdmi_group = 2 hdmi_mode = 87 hdmi_cvt = 1024 600 60 6 0 0 0 dtoverlay = ads7846,cs=1,penirq=25,penirq_pull=2,speed=50000,keep_vref_on=0,swapxy=0,pmax=255,xohms=150,xmin=200,xmax=3900,ymin=200,ymax=3900 Enable SSH Add an empty file ssh in the system-boot partition to enable SSH. Set up Network Scan IP in LAN: for /L %i in (1,1,254) do ping -n 1 192.168.100.% i | findstr \"ms\" && echo %i >> ip.txt Then select an available IP in the network. e.g. 192.168.100.190. Starting from Ubuntu 18.04 LTS, Ubuntu uses Netplan to configure network interfaces by default. Edit the Netplan YAML configuration file network-config with the following content: version : 2 ethernets : eth0 : addresses : [ 192.168.100.190/24 ] gateway4 : 192.168.100.1 nameservers : addresses : [ 192.168.100.4 , 8.8.8.8 ] wifis : wlan0 : dhcp4 : true access-points : \"mynetwork\" : password : \"123456789\" This file is only used once at the first boot The configs will be copied to /etc/netplan/50-cloud-init.yaml . Scan for IP If you don\u2019t want to set a static IP, you can let the router assign an address using dhcp4: true option, and then scan for it later using ARP table. Ping all hosts in the LAN: for /L %i in (1,1,254) do ping -n 1 192.168.100.% i Check ARP table, and look for MAC of Pi 3 b8-27-eb or Pi 4 dc-a6-32 : arp -a | findstr b8-27-eb Boot up Use SSH to log in with the default user ubuntu , password: ubuntu . Right after the first time logging in, default password have to be changed. To skip entering password on sudo command, add current user to sudoers with the rule NOPASSWD : sudo bash -c \"echo ' $USER ALL=(ALL) NOPASSWD: ALL' > /etc/sudoers.d/ $USER \" Install Desktop Update packages: sudo apt update && \\ sudo apt upgrade -y Install Unity desktop environment without addons: sudo apt install ubuntu-desktop --no-install-recommends Or install the lightweight Xubuntu desktop without addons: sudo apt install xubuntu-desktop --no-install-recommends Missing packages in a minimal installation The option --no-install-recommends will not install many bloat packages (offices, mail, etc.,) that helps to reduce download and install size. However, it may cause GUI does not show up. The most happened issue is missing fbdev which shown in the log: ~/.local/share/xorg/Xorg.0.log ... (WW) Warning, couldn't open module fbdev (EE) Failed to load module \"fbdev\" (module does not exist, 0) ... Fatal server error: (EE) no screens found(EE) ... To install fbdev , run: sudo apt install xserver-xorg-video-fbdev Calibrate touch sensor The display can be calibrated via xinput-calibrator . sudo apt install xserver-xorg-input-evdev xinput-calibrator Create calibration config: sudo cp -rf /usr/share/X11/xorg.conf.d/10-evdev.conf /usr/share/X11/xorg.conf.d/45-evdev.conf sudo nano /usr/share/X11/xorg.conf.d/99-calibration.conf /usr/share/X11/xorg.conf.d/99-calibration.conf Section \"InputClass\" Identifier \"calibration\" MatchProduct \"ADS7846 Touchscreen\" Option \"Calibration\" \"106 3990 3826 172\" Option \"SwapAxes\" \"1\" Option \"EmulateThirdButton\" \"1\" Option \"EmulateThirdButtonTimeout\" \"1000\" Option \"EmulateThirdButtonMoveThreshold\" \"300\" EndSection After reboot, touch will work normally. You can perform touch calibration by clicking the Menu icon on the taskbar, selecting Preferences \u2192 Calibrate Touchscreen , and following the displayed prompts. Note to save calibration data back to /usr/share/X11/xorg.conf.d/99-calibration.conf . Auto Login Add new config for LightDM in sudo nano /etc/lightdm/lightdm.conf.d/60-xubuntu.conf /etc/lightdm/lightdm.conf.d/60-xubuntu.conf [Seat:*] user-session = xubuntu autologin-user = ubuntu Automount USB Install additional packages: sudo apt install thunar-volman gvfs udisks2 Plugged-in USB will be mounted into /media/ubuntu/<Label> or /media/ubuntu/<sdXy> . Install ROS # Adding repository and source list sudo apt-add-repository universe sudo apt-add-repository multiverse sudo apt-add-repository restricted sudo apt update Setup source list to get ROS packages: sudo sh -c 'echo \"deb http://packages.ros.org/ros/ubuntu $(lsb_release -sc) main\" > /etc/apt/sources.list.d/ros-latest.list' Add keys: sudo apt install -y curl && \\ curl -s https://raw.githubusercontent.com/ros/rosdistro/master/ros.asc | sudo apt-key add - Pull the package list: sudo apt update Install ROS Melodic desktop: sudo apt install -y ros-melodic-desktop --no-install-recommends It\u2019s convenient if the ROS environment variables are automatically added to a bash session every time a new shell is launched: echo \"source /opt/ros/melodic/setup.bash\" >> ~/.bashrc && \\ source ~/.bashrc A good way to check the installation is to ensure that environment variables like ROS_ROOT and ROS_PACKAGE_PATH are set: printenv | grep ROS ROS_ETC_DIR = /opt/ros/melodic/etc/ros ROS_ROOT = /opt/ros/melodic/share/ros ROS_MASTER_URI = http://localhost:11311 ROS_VERSION = 1 ROS_PYTHON_VERSION = 2 ROS_PACKAGE_PATH = /opt/ros/melodic/share ROSLISP_PACKAGE_DIRECTORIES = ROS_DISTRO = melodic Initialize the package rosdep to track package dependency: sudo apt install -y python-rosdep && \\ sudo rosdep init && \\ rosdep update Build packages are needed for code compilation. sudo apt install -y python-rosinstall python-rosinstall-generator python-wstool build-essential Create a catkin workspace and try to build it: mkdir -p ~/catkin_ws/src && \\ cd ~/catkin_ws/src && \\ catkin_init_workspace && \\ cd .. && \\ catkin_make The workspace should be built successfully. Install Livox SDK # Dependency # Livox SDK needs to be built in the host machine, therefore, some tool-chain and build tools have to be installed. sudo apt update && \\ sudo apt install -y build-essential && \\ sudo apt install -y curl && \\ sudo apt install -y git && \\ sudo apt install -y cmake The Pointcloud Library (PCL): sudo apt install -y libpcl-dev sudo apt install -y ros-melodic-pcl-ros Eigen is a C++ template library for linear algebra: sudo apt install -y libeigen3-dev OpenCV (Open Source Computer Vision Library) is an open-source computer vision library: sudo apt install -y python-opencv python3-opencv Re-link libraries: sudo ln -s /usr/bin/vtk6 /usr/bin/vtk aarch64 sudo ln -s /usr/lib/python2.7/dist-packages/vtk/libvtkRenderingPythonTkWidgets.aarch64-linux-gnu.so /usr/lib/aarch64-linux-gnu/libvtkRenderingPythonTkWidgets.so Livox SDK # The official guide is at https://github.com/Livox-SDK/Livox-SDK. Livox SDK is the software development kit designed for all Livox products. It is developed based on C/C++ following Livox SDK Communication Protocol, and provides easy-to-use C style API. With Livox SDK, users can quickly connect to Livox products and receive pointcloud data. Installation git clone https://github.com/Livox-SDK/Livox-SDK.git && \\ cd Livox-SDK && \\ cd build && \\ cmake .. && \\ make && \\ sudo make install The Livox SDK will be built and installed in /usr/local/lib : Install the project... -- Install configuration: \"\" -- Installing: /usr/local/lib/liblivox_sdk_static.a -- Installing: /usr/local/include/livox_def.h -- Installing: /usr/local/include/livox_sdk.h Install Livox ROS Driver # Get livox_ros_driver from GitHub git clone https://github.com/Livox-SDK/livox_ros_driver.git ws_livox/src Then build it: cd ws_livox && \\ catkin_make Compilation errors If running catkin_make gives error of command not found, it\u2019s probably that the ROS setup.bash is not executed and included in ~/.bashrc . See above section to source it. If gcc is halted, usually it is caused by lack of memory. The compilation takes more than 1.2 GB of RAM at peak! Test Lidar # Chang Ethernet IP to static IP in subnet 192.168.1.0/24 : /etc/netplan/50-cloud-init.yaml version : 2 ethernets : eth0 : addresses : [ 192.168.1.12/24 ] gateway4 : 192.168.1.1 Use Livox Viewer to set a Static IP for the Lidar module. Livox only accepts IP in 192.168.1.0 subnet. Then run the livox_lidar_rviz example: cd ws_livox source ./devel/setup.bash roslaunch livox_ros_driver livox_lidar_rviz.launch This will run Livox ROS and Rviz to visualize the received pointcloud.","title":"Set up a Lidar Base station for detecting vehicles"},{"location":"projects/lidar-base/#components","text":"Livox Lidar Livox Mid-40 provides SDK for Linux native C++ APIs and ROS driver . Livox only provides Livox Viewer 0.10.0 for 64-bit Ubuntu 16.04 (Xenial), no source code published. Raspberry Pi 4 B Official Raspberry Pi OS does not have 64-bit version until 20.04 (Bullseye). Ubuntu has provided 64-bit OS version for Raspberry Pi 4 from 18.04 (Bionic). ROS Livox ROS driver supports 64-bit Ubuntu 18.04, and ROS Melodic also fully supports Ubuntu 18.04.","title":"Components"},{"location":"projects/lidar-base/#install-os","text":"Flash Image Download Ubuntu 18.04.5 arm64 raspi3 and use Etcher to flash image to an SD Card. After flashing, there are 2 partitions on the SD Card: system-boot : startup files and bootloader configs writeable : root path of system By default, Ubuntu image enables the primary mini UART port, and also enables the Linux system console on that port. Connect a USB to TTL serial converter to GPIO 14 (PIN8) and GPIO 15 (PIN 10) to access Pi through the UART port. To access Pi through network, follow below instructions. Refer Ubuntu on Raspberry Pi for more information. Configure HDMI LCD (optional) This section is for WaveShare 7-inch HDMI LCD . In the system-boot partition, add below lines to the end of the file usercfg.txt : hdmi_group = 2 hdmi_mode = 87 hdmi_cvt = 1024 600 60 6 0 0 0 dtoverlay = ads7846,cs=1,penirq=25,penirq_pull=2,speed=50000,keep_vref_on=0,swapxy=0,pmax=255,xohms=150,xmin=200,xmax=3900,ymin=200,ymax=3900 Enable SSH Add an empty file ssh in the system-boot partition to enable SSH. Set up Network Scan IP in LAN: for /L %i in (1,1,254) do ping -n 1 192.168.100.% i | findstr \"ms\" && echo %i >> ip.txt Then select an available IP in the network. e.g. 192.168.100.190. Starting from Ubuntu 18.04 LTS, Ubuntu uses Netplan to configure network interfaces by default. Edit the Netplan YAML configuration file network-config with the following content: version : 2 ethernets : eth0 : addresses : [ 192.168.100.190/24 ] gateway4 : 192.168.100.1 nameservers : addresses : [ 192.168.100.4 , 8.8.8.8 ] wifis : wlan0 : dhcp4 : true access-points : \"mynetwork\" : password : \"123456789\" This file is only used once at the first boot The configs will be copied to /etc/netplan/50-cloud-init.yaml . Scan for IP If you don\u2019t want to set a static IP, you can let the router assign an address using dhcp4: true option, and then scan for it later using ARP table. Ping all hosts in the LAN: for /L %i in (1,1,254) do ping -n 1 192.168.100.% i Check ARP table, and look for MAC of Pi 3 b8-27-eb or Pi 4 dc-a6-32 : arp -a | findstr b8-27-eb Boot up Use SSH to log in with the default user ubuntu , password: ubuntu . Right after the first time logging in, default password have to be changed. To skip entering password on sudo command, add current user to sudoers with the rule NOPASSWD : sudo bash -c \"echo ' $USER ALL=(ALL) NOPASSWD: ALL' > /etc/sudoers.d/ $USER \" Install Desktop Update packages: sudo apt update && \\ sudo apt upgrade -y Install Unity desktop environment without addons: sudo apt install ubuntu-desktop --no-install-recommends Or install the lightweight Xubuntu desktop without addons: sudo apt install xubuntu-desktop --no-install-recommends Missing packages in a minimal installation The option --no-install-recommends will not install many bloat packages (offices, mail, etc.,) that helps to reduce download and install size. However, it may cause GUI does not show up. The most happened issue is missing fbdev which shown in the log: ~/.local/share/xorg/Xorg.0.log ... (WW) Warning, couldn't open module fbdev (EE) Failed to load module \"fbdev\" (module does not exist, 0) ... Fatal server error: (EE) no screens found(EE) ... To install fbdev , run: sudo apt install xserver-xorg-video-fbdev Calibrate touch sensor The display can be calibrated via xinput-calibrator . sudo apt install xserver-xorg-input-evdev xinput-calibrator Create calibration config: sudo cp -rf /usr/share/X11/xorg.conf.d/10-evdev.conf /usr/share/X11/xorg.conf.d/45-evdev.conf sudo nano /usr/share/X11/xorg.conf.d/99-calibration.conf /usr/share/X11/xorg.conf.d/99-calibration.conf Section \"InputClass\" Identifier \"calibration\" MatchProduct \"ADS7846 Touchscreen\" Option \"Calibration\" \"106 3990 3826 172\" Option \"SwapAxes\" \"1\" Option \"EmulateThirdButton\" \"1\" Option \"EmulateThirdButtonTimeout\" \"1000\" Option \"EmulateThirdButtonMoveThreshold\" \"300\" EndSection After reboot, touch will work normally. You can perform touch calibration by clicking the Menu icon on the taskbar, selecting Preferences \u2192 Calibrate Touchscreen , and following the displayed prompts. Note to save calibration data back to /usr/share/X11/xorg.conf.d/99-calibration.conf . Auto Login Add new config for LightDM in sudo nano /etc/lightdm/lightdm.conf.d/60-xubuntu.conf /etc/lightdm/lightdm.conf.d/60-xubuntu.conf [Seat:*] user-session = xubuntu autologin-user = ubuntu Automount USB Install additional packages: sudo apt install thunar-volman gvfs udisks2 Plugged-in USB will be mounted into /media/ubuntu/<Label> or /media/ubuntu/<sdXy> .","title":"Install OS"},{"location":"projects/lidar-base/#install-ros","text":"Adding repository and source list sudo apt-add-repository universe sudo apt-add-repository multiverse sudo apt-add-repository restricted sudo apt update Setup source list to get ROS packages: sudo sh -c 'echo \"deb http://packages.ros.org/ros/ubuntu $(lsb_release -sc) main\" > /etc/apt/sources.list.d/ros-latest.list' Add keys: sudo apt install -y curl && \\ curl -s https://raw.githubusercontent.com/ros/rosdistro/master/ros.asc | sudo apt-key add - Pull the package list: sudo apt update Install ROS Melodic desktop: sudo apt install -y ros-melodic-desktop --no-install-recommends It\u2019s convenient if the ROS environment variables are automatically added to a bash session every time a new shell is launched: echo \"source /opt/ros/melodic/setup.bash\" >> ~/.bashrc && \\ source ~/.bashrc A good way to check the installation is to ensure that environment variables like ROS_ROOT and ROS_PACKAGE_PATH are set: printenv | grep ROS ROS_ETC_DIR = /opt/ros/melodic/etc/ros ROS_ROOT = /opt/ros/melodic/share/ros ROS_MASTER_URI = http://localhost:11311 ROS_VERSION = 1 ROS_PYTHON_VERSION = 2 ROS_PACKAGE_PATH = /opt/ros/melodic/share ROSLISP_PACKAGE_DIRECTORIES = ROS_DISTRO = melodic Initialize the package rosdep to track package dependency: sudo apt install -y python-rosdep && \\ sudo rosdep init && \\ rosdep update Build packages are needed for code compilation. sudo apt install -y python-rosinstall python-rosinstall-generator python-wstool build-essential Create a catkin workspace and try to build it: mkdir -p ~/catkin_ws/src && \\ cd ~/catkin_ws/src && \\ catkin_init_workspace && \\ cd .. && \\ catkin_make The workspace should be built successfully.","title":"Install ROS"},{"location":"projects/lidar-base/#install-livox-sdk","text":"","title":"Install Livox SDK"},{"location":"projects/lidar-base/#dependency","text":"Livox SDK needs to be built in the host machine, therefore, some tool-chain and build tools have to be installed. sudo apt update && \\ sudo apt install -y build-essential && \\ sudo apt install -y curl && \\ sudo apt install -y git && \\ sudo apt install -y cmake The Pointcloud Library (PCL): sudo apt install -y libpcl-dev sudo apt install -y ros-melodic-pcl-ros Eigen is a C++ template library for linear algebra: sudo apt install -y libeigen3-dev OpenCV (Open Source Computer Vision Library) is an open-source computer vision library: sudo apt install -y python-opencv python3-opencv Re-link libraries: sudo ln -s /usr/bin/vtk6 /usr/bin/vtk aarch64 sudo ln -s /usr/lib/python2.7/dist-packages/vtk/libvtkRenderingPythonTkWidgets.aarch64-linux-gnu.so /usr/lib/aarch64-linux-gnu/libvtkRenderingPythonTkWidgets.so","title":"Dependency"},{"location":"projects/lidar-base/#livox-sdk","text":"The official guide is at https://github.com/Livox-SDK/Livox-SDK. Livox SDK is the software development kit designed for all Livox products. It is developed based on C/C++ following Livox SDK Communication Protocol, and provides easy-to-use C style API. With Livox SDK, users can quickly connect to Livox products and receive pointcloud data. Installation git clone https://github.com/Livox-SDK/Livox-SDK.git && \\ cd Livox-SDK && \\ cd build && \\ cmake .. && \\ make && \\ sudo make install The Livox SDK will be built and installed in /usr/local/lib : Install the project... -- Install configuration: \"\" -- Installing: /usr/local/lib/liblivox_sdk_static.a -- Installing: /usr/local/include/livox_def.h -- Installing: /usr/local/include/livox_sdk.h","title":"Livox SDK"},{"location":"projects/lidar-base/#install-livox-ros-driver","text":"Get livox_ros_driver from GitHub git clone https://github.com/Livox-SDK/livox_ros_driver.git ws_livox/src Then build it: cd ws_livox && \\ catkin_make Compilation errors If running catkin_make gives error of command not found, it\u2019s probably that the ROS setup.bash is not executed and included in ~/.bashrc . See above section to source it. If gcc is halted, usually it is caused by lack of memory. The compilation takes more than 1.2 GB of RAM at peak!","title":"Install Livox ROS Driver"},{"location":"projects/lidar-base/#test-lidar","text":"Chang Ethernet IP to static IP in subnet 192.168.1.0/24 : /etc/netplan/50-cloud-init.yaml version : 2 ethernets : eth0 : addresses : [ 192.168.1.12/24 ] gateway4 : 192.168.1.1 Use Livox Viewer to set a Static IP for the Lidar module. Livox only accepts IP in 192.168.1.0 subnet. Then run the livox_lidar_rviz example: cd ws_livox source ./devel/setup.bash roslaunch livox_ros_driver livox_lidar_rviz.launch This will run Livox ROS and Rviz to visualize the received pointcloud.","title":"Test Lidar"},{"location":"projects/lidar-mapping-poc/","text":"Work-in-Progress This project is a personal project for me to learn a new area. Some changes in hardware, software may not be fully updated in the documents here. Issue List Reference Components System Design GNSS Modules IMU Module Base Station Rover System Notes","title":"Lidar Mapping (PoC)"},{"location":"projects/lidar-mapping-poc/base/","text":"Operating System # Download Raspberry Pi Imager and install it. Run the Pi Imager, and select the Desktop version but without recommended software . Press Ctrl + Shift + X to show the advanced menu, fill some settings as below: Hostname: base SSH: yes Default username: pi , with password raspberry WiFi (optional): set SSID and password Alternative method using balenaEtcher Download Raspberry Pi OS image, select Desktop version but without recommended software . Download balenaEtcher and install it, and write the Image in an SD Card. After finishing, re-plug the SD Card. Initial settings: Default hostname: raspberrypi.local Add an empty file with name ssh into the boot partition to enabled SSH. Default username: pi , with password raspberry WiFi (optional): Enabling WiFi network by add a file wpa_supplicant.conf in the boot partition: country = US ctrl_interface = DIR=/var/run/wpa_supplicant GROUP=netdev update_config = 1 network = { ssid = \"NETWORK-NAME\" psk = \"NETWORK-PASSWORD\" } Some tweaks can be applied after login To use some list command, in .bashrc , enable alias for ls command. To disable animation on GUI: gsettings set org.gnome.desktop.interface enable-animations false If eth0 is used, it may take priority of network connection over the wlan0 . If internet is accessible through wlan0 , edit /etc/dhcpcd.conf and add this: interface wlan0 metric 100 Then wireless will have precedence, its default route/gateway will be used. Enable GPIO and peripherals The official tool raspi-config should be used to configure the Pi: sudo raspi-config Select Interfacing Options and select below item: SPI \u2192 Enable I2C \u2192 Enable Serial Port \u2192 No login shell \u2192 Enable After enabling the primary UART, the VPU clock will be set at 250 MHz. CPU clock will not be affected. We aren\u2019t going to use VPU, so it is acceptable to reduce its clock. Run groups to see the current user is added into groups for using GPIO including gpio , i2c and spi . Raspberry Pi 40-pin header UART Config # Refer to Raspberry Pi UART . There are two types of UART available on the Raspberry Pi - PL011 and mini UART . The PL011 is a capable, broadly 16550-compatible UART, while the mini UART has a reduced feature set. All UARTs on the Raspberry Pi are 3.3 V only. The Raspberry Pi 3 has below default UART configuration: Port Type Usage Pin Map Linux Device UART0 PL011 Secondary (Bluetooth), Enabled N/A /dev/serial1 UART1 mini UART Primary, Disabled GPIO 14 (TX), GPIO 15 (RX) /dev/serial0 That means the exported UART port on GPIO header is a mini-UART. The problem is the speed of mini-UART port depends on VPU (graphic) Core Frequency. The primary UART is disabled by default. It has to be enabled by running raspi-config to set up interfaces. Use PL011 on the primary UART via Device Tree overlay The two most useful overlays are disable-bt and miniuart-bt which can be added config.txt file, such as: dtoverlay = disable-bt The option disable-bt disables the Bluetooth device and makes the first PL011 (UART0) the primary UART. You must also disable the system service that initializes the modem, so it does not connect to the UART: sudo systemctl disable hciuart To get rid of using sudo permission, add current user into the serial group. Run ls -al /dev/tty* to check the user group of ttyS0 , ttyTHS1 . Normally, it is needed to add current user into tty and dialout groups: sudo usermod -a -G tty $USER && \\ sudo usermod -a -G dialout $USER && \\ sudo reboot UART Testing For testing, a serial terminal must be installed. Choose one of below. putty sudo apt install -y putty putty Follow GUI to run. minicom sudo apt install -y minicom minicom -D /dev/ttyS0 -b 115200 Press Ctrl-A X to exit. picocom sudo apt install -y picocom picocom /dev/ttyS0 -b 115200 Press Ctrl-A and Ctrl-X to exit. screen sudo apt install -y screen screen /dev/ttyS0 115200 Press Ctrl-A K to exit. Module Connection # Refer to below pinout diagram: Base wiring Serial driver # Download source code and build: git clone https://github.com/vuquangtrong/SerialPort.git && \\ cd SerialPort && \\ make && \\ sudo make install An example to communicate with Serial port: // Serial library #include \"serial/SerialPort.h\" #include <unistd.h> #include <stdio.h> #define SERIAL_PORT \"/dev/ttyS0\" int main ( /*int argc, char *argv[]*/ ) { SerialPort serial ; char errorOpening = serial . openDevice ( SERIAL_PORT , 115200 ); if ( errorOpening != 1 ) return errorOpening ; printf ( \"Successful connection to %s \\n \" , SERIAL_PORT ); // Display ASCII characters (from 32 to 128) for ( int c = 32 ; c < 128 ; c ++ ) { serial . writeChar ( c ); usleep ( 10000 ); } // Read lines and print them out char line [ 1024 ]; while ( 1 ) { int n = serial . readBytes ( line , sizeof ( line )); if ( n >= 0 ) { std :: cout << std :: string ( line , n ) << std :: endl ; } } // Close the serial device serial . closeDevice (); return 0 ; } Compile and run: g++ example.cpp -lserial -o example nRF24 driver # Download source code from GitHub and build: git clone https://github.com/vuquangtrong/RF24 && \\ cd RF24 && \\ ./configure --driver = SPIDEV && \\ make && \\ sudo make install SPIDEV must be used to avoid permission error when using default RPi BCM driver Work with the original source code GitHub at https://github.com/nRF24/RF24 . The guide to install in Linux at https://nrf24.github.io/RF24/md_docs_linux_install.html . Download the install.sh file: wget http://tmrh20.github.io/RF24Installer/RPi/install.sh Make it executable: chmod +x install.sh Run it and choose the option: RF24 Core SPIDEV driver ./install.sh Do you want to install GIT using APT (Used to download source code) [y/N]? n Do you want to install the RF24 core library, [y/N]? y Do you want to install the RF24Network library [y/N]? Do you want to install the RF24Mesh library [y/N]? Do you want to install the RF24Gateway library [y/N]? Installing RF24 Repo... __* Install RF24 core using? *__ 1.BCM2835 Driver(Performance) 2.SPIDEV(Compatibility, Default) 3.WiringPi(Its WiringPi!) 4.MRAA(Intel Devices) 5.LittleWire 2 ... [Installing Libs to /usr/local/lib] [Installing Headers to /usr/local/include/RF24] make: Leaving directory '/home/pi/rf24libs/RF24' Source to test data receiving. Check the transferring site in Rover . rf24_tx.cpp #include <iostream> // cin, cout, endl #include <RF24/RF24.h> // create RF24 instance RF24 radio ( 24 /* CE = sys_gpio_24 */ , 0 /* CSN = 0 means spidev0.0 */ /* default speed is 10 Mbps */ ); // max payload of RF24 is 32 bytes uint8_t payload [ 32 ]; int main ( int argc , char ** argv ) { // perform hardware check if ( ! radio . begin ()) { std :: cout << \"radio hardware is not responding!!\" << std :: endl ; return 0 ; // quit now } radio . setPayloadSize ( 32 ); radio . setChannel ( 100 ); // 2400 + 100 = 2500 MHz, out of WiFi band // address, defaut length is 5 uint8_t tx_address [ 6 ] = \"1Addr\" ; // write to radio . openWritingPipe ( tx_address ); // always uses pipe 0 // (smaller) function that prints raw register values radio . printDetails (); // (larger) function that prints human readable data radio . printPrettyDetails (); // Start std :: cout << \"Start TX\" << std :: endl ; radio . stopListening (); // put radio in TX mode while ( true ) { radio . write ( & payload , 32 ); // transmit } } Compile the source code: arm-linux-gnueabihf-g++ -marm -march = armv6zk -mtune = arm1176jzf-s -mfpu = vfp -mfloat-abi = hard -Ofast -Wall -pthread rf24_tx.cpp -lrf24 -o rf24_tx or just use: g++ -Ofast -Wall -pthread rf24_tx.cpp -lrf24 -o rf24_tx Run it and see the log: ================ SPI Configuration ================ CSN Pin = /dev/spidev0.0 CE Pin = Custom GPIO24 SPI Speedz = 10 Mhz ================ NRF Configuration ================ STATUS = 0x0e RX_DR = 0 TX_DS = 0 MAX_RT = 0 RX_P_NO = 7 TX_FULL = 0 RX_ADDR_P0-1 = 0x7264644131 0x65646f4e31 RX_ADDR_P2-5 = 0xc3 0xc4 0xc5 0xc6 TX_ADDR = 0x7264644131 RX_PW_P0-6 = 0x20 0x20 0x20 0x20 0x20 0x20 EN_AA = 0x3f EN_RXADDR = 0x03 RF_CH = 0x64 RF_SETUP = 0x03 CONFIG = 0x0e DYNPD/FEATURE = 0x00 0x00 Data Rate = 1 MBPS Model = nRF24L01+ CRC Length = 16 bits PA Power = PA_LOW ARC = 0 ================ SPI Configuration ================ CSN Pin = /dev/spidev0.0 CE Pin = Custom GPIO24 SPI Frequency = 10 Mhz ================ NRF Configuration ================ Channel = 100 ( ~ 2500 MHz ) RF Data Rate = 1 MBPS RF Power Amplifier = PA_LOW RF Low Noise Amplifier = Enabled CRC Length = 16 bits Address Length = 5 bytes Static Payload Length = 32 bytes Auto Retry Delay = 1500 microseconds Auto Retry Attempts = 15 maximum Packets lost on current channel = 0 Retry attempts made for last transmission = 0 Multicast = Disabled Custom ACK Payload = Disabled Dynamic Payloads = Disabled Auto Acknowledgment = Enabled Primary Mode = TX TX address = 0x7264644131 pipe 0 ( open ) bound = 0x7264644131 pipe 1 ( open ) bound = 0x65646f4e31 pipe 2 ( closed ) bound = 0xc3 pipe 3 ( closed ) bound = 0xc4 pipe 4 ( closed ) bound = 0xc5 pipe 5 ( closed ) bound = 0xc6 Start TX OLED driver # Download source code and build: git clone https://github.com/vuquangtrong/OLED_SSD1306_I2C_Linux.git && \\ cd OLED_SSD1306_I2C_Linux && \\ make && \\ sudo make install Write a simple app to a progress bar with label and numeric value: progress_bar.c #include <string.h> #include <unistd.h> #include <SSD1306/ssd1306.h> int main () { char counter = 0 ; char buffer [ 3 ]; SSD1306_Init ( \"/dev/i2c-1\" ); while ( 1 ) { sprintf ( buffer , \"%d\" , counter ++ ); SSD1306_Clear (); SSD1306_WriteString ( 0 , 0 , \"counter:\" , & Font_7x10 , SSD1306_WHITE , SSD1306_OVERRIDE ); SSD1306_WriteString ( 0 , 10 , buffer , & Font_11x18 , SSD1306_WHITE , SSD1306_OVERRIDE ); SSD1306_DrawRectangle ( 0 , 28 , 128 , 4 , SSD1306_WHITE ); SSD1306_DrawFilledRectangle ( 0 , 28 , counter * 128 / 256 , 4 , SSD1306_WHITE ); SSD1306_Screen_Update (); sleep ( 0.2 ); } return 0 ; } Compile and run: gcc progress_bar.c -lssd1306 -o progress_bar && \\ ./progress_bar Auto-mount USB # Check out and install: git clone https://github.com/vuquangtrong/USB_Automount.git && \\ cd USB_Automount && \\ ./install Plugged-in USB will be mounted into /media/<Label> or /media/<sdXy> . Auto-start application # Refer to Rover setup .","title":"Base Stattion on Raspberry Pi 3 B+ board"},{"location":"projects/lidar-mapping-poc/base/#operating-system","text":"Download Raspberry Pi Imager and install it. Run the Pi Imager, and select the Desktop version but without recommended software . Press Ctrl + Shift + X to show the advanced menu, fill some settings as below: Hostname: base SSH: yes Default username: pi , with password raspberry WiFi (optional): set SSID and password Alternative method using balenaEtcher Download Raspberry Pi OS image, select Desktop version but without recommended software . Download balenaEtcher and install it, and write the Image in an SD Card. After finishing, re-plug the SD Card. Initial settings: Default hostname: raspberrypi.local Add an empty file with name ssh into the boot partition to enabled SSH. Default username: pi , with password raspberry WiFi (optional): Enabling WiFi network by add a file wpa_supplicant.conf in the boot partition: country = US ctrl_interface = DIR=/var/run/wpa_supplicant GROUP=netdev update_config = 1 network = { ssid = \"NETWORK-NAME\" psk = \"NETWORK-PASSWORD\" } Some tweaks can be applied after login To use some list command, in .bashrc , enable alias for ls command. To disable animation on GUI: gsettings set org.gnome.desktop.interface enable-animations false If eth0 is used, it may take priority of network connection over the wlan0 . If internet is accessible through wlan0 , edit /etc/dhcpcd.conf and add this: interface wlan0 metric 100 Then wireless will have precedence, its default route/gateway will be used. Enable GPIO and peripherals The official tool raspi-config should be used to configure the Pi: sudo raspi-config Select Interfacing Options and select below item: SPI \u2192 Enable I2C \u2192 Enable Serial Port \u2192 No login shell \u2192 Enable After enabling the primary UART, the VPU clock will be set at 250 MHz. CPU clock will not be affected. We aren\u2019t going to use VPU, so it is acceptable to reduce its clock. Run groups to see the current user is added into groups for using GPIO including gpio , i2c and spi . Raspberry Pi 40-pin header","title":"Operating System"},{"location":"projects/lidar-mapping-poc/base/#uart-config","text":"Refer to Raspberry Pi UART . There are two types of UART available on the Raspberry Pi - PL011 and mini UART . The PL011 is a capable, broadly 16550-compatible UART, while the mini UART has a reduced feature set. All UARTs on the Raspberry Pi are 3.3 V only. The Raspberry Pi 3 has below default UART configuration: Port Type Usage Pin Map Linux Device UART0 PL011 Secondary (Bluetooth), Enabled N/A /dev/serial1 UART1 mini UART Primary, Disabled GPIO 14 (TX), GPIO 15 (RX) /dev/serial0 That means the exported UART port on GPIO header is a mini-UART. The problem is the speed of mini-UART port depends on VPU (graphic) Core Frequency. The primary UART is disabled by default. It has to be enabled by running raspi-config to set up interfaces. Use PL011 on the primary UART via Device Tree overlay The two most useful overlays are disable-bt and miniuart-bt which can be added config.txt file, such as: dtoverlay = disable-bt The option disable-bt disables the Bluetooth device and makes the first PL011 (UART0) the primary UART. You must also disable the system service that initializes the modem, so it does not connect to the UART: sudo systemctl disable hciuart To get rid of using sudo permission, add current user into the serial group. Run ls -al /dev/tty* to check the user group of ttyS0 , ttyTHS1 . Normally, it is needed to add current user into tty and dialout groups: sudo usermod -a -G tty $USER && \\ sudo usermod -a -G dialout $USER && \\ sudo reboot UART Testing For testing, a serial terminal must be installed. Choose one of below. putty sudo apt install -y putty putty Follow GUI to run. minicom sudo apt install -y minicom minicom -D /dev/ttyS0 -b 115200 Press Ctrl-A X to exit. picocom sudo apt install -y picocom picocom /dev/ttyS0 -b 115200 Press Ctrl-A and Ctrl-X to exit. screen sudo apt install -y screen screen /dev/ttyS0 115200 Press Ctrl-A K to exit.","title":"UART Config"},{"location":"projects/lidar-mapping-poc/base/#module-connection","text":"Refer to below pinout diagram: Base wiring","title":"Module Connection"},{"location":"projects/lidar-mapping-poc/base/#serial-driver","text":"Download source code and build: git clone https://github.com/vuquangtrong/SerialPort.git && \\ cd SerialPort && \\ make && \\ sudo make install An example to communicate with Serial port: // Serial library #include \"serial/SerialPort.h\" #include <unistd.h> #include <stdio.h> #define SERIAL_PORT \"/dev/ttyS0\" int main ( /*int argc, char *argv[]*/ ) { SerialPort serial ; char errorOpening = serial . openDevice ( SERIAL_PORT , 115200 ); if ( errorOpening != 1 ) return errorOpening ; printf ( \"Successful connection to %s \\n \" , SERIAL_PORT ); // Display ASCII characters (from 32 to 128) for ( int c = 32 ; c < 128 ; c ++ ) { serial . writeChar ( c ); usleep ( 10000 ); } // Read lines and print them out char line [ 1024 ]; while ( 1 ) { int n = serial . readBytes ( line , sizeof ( line )); if ( n >= 0 ) { std :: cout << std :: string ( line , n ) << std :: endl ; } } // Close the serial device serial . closeDevice (); return 0 ; } Compile and run: g++ example.cpp -lserial -o example","title":"Serial driver"},{"location":"projects/lidar-mapping-poc/base/#nrf24-driver","text":"Download source code from GitHub and build: git clone https://github.com/vuquangtrong/RF24 && \\ cd RF24 && \\ ./configure --driver = SPIDEV && \\ make && \\ sudo make install SPIDEV must be used to avoid permission error when using default RPi BCM driver Work with the original source code GitHub at https://github.com/nRF24/RF24 . The guide to install in Linux at https://nrf24.github.io/RF24/md_docs_linux_install.html . Download the install.sh file: wget http://tmrh20.github.io/RF24Installer/RPi/install.sh Make it executable: chmod +x install.sh Run it and choose the option: RF24 Core SPIDEV driver ./install.sh Do you want to install GIT using APT (Used to download source code) [y/N]? n Do you want to install the RF24 core library, [y/N]? y Do you want to install the RF24Network library [y/N]? Do you want to install the RF24Mesh library [y/N]? Do you want to install the RF24Gateway library [y/N]? Installing RF24 Repo... __* Install RF24 core using? *__ 1.BCM2835 Driver(Performance) 2.SPIDEV(Compatibility, Default) 3.WiringPi(Its WiringPi!) 4.MRAA(Intel Devices) 5.LittleWire 2 ... [Installing Libs to /usr/local/lib] [Installing Headers to /usr/local/include/RF24] make: Leaving directory '/home/pi/rf24libs/RF24' Source to test data receiving. Check the transferring site in Rover . rf24_tx.cpp #include <iostream> // cin, cout, endl #include <RF24/RF24.h> // create RF24 instance RF24 radio ( 24 /* CE = sys_gpio_24 */ , 0 /* CSN = 0 means spidev0.0 */ /* default speed is 10 Mbps */ ); // max payload of RF24 is 32 bytes uint8_t payload [ 32 ]; int main ( int argc , char ** argv ) { // perform hardware check if ( ! radio . begin ()) { std :: cout << \"radio hardware is not responding!!\" << std :: endl ; return 0 ; // quit now } radio . setPayloadSize ( 32 ); radio . setChannel ( 100 ); // 2400 + 100 = 2500 MHz, out of WiFi band // address, defaut length is 5 uint8_t tx_address [ 6 ] = \"1Addr\" ; // write to radio . openWritingPipe ( tx_address ); // always uses pipe 0 // (smaller) function that prints raw register values radio . printDetails (); // (larger) function that prints human readable data radio . printPrettyDetails (); // Start std :: cout << \"Start TX\" << std :: endl ; radio . stopListening (); // put radio in TX mode while ( true ) { radio . write ( & payload , 32 ); // transmit } } Compile the source code: arm-linux-gnueabihf-g++ -marm -march = armv6zk -mtune = arm1176jzf-s -mfpu = vfp -mfloat-abi = hard -Ofast -Wall -pthread rf24_tx.cpp -lrf24 -o rf24_tx or just use: g++ -Ofast -Wall -pthread rf24_tx.cpp -lrf24 -o rf24_tx Run it and see the log: ================ SPI Configuration ================ CSN Pin = /dev/spidev0.0 CE Pin = Custom GPIO24 SPI Speedz = 10 Mhz ================ NRF Configuration ================ STATUS = 0x0e RX_DR = 0 TX_DS = 0 MAX_RT = 0 RX_P_NO = 7 TX_FULL = 0 RX_ADDR_P0-1 = 0x7264644131 0x65646f4e31 RX_ADDR_P2-5 = 0xc3 0xc4 0xc5 0xc6 TX_ADDR = 0x7264644131 RX_PW_P0-6 = 0x20 0x20 0x20 0x20 0x20 0x20 EN_AA = 0x3f EN_RXADDR = 0x03 RF_CH = 0x64 RF_SETUP = 0x03 CONFIG = 0x0e DYNPD/FEATURE = 0x00 0x00 Data Rate = 1 MBPS Model = nRF24L01+ CRC Length = 16 bits PA Power = PA_LOW ARC = 0 ================ SPI Configuration ================ CSN Pin = /dev/spidev0.0 CE Pin = Custom GPIO24 SPI Frequency = 10 Mhz ================ NRF Configuration ================ Channel = 100 ( ~ 2500 MHz ) RF Data Rate = 1 MBPS RF Power Amplifier = PA_LOW RF Low Noise Amplifier = Enabled CRC Length = 16 bits Address Length = 5 bytes Static Payload Length = 32 bytes Auto Retry Delay = 1500 microseconds Auto Retry Attempts = 15 maximum Packets lost on current channel = 0 Retry attempts made for last transmission = 0 Multicast = Disabled Custom ACK Payload = Disabled Dynamic Payloads = Disabled Auto Acknowledgment = Enabled Primary Mode = TX TX address = 0x7264644131 pipe 0 ( open ) bound = 0x7264644131 pipe 1 ( open ) bound = 0x65646f4e31 pipe 2 ( closed ) bound = 0xc3 pipe 3 ( closed ) bound = 0xc4 pipe 4 ( closed ) bound = 0xc5 pipe 5 ( closed ) bound = 0xc6 Start TX","title":"nRF24 driver"},{"location":"projects/lidar-mapping-poc/base/#oled-driver","text":"Download source code and build: git clone https://github.com/vuquangtrong/OLED_SSD1306_I2C_Linux.git && \\ cd OLED_SSD1306_I2C_Linux && \\ make && \\ sudo make install Write a simple app to a progress bar with label and numeric value: progress_bar.c #include <string.h> #include <unistd.h> #include <SSD1306/ssd1306.h> int main () { char counter = 0 ; char buffer [ 3 ]; SSD1306_Init ( \"/dev/i2c-1\" ); while ( 1 ) { sprintf ( buffer , \"%d\" , counter ++ ); SSD1306_Clear (); SSD1306_WriteString ( 0 , 0 , \"counter:\" , & Font_7x10 , SSD1306_WHITE , SSD1306_OVERRIDE ); SSD1306_WriteString ( 0 , 10 , buffer , & Font_11x18 , SSD1306_WHITE , SSD1306_OVERRIDE ); SSD1306_DrawRectangle ( 0 , 28 , 128 , 4 , SSD1306_WHITE ); SSD1306_DrawFilledRectangle ( 0 , 28 , counter * 128 / 256 , 4 , SSD1306_WHITE ); SSD1306_Screen_Update (); sleep ( 0.2 ); } return 0 ; } Compile and run: gcc progress_bar.c -lssd1306 -o progress_bar && \\ ./progress_bar","title":"OLED driver"},{"location":"projects/lidar-mapping-poc/base/#auto-mount-usb","text":"Check out and install: git clone https://github.com/vuquangtrong/USB_Automount.git && \\ cd USB_Automount && \\ ./install Plugged-in USB will be mounted into /media/<Label> or /media/<sdXy> .","title":"Auto-mount USB"},{"location":"projects/lidar-mapping-poc/base/#auto-start-application","text":"Refer to Rover setup .","title":"Auto-start application"},{"location":"projects/lidar-mapping-poc/components/","text":".md-typeset .admonition.specs, .md-typeset details.specs { margin: -2rem 0 0 -1.2rem; } .md-typeset .admonition.specs > .admonition-title::before, .md-typeset details.specs > summary::before{ visibility: hidden; } .md-typeset :is(.admonition, details) > *:not(.admonition-title, summary) { padding-left: .6rem } The system has 2 main parts: Rover System is mounted on an RC Car or Drone to scan an area and map the captured point-cloud. Base Station acts as a stationary point which provide positioning correction to Rover for better accuracy. var expanded = false; function toggleDetails() { expanded = !expanded; self.checked = expanded; var d = document.getElementsByTagName(\"details\"); Array.from(d).forEach( function(obj, idx) { obj.open = expanded; }); var i = document.querySelectorAll(\"input.specs\"); console.log(i) Array.from(i).forEach( function(obj, idx) { obj.checked = expanded; }); } Rover System # Show specification 1 Livox Lidar Mid-40 It\u2019s better to get Converter 2.0 100,000 points per second POV: 38.4\u00b0 circular Upto 260m @ 80% reflectivity Livox Converter 1.0 : Power, Ethernet, Sync RS485. Jetson Nano Developer Kit CPU Quad-core ARM A57 @ 1.43 GHz GPU 128-core Maxwell RAM 4 GB 64-bit LPDDR4 25.6 GB/s Gigabit Ethernet, M.2 Key E 4x USB 3.0, USB 2.0 Micro-B GPIO, I2C, I2S, SPI, UARTs Micro-SD Card Should have 32 GB at high speed (V30) for saving point louds Sandisk Ultra 16 GB, class 10, SDHC I Unicorecomm GNSS UB482 GPS L1/L2 + BDS B1/B2 + GLONASS L1/ L2 + Galileo E1/E5b + QZSS L1/L2 Two antennas, support heading 20 Hz data output rate Ethernet, serial port, SPI, 1x PPS Harxon HX-CH7604A antennas All-constellation Multi-frequency L1/L2, G1/G2, E1, B1/B2/B3 SMA Female to MMCX Male UB482 has MMCX (Mini-MCX) Female connector HX-CH7604A has SMA Male connector InvenSense DK-20789 7-axis motion sensor Embedded Microchip G55 MCU and debugger Embedded Motion Drivers Rechargeable Battery 16 V with 2000 mAh Peak current at 4 A DC-DC Converter Except Lidar, all other boards use 5V Peak current at 4 A USB WiFi dongle TP-Link WN725N 150 Mbps 802.11 b/g/n, Internal antenna Ad-Hoc / Infrastructure Mode WiFi router No need this component if using a USB WiFi dongle connected to the Jetson board, and Lidar is connected directly with it. 4-port LAN Router 2 x Ethernet Cable Either connect Lidar to the Router or connect to the Jetson board directly after setting up static IPs on both sides. nRF24L01 2.4GHz Transceiver + PA + LNA ISM 2.4 GHz, 126 Channels GFSK 250 kbps, 1 Mbps v\u00e0 2 Mbps SPI interface to host MCU PA + LNA for upto 1 Km range USB TTL to RS485 No need this component if using Livox Converter 2.0 5 V operation, differential voltage >= 200 mV 3x USB TTL to COM No need this component if using on-board UARTs port after reconfiguring OS kernel 3.3 V/ 5 V USB to COM OLED LCD Show system status without connecting to PC via WiFi 128x64 Monochrome I2C interface Base Station # Show specification Raspberry Pi 3 B+ This can be repalaced by a MCU as Base only needs to log data and transmit RTCM3 messages Broadcom BCM2837B0, Cortex-A53 (ARMv8) 64-bit SoC @ 1.4 GHz 1 GB LPDDR2 SDRAM 2.4 GHz and 5 GHz IEEE 802.11.b/g/n/ac wireless LAN, Bluetooth 4.2, BLE Gigabit Ethernet over USB 2.0 4 USB 2.0 ports GPIO, I2C, I2S, SPI, UARTs Unicorecomm GNSS UB4B0M GPS L1/L2/L5 + BDS B1/B2/B3 + GLONASS L1/L2 + Galileo E1/E5a/E5b+ QZSS L1/L2/L5 Should cover the same constellation system of the Rover UARTs, 1x PPS Onboard MEMS integrated navigation Confirmed by Unicorecomm: new products do no have MEMS due to lack of chips! Harxon HX-CH7604A antennas All-constellation Multi-frequency L1/L2, G1/G2, E1, B1/B2/B3 SMA Female to MCX Male UB4B0M has MCX Female connector HX-CH7604A has SMA Male connector MicroSD Card Sandisk Ultra 16 GB, class 10, SDHC I Rechargeable Battery 5 V with 2000 mAh Peak current at 2 A nRF24L01 2.4 GHz Transceiver + PA + LNA ISM 2.4 GHz, 126 Channels GFSK 250 kbps, 1 Mbps v\u00e0 2 Mbps SPI interface to host MCU PA + LNA for upto 1 Km range USB TTL to COM No need this component if using on-board UARTs port after reconfiguring OS kernel 3.3 V/ 5 V to USB COM OLED LCD Show system status without connecting to PC via WiFi 128x64 Monochrome I2C interface Other stuff # Show specification PCB boards, M2.5 and M3 Copper Cylinder, Bolts STM32 Dev board Emulate GNSS data when GPS is not available (in house, or cloudy days) Header 2.0 mm, 2.54 mm Unicorecomm GNSS modules use headers at 2.0 mm pitch Jetson and Pi modules use headers at 2.54 mm pitch Remote Control Car with large base Mount Rover on the car for testing Script to expand detail blocks: < script > var expanded = false ; function toggleDetails () { expanded = ! expanded ; self . checked = expanded ; var d = document . getElementsByTagName ( \"details\" ); Array . from ( d ). forEach ( function ( obj , idx ) { obj . open = expanded ; }); var i = document . querySelectorAll ( \"input.specs\" ); console . log ( i ) Array . from ( i ). forEach ( function ( obj , idx ) { obj . checked = expanded ; }); } </ script > < label > < input type = \"checkbox\" class = \"specs\" onclick = \"toggleDetails()\" > Show specification[^scr] </ input > </ label > ??? specs \"\" Expandable content \u21a9","title":"Components"},{"location":"projects/lidar-mapping-poc/components/#rover-system","text":"Show specification 1 Livox Lidar Mid-40 It\u2019s better to get Converter 2.0 100,000 points per second POV: 38.4\u00b0 circular Upto 260m @ 80% reflectivity Livox Converter 1.0 : Power, Ethernet, Sync RS485. Jetson Nano Developer Kit CPU Quad-core ARM A57 @ 1.43 GHz GPU 128-core Maxwell RAM 4 GB 64-bit LPDDR4 25.6 GB/s Gigabit Ethernet, M.2 Key E 4x USB 3.0, USB 2.0 Micro-B GPIO, I2C, I2S, SPI, UARTs Micro-SD Card Should have 32 GB at high speed (V30) for saving point louds Sandisk Ultra 16 GB, class 10, SDHC I Unicorecomm GNSS UB482 GPS L1/L2 + BDS B1/B2 + GLONASS L1/ L2 + Galileo E1/E5b + QZSS L1/L2 Two antennas, support heading 20 Hz data output rate Ethernet, serial port, SPI, 1x PPS Harxon HX-CH7604A antennas All-constellation Multi-frequency L1/L2, G1/G2, E1, B1/B2/B3 SMA Female to MMCX Male UB482 has MMCX (Mini-MCX) Female connector HX-CH7604A has SMA Male connector InvenSense DK-20789 7-axis motion sensor Embedded Microchip G55 MCU and debugger Embedded Motion Drivers Rechargeable Battery 16 V with 2000 mAh Peak current at 4 A DC-DC Converter Except Lidar, all other boards use 5V Peak current at 4 A USB WiFi dongle TP-Link WN725N 150 Mbps 802.11 b/g/n, Internal antenna Ad-Hoc / Infrastructure Mode WiFi router No need this component if using a USB WiFi dongle connected to the Jetson board, and Lidar is connected directly with it. 4-port LAN Router 2 x Ethernet Cable Either connect Lidar to the Router or connect to the Jetson board directly after setting up static IPs on both sides. nRF24L01 2.4GHz Transceiver + PA + LNA ISM 2.4 GHz, 126 Channels GFSK 250 kbps, 1 Mbps v\u00e0 2 Mbps SPI interface to host MCU PA + LNA for upto 1 Km range USB TTL to RS485 No need this component if using Livox Converter 2.0 5 V operation, differential voltage >= 200 mV 3x USB TTL to COM No need this component if using on-board UARTs port after reconfiguring OS kernel 3.3 V/ 5 V USB to COM OLED LCD Show system status without connecting to PC via WiFi 128x64 Monochrome I2C interface","title":"Rover System"},{"location":"projects/lidar-mapping-poc/components/#base-station","text":"Show specification Raspberry Pi 3 B+ This can be repalaced by a MCU as Base only needs to log data and transmit RTCM3 messages Broadcom BCM2837B0, Cortex-A53 (ARMv8) 64-bit SoC @ 1.4 GHz 1 GB LPDDR2 SDRAM 2.4 GHz and 5 GHz IEEE 802.11.b/g/n/ac wireless LAN, Bluetooth 4.2, BLE Gigabit Ethernet over USB 2.0 4 USB 2.0 ports GPIO, I2C, I2S, SPI, UARTs Unicorecomm GNSS UB4B0M GPS L1/L2/L5 + BDS B1/B2/B3 + GLONASS L1/L2 + Galileo E1/E5a/E5b+ QZSS L1/L2/L5 Should cover the same constellation system of the Rover UARTs, 1x PPS Onboard MEMS integrated navigation Confirmed by Unicorecomm: new products do no have MEMS due to lack of chips! Harxon HX-CH7604A antennas All-constellation Multi-frequency L1/L2, G1/G2, E1, B1/B2/B3 SMA Female to MCX Male UB4B0M has MCX Female connector HX-CH7604A has SMA Male connector MicroSD Card Sandisk Ultra 16 GB, class 10, SDHC I Rechargeable Battery 5 V with 2000 mAh Peak current at 2 A nRF24L01 2.4 GHz Transceiver + PA + LNA ISM 2.4 GHz, 126 Channels GFSK 250 kbps, 1 Mbps v\u00e0 2 Mbps SPI interface to host MCU PA + LNA for upto 1 Km range USB TTL to COM No need this component if using on-board UARTs port after reconfiguring OS kernel 3.3 V/ 5 V to USB COM OLED LCD Show system status without connecting to PC via WiFi 128x64 Monochrome I2C interface","title":"Base Station"},{"location":"projects/lidar-mapping-poc/components/#other-stuff","text":"Show specification PCB boards, M2.5 and M3 Copper Cylinder, Bolts STM32 Dev board Emulate GNSS data when GPS is not available (in house, or cloudy days) Header 2.0 mm, 2.54 mm Unicorecomm GNSS modules use headers at 2.0 mm pitch Jetson and Pi modules use headers at 2.54 mm pitch Remote Control Car with large base Mount Rover on the car for testing Script to expand detail blocks: < script > var expanded = false ; function toggleDetails () { expanded = ! expanded ; self . checked = expanded ; var d = document . getElementsByTagName ( \"details\" ); Array . from ( d ). forEach ( function ( obj , idx ) { obj . open = expanded ; }); var i = document . querySelectorAll ( \"input.specs\" ); console . log ( i ) Array . from ( i ). forEach ( function ( obj , idx ) { obj . checked = expanded ; }); } </ script > < label > < input type = \"checkbox\" class = \"specs\" onclick = \"toggleDetails()\" > Show specification[^scr] </ input > </ label > ??? specs \"\" Expandable content \u21a9","title":"Other stuff"},{"location":"projects/lidar-mapping-poc/design/","text":"Based on the study of a reference project from Livox. Hardware # Check the list of Components . Block diagram # Base\u2019s components Rover\u2019s components Notes : All modules, except Livox\u2019s, are 3.3V level, so they can be connected directly. This helps to omit USB TTL-to-COM. Raspberry Pi 3 B+ has a built-in WiFi module. Power supply # Base\u2019s power supply Rover\u2019s power supply Wiring # Base wiring Rover wiring UART RX/TX problem Here is some reports showing that Jetson boards have problems on UART RX/TX pin when connecting that port directly to an other board. It maily causes by the capitive loading on the pin, if the loop-back test does not have any problem. If that problem happens, please add a 10 K pull-down resister on RX/TX pin. Refer to Unreliable serial communcation via the UART TX/RX GPIO Pins . Software # The mapping node gets the pointcloud from the Lidar ROS driver node, the GNSS and IMU data from the APX-15 node and processes them together: Store pointcloud with timestamp Store GNSS with timestamp Store IMU with timestamp Align packets using timestamp Apply IMU to GNSS point, and stick geographical information to pointcloud Combine position and pose into pointcloud","title":"System Design"},{"location":"projects/lidar-mapping-poc/design/#hardware","text":"Check the list of Components .","title":"Hardware"},{"location":"projects/lidar-mapping-poc/design/#block-diagram","text":"Base\u2019s components Rover\u2019s components Notes : All modules, except Livox\u2019s, are 3.3V level, so they can be connected directly. This helps to omit USB TTL-to-COM. Raspberry Pi 3 B+ has a built-in WiFi module.","title":"Block diagram"},{"location":"projects/lidar-mapping-poc/design/#power-supply","text":"Base\u2019s power supply Rover\u2019s power supply","title":"Power supply"},{"location":"projects/lidar-mapping-poc/design/#wiring","text":"Base wiring Rover wiring UART RX/TX problem Here is some reports showing that Jetson boards have problems on UART RX/TX pin when connecting that port directly to an other board. It maily causes by the capitive loading on the pin, if the loop-back test does not have any problem. If that problem happens, please add a 10 K pull-down resister on RX/TX pin. Refer to Unreliable serial communcation via the UART TX/RX GPIO Pins .","title":"Wiring"},{"location":"projects/lidar-mapping-poc/design/#software","text":"The mapping node gets the pointcloud from the Lidar ROS driver node, the GNSS and IMU data from the APX-15 node and processes them together: Store pointcloud with timestamp Store GNSS with timestamp Store IMU with timestamp Align packets using timestamp Apply IMU to GNSS point, and stick geographical information to pointcloud Combine position and pose into pointcloud","title":"Software"},{"location":"projects/lidar-mapping-poc/gnss/","text":"Overview # Key features All-constellation multi-frequency high-precision RTK and heading board, support BDS B1I/B2I + GPSL1/L2+GLONASS L1/L2+Galileo E1/E5b+QZSS L1/L2 Precise RTK positioning and heading Fast RTK Initialization time < 5 s. As tested, RTK Float status is acquired in 5 s, but RTK Fix status needs more time. 20 Hz data output rate Adaptive recognition of RTCM input data format Accuracy Single point: H = 1.5 m, V = 2.5 m DGPS & SAAB: H = 0.4 m, V = 0.8 m RTK: H = 1 cm, V = 1.5 m (RTK Fix only) Operation conditions All I/O pins are LV-TTL Level. Power Supply The module needs a stable power source, from 3.3 V to 5 V, with ripple rate is < 50 mA. Be aware that if connect to 3.3 V power, the drop voltage may happen and board will not work. It is recommended to use a power chip with current output capacity greater than 2 A to power the board. Power consumption may reach 2.6 W. UPrecise GUI UPrecise software provides a graphical interface to control and display the operation of the receiver. UPrecise GUI Right after connecting to the board though a UART port, UPrecise sends below commands: unlog # stop print out all logs gngga 1 # log position gngsv 1 # log satellite in view Commands # Reset Factory reset, clear all user configurations: freset System reset: reset Information Read version: versiona # VERSIONA,90,GPS,FINE,2171,345750000,0,0,18,28 ; \"UB482\" , \"R3.00Build20655\" , \"B123G12R12E15bS1Z12-HRBMDFS0011N1-S20-P20-A3L:2120/Jan/6\" , \"2330319000062-GN1201212700556\" , \"1432034796888\" , \"2019/Aug/27\" *cf090e25 Check antennas: antennaa # ANTENNAA,COM2,0,93.0,FINE,2171,347565.800,793915,4,18 ; ON,ON,OFF,0*ff8fa62e Configuration Get current settings: config $ command,config,response: OK*54 $ CONFIG,COM1,CONFIG COM1 115200 *23 $ CONFIG,COM2,CONFIG COM2 115200 *23 $ CONFIG,COM3,CONFIG COM3 115200 *23 $ CONFIG,PPS,CONFIG PPS ENABLE GPS POSITIVE 500000 1000 0 0 *6E $ CONFIG,INS,CONFIG INS DISABLE*70 $ CONFIG,INS,CONFIG INS ANGLE 0 ,0,0*75 $ CONFIG,INS,CONFIG INS ALIGNMENTVEL 5 .0*2F $ CONFIG,INS,CONFIG INS TIMEOUT 200 *6D $ CONFIG,INS,CONFIG IMUTOANT OFFSET 0 0 0 0 0 0 *6C $ CONFIG,INS,CONFIG IMUTOANT2 OFFSET 0 0 0 0 0 0 *5E $ CONFIG,INS,CONFIG INSSOL OFFSET 0 .0 0 .0 0 .0*77 $ CONFIG,UNDULATION,CONFIG UNDULATION AUTO*2B $ CONFIG,EVENT,CONFIG EVENT DISABLE*70 $ CONFIG,DGPSTIMEOUT,CONFIG DGPS TIMEOUT 300 *37 $ CONFIG,RTKTIMEOUT,CONFIG RTK TIMEOUT 100 *35 $ CONFIG,HEADING,CONFIG HEADING FIXLENGTH*6F $ CONFIG,PSRSMOOTH,CONFIG PSRSMOOTH DISABLE*70 Save settings: saveconfig Get current mode: mode # MODE,94,GPS,FINE,2171,345803000,0,0,18,982 ; mode rover,HEADINGMODE FIXLENGTH*2F By default, after factory reset, receiver will work in Rover Dynamic mode, which is the same as the below config: mode rover The receiver will automatically start RTK positioning when receiving correction data from any serial ports. NMEA Messages Get Position: gngga <period> Get satellites in view: gngsv <period> Get heading: gphdt <period> Get timestamp: gnrmc <period> Setup NTRIP client # The site http://rtk2go.com hosts free mount points for NTRIP casters. Accessing http://rtk2go.com:2101 will get a list of casters. A NTRIP client can access to its via either URL at rtk2go.com:2101 or via IP Address at 3.16.214.124:2101 . The open source project at http://rtklib.com has a tool STRSVR to stream NTRIP data from a caster. It firstly lists the available mount points to select, and then can forward the data stream to the UB482\u2019s COM2 (displayed as a COMx in host PC). The COM2 has to be set at high baudrate to be able to get correction message quickly: config com2 460800 RTKLib Stream Server RTK performance # Right after UB482 gets correction messages from NTRIP from its COM2 port: take 2 seconds to get DGPS/ SAAB accuracy (meter accuracy) take 5 seconds to get RTK Float accuracy (decimeter accuracy) take 5 minutes to get RTK Fix accuracy (centimeter accuracy) RTK Fix accuracy Some issues # Sometimes, system stays in RTK Float, and there is no RTK Fix in long time \u2192 Need to check other conditions which affect to RTK process. In Rover mode, there is no way to export raw observation data to use in post-processing. RTCM messages are only printed out in Base mode. Unicorecomm data has some observation messages OBSVMA . Unicorecomm has fixed their converter tool to convert OBSVMA data to RINEX format. There are some commands which do not work event are listed in UPrecise or in documents: Turning on IMU with config ins enable returns OK, but running rawimua returns an Unknown IMU type. \u2192 All new Unicorecomm GNSS modules have no INS feature, confirmed by Unicorecomm\u2019s engineers !!! Command interfacemode com2 rtcmv3 unicorecomm on returns wrong syntax. \u2192 No Unicorecomm output format in GNSS module !!! UB4B0 on Base # For RTK base station (fixed base station), the antenna is placed at a known coordinate with no changes during the whole use. Meanwhile, the precise coordinates of the known measurement station and the received satellite information will be sent to rover (yet to be positioned) by RTCM protocol directly or after processing. Communication RTCM message will be available on the COM1, at 115200 bps (8N1). Base\u2019s coordinate Since the base coordinate is unknown, Base will be set to self-optimization mode: mode base time 60 1 .0 2 .0 The command means: Within 60 seconds or when the standard deviation of horizontal position is less than 1.0 m and that of vertical position is less than 2.0 m, set the average position as the base\u2019s coordinate. Trigger below command once to get Base coordinate: gngga RTCM output Send below commands to get RTCM info: rtcm1006 com1 10 # Base station antenna rtcm1033 com1 10 # Description of receiver rtcm1074 com1 1 # GPS system correction data rtcm1124 com1 1 # BDS system correction data rtcm1084 com1 1 # Glonass system correction data rtcm1094 com1 1 # Galileo system correction data UB482 on Rover # Rover Station receives the real-time differential correction data from the base station. Rover can automatically recognize the RTCM data and perform RTK solution. There are three kinds of RTK mode: static mode , dynamic mode and automatic mode . The default setting is dynamic mode. The receiver will automatically start RTK positioning when receiving correction data from any serial ports. mode rover GNGGA output The position information should be sent on COM2 every second: gngga com2 1 The output frequency can be set up to 20 Hz: gngga com2 0 .05 GPRMC output The date time information should be sent on COM3 every second: gprmc com3 1 Appendix # Emlid provides RTK GNSS modules such as REACH M+ (at $265) which use U-Blox GNSS module and an integrated IMU. These modules support raw output for post-processing. A cheaper module named Navio2 is a good choice for an Autopilot HAT on Raspberry Pi. Emlid also provides free NTRIP Caster mount points to send corrections over the internet. It is similar to rtk2go .","title":"GNSS Module using Unicorecomm boards"},{"location":"projects/lidar-mapping-poc/gnss/#overview","text":"Key features All-constellation multi-frequency high-precision RTK and heading board, support BDS B1I/B2I + GPSL1/L2+GLONASS L1/L2+Galileo E1/E5b+QZSS L1/L2 Precise RTK positioning and heading Fast RTK Initialization time < 5 s. As tested, RTK Float status is acquired in 5 s, but RTK Fix status needs more time. 20 Hz data output rate Adaptive recognition of RTCM input data format Accuracy Single point: H = 1.5 m, V = 2.5 m DGPS & SAAB: H = 0.4 m, V = 0.8 m RTK: H = 1 cm, V = 1.5 m (RTK Fix only) Operation conditions All I/O pins are LV-TTL Level. Power Supply The module needs a stable power source, from 3.3 V to 5 V, with ripple rate is < 50 mA. Be aware that if connect to 3.3 V power, the drop voltage may happen and board will not work. It is recommended to use a power chip with current output capacity greater than 2 A to power the board. Power consumption may reach 2.6 W. UPrecise GUI UPrecise software provides a graphical interface to control and display the operation of the receiver. UPrecise GUI Right after connecting to the board though a UART port, UPrecise sends below commands: unlog # stop print out all logs gngga 1 # log position gngsv 1 # log satellite in view","title":"Overview"},{"location":"projects/lidar-mapping-poc/gnss/#commands","text":"Reset Factory reset, clear all user configurations: freset System reset: reset Information Read version: versiona # VERSIONA,90,GPS,FINE,2171,345750000,0,0,18,28 ; \"UB482\" , \"R3.00Build20655\" , \"B123G12R12E15bS1Z12-HRBMDFS0011N1-S20-P20-A3L:2120/Jan/6\" , \"2330319000062-GN1201212700556\" , \"1432034796888\" , \"2019/Aug/27\" *cf090e25 Check antennas: antennaa # ANTENNAA,COM2,0,93.0,FINE,2171,347565.800,793915,4,18 ; ON,ON,OFF,0*ff8fa62e Configuration Get current settings: config $ command,config,response: OK*54 $ CONFIG,COM1,CONFIG COM1 115200 *23 $ CONFIG,COM2,CONFIG COM2 115200 *23 $ CONFIG,COM3,CONFIG COM3 115200 *23 $ CONFIG,PPS,CONFIG PPS ENABLE GPS POSITIVE 500000 1000 0 0 *6E $ CONFIG,INS,CONFIG INS DISABLE*70 $ CONFIG,INS,CONFIG INS ANGLE 0 ,0,0*75 $ CONFIG,INS,CONFIG INS ALIGNMENTVEL 5 .0*2F $ CONFIG,INS,CONFIG INS TIMEOUT 200 *6D $ CONFIG,INS,CONFIG IMUTOANT OFFSET 0 0 0 0 0 0 *6C $ CONFIG,INS,CONFIG IMUTOANT2 OFFSET 0 0 0 0 0 0 *5E $ CONFIG,INS,CONFIG INSSOL OFFSET 0 .0 0 .0 0 .0*77 $ CONFIG,UNDULATION,CONFIG UNDULATION AUTO*2B $ CONFIG,EVENT,CONFIG EVENT DISABLE*70 $ CONFIG,DGPSTIMEOUT,CONFIG DGPS TIMEOUT 300 *37 $ CONFIG,RTKTIMEOUT,CONFIG RTK TIMEOUT 100 *35 $ CONFIG,HEADING,CONFIG HEADING FIXLENGTH*6F $ CONFIG,PSRSMOOTH,CONFIG PSRSMOOTH DISABLE*70 Save settings: saveconfig Get current mode: mode # MODE,94,GPS,FINE,2171,345803000,0,0,18,982 ; mode rover,HEADINGMODE FIXLENGTH*2F By default, after factory reset, receiver will work in Rover Dynamic mode, which is the same as the below config: mode rover The receiver will automatically start RTK positioning when receiving correction data from any serial ports. NMEA Messages Get Position: gngga <period> Get satellites in view: gngsv <period> Get heading: gphdt <period> Get timestamp: gnrmc <period>","title":"Commands"},{"location":"projects/lidar-mapping-poc/gnss/#setup-ntrip-client","text":"The site http://rtk2go.com hosts free mount points for NTRIP casters. Accessing http://rtk2go.com:2101 will get a list of casters. A NTRIP client can access to its via either URL at rtk2go.com:2101 or via IP Address at 3.16.214.124:2101 . The open source project at http://rtklib.com has a tool STRSVR to stream NTRIP data from a caster. It firstly lists the available mount points to select, and then can forward the data stream to the UB482\u2019s COM2 (displayed as a COMx in host PC). The COM2 has to be set at high baudrate to be able to get correction message quickly: config com2 460800 RTKLib Stream Server","title":"Setup NTRIP client"},{"location":"projects/lidar-mapping-poc/gnss/#rtk-performance","text":"Right after UB482 gets correction messages from NTRIP from its COM2 port: take 2 seconds to get DGPS/ SAAB accuracy (meter accuracy) take 5 seconds to get RTK Float accuracy (decimeter accuracy) take 5 minutes to get RTK Fix accuracy (centimeter accuracy) RTK Fix accuracy","title":"RTK performance"},{"location":"projects/lidar-mapping-poc/gnss/#some-issues","text":"Sometimes, system stays in RTK Float, and there is no RTK Fix in long time \u2192 Need to check other conditions which affect to RTK process. In Rover mode, there is no way to export raw observation data to use in post-processing. RTCM messages are only printed out in Base mode. Unicorecomm data has some observation messages OBSVMA . Unicorecomm has fixed their converter tool to convert OBSVMA data to RINEX format. There are some commands which do not work event are listed in UPrecise or in documents: Turning on IMU with config ins enable returns OK, but running rawimua returns an Unknown IMU type. \u2192 All new Unicorecomm GNSS modules have no INS feature, confirmed by Unicorecomm\u2019s engineers !!! Command interfacemode com2 rtcmv3 unicorecomm on returns wrong syntax. \u2192 No Unicorecomm output format in GNSS module !!!","title":"Some issues"},{"location":"projects/lidar-mapping-poc/gnss/#ub4b0-on-base","text":"For RTK base station (fixed base station), the antenna is placed at a known coordinate with no changes during the whole use. Meanwhile, the precise coordinates of the known measurement station and the received satellite information will be sent to rover (yet to be positioned) by RTCM protocol directly or after processing. Communication RTCM message will be available on the COM1, at 115200 bps (8N1). Base\u2019s coordinate Since the base coordinate is unknown, Base will be set to self-optimization mode: mode base time 60 1 .0 2 .0 The command means: Within 60 seconds or when the standard deviation of horizontal position is less than 1.0 m and that of vertical position is less than 2.0 m, set the average position as the base\u2019s coordinate. Trigger below command once to get Base coordinate: gngga RTCM output Send below commands to get RTCM info: rtcm1006 com1 10 # Base station antenna rtcm1033 com1 10 # Description of receiver rtcm1074 com1 1 # GPS system correction data rtcm1124 com1 1 # BDS system correction data rtcm1084 com1 1 # Glonass system correction data rtcm1094 com1 1 # Galileo system correction data","title":"UB4B0 on Base"},{"location":"projects/lidar-mapping-poc/gnss/#ub482-on-rover","text":"Rover Station receives the real-time differential correction data from the base station. Rover can automatically recognize the RTCM data and perform RTK solution. There are three kinds of RTK mode: static mode , dynamic mode and automatic mode . The default setting is dynamic mode. The receiver will automatically start RTK positioning when receiving correction data from any serial ports. mode rover GNGGA output The position information should be sent on COM2 every second: gngga com2 1 The output frequency can be set up to 20 Hz: gngga com2 0 .05 GPRMC output The date time information should be sent on COM3 every second: gprmc com3 1","title":"UB482 on Rover"},{"location":"projects/lidar-mapping-poc/gnss/#appendix","text":"Emlid provides RTK GNSS modules such as REACH M+ (at $265) which use U-Blox GNSS module and an integrated IMU. These modules support raw output for post-processing. A cheaper module named Navio2 is a good choice for an Autopilot HAT on Raspberry Pi. Emlid also provides free NTRIP Caster mount points to send corrections over the internet. It is similar to rtk2go .","title":"Appendix"},{"location":"projects/lidar-mapping-poc/gnss-emulator/","text":"Requirements # The emulator should output: PPS signal at 1Hz, 25% duty cycle GPRMC at 1Hz, about 83 bytes per message GNGGA at 1Hz, about 86 bytes per message OBSVMA at 1Hz, about 2700 bytes per message All messages are aligned to the rising edge of PPS signal. Outputs are concurrent . Configuration # The main MCU is STM32F103C8Tx , mounted on a Blue Pill dev board. PPS Signal # PPS signal will be output by PWM function of the Timer 1 module: Clock source: Internal Clock, at 72 MHz Channel 1: PWM Generation CH1 Pre-scaler PSC : 36000-1 Counter Period AAR : 2000-1 PWM Generation Channel 1: Mode: 1 (Positive at start) Pulse: 500 (25% of AAR) Interrupt: on Update UART Protocol # Using a setting of 8-N-1 (8 bit, No parity, 1 stop bit), each byte requires 10 bits. Baud rate at 115200 bit-per-second means the speed is 11520 byte-per-second. At this speed, 4 OBSVMA messages can be transfer completely in a second. All messages on UART ports will be sent in DMA mode which allows sending data concurrently. Interrupt must be enabled to make DMA function work properly. The UART1, UART2, UART3 are configured as: Mode: Asynchronous Hardware Flow Control: Disabled Baud Rate: 115200 bps, 8-N-1 Interrupt: Enabled DMA: Channel: TX Direction: Memory to Peripheral , Mode: Normal Data width: Byte Increment Address: Memory only Messages # All messages are pre-filled, only some necessary parts will be modified to reduce processing time. UTC Time must be updated every second in GPRMC and GNGGA GPRMC message must have correct CRC value GPRMC: $GPRMC , 000000.00 , A , 2057.59811106 , N , 10546.17288672 , E , 0.109 , 193.8 , 200821 , 1.5 , W , A * 21 GNGGA: $GNGGA , 000000.00 , 2057.59811106 , N , 10546.17288672 , E , 1 , 18 , 2.2 , 16.5017 , M , -28.2478 , M ,, * 61 OBSVMA: #OBSVMA,92,GPS,FINE,2172,171764000,0,0,18,4;36,0,6,21338531.558,...,02331d40*a302f998 OBSVMA is a long message, at least 2600 bytes Pin map on STM32F103C8Tx Implementation # Messages Messages are predefined. Only timestamp bytes and CRC need to be updated. Pre-calculate an CRC byte except timestamp bytes at startup. When timestamp is update, new CRC is calculated using pre-calculated CRC and timestamp bytes. This reduces time of updating message. All messages will be sent using DMA mode to not block each other. Example for GPRMC messages: uint8_t GPRMC_Buffer [] = \"$GPRMC,000000.00,A,2057.59811106,N,10546.17288672,E,0.109,193.8,200821,1.5,W,A*21 \\r\\n \" ; uint32_t GPRMC_Length = 0 ; uint8_t GPRMC_CRC_Old = 0 ; // CRC except time, calculated once at startup uint8_t GPRMC_CRC_New = 0 ; // CRC New = CRC Old + Timestamps[] Main loop will send 3 messages using DMA: int main ( void ) { GPRMC_Length = strlen (( char * ) GPRMC_Buffer ); GPRMC_CRC_Old = CalculateCRC ( GPRMC_Buffer , GPRMC_Length ); while ( 1 ) { if ( PPS_flag == 1 ) { UpdateTime ( GPRMC_Buffer + 7 , & Clock ); GPRMC_CRC_New = RecalculatedCRC ( GPRMC_Buffer + 7 , 6 , & GPRMC_CRC_Old ); UpdateCRC ( GPRMC_Buffer + 79 , & GPRMC_CRC_New ); HAL_UART_Transmit_DMA ( & huart1 , GPRMC_Buffer , GPRMC_Length ); ... other code ... HAL_UART_Transmit_DMA ( & huart2 , GNGGA_Buffer , GNGGA_Length ); ... other code ... HAL_UART_Transmit_DMA ( & huart3 , OBSVMA_Buffer , OBSVMA_Length ); } } } Result : Output of GNSS emulator Concurrent outputs","title":"GNSS Emulator using STM32 MCU"},{"location":"projects/lidar-mapping-poc/gnss-emulator/#requirements","text":"The emulator should output: PPS signal at 1Hz, 25% duty cycle GPRMC at 1Hz, about 83 bytes per message GNGGA at 1Hz, about 86 bytes per message OBSVMA at 1Hz, about 2700 bytes per message All messages are aligned to the rising edge of PPS signal. Outputs are concurrent .","title":"Requirements"},{"location":"projects/lidar-mapping-poc/gnss-emulator/#configuration","text":"The main MCU is STM32F103C8Tx , mounted on a Blue Pill dev board.","title":"Configuration"},{"location":"projects/lidar-mapping-poc/gnss-emulator/#pps-signal","text":"PPS signal will be output by PWM function of the Timer 1 module: Clock source: Internal Clock, at 72 MHz Channel 1: PWM Generation CH1 Pre-scaler PSC : 36000-1 Counter Period AAR : 2000-1 PWM Generation Channel 1: Mode: 1 (Positive at start) Pulse: 500 (25% of AAR) Interrupt: on Update","title":"PPS Signal"},{"location":"projects/lidar-mapping-poc/gnss-emulator/#uart-protocol","text":"Using a setting of 8-N-1 (8 bit, No parity, 1 stop bit), each byte requires 10 bits. Baud rate at 115200 bit-per-second means the speed is 11520 byte-per-second. At this speed, 4 OBSVMA messages can be transfer completely in a second. All messages on UART ports will be sent in DMA mode which allows sending data concurrently. Interrupt must be enabled to make DMA function work properly. The UART1, UART2, UART3 are configured as: Mode: Asynchronous Hardware Flow Control: Disabled Baud Rate: 115200 bps, 8-N-1 Interrupt: Enabled DMA: Channel: TX Direction: Memory to Peripheral , Mode: Normal Data width: Byte Increment Address: Memory only","title":"UART Protocol"},{"location":"projects/lidar-mapping-poc/gnss-emulator/#messages","text":"All messages are pre-filled, only some necessary parts will be modified to reduce processing time. UTC Time must be updated every second in GPRMC and GNGGA GPRMC message must have correct CRC value GPRMC: $GPRMC , 000000.00 , A , 2057.59811106 , N , 10546.17288672 , E , 0.109 , 193.8 , 200821 , 1.5 , W , A * 21 GNGGA: $GNGGA , 000000.00 , 2057.59811106 , N , 10546.17288672 , E , 1 , 18 , 2.2 , 16.5017 , M , -28.2478 , M ,, * 61 OBSVMA: #OBSVMA,92,GPS,FINE,2172,171764000,0,0,18,4;36,0,6,21338531.558,...,02331d40*a302f998 OBSVMA is a long message, at least 2600 bytes Pin map on STM32F103C8Tx","title":"Messages"},{"location":"projects/lidar-mapping-poc/gnss-emulator/#implementation","text":"Messages Messages are predefined. Only timestamp bytes and CRC need to be updated. Pre-calculate an CRC byte except timestamp bytes at startup. When timestamp is update, new CRC is calculated using pre-calculated CRC and timestamp bytes. This reduces time of updating message. All messages will be sent using DMA mode to not block each other. Example for GPRMC messages: uint8_t GPRMC_Buffer [] = \"$GPRMC,000000.00,A,2057.59811106,N,10546.17288672,E,0.109,193.8,200821,1.5,W,A*21 \\r\\n \" ; uint32_t GPRMC_Length = 0 ; uint8_t GPRMC_CRC_Old = 0 ; // CRC except time, calculated once at startup uint8_t GPRMC_CRC_New = 0 ; // CRC New = CRC Old + Timestamps[] Main loop will send 3 messages using DMA: int main ( void ) { GPRMC_Length = strlen (( char * ) GPRMC_Buffer ); GPRMC_CRC_Old = CalculateCRC ( GPRMC_Buffer , GPRMC_Length ); while ( 1 ) { if ( PPS_flag == 1 ) { UpdateTime ( GPRMC_Buffer + 7 , & Clock ); GPRMC_CRC_New = RecalculatedCRC ( GPRMC_Buffer + 7 , 6 , & GPRMC_CRC_Old ); UpdateCRC ( GPRMC_Buffer + 79 , & GPRMC_CRC_New ); HAL_UART_Transmit_DMA ( & huart1 , GPRMC_Buffer , GPRMC_Length ); ... other code ... HAL_UART_Transmit_DMA ( & huart2 , GNGGA_Buffer , GNGGA_Length ); ... other code ... HAL_UART_Transmit_DMA ( & huart3 , OBSVMA_Buffer , OBSVMA_Length ); } } } Result : Output of GNSS emulator Concurrent outputs","title":"Implementation"},{"location":"projects/lidar-mapping-poc/imu/","text":"Some issues found in the current implementation IMU Timestamp is wrong IMU data for Accelerator and Gyroscope does not have same timestamp Example project # The development board DK-20789 comes with some example projects which are very good base to start with. The project is NOT documented, and some parts are close-source. Documents # Firstly, check the ICM-20789 Datasheet . Have a quick look of different development kits which can be found in SmartMotion Platform Introduction and Training . The SmartMotion Hardware User Guide shows the notes and schematics of development kits. Download # Register an account and download Embedded Motion Drivers (eMD) from the Download center . There are 2 versions : Without Digital Motion Processor , named eMD-SmartMotion_ICM207xx : Motion processing algorithms will be run on the host processor. The host process reads all raw data and the process them. The prebuilt TDK algorithm and math libraries is not open source. It is compiled and provided as library files libAlgoInvn.a and libMLMath.a . Non-DMP version exposes below raw sensor\u2019s data: SENSOR_ACCELEROMETER (id: 1) SENSOR_GYROSCOPE (id: 4) SENSOR_GRAVITY (id: 9) SENSOR_LINEAR_ACCELERATION (id: 10) SENSOR_GAME_ROTATION_VECTOR (id: 15) SENSOR_UNCAL_GYROSCOPE (id: 16) SENSOR_RAW_ACCELEROMETER (id: 32) SENSOR_RAW_GYROSCOPE (id: 33) SENSOR_CUSTOM_PRESSURE (id: 36) With Digital Motion Processor enabled , named eMD-SmartMotion-ICM20789-20689-DMP : Motion processing algorithms will be run on sensor itself. The host process reads all processed data when DMP sends an interrupt status. The firmware of the DMP processor is also prebuilt. It\u2019s stored in the binary array defined in icm20789_img.dmp3.h . This array will be uploaded to the DMP Processor when the main application runs. DMP version exposes below processed sensor\u2019s data : SENSOR_GYROSCOPE (id: 4) SENSOR_GAME_ROTATION_VECTOR (id: 15) SENSOR_UNCAL_GYROSCOPE (id: 16) SENSOR_RAW_ACCELEROMETER (id: 32) SENSOR_RAW_GYROSCOPE (id: 33) SENSOR_CUSTOM_PRESSURE (id: 36) The projects which are used on the DK-20789 board are built with Atmel Studio (newly changed to Microchip Studio). Download the Atmel Studio at the Microchip download page for AVR and SAM devices . After download the eMD SmartMotion ICM-20789 DMP project, open the solution file EMD-G55-ICM207*.atsln to start the project. Understanding the example projects # The example projects come with some components of InvenSense, such as Dynamic Protocol Adapter (with Data and Transport layers), and prebuilt algorithms. I haven\u2019t found any document about InvenSense\u2019s Dynamic Protocol. The application initializes all the components, and then finally does a loop to: read bytes from UART to process commands in Dynamic Protocol Adapter poll sensor\u2019s data when sensor sends an interrupt call the algorithms to process sensor\u2019s data converted processed sensor\u2019s data to messages for Dynamic Protocol Adapter to send through UART Dynamic Protocol Adapter is working well with a provided example host\u2019s application named sensor_cli . But this program is close-source, and no document of Dynamic Protocol Adapter is found, Dynamic Protocol Adapter layer should be removed in customized projects. Let\u2019s quickly review the application code. UART ports are set up in the function configure_console() . The debug port is through the FLEXCOM7 peripheral, at 921600 bps. The main console is through the FLEXCOM0 peripheral at 2000000 bps. The console UART also enables interruption for receiving ready US_IER_RXRDY . Sensors are set up in the function icm207xx_sensor_setup() and the initial configurations are set in icm207xx_sensor_configuration() function. By default, the Accelerator sensor at \u00b1 4000 mg, the Gyroscope sensor at \u00b1 2000 dps, and the Temperature sensors are enabled, and the output rate is 50 Hz. The application attaches the console UART to the Dynamic Protocol Adapter with DynProTransportUart_init() and DynProtocol_init() which set callbacks to handle data in and out through the console UART port. The algorithms are then initialized and configured by the algorithms_init() and algorithms_configure_odr() . Note the output data rate of the sensor should be matched with algorithm\u2019s. At the boot time, all sensor output types are turned on. The variable enabled_sensor_mask is used as the flags to set which output types are enabled. Here is the list of sensor output types: Raw Accelerator data Raw Gyroscope data Calibrated Accelerator data Calibrated Gyroscope data Un-calibrated Gyroscope data Game Rotation Vector Two tasks commandHandlerTask and blinkerLedTask are initialized, and started in the InvenSense\u2019s scheduler (no document about it, though its code, this not an RTOS, because it schedules tasks and run the selected task in the main loop). In the main loop: the scheduler will check the task which will be executed and runs it call to Icm207xx_data_poll() function to read sensor\u2019s data when the interrupt flag irq_from_device is set call to sensor_event() to forward sensor\u2019s data to the Dynamic Protocol to encode the message and transmit it to the host The call sequence and data-flow should be modified Send raw sensor\u2019s data # The example project needs to be modified to adapt to new system: Start with Non-DMP version from eMD-SmartMotion_ICM207xx_1.0.5 . Set jump J1 at pin 5-6 to select power from FTDI USB port Configure project and board to use SPI protocol which provides higher data rate. Set #define USE_SPI_NOT_I2C 1 in file system.h Remove jumps on J2 to use SPI between ATSAMG55 and ICM207xx Set jump J3 on pin 1-2 and 3-4 to use UART over FTDI USB port Disable reading pressure sensor save CPU usage In main.c , remove all defines and function calls related to pressure sensor: invpres_serif , inv_invpres_setup , irq_start_pressure_capture Remove Dynamic protocol to and Scheduler to work with raw data from sensor In main.c , remove all function calls to set up protocol, such as DynProTransportUart_init , DynProtocol_init In main.c , remove all function calls to scheduler, such as InvScheduler_init , InvScheduler_initTask , InvScheduler_startTask In system.c , remove code inside the functions TC0_Handler and SysTick_Handler . In main.c , set sensor mask to get calibrated Accelerometer enabled_sensor_mask |= ( 1 << SENSOR_ACC ); // Calibrated ACCELEROMETER enabled_sensor_mask |= ( 1 << SENSOR_GYR ); // Calibrated GYROSCOPE Send raw sensor\u2019s event data to UART In sensor.c , at the beginning of the function sensor_event() , call to UART write function: void sensor_event ( const inv_sensor_event_t * event , void * arg ) { usart_serial_write_packet ( CONF_UART , ( uint8_t * ) event , sizeof ( inv_sensor_event_t )); ioport_toggle_pin_level ( LED_0_PIN ); } Remove timestamp in inv_sensor_event_t , add syncBytes to mark the start of event struct, and shorten the struct definition to get a smaller size typedef struct inv_sensor_event { unsigned int syncBytes ; /**< 0x55AA55AA */ unsigned int sensor ; /**< sensor type */ union { struct { float vect [ 3 ]; /**< x,y,z vector data */ float bias [ 3 ]; /**< x,y,z bias vector data */ uint8_t accuracy_flag ; /**< accuracy flag */ } acc ; /**< 3d accelerometer data in g */ struct { float vect [ 3 ]; /**< x,y,z vector data */ float bias [ 3 ]; /**< x,y,z bias vector data (for uncal sensor variant) */ uint8_t accuracy_flag ; /**< accuracy flag */ } gyr ; /**< 3d gyroscope data in deg/s */ struct { float quat [ 4 ]; /**< w,x,y,z quaternion data */ float accuracy ; /**< heading accuracy in deg */ uint8_t accuracy_flag ; /**< accuracy flag specific for GRV*/ } quaternion ; /**< quaternion data */ struct { int32_t vect [ 3 ]; /**< x,y,z vector data */ uint32_t fsr ; /**< full scale range */ } raw3d ; /**< 3d raw acc, mag or gyr*/ } data ; /**< sensor data */ } inv_sensor_event_t ; The sync bytes must be assigned when a new event is created, such as in notify_event function: void notify_event ( uint64_t timestamp ) { inv_sensor_event_t event ; memset ( & event , 0 , sizeof ( event )); event . syncBytes = 0x55AA55AA ; ... } At this step, the main loop of sensor data handler is reduced as below main () { while ( 1 ) { if ( irq_from_device ) { Icm207xx_data_poll () { inv_icm207xx_poll_fifo_data () algorithms_process () notify_event () { for each enabled sensor in enabled_sensor_mask { new inv_sensor_event_t sensor_event () { usart_serial_write_packet (); ioport_toggle_pin_level (); ... Change output rate In algo_eapi.h , set the definition DEFAULT_ODR_US to 5000 (ms) to get 200 Hz output rate The bit rate of UART port CONF_UART_BAUDRATE also need to be increased to 921600 bps in conf_uart_serial.h Mismatched timestamp for Accelerator and Gyroscope data Accelerator and Gyroscope should be the same timestamp, but DK-20789 sends those data in 2 different packages. Todo: Fuse Accelerator and Gyroscope data before sending to synchronize timestamp Handshake protocol # Due to the output rate is 200 Hz, the receiver buffer can be overflown if the messages keep coming at startup. Therefore, it is better to keep IMU output off, and only turns it on when receiver is ready to handle data. DK-20789 board reads from the console UART to check the commands: 0xAA 0x55 0xAA 0x55 0x00 to turn off output 0xAA 0x55 0xAA 0x55 0x5A to turn ON output This method is implemented in the function console_uart_irq_handler() . Data types output from ICM-20789 sensor Appendix # Digital Motion Processor The embedded Digital Motion Processor (DMP) offloads computation of motion processing algorithms from the host processor. The DMP acquires data from the accelerometer and gyroscope, processes the data, and the results can be read from the FIFO. The DMP has access to one of the external pins, which can be used for generating interrupts. The purpose of the DMP is to offload both timing requirements and processing power from the host processor. Typically, motion processing algorithms should be run at a high rate, often around 200 Hz to provide accurate results with low latency. This is required even if the application updates at a much lower rate; for example, a low power user interface may update as slowly as 5 Hz, but the motion processing should still run at 200 Hz. The DMP can be used to minimize power, simplify timing, simplify the software architecture, and save valuable MIPS on the host processor for use in applications. DMP operation is possible in low-power gyroscope and low-power accelerometer modes.","title":"IMU Module using DK-20789"},{"location":"projects/lidar-mapping-poc/imu/#example-project","text":"The development board DK-20789 comes with some example projects which are very good base to start with. The project is NOT documented, and some parts are close-source.","title":"Example project"},{"location":"projects/lidar-mapping-poc/imu/#documents","text":"Firstly, check the ICM-20789 Datasheet . Have a quick look of different development kits which can be found in SmartMotion Platform Introduction and Training . The SmartMotion Hardware User Guide shows the notes and schematics of development kits.","title":"Documents"},{"location":"projects/lidar-mapping-poc/imu/#download","text":"Register an account and download Embedded Motion Drivers (eMD) from the Download center . There are 2 versions : Without Digital Motion Processor , named eMD-SmartMotion_ICM207xx : Motion processing algorithms will be run on the host processor. The host process reads all raw data and the process them. The prebuilt TDK algorithm and math libraries is not open source. It is compiled and provided as library files libAlgoInvn.a and libMLMath.a . Non-DMP version exposes below raw sensor\u2019s data: SENSOR_ACCELEROMETER (id: 1) SENSOR_GYROSCOPE (id: 4) SENSOR_GRAVITY (id: 9) SENSOR_LINEAR_ACCELERATION (id: 10) SENSOR_GAME_ROTATION_VECTOR (id: 15) SENSOR_UNCAL_GYROSCOPE (id: 16) SENSOR_RAW_ACCELEROMETER (id: 32) SENSOR_RAW_GYROSCOPE (id: 33) SENSOR_CUSTOM_PRESSURE (id: 36) With Digital Motion Processor enabled , named eMD-SmartMotion-ICM20789-20689-DMP : Motion processing algorithms will be run on sensor itself. The host process reads all processed data when DMP sends an interrupt status. The firmware of the DMP processor is also prebuilt. It\u2019s stored in the binary array defined in icm20789_img.dmp3.h . This array will be uploaded to the DMP Processor when the main application runs. DMP version exposes below processed sensor\u2019s data : SENSOR_GYROSCOPE (id: 4) SENSOR_GAME_ROTATION_VECTOR (id: 15) SENSOR_UNCAL_GYROSCOPE (id: 16) SENSOR_RAW_ACCELEROMETER (id: 32) SENSOR_RAW_GYROSCOPE (id: 33) SENSOR_CUSTOM_PRESSURE (id: 36) The projects which are used on the DK-20789 board are built with Atmel Studio (newly changed to Microchip Studio). Download the Atmel Studio at the Microchip download page for AVR and SAM devices . After download the eMD SmartMotion ICM-20789 DMP project, open the solution file EMD-G55-ICM207*.atsln to start the project.","title":"Download"},{"location":"projects/lidar-mapping-poc/imu/#understanding-the-example-projects","text":"The example projects come with some components of InvenSense, such as Dynamic Protocol Adapter (with Data and Transport layers), and prebuilt algorithms. I haven\u2019t found any document about InvenSense\u2019s Dynamic Protocol. The application initializes all the components, and then finally does a loop to: read bytes from UART to process commands in Dynamic Protocol Adapter poll sensor\u2019s data when sensor sends an interrupt call the algorithms to process sensor\u2019s data converted processed sensor\u2019s data to messages for Dynamic Protocol Adapter to send through UART Dynamic Protocol Adapter is working well with a provided example host\u2019s application named sensor_cli . But this program is close-source, and no document of Dynamic Protocol Adapter is found, Dynamic Protocol Adapter layer should be removed in customized projects. Let\u2019s quickly review the application code. UART ports are set up in the function configure_console() . The debug port is through the FLEXCOM7 peripheral, at 921600 bps. The main console is through the FLEXCOM0 peripheral at 2000000 bps. The console UART also enables interruption for receiving ready US_IER_RXRDY . Sensors are set up in the function icm207xx_sensor_setup() and the initial configurations are set in icm207xx_sensor_configuration() function. By default, the Accelerator sensor at \u00b1 4000 mg, the Gyroscope sensor at \u00b1 2000 dps, and the Temperature sensors are enabled, and the output rate is 50 Hz. The application attaches the console UART to the Dynamic Protocol Adapter with DynProTransportUart_init() and DynProtocol_init() which set callbacks to handle data in and out through the console UART port. The algorithms are then initialized and configured by the algorithms_init() and algorithms_configure_odr() . Note the output data rate of the sensor should be matched with algorithm\u2019s. At the boot time, all sensor output types are turned on. The variable enabled_sensor_mask is used as the flags to set which output types are enabled. Here is the list of sensor output types: Raw Accelerator data Raw Gyroscope data Calibrated Accelerator data Calibrated Gyroscope data Un-calibrated Gyroscope data Game Rotation Vector Two tasks commandHandlerTask and blinkerLedTask are initialized, and started in the InvenSense\u2019s scheduler (no document about it, though its code, this not an RTOS, because it schedules tasks and run the selected task in the main loop). In the main loop: the scheduler will check the task which will be executed and runs it call to Icm207xx_data_poll() function to read sensor\u2019s data when the interrupt flag irq_from_device is set call to sensor_event() to forward sensor\u2019s data to the Dynamic Protocol to encode the message and transmit it to the host The call sequence and data-flow should be modified","title":"Understanding the example projects"},{"location":"projects/lidar-mapping-poc/imu/#send-raw-sensors-data","text":"The example project needs to be modified to adapt to new system: Start with Non-DMP version from eMD-SmartMotion_ICM207xx_1.0.5 . Set jump J1 at pin 5-6 to select power from FTDI USB port Configure project and board to use SPI protocol which provides higher data rate. Set #define USE_SPI_NOT_I2C 1 in file system.h Remove jumps on J2 to use SPI between ATSAMG55 and ICM207xx Set jump J3 on pin 1-2 and 3-4 to use UART over FTDI USB port Disable reading pressure sensor save CPU usage In main.c , remove all defines and function calls related to pressure sensor: invpres_serif , inv_invpres_setup , irq_start_pressure_capture Remove Dynamic protocol to and Scheduler to work with raw data from sensor In main.c , remove all function calls to set up protocol, such as DynProTransportUart_init , DynProtocol_init In main.c , remove all function calls to scheduler, such as InvScheduler_init , InvScheduler_initTask , InvScheduler_startTask In system.c , remove code inside the functions TC0_Handler and SysTick_Handler . In main.c , set sensor mask to get calibrated Accelerometer enabled_sensor_mask |= ( 1 << SENSOR_ACC ); // Calibrated ACCELEROMETER enabled_sensor_mask |= ( 1 << SENSOR_GYR ); // Calibrated GYROSCOPE Send raw sensor\u2019s event data to UART In sensor.c , at the beginning of the function sensor_event() , call to UART write function: void sensor_event ( const inv_sensor_event_t * event , void * arg ) { usart_serial_write_packet ( CONF_UART , ( uint8_t * ) event , sizeof ( inv_sensor_event_t )); ioport_toggle_pin_level ( LED_0_PIN ); } Remove timestamp in inv_sensor_event_t , add syncBytes to mark the start of event struct, and shorten the struct definition to get a smaller size typedef struct inv_sensor_event { unsigned int syncBytes ; /**< 0x55AA55AA */ unsigned int sensor ; /**< sensor type */ union { struct { float vect [ 3 ]; /**< x,y,z vector data */ float bias [ 3 ]; /**< x,y,z bias vector data */ uint8_t accuracy_flag ; /**< accuracy flag */ } acc ; /**< 3d accelerometer data in g */ struct { float vect [ 3 ]; /**< x,y,z vector data */ float bias [ 3 ]; /**< x,y,z bias vector data (for uncal sensor variant) */ uint8_t accuracy_flag ; /**< accuracy flag */ } gyr ; /**< 3d gyroscope data in deg/s */ struct { float quat [ 4 ]; /**< w,x,y,z quaternion data */ float accuracy ; /**< heading accuracy in deg */ uint8_t accuracy_flag ; /**< accuracy flag specific for GRV*/ } quaternion ; /**< quaternion data */ struct { int32_t vect [ 3 ]; /**< x,y,z vector data */ uint32_t fsr ; /**< full scale range */ } raw3d ; /**< 3d raw acc, mag or gyr*/ } data ; /**< sensor data */ } inv_sensor_event_t ; The sync bytes must be assigned when a new event is created, such as in notify_event function: void notify_event ( uint64_t timestamp ) { inv_sensor_event_t event ; memset ( & event , 0 , sizeof ( event )); event . syncBytes = 0x55AA55AA ; ... } At this step, the main loop of sensor data handler is reduced as below main () { while ( 1 ) { if ( irq_from_device ) { Icm207xx_data_poll () { inv_icm207xx_poll_fifo_data () algorithms_process () notify_event () { for each enabled sensor in enabled_sensor_mask { new inv_sensor_event_t sensor_event () { usart_serial_write_packet (); ioport_toggle_pin_level (); ... Change output rate In algo_eapi.h , set the definition DEFAULT_ODR_US to 5000 (ms) to get 200 Hz output rate The bit rate of UART port CONF_UART_BAUDRATE also need to be increased to 921600 bps in conf_uart_serial.h Mismatched timestamp for Accelerator and Gyroscope data Accelerator and Gyroscope should be the same timestamp, but DK-20789 sends those data in 2 different packages. Todo: Fuse Accelerator and Gyroscope data before sending to synchronize timestamp","title":"Send raw sensor's data"},{"location":"projects/lidar-mapping-poc/imu/#handshake-protocol","text":"Due to the output rate is 200 Hz, the receiver buffer can be overflown if the messages keep coming at startup. Therefore, it is better to keep IMU output off, and only turns it on when receiver is ready to handle data. DK-20789 board reads from the console UART to check the commands: 0xAA 0x55 0xAA 0x55 0x00 to turn off output 0xAA 0x55 0xAA 0x55 0x5A to turn ON output This method is implemented in the function console_uart_irq_handler() . Data types output from ICM-20789 sensor","title":"Handshake protocol"},{"location":"projects/lidar-mapping-poc/imu/#appendix","text":"Digital Motion Processor The embedded Digital Motion Processor (DMP) offloads computation of motion processing algorithms from the host processor. The DMP acquires data from the accelerometer and gyroscope, processes the data, and the results can be read from the FIFO. The DMP has access to one of the external pins, which can be used for generating interrupts. The purpose of the DMP is to offload both timing requirements and processing power from the host processor. Typically, motion processing algorithms should be run at a high rate, often around 200 Hz to provide accurate results with low latency. This is required even if the application updates at a much lower rate; for example, a low power user interface may update as slowly as 5 Hz, but the motion processing should still run at 200 Hz. The DMP can be used to minimize power, simplify timing, simplify the software architecture, and save valuable MIPS on the host processor for use in applications. DMP operation is possible in low-power gyroscope and low-power accelerometer modes.","title":"Appendix"},{"location":"projects/lidar-mapping-poc/issues/","text":"Overall progress UB480 module is not stable Jetson SPI port does not work properly Jetson is halt during boot Handle high speed data for GNGGA and OBSVMA at 20 Hz Mapping timestamp is hard to match IMU timestamp is wrong IMU data for Accelerator and Gyroscope does not have same timestamp Jetson NX board does not fit ROS system 1. UB480 module is not stable # Problem When powering UB480 board from Raspberry Pi 3.3 V pin, the board cannot work properly, it sometimes reboots unexpectedly. Analysis Measuring the voltage on 3.3 V pin shows that the voltage is dropped to 3.1 V , and the datasheet of Raspberry Pi shows that the maximum current on 3.3 V power rails is 800 mA , however UB480 needs up to 2 A at peak. Solution Use 5 V power line on Raspberry which is connected directly to the power adapter to provide a total current of 3 A. UB480 can work at max 5 V. 2. Jetson SPI port does not work properly # Problem RF24 can not send message even the same source code work normally in Raspberry Pi. NRF24 TX failed Analysis Hook up a Logic Analyzer to SPI pin, it showed a byte was missed due to CSN pin was not pulled down!!! NRF24 did miss one byte Solution Force change CSN pin on each byte in the SPI driver. Refer to vuquangtrong/RF24/commit/0ce98c utility/SPIDEV/spi.cpp uint8_t SPI::transfer ( uint8_t tx ) { struct spi_ioc_transfer tr ; memset ( & tr , 0 , sizeof ( tr )); tr . tx_buf = ( unsigned long ) & tx ; uint8_t rx ; tr . rx_buf = ( unsigned long ) & rx ; tr . len = sizeof ( tx ); tr . speed_hz = _spi_speed ; //RF24_SPI_SPEED; tr . delay_usecs = 0 ; tr . bits_per_word = RF24_SPIDEV_BITS ; #ifdef JETSON_NANO_DEV_KIT tr . cs_change = 1 ; #else tr . cs_change = 0 ; #endif ... } NRF24 can read properly 3. Jetson is halt during boot # Problem System is halt when GNSS module is connected to Jetson board. Analysis Unplug RX pin of ttyS0 port, system can boot successfully. After checking, it turns out that the ttyS0 port of Jetson is configured as the System Console for U-Boot (bootloader), which looks for an input character to stop booting. GNSS module actually sends a message during it start up routine, causing U-Boot stop !!! Solution Disable system console in U-Boot Follow the guide in Linux for Tegra - U-Boot Customization to download U-Boot source code. Add a new line at the end of the file /config/p3450-0000_defconfig : CONFIG_BOOTDELAY=-2 Recompile the U-Boot, then copy the new u-boot.bin to /bootloader/t210ref/p3450-0000 . Re-flash the LNX partition: ./flash -k LNX jetson-nano-devkit mmcblk0p1 Keep one boot entry only In the file /boot/extlinux/exlinux.conf , if there are more than 1 active entry, U-Boot also pauses on any key in console to select a boot entry. Therefore, keep only one entry which has SPI-enabled DTB. 4. Handle high speed data for GNGGA and OBSVMA at 20 Hz # Problem When enable logging OBSVMA at 20 Hz, system can not handle data correctly, causing delay. To-do Check performance of system to handle multi-threads 5. Mapping timestamp is hard to match # Problem The mapping function still does not work correctly because many packages from Lidar/ GNSS/ and IMU do not have matching timestamp. Analysis Adding debug timestamp of IMU showing that DK-20789 board sends correct timestamp but Jetson board could not read at high speed leading to wrong timestamp in ROS message. Refer to below problem IMU timestamp is wrong . Solution Re-check the timestamp of all component: GNSS, IMU, and Lidar 6. IMU Timestamp is wrong # Problem The IMU output rate is set at 200 Hz (period is 5 ms). DK-20789 correctly sends out message: IMU output rate 200 Hz But the reading rate is not correct: Sample are read at very fast speed (52 us) in a burst and then there is a big delay (80-100 ms) between bursts. IMU input rate is unstable Analysis The DFTI USB chip of DK-20789 has some delay on buffer, refer to Effect of USB buffer size and the Latency on Data Throughput . Note from FTDI : Therefore, if data is received at a rate of 3875 bytes per second (38.75 KBaud) or faster, then the data will be subject to delays based on the requested USB block length. If data is received at a slower rate, then there will be less than 62 bytes (64 including our 2 status bytes) available after 16 milliseconds. Therefore, a short packet will occur, thus terminating the USB request and passing the data back. At the limit condition of 38.75 KBaud it will take approximately 1.06 seconds between data buffers into the user\u2019s application (assuming a 4 Kbyte USB block request buffer size). To get around this you can either increase the latency timer or reduce the USB block request. Reducing the USB block request is the preferred method though a balance between the 2 may be sought for optimum system response. Solution Option 1 : Change FTDI USB Buffer size No document found yet!!! Option 2 : Re-assign timestamp in software The mapping process need real-time data, therefore, delayed packages are invalid. Option 3 : Direct wire DK-20789 COM7 to Jetson Nano Jetson only has 2 accessible physical UART ports (on J41 and J50). Consider to use USB for slower data input. Connect IMU to UART on J41 7. IMU data for Accelerator and Gyroscope does not have same timestamp # Problem Accelerator and Gyroscope should be the same timestamp, but DK-20789 sends those data in 2 different packages. Solution Fuse Accelerator and Gyroscope data before sending to synchronize timestamp 8. Jetson NX board does not fit ROS system # Problem The Jetson NX board only has 16 GB eMMC, which is not enough to hold ROS system. To-do Rebuild Jetson OS to remove unnecessary packages Flash to eMMC via Recovery Mode","title":"Issue List"},{"location":"projects/lidar-mapping-poc/issues/#1-ub480-module-is-not-stable","text":"Problem When powering UB480 board from Raspberry Pi 3.3 V pin, the board cannot work properly, it sometimes reboots unexpectedly. Analysis Measuring the voltage on 3.3 V pin shows that the voltage is dropped to 3.1 V , and the datasheet of Raspberry Pi shows that the maximum current on 3.3 V power rails is 800 mA , however UB480 needs up to 2 A at peak. Solution Use 5 V power line on Raspberry which is connected directly to the power adapter to provide a total current of 3 A. UB480 can work at max 5 V.","title":"1. UB480 module is not stable"},{"location":"projects/lidar-mapping-poc/issues/#2-jetson-spi-port-does-not-work-properly","text":"Problem RF24 can not send message even the same source code work normally in Raspberry Pi. NRF24 TX failed Analysis Hook up a Logic Analyzer to SPI pin, it showed a byte was missed due to CSN pin was not pulled down!!! NRF24 did miss one byte Solution Force change CSN pin on each byte in the SPI driver. Refer to vuquangtrong/RF24/commit/0ce98c utility/SPIDEV/spi.cpp uint8_t SPI::transfer ( uint8_t tx ) { struct spi_ioc_transfer tr ; memset ( & tr , 0 , sizeof ( tr )); tr . tx_buf = ( unsigned long ) & tx ; uint8_t rx ; tr . rx_buf = ( unsigned long ) & rx ; tr . len = sizeof ( tx ); tr . speed_hz = _spi_speed ; //RF24_SPI_SPEED; tr . delay_usecs = 0 ; tr . bits_per_word = RF24_SPIDEV_BITS ; #ifdef JETSON_NANO_DEV_KIT tr . cs_change = 1 ; #else tr . cs_change = 0 ; #endif ... } NRF24 can read properly","title":"2. Jetson SPI port does not work properly"},{"location":"projects/lidar-mapping-poc/issues/#3-jetson-is-halt-during-boot","text":"Problem System is halt when GNSS module is connected to Jetson board. Analysis Unplug RX pin of ttyS0 port, system can boot successfully. After checking, it turns out that the ttyS0 port of Jetson is configured as the System Console for U-Boot (bootloader), which looks for an input character to stop booting. GNSS module actually sends a message during it start up routine, causing U-Boot stop !!! Solution Disable system console in U-Boot Follow the guide in Linux for Tegra - U-Boot Customization to download U-Boot source code. Add a new line at the end of the file /config/p3450-0000_defconfig : CONFIG_BOOTDELAY=-2 Recompile the U-Boot, then copy the new u-boot.bin to /bootloader/t210ref/p3450-0000 . Re-flash the LNX partition: ./flash -k LNX jetson-nano-devkit mmcblk0p1 Keep one boot entry only In the file /boot/extlinux/exlinux.conf , if there are more than 1 active entry, U-Boot also pauses on any key in console to select a boot entry. Therefore, keep only one entry which has SPI-enabled DTB.","title":"3. Jetson is halt during boot"},{"location":"projects/lidar-mapping-poc/issues/#4-handle-high-speed-data-for-gngga-and-obsvma-at-20-hz","text":"Problem When enable logging OBSVMA at 20 Hz, system can not handle data correctly, causing delay. To-do Check performance of system to handle multi-threads","title":"4. Handle high speed data for GNGGA and OBSVMA at 20 Hz"},{"location":"projects/lidar-mapping-poc/issues/#5-mapping-timestamp-is-hard-to-match","text":"Problem The mapping function still does not work correctly because many packages from Lidar/ GNSS/ and IMU do not have matching timestamp. Analysis Adding debug timestamp of IMU showing that DK-20789 board sends correct timestamp but Jetson board could not read at high speed leading to wrong timestamp in ROS message. Refer to below problem IMU timestamp is wrong . Solution Re-check the timestamp of all component: GNSS, IMU, and Lidar","title":"5. Mapping timestamp is hard to match"},{"location":"projects/lidar-mapping-poc/issues/#6-imu-timestamp-is-wrong","text":"Problem The IMU output rate is set at 200 Hz (period is 5 ms). DK-20789 correctly sends out message: IMU output rate 200 Hz But the reading rate is not correct: Sample are read at very fast speed (52 us) in a burst and then there is a big delay (80-100 ms) between bursts. IMU input rate is unstable Analysis The DFTI USB chip of DK-20789 has some delay on buffer, refer to Effect of USB buffer size and the Latency on Data Throughput . Note from FTDI : Therefore, if data is received at a rate of 3875 bytes per second (38.75 KBaud) or faster, then the data will be subject to delays based on the requested USB block length. If data is received at a slower rate, then there will be less than 62 bytes (64 including our 2 status bytes) available after 16 milliseconds. Therefore, a short packet will occur, thus terminating the USB request and passing the data back. At the limit condition of 38.75 KBaud it will take approximately 1.06 seconds between data buffers into the user\u2019s application (assuming a 4 Kbyte USB block request buffer size). To get around this you can either increase the latency timer or reduce the USB block request. Reducing the USB block request is the preferred method though a balance between the 2 may be sought for optimum system response. Solution Option 1 : Change FTDI USB Buffer size No document found yet!!! Option 2 : Re-assign timestamp in software The mapping process need real-time data, therefore, delayed packages are invalid. Option 3 : Direct wire DK-20789 COM7 to Jetson Nano Jetson only has 2 accessible physical UART ports (on J41 and J50). Consider to use USB for slower data input. Connect IMU to UART on J41","title":"6. IMU Timestamp is wrong"},{"location":"projects/lidar-mapping-poc/issues/#7-imu-data-for-accelerator-and-gyroscope-does-not-have-same-timestamp","text":"Problem Accelerator and Gyroscope should be the same timestamp, but DK-20789 sends those data in 2 different packages. Solution Fuse Accelerator and Gyroscope data before sending to synchronize timestamp","title":"7. IMU data for Accelerator and Gyroscope does not have same timestamp"},{"location":"projects/lidar-mapping-poc/issues/#8-jetson-nx-board-does-not-fit-ros-system","text":"Problem The Jetson NX board only has 16 GB eMMC, which is not enough to hold ROS system. To-do Rebuild Jetson OS to remove unnecessary packages Flash to eMMC via Recovery Mode","title":"8. Jetson NX board does not fit ROS system"},{"location":"projects/lidar-mapping-poc/mapping/","text":"The mapping package # Check out the source code from GitHub: git clone --recursive https://github.com/vuquangtrong/lidar-mapping-poc.git && \\ cd lidar-mapping-poc The folder structure is as below: . \u251c\u2500 docs # the documents in HTML format \u2502 \u2514\u2500 pdf # the documents in PDF format \u251c\u2500 packages # Libraries of peripherals \u251c\u2500 base # Base controller source code \u2514\u2500 rover # Rover ROS package \u2514\u2500 src # Rover packages source code Build the system: ./build.sh Controllers # Controllers run at startup and configure attached modules including GNSS, RF24 and OLED. Base Controller # Base controller runs 2 threads : Data Forwarding Thread Open the serial port at /dev/ttyS0 which connects to the GNSS module Set GNSS module in base mode Set config to produce different RTCM message types Connect to RF24 radio module Set the radio on transmitting mode on the channel 100 (2500 Mhz), using the address R0v3r In the forever loop, read RTCM data from serial port and send to radio System Status Thread Connect to OLED module In the forever loop, get data and print out status on screen Rover Controller # Rover controller runs 2 threads : Data Forwarding Thread Open the serial port at /dev/ttyTHS1 which connects to the GNSS module Set GNSS module in rover mode Set config to produce GNGGA message on COM2 and GPRMC messages on COM3 Connect to RF24 radio module Set the radio on receiving mode on the channel 100 (2500 Mhz), using the address R0v3r In the forever loop, read RTCM data from radio and send to serial port System Status Thread Connect to OLED module In the forever loop, get data and print out status on screen ROS packages # Livox Driver # GNSS Parser # IMU Parser # Mapper #","title":"Fuse Position and IMU data to Pointclouds"},{"location":"projects/lidar-mapping-poc/mapping/#the-mapping-package","text":"Check out the source code from GitHub: git clone --recursive https://github.com/vuquangtrong/lidar-mapping-poc.git && \\ cd lidar-mapping-poc The folder structure is as below: . \u251c\u2500 docs # the documents in HTML format \u2502 \u2514\u2500 pdf # the documents in PDF format \u251c\u2500 packages # Libraries of peripherals \u251c\u2500 base # Base controller source code \u2514\u2500 rover # Rover ROS package \u2514\u2500 src # Rover packages source code Build the system: ./build.sh","title":"The mapping package"},{"location":"projects/lidar-mapping-poc/mapping/#controllers","text":"Controllers run at startup and configure attached modules including GNSS, RF24 and OLED.","title":"Controllers"},{"location":"projects/lidar-mapping-poc/mapping/#base-controller","text":"Base controller runs 2 threads : Data Forwarding Thread Open the serial port at /dev/ttyS0 which connects to the GNSS module Set GNSS module in base mode Set config to produce different RTCM message types Connect to RF24 radio module Set the radio on transmitting mode on the channel 100 (2500 Mhz), using the address R0v3r In the forever loop, read RTCM data from serial port and send to radio System Status Thread Connect to OLED module In the forever loop, get data and print out status on screen","title":"Base Controller"},{"location":"projects/lidar-mapping-poc/mapping/#rover-controller","text":"Rover controller runs 2 threads : Data Forwarding Thread Open the serial port at /dev/ttyTHS1 which connects to the GNSS module Set GNSS module in rover mode Set config to produce GNGGA message on COM2 and GPRMC messages on COM3 Connect to RF24 radio module Set the radio on receiving mode on the channel 100 (2500 Mhz), using the address R0v3r In the forever loop, read RTCM data from radio and send to serial port System Status Thread Connect to OLED module In the forever loop, get data and print out status on screen","title":"Rover Controller"},{"location":"projects/lidar-mapping-poc/mapping/#ros-packages","text":"","title":"ROS packages"},{"location":"projects/lidar-mapping-poc/mapping/#livox-driver","text":"","title":"Livox Driver"},{"location":"projects/lidar-mapping-poc/mapping/#gnss-parser","text":"","title":"GNSS Parser"},{"location":"projects/lidar-mapping-poc/mapping/#imu-parser","text":"","title":"IMU Parser"},{"location":"projects/lidar-mapping-poc/mapping/#mapper","text":"","title":"Mapper"},{"location":"projects/lidar-mapping-poc/notes/","tags":["notes"],"text":"Check log # Get system log: dmesg Log file: cat /var/log/syslog List of built-in modules # cat /lib/modules/ $( uname -r ) /modules.builtin | grep spi kernel/drivers/media/spi/imx204.ko kernel/drivers/mtd/devices/qspi_mtd.ko kernel/drivers/mtd/spi-nor/spi-nor.ko kernel/drivers/spi/spi-tegra114.ko kernel/drivers/spi/spi-tegra124-slave.ko kernel/drivers/spi/spi-tegra210-qspi.ko Build kernel and modules # This is a method to build Kernel image and modules directly on the Jetson board. Firstly, clone build scripts: git clone https://github.com/jetsonhacks/jetson-linux-build.git && \\ cd jetson-linux-build Download kernel source. The script will automatically detect the kernel version. ./getKernelSources.sh Kernel modules can be configured using KConfig Menu: ./editConfig.sh Example of reviewing SPI driver for Tegra114. Browse to Device Drivers \u2192 SPI support and check detail of NVIDIA Tegra114 SPI Controller by pressing H : .config - Linux/arm64 4 .9.140 Kernel Configuration > Device Drivers > SPI support ------------ ------NVIDIA Tegra114 SPI Controller------- \u2502 CONFIG_SPI_TEGRA114: \u2502 \u2502 \u2502 \u2502 Symbol: SPI_TEGRA114 [=y] \u2502 \u2502 Type : tristate \u2502 \u2502 Prompt: NVIDIA Tegra114 SPI Controller \u2502 \u2502 Location: \u2502 \u2502 -> Device Drivers \u2502 \u2502 -> SPI support ( SPI [=y]) \u2502 \u2502 Defined at drivers/spi/Kconfig:626 \u2502 \u2502 Depends on:... This driver uses the symbol SPI_TEGRA114 which is defined at drivers/spi/Kconfig:626 . Check the Makefile in /usr/src/kernel/$(uname -r)/drivers/spi/Makefile : obj-$(CONFIG_SPI_MASTER) += spi.o obj-$(CONFIG_SPI_SPIDEV) += spidev.o obj-$(CONFIG_SPI_LOOPBACK_TEST) += spi-loopback-test.o obj-$(CONFIG_SPI_TEGRA114) += spi-tegra114.o Trace to .config file in the kernel folder /usr/src/kernel/$(uname -r) . Read more at Makefile . CONFIG_SPI = y CONFIG_SPI_MASTER = y CONFIG_SPI_SPIDEV = m CONFIG_SPI_TEGRA114 = y The CONFIG_SPI_TEGRA114=y means spi_tegra114 is a platform driver , not a module, therefore it needs to rebuild kernel image to include change in that driver. Edit the source code or apply a patch Rebuild kernel image ./makeKernel.sh It takes about an hour at the first time. Replace BOOT image at line LINUX /boot/Image by editing the boot file: cat /boot/extlinux/extlinux.conf Should back up the kernel image first. Reboot! Find in file # grep --include=\\*.{c,h} -rnw '.' -e \"SPI_MODE_1\" Check shared libraries # ld -lrf24 --verbose Wrap C lib to C++ lib # Add wrapper to the header file #ifdef __cplusplus extern \"C\" { #endif ... header content here ... #ifdef __cplusplus } #endif Device Tree Compile # Decompile: dtc -I dtb -O dts <input.dtb> -o <output.dts> Edit .dts file, and then recompile: dtc -I dts -O dtb <input.dts> -o <output.dtb> Replace FDT file at line FDT /boot/xxx.dtb by editing the boot file cat /boot/extlinux/extlinux.conf . Should back up the kernel image first. Fix USB Partition # USB with wrong partition table can not be read. Erase the entire partition table is needed. sudo dd if = /dev/zero of = /dev/sda bs = 512 count = 1 Then use fdisk to create GPT partition table and add new partition. sudo fdisk /dev/sdx The format the partition: sudo mkfs.ext4 /dev/sdxy Visual Studio Code # Visual Studio Code is far better than Sublime Text. Here is a method to install it automatically: wget -qO- https://packages.microsoft.com/keys/microsoft.asc \\ | gpg --dearmor \\ > packages.microsoft.gpg \\ && \\ sudo install -o root -g root -m 644 \\ packages.microsoft.gpg \\ /etc/apt/trusted.gpg.d/ \\ && \\ rm -f packages.microsoft.gpg \\ && \\ sudo sh -c \\ 'echo \"\\ deb [signed-by=/etc/apt/trusted.gpg.d/packages.microsoft.gpg] \\ https://packages.microsoft.com/repos/code stable main\\ \" \\ > /etc/apt/sources.list.d/vscode.list' \\ && \\ sudo apt install -y apt-transport-https \\ && \\ sudo apt update \\ && \\ sudo apt install -y code Plugins : Sublime Text key map C/C++ Configs : .vscode\\c_cpp_properties.json { \"configurations\" : [ { \"browse\" : { \"databaseFilename\" : \"\" , \"limitSymbolsToIncludedHeaders\" : true }, \"includePath\" : [ \"${workspaceFolder}/devel/include\" , \"/opt/ros/melodic/include/**\" , \"/usr/include/**\" , \"${workspaceFolder}/**\" ], \"name\" : \"ROS\" , \"configurationProvider\" : \"ms-vscode.cmake-tools\" } ], \"version\" : 4 } Submodule in Git # Add a new module: git submodule add <remote_url> Initialize submodule: git submodule init Download submodule after initializing: git submodule update Remove a module: git submodule deinit <submodule_name> Clone and download all submodules: git clone --recursive <repo_url>","title":"Notes for Jetson Nano"},{"location":"projects/lidar-mapping-poc/notes/#check-log","text":"Get system log: dmesg Log file: cat /var/log/syslog","title":"Check log"},{"location":"projects/lidar-mapping-poc/notes/#list-of-built-in-modules","text":"cat /lib/modules/ $( uname -r ) /modules.builtin | grep spi kernel/drivers/media/spi/imx204.ko kernel/drivers/mtd/devices/qspi_mtd.ko kernel/drivers/mtd/spi-nor/spi-nor.ko kernel/drivers/spi/spi-tegra114.ko kernel/drivers/spi/spi-tegra124-slave.ko kernel/drivers/spi/spi-tegra210-qspi.ko","title":"List of built-in modules"},{"location":"projects/lidar-mapping-poc/notes/#build-kernel-and-modules","text":"This is a method to build Kernel image and modules directly on the Jetson board. Firstly, clone build scripts: git clone https://github.com/jetsonhacks/jetson-linux-build.git && \\ cd jetson-linux-build Download kernel source. The script will automatically detect the kernel version. ./getKernelSources.sh Kernel modules can be configured using KConfig Menu: ./editConfig.sh Example of reviewing SPI driver for Tegra114. Browse to Device Drivers \u2192 SPI support and check detail of NVIDIA Tegra114 SPI Controller by pressing H : .config - Linux/arm64 4 .9.140 Kernel Configuration > Device Drivers > SPI support ------------ ------NVIDIA Tegra114 SPI Controller------- \u2502 CONFIG_SPI_TEGRA114: \u2502 \u2502 \u2502 \u2502 Symbol: SPI_TEGRA114 [=y] \u2502 \u2502 Type : tristate \u2502 \u2502 Prompt: NVIDIA Tegra114 SPI Controller \u2502 \u2502 Location: \u2502 \u2502 -> Device Drivers \u2502 \u2502 -> SPI support ( SPI [=y]) \u2502 \u2502 Defined at drivers/spi/Kconfig:626 \u2502 \u2502 Depends on:... This driver uses the symbol SPI_TEGRA114 which is defined at drivers/spi/Kconfig:626 . Check the Makefile in /usr/src/kernel/$(uname -r)/drivers/spi/Makefile : obj-$(CONFIG_SPI_MASTER) += spi.o obj-$(CONFIG_SPI_SPIDEV) += spidev.o obj-$(CONFIG_SPI_LOOPBACK_TEST) += spi-loopback-test.o obj-$(CONFIG_SPI_TEGRA114) += spi-tegra114.o Trace to .config file in the kernel folder /usr/src/kernel/$(uname -r) . Read more at Makefile . CONFIG_SPI = y CONFIG_SPI_MASTER = y CONFIG_SPI_SPIDEV = m CONFIG_SPI_TEGRA114 = y The CONFIG_SPI_TEGRA114=y means spi_tegra114 is a platform driver , not a module, therefore it needs to rebuild kernel image to include change in that driver. Edit the source code or apply a patch Rebuild kernel image ./makeKernel.sh It takes about an hour at the first time. Replace BOOT image at line LINUX /boot/Image by editing the boot file: cat /boot/extlinux/extlinux.conf Should back up the kernel image first. Reboot!","title":"Build kernel and modules"},{"location":"projects/lidar-mapping-poc/notes/#find-in-file","text":"grep --include=\\*.{c,h} -rnw '.' -e \"SPI_MODE_1\"","title":"Find in file"},{"location":"projects/lidar-mapping-poc/notes/#check-shared-libraries","text":"ld -lrf24 --verbose","title":"Check shared libraries"},{"location":"projects/lidar-mapping-poc/notes/#wrap-c-lib-to-c-lib","text":"Add wrapper to the header file #ifdef __cplusplus extern \"C\" { #endif ... header content here ... #ifdef __cplusplus } #endif","title":"Wrap C lib to C++ lib"},{"location":"projects/lidar-mapping-poc/notes/#device-tree-compile","text":"Decompile: dtc -I dtb -O dts <input.dtb> -o <output.dts> Edit .dts file, and then recompile: dtc -I dts -O dtb <input.dts> -o <output.dtb> Replace FDT file at line FDT /boot/xxx.dtb by editing the boot file cat /boot/extlinux/extlinux.conf . Should back up the kernel image first.","title":"Device Tree Compile"},{"location":"projects/lidar-mapping-poc/notes/#fix-usb-partition","text":"USB with wrong partition table can not be read. Erase the entire partition table is needed. sudo dd if = /dev/zero of = /dev/sda bs = 512 count = 1 Then use fdisk to create GPT partition table and add new partition. sudo fdisk /dev/sdx The format the partition: sudo mkfs.ext4 /dev/sdxy","title":"Fix USB Partition"},{"location":"projects/lidar-mapping-poc/notes/#visual-studio-code","text":"Visual Studio Code is far better than Sublime Text. Here is a method to install it automatically: wget -qO- https://packages.microsoft.com/keys/microsoft.asc \\ | gpg --dearmor \\ > packages.microsoft.gpg \\ && \\ sudo install -o root -g root -m 644 \\ packages.microsoft.gpg \\ /etc/apt/trusted.gpg.d/ \\ && \\ rm -f packages.microsoft.gpg \\ && \\ sudo sh -c \\ 'echo \"\\ deb [signed-by=/etc/apt/trusted.gpg.d/packages.microsoft.gpg] \\ https://packages.microsoft.com/repos/code stable main\\ \" \\ > /etc/apt/sources.list.d/vscode.list' \\ && \\ sudo apt install -y apt-transport-https \\ && \\ sudo apt update \\ && \\ sudo apt install -y code Plugins : Sublime Text key map C/C++ Configs : .vscode\\c_cpp_properties.json { \"configurations\" : [ { \"browse\" : { \"databaseFilename\" : \"\" , \"limitSymbolsToIncludedHeaders\" : true }, \"includePath\" : [ \"${workspaceFolder}/devel/include\" , \"/opt/ros/melodic/include/**\" , \"/usr/include/**\" , \"${workspaceFolder}/**\" ], \"name\" : \"ROS\" , \"configurationProvider\" : \"ms-vscode.cmake-tools\" } ], \"version\" : 4 }","title":"Visual Studio Code"},{"location":"projects/lidar-mapping-poc/notes/#submodule-in-git","text":"Add a new module: git submodule add <remote_url> Initialize submodule: git submodule init Download submodule after initializing: git submodule update Remove a module: git submodule deinit <submodule_name> Clone and download all submodules: git clone --recursive <repo_url>","title":"Submodule in Git"},{"location":"projects/lidar-mapping-poc/reference/","text":"Overview # The official guide and source code is hosted in livox_high_precision_mapping . This project aims to stick geographical information into a pointcloud. The data from GNSS and INS module is used to calculate high precision position of every point captured from the Lidar. The sample project uses a Livox Mid-40 Lidar and an APX-15 GNSS-INS module. Install and build : cd ws_livox/src && \\ git clone https://github.com/Livox-SDK/livox_high_precision_mapping.git && \\ cd ws_livox && \\ catkin_make && \\ source ./devel/setup.sh The system block diagram looks like below: Livox mapping using APX-15 The APX-15 module sends PPS pulse to Livox, and sends GPS timestamp in GNRMC messages to the Manifold 2 computer which forwards timestamp to Livox through an Ethernet connection The APX-15 module sends Trimble\u2019s GSOF messages which contains GNSS location data and IMU information to the Manifold 2 The Livox Mid-40, gets PPS and GNRMC timestamp then sends pointcloud message to the Manifold 2 on the Ethernet connection The Manifold2 processes GNSS, IMU and pointcloud together to create a geo-referenced pointcloud Mapping package # The data flow is described in the below diagram: Lidar Mapping system calls and data flow User configuration points: Turn on Timestamp Synchronization and set GNRMC input device in livox_lidar_config.json Set GSOF input device in apx15.launch Run the mapping_online.launch file to generate pointcloud data in the pointcloud2 format that combines the IMU pose and GNSS position: roslaunch livox_mapping mapping_online.launch APX-15 Node # The APX-15 node reads GSOF messages from APX and extract the GNSS and IMU data from the Report Packet (0x40 \u2014 GENOUT) . There are 3 interesting message types: UTC message (ID = 16) INS Navigation message (ID = 49) INS RMS message (ID = 50) These extracted information will be used to make 2 new messages: sensor_msgs::NavSatFix and sensor_msgs::Imu which are posted to the mapping node. Extract data from APX-15 GSOF message Mapping node # The mapping node gets the pointcloud from the Lidar ROS driver node, the GNSS and IMU data from the APX-15 node and processes them together: Store pointcloud with timestamp Store GNSS with timestamp Store IMU with timestamp Align packets using timestamp Apply IMU to GNSS point, and stick geographical information to pointcloud Combine position and pose into pointcloud","title":"Livox's Reference Project"},{"location":"projects/lidar-mapping-poc/reference/#overview","text":"The official guide and source code is hosted in livox_high_precision_mapping . This project aims to stick geographical information into a pointcloud. The data from GNSS and INS module is used to calculate high precision position of every point captured from the Lidar. The sample project uses a Livox Mid-40 Lidar and an APX-15 GNSS-INS module. Install and build : cd ws_livox/src && \\ git clone https://github.com/Livox-SDK/livox_high_precision_mapping.git && \\ cd ws_livox && \\ catkin_make && \\ source ./devel/setup.sh The system block diagram looks like below: Livox mapping using APX-15 The APX-15 module sends PPS pulse to Livox, and sends GPS timestamp in GNRMC messages to the Manifold 2 computer which forwards timestamp to Livox through an Ethernet connection The APX-15 module sends Trimble\u2019s GSOF messages which contains GNSS location data and IMU information to the Manifold 2 The Livox Mid-40, gets PPS and GNRMC timestamp then sends pointcloud message to the Manifold 2 on the Ethernet connection The Manifold2 processes GNSS, IMU and pointcloud together to create a geo-referenced pointcloud","title":"Overview"},{"location":"projects/lidar-mapping-poc/reference/#mapping-package","text":"The data flow is described in the below diagram: Lidar Mapping system calls and data flow User configuration points: Turn on Timestamp Synchronization and set GNRMC input device in livox_lidar_config.json Set GSOF input device in apx15.launch Run the mapping_online.launch file to generate pointcloud data in the pointcloud2 format that combines the IMU pose and GNSS position: roslaunch livox_mapping mapping_online.launch","title":"Mapping package"},{"location":"projects/lidar-mapping-poc/reference/#apx-15-node","text":"The APX-15 node reads GSOF messages from APX and extract the GNSS and IMU data from the Report Packet (0x40 \u2014 GENOUT) . There are 3 interesting message types: UTC message (ID = 16) INS Navigation message (ID = 49) INS RMS message (ID = 50) These extracted information will be used to make 2 new messages: sensor_msgs::NavSatFix and sensor_msgs::Imu which are posted to the mapping node. Extract data from APX-15 GSOF message","title":"APX-15 Node"},{"location":"projects/lidar-mapping-poc/reference/#mapping-node","text":"The mapping node gets the pointcloud from the Lidar ROS driver node, the GNSS and IMU data from the APX-15 node and processes them together: Store pointcloud with timestamp Store GNSS with timestamp Store IMU with timestamp Align packets using timestamp Apply IMU to GNSS point, and stick geographical information to pointcloud Combine position and pose into pointcloud","title":"Mapping node"},{"location":"projects/lidar-mapping-poc/rover/","text":"Operating System # Installation # You can select one of below method: Pre-built image # Download the latest Jetson Nano Developer Kit SD Card Image . Other older versions can be found in Jetpack Archive . As the pre-built image is about 13 GB, which includes full JetPack source, libraies and example, you will need a micro-SD Card with at least 32 GB to be able to install ROS. Download balenaEtcher and install it, and write Jetson Image in an SD Card. Power on the board, either use Monitor with Keyboard and Mouse, or use Headless Mode by using DC jack (Jumper J48 connected) and connect micro-USB port to PC. Headless setup only available on the virtual COM port when power up via DC Jack! UART2 @ J50 Starting kernel ... [ 0.000000] earlycon: uart8250 at MMIO32 0x0000000070006000 (options '') [ 0.000000] bootconsole [uart8250] enabled [ 15.823522] Please complete system configuration setup on the serial port provided device mode connection. e.g. /dev/ttyACMx where x can 0, 1, 2 etc. Build an official image # To not include the Jetpack source code, libraries and example, you can follow the guide in Build system image to create a new system image which is about 5.5 GB. This image will have full OS and pre-installed software, such as Office, Web Browser, etc. Power on the board, either use Monitor with Keyboard and Mouse, or use Headless Mode by using DC jack (Jumper J48 connected) and connect micro-USB port to PC. Build a customized image # To create a lightweight system image, checkout jetson-custom-image and follow the scripting steps to make a customized image. Note to run extra steps in the folder custom_bsp_for_nano_dev_kit . The final image is about 2.4 GB, which only includes Ubuntu base, lightweight Xfce desktop environment, Jetson driver and libraries, and some BSP modifications Skip handling key pressing during U-Boot: Disable bootdelay in U-Boot by setting CONFIG_BOOTDELAY=-2 Keep one boot entry in extlinux.conf Add spidev to /etc/modules to load SPI driver at startup Add user to tty , dialout , gpio groups Enable Autologin Run on-screen keyboard onboard at start-up There is no setup process required anymore. Use a keyboard and mouse to start working on the board. For touchable monitor, use onboard program to access to on-screen keyboard. System config # General # Time Mode: UTC Username: jetson Password: cccc APP Partition Size: 0 (max size) Primary Network: dummy then skip network setting (will add USB WiFi later) Hostname: rover Nvpmodel: MAXN Maximum power scheme After finishing system configuration, system console are available at: Physical UART1 at /dev/ttyTHS1 run by a service Physical UART2 at /dev/ttyS0 started by command line option Virtual COM Port at /dev/ttyGS0 run when micro-USB is connected in device mode UART ports Jetson Nano has 3 physical UART ports : UART0 at the M2 Slot for WiFi/BT card UART1 at the J41 Header (40-pin connector) for System Console after boot up (run by a service), Pin 8 - TX , Pin 10 - RX UART2 at the J50 header for debug (early access during boot from bootloader), Pin 4 - RX , Pin 5 - TX Network # WiFi is used for main communication with host PC, as the Ethernet port is used to connect to Lidar. Plug TP-Link WN725N USB dongle, make sure it is recognized. lsusb Bus 001 Device 004: ID 0bda:8179 Realtek Semiconductor Corp. RTL8188EUS 802.11n Wireless Network Adapter Then Wireless interface also appears and is ready to check: sudo ifconfig wlan0 up List WiFi Network: sudo iwlist wlan0 scan sudo nmcli device wifi list - List info on your wifi signal Connect to an AP: sudo nmcli device wifi connect \"SSID\" password \"PASSWORD\" SSH connection With network enabled, through either Ethernet or WiFi, Jetson board will be also accessed via SSH. If using any X11-forwarding SSH client, such as MobaXterm, GUI app can be show through SSH. In some case, it is recommended to turn power saving mode off sudo iw dev wlan0 set power_save off Update the system at the first time: sudo apt update Ethernet should be set to use a static IP which is in the subnet of 192.168.1.0 where Lidar is also set its IP in. Bring up the interface: sudo ifconfig eth0 up Edit the network interface: /etc/network/interfaces auto eth0 iface eth0 inet static address 192.168.1.12 netmask 255.255.255.0 It is needed to change network connection priority, as Linux prefers to use Ethernet when it is connected. Install ifmetric tool: sudo apt install -y ifmetric To use this, first see the metrics using route command: route -n Kernel IP routing table Destination Gateway Genmask Flags Metric Ref Use Iface 0 .0.0.0 10 .42.0.1 0 .0.0.0 UG 100 0 0 eth0 0 .0.0.0 10 .42.0.2 0 .0.0.0 UG 600 0 0 wlan0 Here, eth0 has lower metric, so it will be preferred over wlan0 . If you want to prefer wlan0 , then lower its metric: sudo ifmetric wlan0 50 Now Linux will be using wlan0 for Internet. The change will be reflected immediately. Tweaks # To skip entering password on sudo command, add current user to sudoers with the rule NOPASSWD : sudo bash -c \"echo ' $USER ALL=(ALL) NOPASSWD: ALL' > /etc/sudoers.d/ $USER \" Install nano for editing in terminal: sudo apt update && \\ sudo apt install -y nano To make terminal display colorfully, in .bashrc , enable force_color_prompt = yes . To disable animation on GUI: gsettings set org.gnome.desktop.interface enable-animations false Enable SPI # Starting from L4T kernel 32.4.2+, the initial user created in system configuration will be added into all GPIO groups. Run groups to see the current user is added into gpio , i2c . Note that, Jetson L4T does not have spi group, SPI devices use gpio group. By default, GPIO and I2C are enabled. SPI, PWM, I2S and some extra pins are disabled. To change the setting of GPIO, the official tool jetson-io.py will be used: sudo /opt/nvidia/jetson-io/jetson-io.py This tool will configure the Device Tree and add it using FDT option in the /boot/extlinux/extlinux.conf file In Jetpack 4.6, SPI device driver are not loaded into kernel, a manual method is to run sudo modprobe spidev , but spidev should be added into /etc/modules to load that driver at boot time. sudo bash -c 'echo spidev > /etc/modules' UART Config # UART1 # The stock Jetson Nano starts a console on the /dev/ttyTHS1 serial port at startup through a service /etc/systemd/nvgetty.sh which launches getty . Note that normal udev rules will be overridden by the console while the service is running. To disable the console: sudo systemctl stop nvgetty && \\ sudo systemctl disable nvgetty && \\ sudo udevadm trigger Jetson Nano 40-pin header UART2 # The debug serial interface is chosen at the startup of kernel. From L4T kernel 32.4.2+, the debug serial can be disabled through the command line options. The command line can be read from /proc/cmdline : cat /proc/cmdline append: tegraid=21.1.2.0.0 ddr_die=4096M@2048M section=512M memtype=0 vpr_resize usb_port_owner_info=0 lane_owner_info=0 emc_max_dvfs=0 touch_id=0@63 video=tegrafb no_console_suspend=1 console=ttyS0,115200n8 debug_uartport=lsport,4 earlyprintk=uart8250-32bit,0x70006000 maxcpus=4 usbcore.old_scheme_first=1 lp0_vec=0x1000@0xff780000 core_edp_mv=1075 core_edp_ma=4000 gpt earlycon=uart8250,mmio32,0x70006000 root=/dev/mmcblk0p1 rw rootwait rootfstype=ext4 console=ttyS0,115200n8 console=tty0 fbcon=map:0 net.ifnames=0 quiet root=/dev/mmcblk0p1 rw rootwait rootfstype=ext4 console=ttyS0,115200n8 console=tty0 fbcon=map:0 net.ifnames=0 Examine /boot/extlinux/extlinux.conf : TIMEOUT 30 DEFAULT primary MENU TITLE L4T boot options LABEL primary MENU LABEL primary kernel LINUX /boot/Image INITRD /boot/initrd APPEND ${cbootargs} quiet root=/dev/mmcblk0p1 rw rootwait rootfstype=ext4 console=ttyS0,115200n8 console=tty0 fbcon=map:0 net.ifnames=0 Even it is impossible to edit ${cbootargs} without rebuilding kernel, it is still possible to set new command line by overriding the APPEND field. Remove ttyS0 Take the expanded command line in /proc/cmdline and remove all console=ttyS0,115200n8 options, make a new value for APPEND . When a cmdline\u2019s console= is set, the auto-generated serial-getty@ttyXy.service should start agetty and provide system console on that device. If there is no console= option presented, system will attempt to open the first virtual serial port at /dev/tty0 . Reboot the system. Check the dmesg log to see 3 UART ports are available, and system console is on tty0 : dmesg | grep tty [ 0.001665] console [tty0] enabled [ 1.591294] 70006000.serial: ttyS0 at MMIO 0x70006000 (irq = 63, base_baud = 25500000) is a Tegra [ 1.592156] 70006040.serial: ttyTHS1 at MMIO 0x70006040 (irq = 64, base_baud = 0) is a TEGRA_UART [ 1.592584] 70006200.serial: ttyTHS2 at MMIO 0x70006200 (irq = 65, base_baud = 0) is a TEGRA_UART UART2 still is accessible in boot up time, as it is attached to the bootloader. Send any data at very early time will stop the auto boot. To fix this point, need to use a modifided Uboot firmware. After reboot, run below command to check if there is any ttyS0 or ttyTHSx is running. It should not show any of them. ps -aux | grep tty Permission # To get rid of using sudo permission, add current user into the dialout and spi group. Run ls -al /dev/tty* to check the user group of ttyS0 , ttyTHS1 . Normally, it is needed to add current user into tty and dialout groups. For SPI, it is under gpio group: sudo usermod -a -G tty,dialout,gpio $USER && \\ sudo reboot UART Testing For testing, a serial terminal must be installed. Choose one of below. putty sudo apt install -y putty putty Follow GUI to run. minicom sudo apt install -y minicom minicom -D /dev/ttyS0 -b 115200 Press Ctrl-A X to exit. picocom sudo apt install -y picocom picocom /dev/ttyS0 -b 115200 Press Ctrl-A and Ctrl-X to exit. screen sudo apt install -y screen screen /dev/ttyS0 115200 Press Ctrl-A K to exit. Wiring # Refer to below pinout diagram: Rover wiring UART RX/TX problem Here is some reports showing that Jetson boards have problems on UART RX/TX pin when connecting that port directly to an other board. It maily causes by the capitive loading on the pin, if the loop-back test does not have any problem. If that problem happens, please add a 10K pull-down resister on RX/TX pin. Refer to Unreliable serial communcation via the UART TX/RX GPIO Pins . Serial driver # Download source code and build: git clone https://github.com/vuquangtrong/SerialPort.git && \\ cd SerialPort && \\ make && \\ sudo make install An example to communicate with Serial port: // Serial library #include \"serial/SerialPort.h\" #include <unistd.h> #include <stdio.h> #define SERIAL_PORT \"/dev/ttyS0\" int main ( /*int argc, char *argv[]*/ ) { SerialPort serial ; char errorOpening = serial . openDevice ( SERIAL_PORT , 115200 ); if ( errorOpening != 1 ) return errorOpening ; printf ( \"Successful connection to %s \\n \" , SERIAL_PORT ); // Display ASCII characters (from 32 to 128) for ( int c = 32 ; c < 128 ; c ++ ) { serial . writeChar ( c ); usleep ( 10000 ); } // Read lines and print them out char line [ 1024 ]; while ( 1 ) { int n = serial . readBytes ( line , sizeof ( line )); if ( n >= 0 ) { std :: cout << std :: string ( line , n ) << std :: endl ; } } // Close the serial device serial . closeDevice (); return 0 ; } Compile and run: g++ example.cpp -lserial -o example nRF24L01p driver # Download source code from GitHub and build: git clone https://github.com/vuquangtrong/RF24 && \\ cd RF24 && \\ ./configure --driver = SPIDEV && \\ make && \\ sudo make install Work with the original source code GitHub source code is at https://github.com/nRF24/RF24 . The guide to install in Linux at https://nrf24.github.io/RF24/md_docs_linux_install.html . Download the install.sh file: wget http://tmrh20.github.io/RF24Installer/RPi/install.sh Make it executable: chmod +x install.sh Run it and choose the option: RF24 Core SPIDEV driver ./install.sh Do you want to install GIT using APT (Used to download source code) [y/N]? n Do you want to install the RF24 core library, [y/N]? y Do you want to install the RF24Network library [y/N]? n Do you want to install the RF24Mesh library [y/N]? n Do you want to install the RF24Gateway library [y/N]? n Cloning into './rf24libs/RF24'... __* Install RF24 core using? *__ 1.BCM2835 Driver(Performance) 2.SPIDEV(Compatibility, Default) 3.WiringPi(Its WiringPi!) 4.MRAA(Intel Devices) 5.LittleWire 2 ... [Installing Libs to /usr/local/lib] [Installing Headers to /usr/local/include/RF24] Fix CS pin Jetson Nano spi-tegra114 driver has an issue in driving the CSN pin, therefore, the SPI command must explicitly request to toggle CSN pin. Open the file ~/rf24libs/RF24/utility/SPIDEV/spi.cpp to find tr.cs_change = 0; and replace them by tr.cs_change = 1; . Go back to the `~/rf24libs/RF24 and rebuild the library: sudo make clean all install Fixed in a Seeed Studio\u2019s branch, but not in Nvidia\u2019s Refer: spi: tegra: handle cs_change in modes sw_based_cs & cs_gpios . Source to test data receiving. Check the transferring site in Base . rf24_rx.cpp #include <iostream> // cin, cout, endl #include <time.h> // CLOCK_MONOTONIC_RAW, timespec, clock_gettime() #include <RF24/RF24.h> // create RF24 instance RF24 radio ( 15 /* CE = sys_gpio_15 */ , 0 /* CSN = 0 means spidev0.0 */ /* default speed is 10 Mbps */ ); // max payload of RF24 is 32 bytes uint8_t payload [ 32 ]; uint32_t total_nrx = 0 ; // custom defined timer for evaluating transmission time in microseconds struct timespec startTimer , endTimer ; int main ( int argc , char ** argv ) { setbuf ( stdout , NULL ); // perform hardware check if ( ! radio . begin ()) { cout << \"radio hardware is not responding!!\" << endl ; return 0 ; // quit now } radio . setPayloadSize ( 32 ); radio . setChannel ( 100 ); // 2400 + 100 = 2500 MHz, out of WiFi band // address, defaut length is 5 uint8_t rx_address [ 6 ] = \"1Addr\" ; // read from radio . openReadingPipe ( 1 , rx_address ); // using pip 1 // (smaller) function that prints raw register values radio . printDetails (); // (larger) function that prints human readable data radio . printPrettyDetails (); // Start std :: cout << \"Start RX\" << std :: endl ; radio . startListening (); // put radio in RX mode uint8_t pipe ; uint8_t nrx ; clock_gettime ( CLOCK_MONOTONIC_RAW , & startTimer ); // start the timer cout << \"Begin: \" << startTimer . tv_sec << \".\" << startTimer . tv_nsec << endl ; while ( true ) { if ( radio . available ( & pipe )) { nrx = radio . getPayloadSize (); radio . read ( & payload , nrx ); total_nrx += nrx ; if ( total_nrx >= 1000000 ) { clock_gettime ( CLOCK_MONOTONIC_RAW , & endTimer ); // end the timer cout << \"End: \" << endTimer . tv_sec << \".\" << endTimer . tv_nsec << endl ; break ; } } } int32_t diff_sec = endTimer . tv_sec - startTimer . tv_sec ; int32_t diff_nsec = endTimer . tv_nsec - startTimer . tv_nsec ; if ( diff_nsec < 0 ) { diff_nsec = 1000000000 - diff_nsec ; diff_sec -= 1 ; } cout << \"Received 1000000 bytes in \" << diff_sec << \".\" << diff_nsec << \" seconds\" << endl ; } Compile the source code: g++ -Ofast -Wall -pthread rf24_rx.cpp -lrf24 -o rf24_rx Run it and see the log: ================ SPI Configuration ================ CSN Pin = /dev/spidev0.0 CE Pin = Custom GPIO15 SPI Speedz = 10 Mhz ================ NRF Configuration ================ STATUS = 0x0e RX_DR = 0 TX_DS = 0 MAX_RT = 0 RX_P_NO = 7 TX_FULL = 0 RX_ADDR_P0-1 = 0x65646f4e31 0x7264644131 RX_ADDR_P2-5 = 0xc3 0xc4 0xc5 0xc6 TX_ADDR = 0x65646f4e31 RX_PW_P0-6 = 0x20 0x20 0x20 0x20 0x20 0x20 EN_AA = 0x3f EN_RXADDR = 0x03 RF_CH = 0x64 RF_SETUP = 0x03 CONFIG = 0x0e DYNPD/FEATURE = 0x00 0x00 Data Rate = 1 MBPS Model = nRF24L01+ CRC Length = 16 bits PA Power = PA_LOW ARC = 0 ================ SPI Configuration ================ CSN Pin = /dev/spidev0.0 CE Pin = Custom GPIO15 SPI Frequency = 10 Mhz ================ NRF Configuration ================ Channel = 100 ( ~ 2500 MHz ) RF Data Rate = 1 MBPS RF Power Amplifier = PA_LOW RF Low Noise Amplifier = Enabled CRC Length = 16 bits Address Length = 5 bytes Static Payload Length = 32 bytes Auto Retry Delay = 1500 microseconds Auto Retry Attempts = 15 maximum Packets lost on current channel = 0 Retry attempts made for last transmission = 0 Multicast = Disabled Custom ACK Payload = Disabled Dynamic Payloads = Disabled Auto Acknowledgment = Enabled Primary Mode = TX TX address = 0x65646f4e31 pipe 0 ( open ) bound = 0x65646f4e31 pipe 1 ( open ) bound = 0x7264644131 pipe 2 ( closed ) bound = 0xc3 pipe 3 ( closed ) bound = 0xc4 pipe 4 ( closed ) bound = 0xc5 pipe 5 ( closed ) bound = 0xc6 Start RX Begin: 793 .156527770 End: 821 .645141301 Received 1000000 bytes in 28 .488613531 seconds The example receives 1 MB in 28.5 seconds, which means 35 KBps. While the transfer rate set on the channel is 1Mbps (equals 125 KBps), the example only achieve 28% of bandwidth. OLED driver # Download source code and build: git clone https://github.com/vuquangtrong/OLED_SSD1306_I2C_Linux.git && \\ cd OLED_SSD1306_I2C_Linux && \\ make && \\ sudo make install Write a simple app to a progress bar with label and numeric value: progress_bar.c #include <string.h> #include <unistd.h> #include <SSD1306/ssd1306.h> int main () { char counter = 0 ; char buffer [ 3 ]; SSD1306_Init ( \"/dev/i2c-1\" ); while ( 1 ) { sprintf ( buffer , \"%d\" , counter ++ ); SSD1306_Clear (); SSD1306_WriteString ( 0 , 0 , \"counter:\" , & Font_7x10 , SSD1306_WHITE , SSD1306_OVERRIDE ); SSD1306_WriteString ( 0 , 10 , buffer , & Font_11x18 , SSD1306_WHITE , SSD1306_OVERRIDE ); SSD1306_DrawRectangle ( 0 , 28 , 128 , 4 , SSD1306_WHITE ); SSD1306_DrawFilledRectangle ( 0 , 28 , counter * 128 / 256 , 4 , SSD1306_WHITE ); SSD1306_Screen_Update (); sleep ( 0.2 ); } return 0 ; } Compile and run: gcc progress_bar.c -lssd1306 -o progress_bar && \\ ./progress_bar ROS Melodic # Adding repository and source list sudo apt-add-repository universe sudo apt-add-repository multiverse sudo apt-add-repository restricted sudo apt update Setup source list to get ROS packages: sudo sh -c 'echo \"deb http://packages.ros.org/ros/ubuntu $(lsb_release -sc) main\" > /etc/apt/sources.list.d/ros-latest.list' Add keys: sudo apt install -y curl && \\ curl -s https://raw.githubusercontent.com/ros/rosdistro/master/ros.asc | sudo apt-key add - Pull the package list: sudo apt update Install ROS Melodic desktop: sudo apt install -y ros-melodic-desktop It\u2019s convenient if the ROS environment variables are automatically added to a bash session every time a new shell is launched: echo \"source /opt/ros/melodic/setup.bash\" >> ~/.bashrc && \\ source ~/.bashrc A good way to check the installation is to ensure that environment variables like ROS_ROOT and ROS_PACKAGE_PATH are set: printenv | grep ROS ROS_ETC_DIR = /opt/ros/melodic/etc/ros ROS_ROOT = /opt/ros/melodic/share/ros ROS_MASTER_URI = http://localhost:11311 ROS_VERSION = 1 ROS_PYTHON_VERSION = 2 ROS_PACKAGE_PATH = /opt/ros/melodic/share ROSLISP_PACKAGE_DIRECTORIES = ROS_DISTRO = melodic Initialize the package rosdep to track package dependency: sudo apt install -y python-rosdep && \\ sudo rosdep init && \\ rosdep update Build packages are needed for code compilation. sudo apt install -y python-rosinstall python-rosinstall-generator python-wstool build-essential Create a catkin workspace and try to build it: mkdir -p ~/catkin_ws/src && \\ cd ~/catkin_ws/src && \\ catkin_init_workspace && \\ cd .. && \\ catkin_make The workspace should be built successfully. Livox SDK # Dependencies # Livox SDK needs to be built in the host machine, therefore, some tool-chain and build tools have to be installed. sudo apt update && \\ sudo apt install -y build-essential && \\ sudo apt install -y curl && \\ sudo apt install -y git && \\ sudo apt install -y cmake The pointcloud Library (PCL) is a large scale, open project[1] for pointcloud processing. The PCL framework contains numerous state-of-the art algorithms including filtering, feature estimation, surface reconstruction, registration, model fitting and segmentation. sudo apt install -y libpcl-dev sudo apt install -y ros-melodic-pcl-ros Eigen is a C++ template library for linear algebra: matrices, vectors, numerical solvers, and related algorithms. sudo apt install -y libeigen3-dev OpenCV (Open Source Computer Vision Library) is an open-source computer vision library and has bindings for C++, Python, and Java. It is used for a very wide range of applications, including medical image analysis, stitching street view images, surveillance video, detecting and recognizing faces, tracking moving objects, extracting 3D models, and much more. OpenCV can take advantage of multi-core processing and features GPU acceleration for real-time operation. sudo apt install -y python-opencv python3-opencv Re-link libraries, on Jetson Nano: sudo ln -s /usr/bin/vtk6 /usr/bin/vtk && \\ sudo ln -s /usr/lib/python2.7/dist-packages/vtk/libvtkRenderingPythonTkWidgets.aarch64-linux-gnu.so /usr/lib/aarch64-linux-gnu/libvtkRenderingPythonTkWidgets.so Livox SDK # The official guide is at https://github.com/Livox-SDK/Livox-SDK . Livox SDK is the software development kit designed for all Livox products. It is developed based on C/C++ following Livox SDK Communication Protocol, and provides easy-to-use C style API. With Livox SDK, users can quickly connect to Livox products and receive pointcloud data. Installation git clone https://github.com/Livox-SDK/Livox-SDK.git && \\ cd Livox-SDK && \\ cd build && \\ cmake .. && \\ make && \\ sudo make install The Livox SDK will be built and installed in /usr/local/lib : Install the project... -- Install configuration: \"\" -- Installing: /usr/local/lib/liblivox_sdk_static.a -- Installing: /usr/local/include/livox_def.h -- Installing: /usr/local/include/livox_sdk.h Livox ROS driver # Get livox_ros_driver from GitHub git clone https://github.com/Livox-SDK/livox_ros_driver.git ws_livox/src Then build it: cd ws_livox && \\ catkin_make If running catkin_make gives error of command not found, it\u2019s probably that the ROS setup.bash is not executed and included in ~/.bashrc . See above section to source it. This driver will create a new node named livox_lidar_publisher , which publishes 2 new types of messages: Livox pointcloud message # Livox publish pointcloud msg format. Header header # ROS standard message header uint64 timebase # The time of first point uint32 point_num # Total number of pointclouds uint8 lidar_id # Lidar device id number uint8[3] rsvd # Reserved use CustomPoint[] points # Pointcloud data Livox Point # Livox custom pointcloud format. uint32 offset_time # offset time relative to the base time float32 x # X axis, unit:m float32 y # Y axis, unit:m float32 z # Z axis, unit:m uint8 reflectivity # reflectivity, 0~255 uint8 tag # livox tag uint8 line # laser number in lidar Configurations # The configuration file is in ws_livox/src/livox_ros_driver/config . LiDAR\u2019s configuration parameter Parameter Type Description Default broadcast_code String LiDAR broadcast code N/A enable_connect Boolean false return_mode Int Return mode: 0 \u2013 First single return mode 1 \u2013 The strongest single return mode 2 \u2013 Dual return mode 0 coordinate Int Coordinate: 0 \u2013 Cartesian 1 \u2013 Spherical 0 imu_rate Int Push frequency of IMU sensor data: 0 \u2013 stop push 1 \u2013 200 Hz Currently only Horizon supports this, MID serials do not support it 0 extrinsic_parameter_source Int Whether to enable extrinsic parameter automatic compensation of LiDAR external reference 0 \u2013 Disabled 1 \u2013 Enabled 0 Timestamp synchronization Parameter Type Description Default enable_timesync Boolean false device_name String Name of the serial device which outputs GPRMC/GNRMC messages every second /dev/ttyUSB0 comm_device_type Int Type of device sending timestamp information 0 \u2013 Serial port or USB virtual serial port device other \u2013 not support 0 baudrate_index Int Baud rate of serial device: 0 \u2013 2400 1 \u2013 4800 2 \u2013 9600 3 \u2013 19200 4 \u2013 38400 5 \u2013 57600 6 \u2013 115200 7 \u2013 230400 8 \u2013 460800 9 \u2013 500000 10 \u2013 576000 11 \u2013 921600 2 (9600) parity_index Int parity type 0 \u2013 8 bits data without parity 1 \u2013 7 bits data 1bit even parity 2 \u2013 7 bits data 1bit odd parity 3 \u2013 7 bits data 1bit 0, without parity 0 livox_lidar_config.json { \"lidar_config\" : [ { \"broadcast_code\" : \"1PQDH5B00100041\" , \"enable_connect\" : false , \"return_mode\" : 0 , \"coordinate\" : 0 , \"imu_rate\" : 0 , \"extrinsic_parameter_source\" : 0 , \"enable_high_sensitivity\" : false } ], \"timesync_config\" : { \"enable_timesync\" : false , \"device_name\" : \"/dev/ttyUSB0\" , \"comm_device_type\" : 0 , \"baudrate_index\" : 2 , \"parity_index\" : 0 } } Timestamp # Prepare a GPS device to ensure that the GPS can output UTC time information in GPRMC/GNRMC format through the serial port or USB virtual serial port, and support PPS signal output. Connect the GPS serial port to the host running livox_ros_driver , set the corresponding device name in the config file Connect the GPS PPS signal line to LiDAR Be sure to set the output frequency of GPRMC/GNRMC time information of GPS to 1 Hz Launches # Different launch files have different configuration parameter values and are used in different scenarios: Launch file name Description livox_lidar.launch Connect to Livox LiDAR device Publish pointcloud2 format data livox_lidar_msg.launch Connect to Livox LiDAR device Publish livox customized pointcloud data livox_lidar_rviz.launch Connect to Livox LiDAR device Publish pointcloud2 format data Autoload rviz Launch parameters Parameter Description Default publish_freq Set the frequency of pointcloud publish 10.0 multi_topic 0 \u2013 All LiDAR devices use the same topic to publish pointcloud data 1 \u2013 Each LiDAR device has its own topic to publish pointcloud data 0 xfer_format 0 \u2013 Livox pointcloud2 ( PointXYZRTL ) pointcloud format 1 \u2013 Livox customized pointcloud format 2 \u2013 Standard pointcloud2 ( PointXYZI ) pointcloud format in the PCL library 0 Test ROS # An easy method to connect Livox Lidar with Jetson board is through a LAN router. Below section shows another method to connect 2 modules directly. Set Livox\u2019s Static IP Use Livox Viewer to set a Static IP for the Lidar module. Livox only accepts IP in 192.168.1.0 network. Set Jetson\u2019s Static IP sudo nano /etc/network/interfaces /etc/network/interfaces auto lo iface lo inet loopback auto eth0 iface eth0 inet static address 192.168.1.12 netmask 255.255.255.0 Then run the livox_lidar_rviz example cd ws_livox source ./devel/setup.bash roslaunch livox_ros_driver livox_lidar_rviz.launch This will run Livox ROS and Rviz to visualize the received pointcloud. Auto-mount USB # Check out and install: git clone https://github.com/vuquangtrong/USB_Automount.git && \\ cd USB_Automount && \\ ./install Plugged-in USB will be mounted into /media/<Label> or /media/<sdXy> . Automount scripts Here are scripts to auto-mount storage devices: sudo nano /usr/local/bin/usb-mount.sh #!/bin/bash # This script is called from our systemd unit file to mount or unmount # a USB drive. usage () { echo \"Usage: $0 {add|remove} device_name (e.g. sdb1)\" exit 1 } if [[ $# -ne 2 ]] ; then usage fi ACTION = $1 DEVBASE = $2 DEVICE = \"/dev/ ${ DEVBASE } \" # See if this drive is already mounted, and if so where MOUNT_POINT = $( /bin/mount | /bin/grep ${ DEVICE } | /usr/bin/awk '{ print $3 }' ) do_mount () { if [[ -n ${ MOUNT_POINT } ]] ; then echo \"Warning: ${ DEVICE } is already mounted at ${ MOUNT_POINT } \" exit 1 fi # Get info for this drive: $ID_FS_LABEL, $ID_FS_UUID, and $ID_FS_TYPE eval $( /sbin/blkid -o udev ${ DEVICE } ) # Figure out a mount point to use LABEL = ${ ID_FS_LABEL } if [[ -z \" ${ LABEL } \" ]] ; then LABEL = ${ DEVBASE } elif /bin/grep -q \" /media/ ${ LABEL } \" /etc/mtab ; then # Already in use, make a unique one LABEL += \"- ${ DEVBASE } \" fi MOUNT_POINT = \"/media/ ${ LABEL } \" echo \"Mount point: ${ MOUNT_POINT } \" /bin/mkdir -p ${ MOUNT_POINT } # Global mount options OPTS = \"rw,relatime\" # File system type specific mount options if [[ ${ ID_FS_TYPE } == \"vfat\" ]] ; then OPTS += \",users,gid=100,umask=000,shortname=mixed,utf8=1,flush\" fi if ! /bin/mount -o ${ OPTS } ${ DEVICE } ${ MOUNT_POINT } ; then echo \"Error mounting ${ DEVICE } (status = $? )\" /bin/rmdir ${ MOUNT_POINT } exit 1 fi echo \"__** Mounted ${ DEVICE } at ${ MOUNT_POINT } **__\" } do_unmount () { if [[ -z ${ MOUNT_POINT } ]] ; then echo \"Warning: ${ DEVICE } is not mounted\" else /bin/umount -l ${ DEVICE } echo \"____ Unmounted ${ DEVICE } \" fi # Delete all empty dirs in /media that aren't being used as mount # points. This is kind of overkill, but if the drive was unmounted # prior to removal we no longer know its mount point, and we don't # want to leave it orphaned... for f in /media/* ; do if [[ -n $( /usr/bin/find \" $f \" -maxdepth 0 -type d -empty ) ]] ; then if ! /bin/grep -q \" $f \" /etc/mtab ; then echo \"____ Removing mount point $f \" /bin/rmdir \" $f \" fi fi done } case \" ${ ACTION } \" in add ) do_mount ;; remove ) do_unmount ;; * ) usage ;; esac Change permission: sudo chmod 0755 /usr/local/bin/usb-mount.sh Add service: sudo nano /etc/systemd/system/usb-mount@.service usb-mount@.service [Unit] Description = Mount USB Drive on %i [Service] Type = oneshot RemainAfterExit = true ExecStart = /usr/local/bin/usb-mount.sh add %i ExecStop = /usr/local/bin/usb-mount.sh remove %i The file name uses @ to pass arguments. Add rules for udev when USB event is detected: sudo nano /etc/udev/rules.d/99-usb-mount.rules 99-usb-mount.rules KERNEL = =\"sd[a-z][0-9]\", SUBSYSTEMS==\"usb\", ACTION==\"add\", RUN+=\"/bin/systemctl start usb-mount@%k.service\" KERNEL = =\"sd[a-z][0-9]\", SUBSYSTEMS==\"usb\", ACTION==\"remove\", RUN+=\"/bin/systemctl stop usb-mount@%k.service\" Restart services and rules: sudo udevadm control --reload-rules && \\ sudo systemctl daemon-reload If a USB is not mount automatically, check the system log: cat /var/log/syslog Auto-start application # A simple app that shows IP Address on OLED screen. ipshow.cpp #include <iostream> #include <string> #include <cstring> #include <sys/socket.h> #include <netinet/in.h> #include <arpa/inet.h> #include <unistd.h> #include <sys/types.h> #include <ifaddrs.h> #include <SSD1306/ssd1306.h> using namespace std ; char i2c_dev [] = \"/dev/i2c-1\" ; char noIP [] = \"No IP\" ; void showIP ( int line , char type , char * ip ) { char buffer [ 32 ] = { 0 }; sprintf ( buffer , \"%c:%s\" , type , ip ); SSD1306_WriteString ( 0 , line * 10 , buffer , & Font_7x10 , SSD1306_WHITE , SSD1306_OVERRIDE ); } void getIPAddresses () { struct ifaddrs * interfaces = NULL ; struct ifaddrs * temp_addr = NULL ; int success = 0 ; bool found = false ; // retrieve the current interfaces - returns 0 on success success = getifaddrs ( & interfaces ); if ( success == 0 ) { // Loop through linked list of interfaces temp_addr = interfaces ; while ( temp_addr != NULL ) { if ( temp_addr -> ifa_addr -> sa_family == AF_INET ) { // Check if interface is en0 which is the wifi connection on the iPhone if ( strcmp ( temp_addr -> ifa_name , \"wlan0\" ) == 0 ){ showIP ( 0 , 'W' , inet_ntoa ((( struct sockaddr_in * ) temp_addr -> ifa_addr ) -> sin_addr ) ); found = true ; } if ( strcmp ( temp_addr -> ifa_name , \"eth0\" ) == 0 ){ showIP ( 1 , 'E' , inet_ntoa ((( struct sockaddr_in * ) temp_addr -> ifa_addr ) -> sin_addr ) ); found = true ; } } temp_addr = temp_addr -> ifa_next ; } } // Free memory freeifaddrs ( interfaces ); if ( ! found ) { showIP ( 3 , '?' , noIP ); } } int main ( int argc , char ** argv ) { SSD1306_Init ( i2c_dev ); while ( 1 ) { SSD1306_Clear (); getIPAddresses (); SSD1306_Screen_Update (); sleep ( 10 ); } } Create a service: ipshow.service [Unit] Description = IP Show After = multi-user.target [Service] Type = simple ExecStart = /usr/bin/ipshow [Install] WantedBy = multi-user.target Enable the service: sudo systemctl enable ipshow.service","title":"Rover system on a Jetson Nano Dev Kit"},{"location":"projects/lidar-mapping-poc/rover/#operating-system","text":"","title":"Operating System"},{"location":"projects/lidar-mapping-poc/rover/#installation","text":"You can select one of below method:","title":"Installation"},{"location":"projects/lidar-mapping-poc/rover/#pre-built-image","text":"Download the latest Jetson Nano Developer Kit SD Card Image . Other older versions can be found in Jetpack Archive . As the pre-built image is about 13 GB, which includes full JetPack source, libraies and example, you will need a micro-SD Card with at least 32 GB to be able to install ROS. Download balenaEtcher and install it, and write Jetson Image in an SD Card. Power on the board, either use Monitor with Keyboard and Mouse, or use Headless Mode by using DC jack (Jumper J48 connected) and connect micro-USB port to PC. Headless setup only available on the virtual COM port when power up via DC Jack! UART2 @ J50 Starting kernel ... [ 0.000000] earlycon: uart8250 at MMIO32 0x0000000070006000 (options '') [ 0.000000] bootconsole [uart8250] enabled [ 15.823522] Please complete system configuration setup on the serial port provided device mode connection. e.g. /dev/ttyACMx where x can 0, 1, 2 etc.","title":"Pre-built image"},{"location":"projects/lidar-mapping-poc/rover/#build-an-official-image","text":"To not include the Jetpack source code, libraries and example, you can follow the guide in Build system image to create a new system image which is about 5.5 GB. This image will have full OS and pre-installed software, such as Office, Web Browser, etc. Power on the board, either use Monitor with Keyboard and Mouse, or use Headless Mode by using DC jack (Jumper J48 connected) and connect micro-USB port to PC.","title":"Build an official image"},{"location":"projects/lidar-mapping-poc/rover/#build-a-customized-image","text":"To create a lightweight system image, checkout jetson-custom-image and follow the scripting steps to make a customized image. Note to run extra steps in the folder custom_bsp_for_nano_dev_kit . The final image is about 2.4 GB, which only includes Ubuntu base, lightweight Xfce desktop environment, Jetson driver and libraries, and some BSP modifications Skip handling key pressing during U-Boot: Disable bootdelay in U-Boot by setting CONFIG_BOOTDELAY=-2 Keep one boot entry in extlinux.conf Add spidev to /etc/modules to load SPI driver at startup Add user to tty , dialout , gpio groups Enable Autologin Run on-screen keyboard onboard at start-up There is no setup process required anymore. Use a keyboard and mouse to start working on the board. For touchable monitor, use onboard program to access to on-screen keyboard.","title":"Build a customized image"},{"location":"projects/lidar-mapping-poc/rover/#system-config","text":"","title":"System config"},{"location":"projects/lidar-mapping-poc/rover/#general","text":"Time Mode: UTC Username: jetson Password: cccc APP Partition Size: 0 (max size) Primary Network: dummy then skip network setting (will add USB WiFi later) Hostname: rover Nvpmodel: MAXN Maximum power scheme After finishing system configuration, system console are available at: Physical UART1 at /dev/ttyTHS1 run by a service Physical UART2 at /dev/ttyS0 started by command line option Virtual COM Port at /dev/ttyGS0 run when micro-USB is connected in device mode UART ports Jetson Nano has 3 physical UART ports : UART0 at the M2 Slot for WiFi/BT card UART1 at the J41 Header (40-pin connector) for System Console after boot up (run by a service), Pin 8 - TX , Pin 10 - RX UART2 at the J50 header for debug (early access during boot from bootloader), Pin 4 - RX , Pin 5 - TX","title":"General"},{"location":"projects/lidar-mapping-poc/rover/#network","text":"WiFi is used for main communication with host PC, as the Ethernet port is used to connect to Lidar. Plug TP-Link WN725N USB dongle, make sure it is recognized. lsusb Bus 001 Device 004: ID 0bda:8179 Realtek Semiconductor Corp. RTL8188EUS 802.11n Wireless Network Adapter Then Wireless interface also appears and is ready to check: sudo ifconfig wlan0 up List WiFi Network: sudo iwlist wlan0 scan sudo nmcli device wifi list - List info on your wifi signal Connect to an AP: sudo nmcli device wifi connect \"SSID\" password \"PASSWORD\" SSH connection With network enabled, through either Ethernet or WiFi, Jetson board will be also accessed via SSH. If using any X11-forwarding SSH client, such as MobaXterm, GUI app can be show through SSH. In some case, it is recommended to turn power saving mode off sudo iw dev wlan0 set power_save off Update the system at the first time: sudo apt update Ethernet should be set to use a static IP which is in the subnet of 192.168.1.0 where Lidar is also set its IP in. Bring up the interface: sudo ifconfig eth0 up Edit the network interface: /etc/network/interfaces auto eth0 iface eth0 inet static address 192.168.1.12 netmask 255.255.255.0 It is needed to change network connection priority, as Linux prefers to use Ethernet when it is connected. Install ifmetric tool: sudo apt install -y ifmetric To use this, first see the metrics using route command: route -n Kernel IP routing table Destination Gateway Genmask Flags Metric Ref Use Iface 0 .0.0.0 10 .42.0.1 0 .0.0.0 UG 100 0 0 eth0 0 .0.0.0 10 .42.0.2 0 .0.0.0 UG 600 0 0 wlan0 Here, eth0 has lower metric, so it will be preferred over wlan0 . If you want to prefer wlan0 , then lower its metric: sudo ifmetric wlan0 50 Now Linux will be using wlan0 for Internet. The change will be reflected immediately.","title":"Network"},{"location":"projects/lidar-mapping-poc/rover/#tweaks","text":"To skip entering password on sudo command, add current user to sudoers with the rule NOPASSWD : sudo bash -c \"echo ' $USER ALL=(ALL) NOPASSWD: ALL' > /etc/sudoers.d/ $USER \" Install nano for editing in terminal: sudo apt update && \\ sudo apt install -y nano To make terminal display colorfully, in .bashrc , enable force_color_prompt = yes . To disable animation on GUI: gsettings set org.gnome.desktop.interface enable-animations false","title":"Tweaks"},{"location":"projects/lidar-mapping-poc/rover/#enable-spi","text":"Starting from L4T kernel 32.4.2+, the initial user created in system configuration will be added into all GPIO groups. Run groups to see the current user is added into gpio , i2c . Note that, Jetson L4T does not have spi group, SPI devices use gpio group. By default, GPIO and I2C are enabled. SPI, PWM, I2S and some extra pins are disabled. To change the setting of GPIO, the official tool jetson-io.py will be used: sudo /opt/nvidia/jetson-io/jetson-io.py This tool will configure the Device Tree and add it using FDT option in the /boot/extlinux/extlinux.conf file In Jetpack 4.6, SPI device driver are not loaded into kernel, a manual method is to run sudo modprobe spidev , but spidev should be added into /etc/modules to load that driver at boot time. sudo bash -c 'echo spidev > /etc/modules'","title":"Enable SPI"},{"location":"projects/lidar-mapping-poc/rover/#uart-config","text":"","title":"UART Config"},{"location":"projects/lidar-mapping-poc/rover/#uart1","text":"The stock Jetson Nano starts a console on the /dev/ttyTHS1 serial port at startup through a service /etc/systemd/nvgetty.sh which launches getty . Note that normal udev rules will be overridden by the console while the service is running. To disable the console: sudo systemctl stop nvgetty && \\ sudo systemctl disable nvgetty && \\ sudo udevadm trigger Jetson Nano 40-pin header","title":"UART1"},{"location":"projects/lidar-mapping-poc/rover/#uart2","text":"The debug serial interface is chosen at the startup of kernel. From L4T kernel 32.4.2+, the debug serial can be disabled through the command line options. The command line can be read from /proc/cmdline : cat /proc/cmdline append: tegraid=21.1.2.0.0 ddr_die=4096M@2048M section=512M memtype=0 vpr_resize usb_port_owner_info=0 lane_owner_info=0 emc_max_dvfs=0 touch_id=0@63 video=tegrafb no_console_suspend=1 console=ttyS0,115200n8 debug_uartport=lsport,4 earlyprintk=uart8250-32bit,0x70006000 maxcpus=4 usbcore.old_scheme_first=1 lp0_vec=0x1000@0xff780000 core_edp_mv=1075 core_edp_ma=4000 gpt earlycon=uart8250,mmio32,0x70006000 root=/dev/mmcblk0p1 rw rootwait rootfstype=ext4 console=ttyS0,115200n8 console=tty0 fbcon=map:0 net.ifnames=0 quiet root=/dev/mmcblk0p1 rw rootwait rootfstype=ext4 console=ttyS0,115200n8 console=tty0 fbcon=map:0 net.ifnames=0 Examine /boot/extlinux/extlinux.conf : TIMEOUT 30 DEFAULT primary MENU TITLE L4T boot options LABEL primary MENU LABEL primary kernel LINUX /boot/Image INITRD /boot/initrd APPEND ${cbootargs} quiet root=/dev/mmcblk0p1 rw rootwait rootfstype=ext4 console=ttyS0,115200n8 console=tty0 fbcon=map:0 net.ifnames=0 Even it is impossible to edit ${cbootargs} without rebuilding kernel, it is still possible to set new command line by overriding the APPEND field. Remove ttyS0 Take the expanded command line in /proc/cmdline and remove all console=ttyS0,115200n8 options, make a new value for APPEND . When a cmdline\u2019s console= is set, the auto-generated serial-getty@ttyXy.service should start agetty and provide system console on that device. If there is no console= option presented, system will attempt to open the first virtual serial port at /dev/tty0 . Reboot the system. Check the dmesg log to see 3 UART ports are available, and system console is on tty0 : dmesg | grep tty [ 0.001665] console [tty0] enabled [ 1.591294] 70006000.serial: ttyS0 at MMIO 0x70006000 (irq = 63, base_baud = 25500000) is a Tegra [ 1.592156] 70006040.serial: ttyTHS1 at MMIO 0x70006040 (irq = 64, base_baud = 0) is a TEGRA_UART [ 1.592584] 70006200.serial: ttyTHS2 at MMIO 0x70006200 (irq = 65, base_baud = 0) is a TEGRA_UART UART2 still is accessible in boot up time, as it is attached to the bootloader. Send any data at very early time will stop the auto boot. To fix this point, need to use a modifided Uboot firmware. After reboot, run below command to check if there is any ttyS0 or ttyTHSx is running. It should not show any of them. ps -aux | grep tty","title":"UART2"},{"location":"projects/lidar-mapping-poc/rover/#permission","text":"To get rid of using sudo permission, add current user into the dialout and spi group. Run ls -al /dev/tty* to check the user group of ttyS0 , ttyTHS1 . Normally, it is needed to add current user into tty and dialout groups. For SPI, it is under gpio group: sudo usermod -a -G tty,dialout,gpio $USER && \\ sudo reboot UART Testing For testing, a serial terminal must be installed. Choose one of below. putty sudo apt install -y putty putty Follow GUI to run. minicom sudo apt install -y minicom minicom -D /dev/ttyS0 -b 115200 Press Ctrl-A X to exit. picocom sudo apt install -y picocom picocom /dev/ttyS0 -b 115200 Press Ctrl-A and Ctrl-X to exit. screen sudo apt install -y screen screen /dev/ttyS0 115200 Press Ctrl-A K to exit.","title":"Permission"},{"location":"projects/lidar-mapping-poc/rover/#wiring","text":"Refer to below pinout diagram: Rover wiring UART RX/TX problem Here is some reports showing that Jetson boards have problems on UART RX/TX pin when connecting that port directly to an other board. It maily causes by the capitive loading on the pin, if the loop-back test does not have any problem. If that problem happens, please add a 10K pull-down resister on RX/TX pin. Refer to Unreliable serial communcation via the UART TX/RX GPIO Pins .","title":"Wiring"},{"location":"projects/lidar-mapping-poc/rover/#serial-driver","text":"Download source code and build: git clone https://github.com/vuquangtrong/SerialPort.git && \\ cd SerialPort && \\ make && \\ sudo make install An example to communicate with Serial port: // Serial library #include \"serial/SerialPort.h\" #include <unistd.h> #include <stdio.h> #define SERIAL_PORT \"/dev/ttyS0\" int main ( /*int argc, char *argv[]*/ ) { SerialPort serial ; char errorOpening = serial . openDevice ( SERIAL_PORT , 115200 ); if ( errorOpening != 1 ) return errorOpening ; printf ( \"Successful connection to %s \\n \" , SERIAL_PORT ); // Display ASCII characters (from 32 to 128) for ( int c = 32 ; c < 128 ; c ++ ) { serial . writeChar ( c ); usleep ( 10000 ); } // Read lines and print them out char line [ 1024 ]; while ( 1 ) { int n = serial . readBytes ( line , sizeof ( line )); if ( n >= 0 ) { std :: cout << std :: string ( line , n ) << std :: endl ; } } // Close the serial device serial . closeDevice (); return 0 ; } Compile and run: g++ example.cpp -lserial -o example","title":"Serial driver"},{"location":"projects/lidar-mapping-poc/rover/#nrf24l01p-driver","text":"Download source code from GitHub and build: git clone https://github.com/vuquangtrong/RF24 && \\ cd RF24 && \\ ./configure --driver = SPIDEV && \\ make && \\ sudo make install Work with the original source code GitHub source code is at https://github.com/nRF24/RF24 . The guide to install in Linux at https://nrf24.github.io/RF24/md_docs_linux_install.html . Download the install.sh file: wget http://tmrh20.github.io/RF24Installer/RPi/install.sh Make it executable: chmod +x install.sh Run it and choose the option: RF24 Core SPIDEV driver ./install.sh Do you want to install GIT using APT (Used to download source code) [y/N]? n Do you want to install the RF24 core library, [y/N]? y Do you want to install the RF24Network library [y/N]? n Do you want to install the RF24Mesh library [y/N]? n Do you want to install the RF24Gateway library [y/N]? n Cloning into './rf24libs/RF24'... __* Install RF24 core using? *__ 1.BCM2835 Driver(Performance) 2.SPIDEV(Compatibility, Default) 3.WiringPi(Its WiringPi!) 4.MRAA(Intel Devices) 5.LittleWire 2 ... [Installing Libs to /usr/local/lib] [Installing Headers to /usr/local/include/RF24] Fix CS pin Jetson Nano spi-tegra114 driver has an issue in driving the CSN pin, therefore, the SPI command must explicitly request to toggle CSN pin. Open the file ~/rf24libs/RF24/utility/SPIDEV/spi.cpp to find tr.cs_change = 0; and replace them by tr.cs_change = 1; . Go back to the `~/rf24libs/RF24 and rebuild the library: sudo make clean all install Fixed in a Seeed Studio\u2019s branch, but not in Nvidia\u2019s Refer: spi: tegra: handle cs_change in modes sw_based_cs & cs_gpios . Source to test data receiving. Check the transferring site in Base . rf24_rx.cpp #include <iostream> // cin, cout, endl #include <time.h> // CLOCK_MONOTONIC_RAW, timespec, clock_gettime() #include <RF24/RF24.h> // create RF24 instance RF24 radio ( 15 /* CE = sys_gpio_15 */ , 0 /* CSN = 0 means spidev0.0 */ /* default speed is 10 Mbps */ ); // max payload of RF24 is 32 bytes uint8_t payload [ 32 ]; uint32_t total_nrx = 0 ; // custom defined timer for evaluating transmission time in microseconds struct timespec startTimer , endTimer ; int main ( int argc , char ** argv ) { setbuf ( stdout , NULL ); // perform hardware check if ( ! radio . begin ()) { cout << \"radio hardware is not responding!!\" << endl ; return 0 ; // quit now } radio . setPayloadSize ( 32 ); radio . setChannel ( 100 ); // 2400 + 100 = 2500 MHz, out of WiFi band // address, defaut length is 5 uint8_t rx_address [ 6 ] = \"1Addr\" ; // read from radio . openReadingPipe ( 1 , rx_address ); // using pip 1 // (smaller) function that prints raw register values radio . printDetails (); // (larger) function that prints human readable data radio . printPrettyDetails (); // Start std :: cout << \"Start RX\" << std :: endl ; radio . startListening (); // put radio in RX mode uint8_t pipe ; uint8_t nrx ; clock_gettime ( CLOCK_MONOTONIC_RAW , & startTimer ); // start the timer cout << \"Begin: \" << startTimer . tv_sec << \".\" << startTimer . tv_nsec << endl ; while ( true ) { if ( radio . available ( & pipe )) { nrx = radio . getPayloadSize (); radio . read ( & payload , nrx ); total_nrx += nrx ; if ( total_nrx >= 1000000 ) { clock_gettime ( CLOCK_MONOTONIC_RAW , & endTimer ); // end the timer cout << \"End: \" << endTimer . tv_sec << \".\" << endTimer . tv_nsec << endl ; break ; } } } int32_t diff_sec = endTimer . tv_sec - startTimer . tv_sec ; int32_t diff_nsec = endTimer . tv_nsec - startTimer . tv_nsec ; if ( diff_nsec < 0 ) { diff_nsec = 1000000000 - diff_nsec ; diff_sec -= 1 ; } cout << \"Received 1000000 bytes in \" << diff_sec << \".\" << diff_nsec << \" seconds\" << endl ; } Compile the source code: g++ -Ofast -Wall -pthread rf24_rx.cpp -lrf24 -o rf24_rx Run it and see the log: ================ SPI Configuration ================ CSN Pin = /dev/spidev0.0 CE Pin = Custom GPIO15 SPI Speedz = 10 Mhz ================ NRF Configuration ================ STATUS = 0x0e RX_DR = 0 TX_DS = 0 MAX_RT = 0 RX_P_NO = 7 TX_FULL = 0 RX_ADDR_P0-1 = 0x65646f4e31 0x7264644131 RX_ADDR_P2-5 = 0xc3 0xc4 0xc5 0xc6 TX_ADDR = 0x65646f4e31 RX_PW_P0-6 = 0x20 0x20 0x20 0x20 0x20 0x20 EN_AA = 0x3f EN_RXADDR = 0x03 RF_CH = 0x64 RF_SETUP = 0x03 CONFIG = 0x0e DYNPD/FEATURE = 0x00 0x00 Data Rate = 1 MBPS Model = nRF24L01+ CRC Length = 16 bits PA Power = PA_LOW ARC = 0 ================ SPI Configuration ================ CSN Pin = /dev/spidev0.0 CE Pin = Custom GPIO15 SPI Frequency = 10 Mhz ================ NRF Configuration ================ Channel = 100 ( ~ 2500 MHz ) RF Data Rate = 1 MBPS RF Power Amplifier = PA_LOW RF Low Noise Amplifier = Enabled CRC Length = 16 bits Address Length = 5 bytes Static Payload Length = 32 bytes Auto Retry Delay = 1500 microseconds Auto Retry Attempts = 15 maximum Packets lost on current channel = 0 Retry attempts made for last transmission = 0 Multicast = Disabled Custom ACK Payload = Disabled Dynamic Payloads = Disabled Auto Acknowledgment = Enabled Primary Mode = TX TX address = 0x65646f4e31 pipe 0 ( open ) bound = 0x65646f4e31 pipe 1 ( open ) bound = 0x7264644131 pipe 2 ( closed ) bound = 0xc3 pipe 3 ( closed ) bound = 0xc4 pipe 4 ( closed ) bound = 0xc5 pipe 5 ( closed ) bound = 0xc6 Start RX Begin: 793 .156527770 End: 821 .645141301 Received 1000000 bytes in 28 .488613531 seconds The example receives 1 MB in 28.5 seconds, which means 35 KBps. While the transfer rate set on the channel is 1Mbps (equals 125 KBps), the example only achieve 28% of bandwidth.","title":"nRF24L01p driver"},{"location":"projects/lidar-mapping-poc/rover/#oled-driver","text":"Download source code and build: git clone https://github.com/vuquangtrong/OLED_SSD1306_I2C_Linux.git && \\ cd OLED_SSD1306_I2C_Linux && \\ make && \\ sudo make install Write a simple app to a progress bar with label and numeric value: progress_bar.c #include <string.h> #include <unistd.h> #include <SSD1306/ssd1306.h> int main () { char counter = 0 ; char buffer [ 3 ]; SSD1306_Init ( \"/dev/i2c-1\" ); while ( 1 ) { sprintf ( buffer , \"%d\" , counter ++ ); SSD1306_Clear (); SSD1306_WriteString ( 0 , 0 , \"counter:\" , & Font_7x10 , SSD1306_WHITE , SSD1306_OVERRIDE ); SSD1306_WriteString ( 0 , 10 , buffer , & Font_11x18 , SSD1306_WHITE , SSD1306_OVERRIDE ); SSD1306_DrawRectangle ( 0 , 28 , 128 , 4 , SSD1306_WHITE ); SSD1306_DrawFilledRectangle ( 0 , 28 , counter * 128 / 256 , 4 , SSD1306_WHITE ); SSD1306_Screen_Update (); sleep ( 0.2 ); } return 0 ; } Compile and run: gcc progress_bar.c -lssd1306 -o progress_bar && \\ ./progress_bar","title":"OLED driver"},{"location":"projects/lidar-mapping-poc/rover/#ros-melodic","text":"Adding repository and source list sudo apt-add-repository universe sudo apt-add-repository multiverse sudo apt-add-repository restricted sudo apt update Setup source list to get ROS packages: sudo sh -c 'echo \"deb http://packages.ros.org/ros/ubuntu $(lsb_release -sc) main\" > /etc/apt/sources.list.d/ros-latest.list' Add keys: sudo apt install -y curl && \\ curl -s https://raw.githubusercontent.com/ros/rosdistro/master/ros.asc | sudo apt-key add - Pull the package list: sudo apt update Install ROS Melodic desktop: sudo apt install -y ros-melodic-desktop It\u2019s convenient if the ROS environment variables are automatically added to a bash session every time a new shell is launched: echo \"source /opt/ros/melodic/setup.bash\" >> ~/.bashrc && \\ source ~/.bashrc A good way to check the installation is to ensure that environment variables like ROS_ROOT and ROS_PACKAGE_PATH are set: printenv | grep ROS ROS_ETC_DIR = /opt/ros/melodic/etc/ros ROS_ROOT = /opt/ros/melodic/share/ros ROS_MASTER_URI = http://localhost:11311 ROS_VERSION = 1 ROS_PYTHON_VERSION = 2 ROS_PACKAGE_PATH = /opt/ros/melodic/share ROSLISP_PACKAGE_DIRECTORIES = ROS_DISTRO = melodic Initialize the package rosdep to track package dependency: sudo apt install -y python-rosdep && \\ sudo rosdep init && \\ rosdep update Build packages are needed for code compilation. sudo apt install -y python-rosinstall python-rosinstall-generator python-wstool build-essential Create a catkin workspace and try to build it: mkdir -p ~/catkin_ws/src && \\ cd ~/catkin_ws/src && \\ catkin_init_workspace && \\ cd .. && \\ catkin_make The workspace should be built successfully.","title":"ROS Melodic"},{"location":"projects/lidar-mapping-poc/rover/#livox-sdk","text":"","title":"Livox SDK"},{"location":"projects/lidar-mapping-poc/rover/#dependencies","text":"Livox SDK needs to be built in the host machine, therefore, some tool-chain and build tools have to be installed. sudo apt update && \\ sudo apt install -y build-essential && \\ sudo apt install -y curl && \\ sudo apt install -y git && \\ sudo apt install -y cmake The pointcloud Library (PCL) is a large scale, open project[1] for pointcloud processing. The PCL framework contains numerous state-of-the art algorithms including filtering, feature estimation, surface reconstruction, registration, model fitting and segmentation. sudo apt install -y libpcl-dev sudo apt install -y ros-melodic-pcl-ros Eigen is a C++ template library for linear algebra: matrices, vectors, numerical solvers, and related algorithms. sudo apt install -y libeigen3-dev OpenCV (Open Source Computer Vision Library) is an open-source computer vision library and has bindings for C++, Python, and Java. It is used for a very wide range of applications, including medical image analysis, stitching street view images, surveillance video, detecting and recognizing faces, tracking moving objects, extracting 3D models, and much more. OpenCV can take advantage of multi-core processing and features GPU acceleration for real-time operation. sudo apt install -y python-opencv python3-opencv Re-link libraries, on Jetson Nano: sudo ln -s /usr/bin/vtk6 /usr/bin/vtk && \\ sudo ln -s /usr/lib/python2.7/dist-packages/vtk/libvtkRenderingPythonTkWidgets.aarch64-linux-gnu.so /usr/lib/aarch64-linux-gnu/libvtkRenderingPythonTkWidgets.so","title":"Dependencies"},{"location":"projects/lidar-mapping-poc/rover/#livox-sdk_1","text":"The official guide is at https://github.com/Livox-SDK/Livox-SDK . Livox SDK is the software development kit designed for all Livox products. It is developed based on C/C++ following Livox SDK Communication Protocol, and provides easy-to-use C style API. With Livox SDK, users can quickly connect to Livox products and receive pointcloud data. Installation git clone https://github.com/Livox-SDK/Livox-SDK.git && \\ cd Livox-SDK && \\ cd build && \\ cmake .. && \\ make && \\ sudo make install The Livox SDK will be built and installed in /usr/local/lib : Install the project... -- Install configuration: \"\" -- Installing: /usr/local/lib/liblivox_sdk_static.a -- Installing: /usr/local/include/livox_def.h -- Installing: /usr/local/include/livox_sdk.h","title":"Livox SDK"},{"location":"projects/lidar-mapping-poc/rover/#livox-ros-driver","text":"Get livox_ros_driver from GitHub git clone https://github.com/Livox-SDK/livox_ros_driver.git ws_livox/src Then build it: cd ws_livox && \\ catkin_make If running catkin_make gives error of command not found, it\u2019s probably that the ROS setup.bash is not executed and included in ~/.bashrc . See above section to source it. This driver will create a new node named livox_lidar_publisher , which publishes 2 new types of messages: Livox pointcloud message # Livox publish pointcloud msg format. Header header # ROS standard message header uint64 timebase # The time of first point uint32 point_num # Total number of pointclouds uint8 lidar_id # Lidar device id number uint8[3] rsvd # Reserved use CustomPoint[] points # Pointcloud data Livox Point # Livox custom pointcloud format. uint32 offset_time # offset time relative to the base time float32 x # X axis, unit:m float32 y # Y axis, unit:m float32 z # Z axis, unit:m uint8 reflectivity # reflectivity, 0~255 uint8 tag # livox tag uint8 line # laser number in lidar","title":"Livox ROS driver"},{"location":"projects/lidar-mapping-poc/rover/#configurations","text":"The configuration file is in ws_livox/src/livox_ros_driver/config . LiDAR\u2019s configuration parameter Parameter Type Description Default broadcast_code String LiDAR broadcast code N/A enable_connect Boolean false return_mode Int Return mode: 0 \u2013 First single return mode 1 \u2013 The strongest single return mode 2 \u2013 Dual return mode 0 coordinate Int Coordinate: 0 \u2013 Cartesian 1 \u2013 Spherical 0 imu_rate Int Push frequency of IMU sensor data: 0 \u2013 stop push 1 \u2013 200 Hz Currently only Horizon supports this, MID serials do not support it 0 extrinsic_parameter_source Int Whether to enable extrinsic parameter automatic compensation of LiDAR external reference 0 \u2013 Disabled 1 \u2013 Enabled 0 Timestamp synchronization Parameter Type Description Default enable_timesync Boolean false device_name String Name of the serial device which outputs GPRMC/GNRMC messages every second /dev/ttyUSB0 comm_device_type Int Type of device sending timestamp information 0 \u2013 Serial port or USB virtual serial port device other \u2013 not support 0 baudrate_index Int Baud rate of serial device: 0 \u2013 2400 1 \u2013 4800 2 \u2013 9600 3 \u2013 19200 4 \u2013 38400 5 \u2013 57600 6 \u2013 115200 7 \u2013 230400 8 \u2013 460800 9 \u2013 500000 10 \u2013 576000 11 \u2013 921600 2 (9600) parity_index Int parity type 0 \u2013 8 bits data without parity 1 \u2013 7 bits data 1bit even parity 2 \u2013 7 bits data 1bit odd parity 3 \u2013 7 bits data 1bit 0, without parity 0 livox_lidar_config.json { \"lidar_config\" : [ { \"broadcast_code\" : \"1PQDH5B00100041\" , \"enable_connect\" : false , \"return_mode\" : 0 , \"coordinate\" : 0 , \"imu_rate\" : 0 , \"extrinsic_parameter_source\" : 0 , \"enable_high_sensitivity\" : false } ], \"timesync_config\" : { \"enable_timesync\" : false , \"device_name\" : \"/dev/ttyUSB0\" , \"comm_device_type\" : 0 , \"baudrate_index\" : 2 , \"parity_index\" : 0 } }","title":"Configurations"},{"location":"projects/lidar-mapping-poc/rover/#timestamp","text":"Prepare a GPS device to ensure that the GPS can output UTC time information in GPRMC/GNRMC format through the serial port or USB virtual serial port, and support PPS signal output. Connect the GPS serial port to the host running livox_ros_driver , set the corresponding device name in the config file Connect the GPS PPS signal line to LiDAR Be sure to set the output frequency of GPRMC/GNRMC time information of GPS to 1 Hz","title":"Timestamp"},{"location":"projects/lidar-mapping-poc/rover/#launches","text":"Different launch files have different configuration parameter values and are used in different scenarios: Launch file name Description livox_lidar.launch Connect to Livox LiDAR device Publish pointcloud2 format data livox_lidar_msg.launch Connect to Livox LiDAR device Publish livox customized pointcloud data livox_lidar_rviz.launch Connect to Livox LiDAR device Publish pointcloud2 format data Autoload rviz Launch parameters Parameter Description Default publish_freq Set the frequency of pointcloud publish 10.0 multi_topic 0 \u2013 All LiDAR devices use the same topic to publish pointcloud data 1 \u2013 Each LiDAR device has its own topic to publish pointcloud data 0 xfer_format 0 \u2013 Livox pointcloud2 ( PointXYZRTL ) pointcloud format 1 \u2013 Livox customized pointcloud format 2 \u2013 Standard pointcloud2 ( PointXYZI ) pointcloud format in the PCL library 0","title":"Launches"},{"location":"projects/lidar-mapping-poc/rover/#test-ros","text":"An easy method to connect Livox Lidar with Jetson board is through a LAN router. Below section shows another method to connect 2 modules directly. Set Livox\u2019s Static IP Use Livox Viewer to set a Static IP for the Lidar module. Livox only accepts IP in 192.168.1.0 network. Set Jetson\u2019s Static IP sudo nano /etc/network/interfaces /etc/network/interfaces auto lo iface lo inet loopback auto eth0 iface eth0 inet static address 192.168.1.12 netmask 255.255.255.0 Then run the livox_lidar_rviz example cd ws_livox source ./devel/setup.bash roslaunch livox_ros_driver livox_lidar_rviz.launch This will run Livox ROS and Rviz to visualize the received pointcloud.","title":"Test ROS"},{"location":"projects/lidar-mapping-poc/rover/#auto-mount-usb","text":"Check out and install: git clone https://github.com/vuquangtrong/USB_Automount.git && \\ cd USB_Automount && \\ ./install Plugged-in USB will be mounted into /media/<Label> or /media/<sdXy> . Automount scripts Here are scripts to auto-mount storage devices: sudo nano /usr/local/bin/usb-mount.sh #!/bin/bash # This script is called from our systemd unit file to mount or unmount # a USB drive. usage () { echo \"Usage: $0 {add|remove} device_name (e.g. sdb1)\" exit 1 } if [[ $# -ne 2 ]] ; then usage fi ACTION = $1 DEVBASE = $2 DEVICE = \"/dev/ ${ DEVBASE } \" # See if this drive is already mounted, and if so where MOUNT_POINT = $( /bin/mount | /bin/grep ${ DEVICE } | /usr/bin/awk '{ print $3 }' ) do_mount () { if [[ -n ${ MOUNT_POINT } ]] ; then echo \"Warning: ${ DEVICE } is already mounted at ${ MOUNT_POINT } \" exit 1 fi # Get info for this drive: $ID_FS_LABEL, $ID_FS_UUID, and $ID_FS_TYPE eval $( /sbin/blkid -o udev ${ DEVICE } ) # Figure out a mount point to use LABEL = ${ ID_FS_LABEL } if [[ -z \" ${ LABEL } \" ]] ; then LABEL = ${ DEVBASE } elif /bin/grep -q \" /media/ ${ LABEL } \" /etc/mtab ; then # Already in use, make a unique one LABEL += \"- ${ DEVBASE } \" fi MOUNT_POINT = \"/media/ ${ LABEL } \" echo \"Mount point: ${ MOUNT_POINT } \" /bin/mkdir -p ${ MOUNT_POINT } # Global mount options OPTS = \"rw,relatime\" # File system type specific mount options if [[ ${ ID_FS_TYPE } == \"vfat\" ]] ; then OPTS += \",users,gid=100,umask=000,shortname=mixed,utf8=1,flush\" fi if ! /bin/mount -o ${ OPTS } ${ DEVICE } ${ MOUNT_POINT } ; then echo \"Error mounting ${ DEVICE } (status = $? )\" /bin/rmdir ${ MOUNT_POINT } exit 1 fi echo \"__** Mounted ${ DEVICE } at ${ MOUNT_POINT } **__\" } do_unmount () { if [[ -z ${ MOUNT_POINT } ]] ; then echo \"Warning: ${ DEVICE } is not mounted\" else /bin/umount -l ${ DEVICE } echo \"____ Unmounted ${ DEVICE } \" fi # Delete all empty dirs in /media that aren't being used as mount # points. This is kind of overkill, but if the drive was unmounted # prior to removal we no longer know its mount point, and we don't # want to leave it orphaned... for f in /media/* ; do if [[ -n $( /usr/bin/find \" $f \" -maxdepth 0 -type d -empty ) ]] ; then if ! /bin/grep -q \" $f \" /etc/mtab ; then echo \"____ Removing mount point $f \" /bin/rmdir \" $f \" fi fi done } case \" ${ ACTION } \" in add ) do_mount ;; remove ) do_unmount ;; * ) usage ;; esac Change permission: sudo chmod 0755 /usr/local/bin/usb-mount.sh Add service: sudo nano /etc/systemd/system/usb-mount@.service usb-mount@.service [Unit] Description = Mount USB Drive on %i [Service] Type = oneshot RemainAfterExit = true ExecStart = /usr/local/bin/usb-mount.sh add %i ExecStop = /usr/local/bin/usb-mount.sh remove %i The file name uses @ to pass arguments. Add rules for udev when USB event is detected: sudo nano /etc/udev/rules.d/99-usb-mount.rules 99-usb-mount.rules KERNEL = =\"sd[a-z][0-9]\", SUBSYSTEMS==\"usb\", ACTION==\"add\", RUN+=\"/bin/systemctl start usb-mount@%k.service\" KERNEL = =\"sd[a-z][0-9]\", SUBSYSTEMS==\"usb\", ACTION==\"remove\", RUN+=\"/bin/systemctl stop usb-mount@%k.service\" Restart services and rules: sudo udevadm control --reload-rules && \\ sudo systemctl daemon-reload If a USB is not mount automatically, check the system log: cat /var/log/syslog","title":"Auto-mount USB"},{"location":"projects/lidar-mapping-poc/rover/#auto-start-application","text":"A simple app that shows IP Address on OLED screen. ipshow.cpp #include <iostream> #include <string> #include <cstring> #include <sys/socket.h> #include <netinet/in.h> #include <arpa/inet.h> #include <unistd.h> #include <sys/types.h> #include <ifaddrs.h> #include <SSD1306/ssd1306.h> using namespace std ; char i2c_dev [] = \"/dev/i2c-1\" ; char noIP [] = \"No IP\" ; void showIP ( int line , char type , char * ip ) { char buffer [ 32 ] = { 0 }; sprintf ( buffer , \"%c:%s\" , type , ip ); SSD1306_WriteString ( 0 , line * 10 , buffer , & Font_7x10 , SSD1306_WHITE , SSD1306_OVERRIDE ); } void getIPAddresses () { struct ifaddrs * interfaces = NULL ; struct ifaddrs * temp_addr = NULL ; int success = 0 ; bool found = false ; // retrieve the current interfaces - returns 0 on success success = getifaddrs ( & interfaces ); if ( success == 0 ) { // Loop through linked list of interfaces temp_addr = interfaces ; while ( temp_addr != NULL ) { if ( temp_addr -> ifa_addr -> sa_family == AF_INET ) { // Check if interface is en0 which is the wifi connection on the iPhone if ( strcmp ( temp_addr -> ifa_name , \"wlan0\" ) == 0 ){ showIP ( 0 , 'W' , inet_ntoa ((( struct sockaddr_in * ) temp_addr -> ifa_addr ) -> sin_addr ) ); found = true ; } if ( strcmp ( temp_addr -> ifa_name , \"eth0\" ) == 0 ){ showIP ( 1 , 'E' , inet_ntoa ((( struct sockaddr_in * ) temp_addr -> ifa_addr ) -> sin_addr ) ); found = true ; } } temp_addr = temp_addr -> ifa_next ; } } // Free memory freeifaddrs ( interfaces ); if ( ! found ) { showIP ( 3 , '?' , noIP ); } } int main ( int argc , char ** argv ) { SSD1306_Init ( i2c_dev ); while ( 1 ) { SSD1306_Clear (); getIPAddresses (); SSD1306_Screen_Update (); sleep ( 10 ); } } Create a service: ipshow.service [Unit] Description = IP Show After = multi-user.target [Service] Type = simple ExecStart = /usr/bin/ipshow [Install] WantedBy = multi-user.target Enable the service: sudo systemctl enable ipshow.service","title":"Auto-start application"},{"location":"projects/lidar-mapping-poc/tasks/","text":"Overall progress Study reference project Analyze hardware components Analyze software source code Design system architecture Hardware block diagram Pinout and wiring Software architecture Get hardware components Rover\u2019s parts Base\u2019s parts Other stuffs for development Gather documents GNSS - Reference commands and output IMU - Development board user guide Jetson Nano - Development board user guide GNSS Module Output PPS Output GPRMC Output GNGGA Output OBSVMA Output both GNGGA and OBSVMA at 20 Hz IMU Module Configure DK-20789 project and build Remove redundant components, e.g. Dynamic protocol, Scheduler, Pressure sensor Modify data flow to output sensor\u2019s data in byte stream Fuse Accelerator and Gyroscope data before sending to synchronize timestamp Develop Base Station Hardware work Power supply Component wiring Implement Base application on Raspberry Pi 3 B+ Install Raspbian OS Read GNSS correction input Configure UART port Read RTCM3 messages Output GNSS correction Configure SPI port Add nRF24 driver Output RTCM3 messages to nRF24 Enable Auto-mount USB Output systems status Configure I2C port Add OLED driver Output system status to OLED Save GNSS correction to USB Develop Rover Hardware work Power supply Component wiring Implement Lidar Mapping ROS application on Jetson Nano Dev Kit Install L4T OS Install ROS platform Install Livox SDK Install Livox ROS driver Setup Ethernet connection with Livox Read GNSS input Configure UART ports Enable Time Sync in Livox ROS driver Read GNGGA messages and publish to the Mapping module Read GNSS correction from Base Configure SPI port Add nRF24 driver Read GNSS correction from nRF24 Forward GNSS correction to GNSS module Read IMU input Read IMU and publish to the Mapping module Implement Mapping module Read Lidar point-cloud and extract timestamp Read GNSS position and extract timestamp Issue: Handle high speed data for GNGGA and OBSVMA at 20 Hz Read IMU pose and extract timestamp Issue: IMU Timestamp is wrong Issue: IMU data for Accelerator and Gyroscope does not have same timestamp Align data using timestamp Issue: Mapping timestamp is hard to match Apply position on point-cloud Apply pose on points Publish mapped point-cloud Output systems status Configure I2C port Add OLED driver Output system status to OLED Enable Auto-mount USB Configure Rover to log Observation Save Lidar point-cloud to USB Save GNSS observation to USB Save IMU pose to USB Migrate rover system to Jetson TX2 NX module Rebuild OS image Re-configure system on Jetson TX2 hardware Develop Post-Processing method Convert GNSS Observation data to RINEX format Request Unicorecomm Converter Integrate Unicorecomm Converter Build RTKLib module to process data Re-apply Mapping on processed Positions","title":"Task List"},{"location":"tags/","text":"","title":"Tags"}]}